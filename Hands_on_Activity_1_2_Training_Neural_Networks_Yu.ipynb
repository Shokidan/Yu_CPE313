{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "union-alcohol",
      "metadata": {
        "id": "union-alcohol"
      },
      "source": [
        "# Activity 1.2 : Training Neural Networks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "floppy-teens",
      "metadata": {
        "id": "floppy-teens"
      },
      "source": [
        "#### Objective(s):\n",
        "\n",
        "This activity aims to demonstrate how to train neural networks using keras"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "engaged-modem",
      "metadata": {
        "id": "engaged-modem"
      },
      "source": [
        "#### Intended Learning Outcomes (ILOs):\n",
        "* Demonstrate how to build and train neural networks\n",
        "* Demonstrate how to evaluate and plot the model using training and validation loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "structured-april",
      "metadata": {
        "id": "structured-april"
      },
      "source": [
        "#### Resources:\n",
        "* Jupyter Notebook\n",
        "\n",
        "CI Pima Diabetes Dataset\n",
        "\n",
        "* pima-indians-diabetes.csv\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cutting-fountain",
      "metadata": {
        "id": "cutting-fountain"
      },
      "source": [
        "#### Procedures"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "entertaining-therapist",
      "metadata": {
        "id": "entertaining-therapist"
      },
      "source": [
        "Load the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "RXUyrOQY3u_v",
        "outputId": "ee8737a5-1683-4712-aae6-3f45d0ff2eb4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "RXUyrOQY3u_v",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "differential-native",
      "metadata": {
        "id": "differential-native"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "other-married",
      "metadata": {
        "id": "other-married"
      },
      "outputs": [],
      "source": [
        "## Import Keras objects for Deep Learning\n",
        "\n",
        "from keras.models  import Sequential\n",
        "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
        "from keras.optimizers import Adam, SGD, RMSprop"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mexican-newsletter",
      "metadata": {
        "id": "mexican-newsletter"
      },
      "source": [
        "Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "studied-twelve",
      "metadata": {
        "id": "studied-twelve"
      },
      "outputs": [],
      "source": [
        "filepath = \"/content/drive/MyDrive/Data Science 3 Datasets/pima-indians-diabetes.csv\"\n",
        "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\",\n",
        "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
        "diabetes_df = pd.read_csv(filepath, names=names)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "photographic-carnival",
      "metadata": {
        "id": "photographic-carnival"
      },
      "source": [
        "Check the top 5 samples of the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "undefined-inventory",
      "metadata": {
        "id": "undefined-inventory",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "a70533fe-15a0-406b-beac-1cd764747d48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(768, 9)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     times_pregnant  glucose_tolerance_test  blood_pressure  skin_thickness  \\\n",
              "638               7                      97              76              32   \n",
              "67                2                     109              92               0   \n",
              "550               1                     116              70              28   \n",
              "164               0                     131              88               0   \n",
              "191               9                     123              70              44   \n",
              "\n",
              "     insulin   bmi  pedigree_function  age  has_diabetes  \n",
              "638       91  40.9              0.871   32             1  \n",
              "67         0  42.7              0.845   54             0  \n",
              "550        0  27.4              0.204   21             0  \n",
              "164        0  31.6              0.743   32             1  \n",
              "191       94  33.1              0.374   40             0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aff73f28-1209-4c8f-abe8-33773e69cd2a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>times_pregnant</th>\n",
              "      <th>glucose_tolerance_test</th>\n",
              "      <th>blood_pressure</th>\n",
              "      <th>skin_thickness</th>\n",
              "      <th>insulin</th>\n",
              "      <th>bmi</th>\n",
              "      <th>pedigree_function</th>\n",
              "      <th>age</th>\n",
              "      <th>has_diabetes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>638</th>\n",
              "      <td>7</td>\n",
              "      <td>97</td>\n",
              "      <td>76</td>\n",
              "      <td>32</td>\n",
              "      <td>91</td>\n",
              "      <td>40.9</td>\n",
              "      <td>0.871</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>2</td>\n",
              "      <td>109</td>\n",
              "      <td>92</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>42.7</td>\n",
              "      <td>0.845</td>\n",
              "      <td>54</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>550</th>\n",
              "      <td>1</td>\n",
              "      <td>116</td>\n",
              "      <td>70</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>27.4</td>\n",
              "      <td>0.204</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>164</th>\n",
              "      <td>0</td>\n",
              "      <td>131</td>\n",
              "      <td>88</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>31.6</td>\n",
              "      <td>0.743</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>191</th>\n",
              "      <td>9</td>\n",
              "      <td>123</td>\n",
              "      <td>70</td>\n",
              "      <td>44</td>\n",
              "      <td>94</td>\n",
              "      <td>33.1</td>\n",
              "      <td>0.374</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aff73f28-1209-4c8f-abe8-33773e69cd2a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-aff73f28-1209-4c8f-abe8-33773e69cd2a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-aff73f28-1209-4c8f-abe8-33773e69cd2a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-eac4ecff-7c46-4bb6-a575-7d78ea9d01a9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-eac4ecff-7c46-4bb6-a575-7d78ea9d01a9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-eac4ecff-7c46-4bb6-a575-7d78ea9d01a9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "print(diabetes_df.shape)\n",
        "diabetes_df.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "systematic-motorcycle",
      "metadata": {
        "id": "systematic-motorcycle",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "007ecb60-0424-423e-c7bc-7a63661c5d30"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "times_pregnant              int64\n",
              "glucose_tolerance_test      int64\n",
              "blood_pressure              int64\n",
              "skin_thickness              int64\n",
              "insulin                     int64\n",
              "bmi                       float64\n",
              "pedigree_function         float64\n",
              "age                         int64\n",
              "has_diabetes                int64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "diabetes_df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "collected-lafayette",
      "metadata": {
        "id": "collected-lafayette"
      },
      "outputs": [],
      "source": [
        "X = diabetes_df.iloc[:, :-1].values\n",
        "y = diabetes_df[\"has_diabetes\"].values"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "acquired-parallel",
      "metadata": {
        "id": "acquired-parallel"
      },
      "source": [
        "Split the data to Train, and Test (75%, 25%)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rational-hollow",
      "metadata": {
        "id": "rational-hollow"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11111)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acceptable-equity",
      "metadata": {
        "id": "acceptable-equity",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3340abe3-d2ba-4f42-ac94-0d27c808be71"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.3489583333333333, 0.6510416666666666)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "np.mean(y), np.mean(1-y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "thick-reconstruction",
      "metadata": {
        "id": "thick-reconstruction"
      },
      "source": [
        "Build a single hidden layer neural network using 12 nodes.\n",
        "Use the sequential model with single layer network and input shape to 8.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dramatic-zealand",
      "metadata": {
        "id": "dramatic-zealand"
      },
      "source": [
        "Normalize the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "painted-mathematics",
      "metadata": {
        "id": "painted-mathematics"
      },
      "outputs": [],
      "source": [
        "normalizer = StandardScaler()\n",
        "X_train_norm = normalizer.fit_transform(X_train)\n",
        "X_test_norm = normalizer.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "previous-electricity",
      "metadata": {
        "id": "previous-electricity"
      },
      "source": [
        "Define the model:\n",
        "* Input size is 8-dimensional\n",
        "* 1 hidden layer, 12 hidden nodes, sigmoid activation\n",
        "* Final layer with one node and sigmoid activation (standard for binary classification)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "found-bowling",
      "metadata": {
        "id": "found-bowling"
      },
      "outputs": [],
      "source": [
        "model  = Sequential([\n",
        "    Dense(12, input_shape=(8,), activation=\"relu\"),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "level-terminal",
      "metadata": {
        "id": "level-terminal"
      },
      "source": [
        "View the model summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "correct-kingdom",
      "metadata": {
        "id": "correct-kingdom",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed9a72de-d27e-425b-83ba-95df13085b0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 12)                108       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 13        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 121 (484.00 Byte)\n",
            "Trainable params: 121 (484.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "herbal-anderson",
      "metadata": {
        "id": "herbal-anderson"
      },
      "source": [
        "Train the model\n",
        "* Compile the model with optimizer, loss function and metrics\n",
        "* Use the fit function to return the run history.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "happy-prompt",
      "metadata": {
        "id": "happy-prompt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29c1d7c6-38a2-4941-ffda-471a0a4af470"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "18/18 [==============================] - 1s 17ms/step - loss: 0.7235 - accuracy: 0.5642 - val_loss: 0.6955 - val_accuracy: 0.5208\n",
            "Epoch 2/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6869 - accuracy: 0.5833 - val_loss: 0.6661 - val_accuracy: 0.6042\n",
            "Epoch 3/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6576 - accuracy: 0.6302 - val_loss: 0.6429 - val_accuracy: 0.6406\n",
            "Epoch 4/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6339 - accuracy: 0.6632 - val_loss: 0.6245 - val_accuracy: 0.6823\n",
            "Epoch 5/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6146 - accuracy: 0.6736 - val_loss: 0.6097 - val_accuracy: 0.6875\n",
            "Epoch 6/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5987 - accuracy: 0.6806 - val_loss: 0.5975 - val_accuracy: 0.6979\n",
            "Epoch 7/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5855 - accuracy: 0.7066 - val_loss: 0.5874 - val_accuracy: 0.7240\n",
            "Epoch 8/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5741 - accuracy: 0.7101 - val_loss: 0.5788 - val_accuracy: 0.7396\n",
            "Epoch 9/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5646 - accuracy: 0.7205 - val_loss: 0.5715 - val_accuracy: 0.7344\n",
            "Epoch 10/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5563 - accuracy: 0.7361 - val_loss: 0.5652 - val_accuracy: 0.7552\n",
            "Epoch 11/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5490 - accuracy: 0.7396 - val_loss: 0.5597 - val_accuracy: 0.7552\n",
            "Epoch 12/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5426 - accuracy: 0.7448 - val_loss: 0.5548 - val_accuracy: 0.7500\n",
            "Epoch 13/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5371 - accuracy: 0.7500 - val_loss: 0.5504 - val_accuracy: 0.7500\n",
            "Epoch 14/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5319 - accuracy: 0.7500 - val_loss: 0.5465 - val_accuracy: 0.7552\n",
            "Epoch 15/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5273 - accuracy: 0.7535 - val_loss: 0.5429 - val_accuracy: 0.7552\n",
            "Epoch 16/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5232 - accuracy: 0.7500 - val_loss: 0.5396 - val_accuracy: 0.7552\n",
            "Epoch 17/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5193 - accuracy: 0.7535 - val_loss: 0.5367 - val_accuracy: 0.7604\n",
            "Epoch 18/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5158 - accuracy: 0.7517 - val_loss: 0.5339 - val_accuracy: 0.7656\n",
            "Epoch 19/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5125 - accuracy: 0.7552 - val_loss: 0.5314 - val_accuracy: 0.7656\n",
            "Epoch 20/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5094 - accuracy: 0.7552 - val_loss: 0.5291 - val_accuracy: 0.7656\n",
            "Epoch 21/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5067 - accuracy: 0.7535 - val_loss: 0.5269 - val_accuracy: 0.7604\n",
            "Epoch 22/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5040 - accuracy: 0.7517 - val_loss: 0.5249 - val_accuracy: 0.7656\n",
            "Epoch 23/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5015 - accuracy: 0.7517 - val_loss: 0.5230 - val_accuracy: 0.7656\n",
            "Epoch 24/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4992 - accuracy: 0.7517 - val_loss: 0.5212 - val_accuracy: 0.7656\n",
            "Epoch 25/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4970 - accuracy: 0.7517 - val_loss: 0.5196 - val_accuracy: 0.7604\n",
            "Epoch 26/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4949 - accuracy: 0.7535 - val_loss: 0.5181 - val_accuracy: 0.7604\n",
            "Epoch 27/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4929 - accuracy: 0.7517 - val_loss: 0.5168 - val_accuracy: 0.7604\n",
            "Epoch 28/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4910 - accuracy: 0.7535 - val_loss: 0.5155 - val_accuracy: 0.7604\n",
            "Epoch 29/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4892 - accuracy: 0.7569 - val_loss: 0.5142 - val_accuracy: 0.7604\n",
            "Epoch 30/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4876 - accuracy: 0.7552 - val_loss: 0.5130 - val_accuracy: 0.7604\n",
            "Epoch 31/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4860 - accuracy: 0.7569 - val_loss: 0.5119 - val_accuracy: 0.7604\n",
            "Epoch 32/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4845 - accuracy: 0.7587 - val_loss: 0.5109 - val_accuracy: 0.7604\n",
            "Epoch 33/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4830 - accuracy: 0.7587 - val_loss: 0.5099 - val_accuracy: 0.7656\n",
            "Epoch 34/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4816 - accuracy: 0.7552 - val_loss: 0.5089 - val_accuracy: 0.7656\n",
            "Epoch 35/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4802 - accuracy: 0.7587 - val_loss: 0.5080 - val_accuracy: 0.7656\n",
            "Epoch 36/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4788 - accuracy: 0.7604 - val_loss: 0.5071 - val_accuracy: 0.7656\n",
            "Epoch 37/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4776 - accuracy: 0.7604 - val_loss: 0.5063 - val_accuracy: 0.7656\n",
            "Epoch 38/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4764 - accuracy: 0.7639 - val_loss: 0.5055 - val_accuracy: 0.7656\n",
            "Epoch 39/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4752 - accuracy: 0.7639 - val_loss: 0.5047 - val_accuracy: 0.7604\n",
            "Epoch 40/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4741 - accuracy: 0.7656 - val_loss: 0.5040 - val_accuracy: 0.7604\n",
            "Epoch 41/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4730 - accuracy: 0.7622 - val_loss: 0.5033 - val_accuracy: 0.7604\n",
            "Epoch 42/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4720 - accuracy: 0.7639 - val_loss: 0.5026 - val_accuracy: 0.7604\n",
            "Epoch 43/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4710 - accuracy: 0.7691 - val_loss: 0.5020 - val_accuracy: 0.7604\n",
            "Epoch 44/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4700 - accuracy: 0.7691 - val_loss: 0.5013 - val_accuracy: 0.7604\n",
            "Epoch 45/200\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4691 - accuracy: 0.7708 - val_loss: 0.5008 - val_accuracy: 0.7604\n",
            "Epoch 46/200\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4682 - accuracy: 0.7674 - val_loss: 0.5002 - val_accuracy: 0.7604\n",
            "Epoch 47/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4674 - accuracy: 0.7726 - val_loss: 0.4997 - val_accuracy: 0.7604\n",
            "Epoch 48/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4665 - accuracy: 0.7708 - val_loss: 0.4992 - val_accuracy: 0.7604\n",
            "Epoch 49/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4657 - accuracy: 0.7708 - val_loss: 0.4987 - val_accuracy: 0.7604\n",
            "Epoch 50/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4650 - accuracy: 0.7726 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
            "Epoch 51/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4642 - accuracy: 0.7760 - val_loss: 0.4978 - val_accuracy: 0.7552\n",
            "Epoch 52/200\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4635 - accuracy: 0.7743 - val_loss: 0.4974 - val_accuracy: 0.7552\n",
            "Epoch 53/200\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4627 - accuracy: 0.7778 - val_loss: 0.4970 - val_accuracy: 0.7552\n",
            "Epoch 54/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4621 - accuracy: 0.7743 - val_loss: 0.4967 - val_accuracy: 0.7552\n",
            "Epoch 55/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4615 - accuracy: 0.7760 - val_loss: 0.4963 - val_accuracy: 0.7552\n",
            "Epoch 56/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4609 - accuracy: 0.7760 - val_loss: 0.4960 - val_accuracy: 0.7552\n",
            "Epoch 57/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4602 - accuracy: 0.7760 - val_loss: 0.4957 - val_accuracy: 0.7552\n",
            "Epoch 58/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4596 - accuracy: 0.7778 - val_loss: 0.4954 - val_accuracy: 0.7552\n",
            "Epoch 59/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4591 - accuracy: 0.7778 - val_loss: 0.4951 - val_accuracy: 0.7552\n",
            "Epoch 60/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4587 - accuracy: 0.7743 - val_loss: 0.4949 - val_accuracy: 0.7552\n",
            "Epoch 61/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4581 - accuracy: 0.7743 - val_loss: 0.4947 - val_accuracy: 0.7552\n",
            "Epoch 62/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4576 - accuracy: 0.7743 - val_loss: 0.4944 - val_accuracy: 0.7552\n",
            "Epoch 63/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4571 - accuracy: 0.7708 - val_loss: 0.4942 - val_accuracy: 0.7552\n",
            "Epoch 64/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4566 - accuracy: 0.7743 - val_loss: 0.4940 - val_accuracy: 0.7604\n",
            "Epoch 65/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4562 - accuracy: 0.7691 - val_loss: 0.4938 - val_accuracy: 0.7604\n",
            "Epoch 66/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4556 - accuracy: 0.7691 - val_loss: 0.4936 - val_accuracy: 0.7604\n",
            "Epoch 67/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4552 - accuracy: 0.7726 - val_loss: 0.4934 - val_accuracy: 0.7604\n",
            "Epoch 68/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4548 - accuracy: 0.7726 - val_loss: 0.4932 - val_accuracy: 0.7552\n",
            "Epoch 69/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4543 - accuracy: 0.7726 - val_loss: 0.4931 - val_accuracy: 0.7552\n",
            "Epoch 70/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4538 - accuracy: 0.7708 - val_loss: 0.4929 - val_accuracy: 0.7552\n",
            "Epoch 71/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4535 - accuracy: 0.7708 - val_loss: 0.4928 - val_accuracy: 0.7552\n",
            "Epoch 72/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4532 - accuracy: 0.7760 - val_loss: 0.4926 - val_accuracy: 0.7552\n",
            "Epoch 73/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4528 - accuracy: 0.7743 - val_loss: 0.4925 - val_accuracy: 0.7552\n",
            "Epoch 74/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4524 - accuracy: 0.7743 - val_loss: 0.4924 - val_accuracy: 0.7552\n",
            "Epoch 75/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4521 - accuracy: 0.7743 - val_loss: 0.4923 - val_accuracy: 0.7552\n",
            "Epoch 76/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4517 - accuracy: 0.7726 - val_loss: 0.4922 - val_accuracy: 0.7552\n",
            "Epoch 77/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4513 - accuracy: 0.7726 - val_loss: 0.4921 - val_accuracy: 0.7552\n",
            "Epoch 78/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4512 - accuracy: 0.7743 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
            "Epoch 79/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4507 - accuracy: 0.7726 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
            "Epoch 80/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4503 - accuracy: 0.7743 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
            "Epoch 81/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4501 - accuracy: 0.7743 - val_loss: 0.4918 - val_accuracy: 0.7500\n",
            "Epoch 82/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4498 - accuracy: 0.7708 - val_loss: 0.4918 - val_accuracy: 0.7500\n",
            "Epoch 83/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4494 - accuracy: 0.7691 - val_loss: 0.4917 - val_accuracy: 0.7552\n",
            "Epoch 84/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4492 - accuracy: 0.7708 - val_loss: 0.4917 - val_accuracy: 0.7552\n",
            "Epoch 85/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4488 - accuracy: 0.7708 - val_loss: 0.4917 - val_accuracy: 0.7552\n",
            "Epoch 86/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4485 - accuracy: 0.7708 - val_loss: 0.4917 - val_accuracy: 0.7552\n",
            "Epoch 87/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4482 - accuracy: 0.7691 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
            "Epoch 88/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4480 - accuracy: 0.7708 - val_loss: 0.4915 - val_accuracy: 0.7552\n",
            "Epoch 89/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4477 - accuracy: 0.7691 - val_loss: 0.4915 - val_accuracy: 0.7552\n",
            "Epoch 90/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4475 - accuracy: 0.7726 - val_loss: 0.4914 - val_accuracy: 0.7552\n",
            "Epoch 91/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4472 - accuracy: 0.7708 - val_loss: 0.4914 - val_accuracy: 0.7552\n",
            "Epoch 92/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4469 - accuracy: 0.7691 - val_loss: 0.4914 - val_accuracy: 0.7552\n",
            "Epoch 93/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4467 - accuracy: 0.7726 - val_loss: 0.4913 - val_accuracy: 0.7552\n",
            "Epoch 94/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4465 - accuracy: 0.7726 - val_loss: 0.4913 - val_accuracy: 0.7552\n",
            "Epoch 95/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4463 - accuracy: 0.7760 - val_loss: 0.4912 - val_accuracy: 0.7552\n",
            "Epoch 96/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4460 - accuracy: 0.7743 - val_loss: 0.4911 - val_accuracy: 0.7552\n",
            "Epoch 97/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.7743 - val_loss: 0.4911 - val_accuracy: 0.7552\n",
            "Epoch 98/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4456 - accuracy: 0.7726 - val_loss: 0.4911 - val_accuracy: 0.7552\n",
            "Epoch 99/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4454 - accuracy: 0.7743 - val_loss: 0.4910 - val_accuracy: 0.7552\n",
            "Epoch 100/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4451 - accuracy: 0.7760 - val_loss: 0.4910 - val_accuracy: 0.7552\n",
            "Epoch 101/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4450 - accuracy: 0.7743 - val_loss: 0.4910 - val_accuracy: 0.7552\n",
            "Epoch 102/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4447 - accuracy: 0.7778 - val_loss: 0.4910 - val_accuracy: 0.7552\n",
            "Epoch 103/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4447 - accuracy: 0.7778 - val_loss: 0.4909 - val_accuracy: 0.7552\n",
            "Epoch 104/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4444 - accuracy: 0.7760 - val_loss: 0.4909 - val_accuracy: 0.7552\n",
            "Epoch 105/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4442 - accuracy: 0.7760 - val_loss: 0.4909 - val_accuracy: 0.7552\n",
            "Epoch 106/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4440 - accuracy: 0.7778 - val_loss: 0.4909 - val_accuracy: 0.7552\n",
            "Epoch 107/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4438 - accuracy: 0.7795 - val_loss: 0.4909 - val_accuracy: 0.7552\n",
            "Epoch 108/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4436 - accuracy: 0.7795 - val_loss: 0.4909 - val_accuracy: 0.7552\n",
            "Epoch 109/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4434 - accuracy: 0.7795 - val_loss: 0.4909 - val_accuracy: 0.7604\n",
            "Epoch 110/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4433 - accuracy: 0.7795 - val_loss: 0.4909 - val_accuracy: 0.7604\n",
            "Epoch 111/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4432 - accuracy: 0.7795 - val_loss: 0.4909 - val_accuracy: 0.7604\n",
            "Epoch 112/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4428 - accuracy: 0.7812 - val_loss: 0.4909 - val_accuracy: 0.7604\n",
            "Epoch 113/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4426 - accuracy: 0.7812 - val_loss: 0.4909 - val_accuracy: 0.7604\n",
            "Epoch 114/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4426 - accuracy: 0.7812 - val_loss: 0.4909 - val_accuracy: 0.7656\n",
            "Epoch 115/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4423 - accuracy: 0.7812 - val_loss: 0.4909 - val_accuracy: 0.7656\n",
            "Epoch 116/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4422 - accuracy: 0.7812 - val_loss: 0.4909 - val_accuracy: 0.7656\n",
            "Epoch 117/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4420 - accuracy: 0.7812 - val_loss: 0.4910 - val_accuracy: 0.7656\n",
            "Epoch 118/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4419 - accuracy: 0.7778 - val_loss: 0.4910 - val_accuracy: 0.7656\n",
            "Epoch 119/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4417 - accuracy: 0.7795 - val_loss: 0.4910 - val_accuracy: 0.7656\n",
            "Epoch 120/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4416 - accuracy: 0.7795 - val_loss: 0.4910 - val_accuracy: 0.7656\n",
            "Epoch 121/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4414 - accuracy: 0.7812 - val_loss: 0.4910 - val_accuracy: 0.7656\n",
            "Epoch 122/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4412 - accuracy: 0.7812 - val_loss: 0.4911 - val_accuracy: 0.7656\n",
            "Epoch 123/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4412 - accuracy: 0.7795 - val_loss: 0.4911 - val_accuracy: 0.7656\n",
            "Epoch 124/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4409 - accuracy: 0.7795 - val_loss: 0.4911 - val_accuracy: 0.7656\n",
            "Epoch 125/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4408 - accuracy: 0.7795 - val_loss: 0.4911 - val_accuracy: 0.7604\n",
            "Epoch 126/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4407 - accuracy: 0.7812 - val_loss: 0.4911 - val_accuracy: 0.7656\n",
            "Epoch 127/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4406 - accuracy: 0.7795 - val_loss: 0.4911 - val_accuracy: 0.7604\n",
            "Epoch 128/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4404 - accuracy: 0.7795 - val_loss: 0.4912 - val_accuracy: 0.7604\n",
            "Epoch 129/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4402 - accuracy: 0.7812 - val_loss: 0.4912 - val_accuracy: 0.7604\n",
            "Epoch 130/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4401 - accuracy: 0.7795 - val_loss: 0.4913 - val_accuracy: 0.7604\n",
            "Epoch 131/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4399 - accuracy: 0.7812 - val_loss: 0.4913 - val_accuracy: 0.7604\n",
            "Epoch 132/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4398 - accuracy: 0.7812 - val_loss: 0.4912 - val_accuracy: 0.7604\n",
            "Epoch 133/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4397 - accuracy: 0.7812 - val_loss: 0.4913 - val_accuracy: 0.7604\n",
            "Epoch 134/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4396 - accuracy: 0.7795 - val_loss: 0.4913 - val_accuracy: 0.7604\n",
            "Epoch 135/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4395 - accuracy: 0.7812 - val_loss: 0.4913 - val_accuracy: 0.7604\n",
            "Epoch 136/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4393 - accuracy: 0.7812 - val_loss: 0.4913 - val_accuracy: 0.7604\n",
            "Epoch 137/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4392 - accuracy: 0.7812 - val_loss: 0.4913 - val_accuracy: 0.7656\n",
            "Epoch 138/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4391 - accuracy: 0.7812 - val_loss: 0.4913 - val_accuracy: 0.7656\n",
            "Epoch 139/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4390 - accuracy: 0.7812 - val_loss: 0.4914 - val_accuracy: 0.7656\n",
            "Epoch 140/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4389 - accuracy: 0.7812 - val_loss: 0.4914 - val_accuracy: 0.7656\n",
            "Epoch 141/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4387 - accuracy: 0.7812 - val_loss: 0.4914 - val_accuracy: 0.7656\n",
            "Epoch 142/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4386 - accuracy: 0.7812 - val_loss: 0.4915 - val_accuracy: 0.7656\n",
            "Epoch 143/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4385 - accuracy: 0.7812 - val_loss: 0.4915 - val_accuracy: 0.7656\n",
            "Epoch 144/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4384 - accuracy: 0.7830 - val_loss: 0.4915 - val_accuracy: 0.7656\n",
            "Epoch 145/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4383 - accuracy: 0.7812 - val_loss: 0.4915 - val_accuracy: 0.7656\n",
            "Epoch 146/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4382 - accuracy: 0.7830 - val_loss: 0.4916 - val_accuracy: 0.7656\n",
            "Epoch 147/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4381 - accuracy: 0.7830 - val_loss: 0.4916 - val_accuracy: 0.7656\n",
            "Epoch 148/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4379 - accuracy: 0.7830 - val_loss: 0.4916 - val_accuracy: 0.7656\n",
            "Epoch 149/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4379 - accuracy: 0.7812 - val_loss: 0.4916 - val_accuracy: 0.7604\n",
            "Epoch 150/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4377 - accuracy: 0.7830 - val_loss: 0.4917 - val_accuracy: 0.7604\n",
            "Epoch 151/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4376 - accuracy: 0.7830 - val_loss: 0.4917 - val_accuracy: 0.7604\n",
            "Epoch 152/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4375 - accuracy: 0.7812 - val_loss: 0.4917 - val_accuracy: 0.7604\n",
            "Epoch 153/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4374 - accuracy: 0.7812 - val_loss: 0.4917 - val_accuracy: 0.7604\n",
            "Epoch 154/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4373 - accuracy: 0.7812 - val_loss: 0.4917 - val_accuracy: 0.7604\n",
            "Epoch 155/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4372 - accuracy: 0.7812 - val_loss: 0.4917 - val_accuracy: 0.7604\n",
            "Epoch 156/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4370 - accuracy: 0.7830 - val_loss: 0.4917 - val_accuracy: 0.7604\n",
            "Epoch 157/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4370 - accuracy: 0.7812 - val_loss: 0.4918 - val_accuracy: 0.7656\n",
            "Epoch 158/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4369 - accuracy: 0.7812 - val_loss: 0.4918 - val_accuracy: 0.7656\n",
            "Epoch 159/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4368 - accuracy: 0.7812 - val_loss: 0.4918 - val_accuracy: 0.7656\n",
            "Epoch 160/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4366 - accuracy: 0.7830 - val_loss: 0.4918 - val_accuracy: 0.7656\n",
            "Epoch 161/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4366 - accuracy: 0.7812 - val_loss: 0.4918 - val_accuracy: 0.7656\n",
            "Epoch 162/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4365 - accuracy: 0.7812 - val_loss: 0.4918 - val_accuracy: 0.7656\n",
            "Epoch 163/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4363 - accuracy: 0.7812 - val_loss: 0.4919 - val_accuracy: 0.7656\n",
            "Epoch 164/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4362 - accuracy: 0.7812 - val_loss: 0.4919 - val_accuracy: 0.7656\n",
            "Epoch 165/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4362 - accuracy: 0.7812 - val_loss: 0.4919 - val_accuracy: 0.7656\n",
            "Epoch 166/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4361 - accuracy: 0.7812 - val_loss: 0.4919 - val_accuracy: 0.7656\n",
            "Epoch 167/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4361 - accuracy: 0.7812 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
            "Epoch 168/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4359 - accuracy: 0.7795 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
            "Epoch 169/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4359 - accuracy: 0.7812 - val_loss: 0.4921 - val_accuracy: 0.7656\n",
            "Epoch 170/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4358 - accuracy: 0.7795 - val_loss: 0.4921 - val_accuracy: 0.7656\n",
            "Epoch 171/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4356 - accuracy: 0.7795 - val_loss: 0.4921 - val_accuracy: 0.7656\n",
            "Epoch 172/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4356 - accuracy: 0.7795 - val_loss: 0.4921 - val_accuracy: 0.7604\n",
            "Epoch 173/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4355 - accuracy: 0.7778 - val_loss: 0.4922 - val_accuracy: 0.7604\n",
            "Epoch 174/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4355 - accuracy: 0.7795 - val_loss: 0.4922 - val_accuracy: 0.7604\n",
            "Epoch 175/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4353 - accuracy: 0.7795 - val_loss: 0.4922 - val_accuracy: 0.7604\n",
            "Epoch 176/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4354 - accuracy: 0.7795 - val_loss: 0.4922 - val_accuracy: 0.7656\n",
            "Epoch 177/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4352 - accuracy: 0.7795 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
            "Epoch 178/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4350 - accuracy: 0.7795 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
            "Epoch 179/200\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 0.4350 - accuracy: 0.7778 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
            "Epoch 180/200\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4349 - accuracy: 0.7795 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
            "Epoch 181/200\n",
            "18/18 [==============================] - 0s 19ms/step - loss: 0.4348 - accuracy: 0.7795 - val_loss: 0.4924 - val_accuracy: 0.7604\n",
            "Epoch 182/200\n",
            "18/18 [==============================] - 0s 24ms/step - loss: 0.4348 - accuracy: 0.7812 - val_loss: 0.4924 - val_accuracy: 0.7604\n",
            "Epoch 183/200\n",
            "18/18 [==============================] - 0s 20ms/step - loss: 0.4347 - accuracy: 0.7795 - val_loss: 0.4924 - val_accuracy: 0.7656\n",
            "Epoch 184/200\n",
            "18/18 [==============================] - 0s 20ms/step - loss: 0.4346 - accuracy: 0.7778 - val_loss: 0.4924 - val_accuracy: 0.7656\n",
            "Epoch 185/200\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4345 - accuracy: 0.7795 - val_loss: 0.4924 - val_accuracy: 0.7656\n",
            "Epoch 186/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4343 - accuracy: 0.7795 - val_loss: 0.4925 - val_accuracy: 0.7604\n",
            "Epoch 187/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4342 - accuracy: 0.7778 - val_loss: 0.4925 - val_accuracy: 0.7656\n",
            "Epoch 188/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4342 - accuracy: 0.7778 - val_loss: 0.4925 - val_accuracy: 0.7656\n",
            "Epoch 189/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4341 - accuracy: 0.7795 - val_loss: 0.4926 - val_accuracy: 0.7604\n",
            "Epoch 190/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4340 - accuracy: 0.7778 - val_loss: 0.4926 - val_accuracy: 0.7604\n",
            "Epoch 191/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4340 - accuracy: 0.7795 - val_loss: 0.4926 - val_accuracy: 0.7604\n",
            "Epoch 192/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4338 - accuracy: 0.7778 - val_loss: 0.4927 - val_accuracy: 0.7708\n",
            "Epoch 193/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4338 - accuracy: 0.7795 - val_loss: 0.4927 - val_accuracy: 0.7708\n",
            "Epoch 194/200\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4337 - accuracy: 0.7812 - val_loss: 0.4927 - val_accuracy: 0.7708\n",
            "Epoch 195/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4335 - accuracy: 0.7812 - val_loss: 0.4928 - val_accuracy: 0.7656\n",
            "Epoch 196/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4334 - accuracy: 0.7830 - val_loss: 0.4928 - val_accuracy: 0.7708\n",
            "Epoch 197/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4333 - accuracy: 0.7812 - val_loss: 0.4928 - val_accuracy: 0.7708\n",
            "Epoch 198/200\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4332 - accuracy: 0.7830 - val_loss: 0.4928 - val_accuracy: 0.7708\n",
            "Epoch 199/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4332 - accuracy: 0.7795 - val_loss: 0.4928 - val_accuracy: 0.7708\n",
            "Epoch 200/200\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4331 - accuracy: 0.7812 - val_loss: 0.4928 - val_accuracy: 0.7708\n"
          ]
        }
      ],
      "source": [
        "model.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "run_hist_1 = model.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "unsigned-nevada",
      "metadata": {
        "id": "unsigned-nevada",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f4b3ccf-23d3-4561-fa62-8e78d2bddd8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 3ms/step\n",
            "6/6 [==============================] - 0s 4ms/step\n"
          ]
        }
      ],
      "source": [
        "## Like we did for the Random Forest, we generate two kinds of predictions\n",
        "#  One is a hard decision, the other is a probabilitistic score.\n",
        "y_pred_class_nn_1 = (model.predict(X_test_norm)> 0.5 ).astype('int32')\n",
        "y_pred_prob_nn_1 = model.predict(X_test_norm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tough-catering",
      "metadata": {
        "id": "tough-catering",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c6de2ab-a3e6-41a9-94bb-b53fa684cfc1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# Let's check out the outputs to get a feel for how keras apis work.\n",
        "y_pred_class_nn_1[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "combined-zimbabwe",
      "metadata": {
        "id": "combined-zimbabwe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c28e66a9-413b-4db5-b0b1-da74249e6a62"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.62997013],\n",
              "       [0.5020282 ],\n",
              "       [0.28853026],\n",
              "       [0.17203137],\n",
              "       [0.1602998 ],\n",
              "       [0.53444177],\n",
              "       [0.02254321],\n",
              "       [0.32344955],\n",
              "       [0.9509052 ],\n",
              "       [0.18956077]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "y_pred_prob_nn_1[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "going-estonia",
      "metadata": {
        "id": "going-estonia"
      },
      "source": [
        "Create the plot_roc function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "supposed-moderator",
      "metadata": {
        "id": "supposed-moderator"
      },
      "outputs": [],
      "source": [
        "def plot_roc(y_test, y_pred, model_name):\n",
        "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
        "    fig, ax = plt.subplots(figsize=(8, 8))\n",
        "    ax.plot(fpr, tpr, 'k-')\n",
        "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
        "    ax.grid(True)\n",
        "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n",
        "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "second-festival",
      "metadata": {
        "id": "second-festival"
      },
      "source": [
        "Evaluate the model performance and plot the ROC CURVE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eleven-nebraska",
      "metadata": {
        "id": "eleven-nebraska",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 735
        },
        "outputId": "c341554c-afb0-4ea1-8c82-cd3c1d578b46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy is 0.771\n",
            "roc-auc is 0.828\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
        "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))\n",
        "\n",
        "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can observe that the model has a gradual increase in accuracy, which can be viewed as our graph goes towards the right side, it becomes closer and close to 1.0"
      ],
      "metadata": {
        "id": "A_dEh07cXLXS"
      },
      "id": "A_dEh07cXLXS"
    },
    {
      "cell_type": "markdown",
      "id": "invalid-nevada",
      "metadata": {
        "id": "invalid-nevada"
      },
      "source": [
        " Plot the training loss and the validation loss over the different epochs and see how it looks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hidden-physics",
      "metadata": {
        "id": "hidden-physics",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c71e7cb-cf57-4ef0-a8cd-d26190448361"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "run_hist_1.history.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "banned-spider",
      "metadata": {
        "id": "banned-spider",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "outputId": "935501e3-934d-4ce8-efd4-bac5525107c4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x79169aff5db0>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "superb-circus",
      "metadata": {
        "id": "superb-circus"
      },
      "source": [
        "What is your interpretation about the result of the train and validation loss?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "jPR4sz6Y9p9K"
      },
      "id": "jPR4sz6Y9p9K"
    },
    {
      "cell_type": "markdown",
      "id": "involved-slovak",
      "metadata": {
        "id": "involved-slovak"
      },
      "source": [
        "#### Supplementary Activity"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pending-publisher",
      "metadata": {
        "id": "pending-publisher"
      },
      "source": [
        "* Build a model with two hidden layers, each with 6 nodes\n",
        "* Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer\n",
        "* Use a learning rate of .003 and train for 1500 epochs\n",
        "* Graph the trajectory of the loss functions, accuracy on both train and test set\n",
        "* Plot the roc curve for the predictions\n",
        "* Use different learning rates, numbers of epochs, and network structures.\n",
        "* Plot the results of training and validation loss using different learning rates, number of epocgs and network structures\n",
        "* Interpret your result"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Using the same dataset as the one above"
      ],
      "metadata": {
        "id": "CIY03N2s-6C2"
      },
      "id": "CIY03N2s-6C2"
    },
    {
      "cell_type": "code",
      "source": [
        "#Model with two hidden layers each having 6 nodes\n",
        "model_1 = Sequential ([\n",
        "    #Layer 1\n",
        "    Dense(6, input_shape=(8,),activation=\"relu\"),\n",
        "    #Layer 2\n",
        "    Dense(6,activation=\"relu\"),\n",
        "    #Output/Final Layer\n",
        "    Dense(1,activation=\"sigmoid\")\n",
        "])"
      ],
      "metadata": {
        "id": "vyHfaWjA-o6V"
      },
      "id": "vyHfaWjA-o6V",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "run_hist_2 = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1500)"
      ],
      "metadata": {
        "id": "uT2HgVLM-pQU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24be3576-4957-4657-a384-546233e604a7"
      },
      "id": "uT2HgVLM-pQU",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1500\n",
            "18/18 [==============================] - 1s 11ms/step - loss: 0.4756 - accuracy: 0.7587 - val_loss: 0.5307 - val_accuracy: 0.7344\n",
            "Epoch 2/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4746 - accuracy: 0.7604 - val_loss: 0.5302 - val_accuracy: 0.7344\n",
            "Epoch 3/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4737 - accuracy: 0.7622 - val_loss: 0.5297 - val_accuracy: 0.7344\n",
            "Epoch 4/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4728 - accuracy: 0.7656 - val_loss: 0.5292 - val_accuracy: 0.7396\n",
            "Epoch 5/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4721 - accuracy: 0.7674 - val_loss: 0.5287 - val_accuracy: 0.7396\n",
            "Epoch 6/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4713 - accuracy: 0.7708 - val_loss: 0.5282 - val_accuracy: 0.7396\n",
            "Epoch 7/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4704 - accuracy: 0.7708 - val_loss: 0.5277 - val_accuracy: 0.7396\n",
            "Epoch 8/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4698 - accuracy: 0.7708 - val_loss: 0.5273 - val_accuracy: 0.7396\n",
            "Epoch 9/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4691 - accuracy: 0.7726 - val_loss: 0.5269 - val_accuracy: 0.7396\n",
            "Epoch 10/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4683 - accuracy: 0.7691 - val_loss: 0.5264 - val_accuracy: 0.7396\n",
            "Epoch 11/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4677 - accuracy: 0.7708 - val_loss: 0.5260 - val_accuracy: 0.7396\n",
            "Epoch 12/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4671 - accuracy: 0.7708 - val_loss: 0.5256 - val_accuracy: 0.7396\n",
            "Epoch 13/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4662 - accuracy: 0.7708 - val_loss: 0.5252 - val_accuracy: 0.7344\n",
            "Epoch 14/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4656 - accuracy: 0.7726 - val_loss: 0.5249 - val_accuracy: 0.7344\n",
            "Epoch 15/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4651 - accuracy: 0.7726 - val_loss: 0.5246 - val_accuracy: 0.7344\n",
            "Epoch 16/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4643 - accuracy: 0.7726 - val_loss: 0.5242 - val_accuracy: 0.7344\n",
            "Epoch 17/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4638 - accuracy: 0.7743 - val_loss: 0.5239 - val_accuracy: 0.7344\n",
            "Epoch 18/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4632 - accuracy: 0.7760 - val_loss: 0.5236 - val_accuracy: 0.7344\n",
            "Epoch 19/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4626 - accuracy: 0.7778 - val_loss: 0.5233 - val_accuracy: 0.7344\n",
            "Epoch 20/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4621 - accuracy: 0.7778 - val_loss: 0.5231 - val_accuracy: 0.7396\n",
            "Epoch 21/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4614 - accuracy: 0.7795 - val_loss: 0.5228 - val_accuracy: 0.7448\n",
            "Epoch 22/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4609 - accuracy: 0.7812 - val_loss: 0.5225 - val_accuracy: 0.7448\n",
            "Epoch 23/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4604 - accuracy: 0.7812 - val_loss: 0.5223 - val_accuracy: 0.7448\n",
            "Epoch 24/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4599 - accuracy: 0.7847 - val_loss: 0.5221 - val_accuracy: 0.7448\n",
            "Epoch 25/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4596 - accuracy: 0.7830 - val_loss: 0.5219 - val_accuracy: 0.7448\n",
            "Epoch 26/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4590 - accuracy: 0.7830 - val_loss: 0.5217 - val_accuracy: 0.7448\n",
            "Epoch 27/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4587 - accuracy: 0.7847 - val_loss: 0.5214 - val_accuracy: 0.7396\n",
            "Epoch 28/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4582 - accuracy: 0.7865 - val_loss: 0.5212 - val_accuracy: 0.7344\n",
            "Epoch 29/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4577 - accuracy: 0.7830 - val_loss: 0.5210 - val_accuracy: 0.7344\n",
            "Epoch 30/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4573 - accuracy: 0.7830 - val_loss: 0.5208 - val_accuracy: 0.7344\n",
            "Epoch 31/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4570 - accuracy: 0.7847 - val_loss: 0.5205 - val_accuracy: 0.7344\n",
            "Epoch 32/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4565 - accuracy: 0.7847 - val_loss: 0.5203 - val_accuracy: 0.7344\n",
            "Epoch 33/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4561 - accuracy: 0.7865 - val_loss: 0.5201 - val_accuracy: 0.7344\n",
            "Epoch 34/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4557 - accuracy: 0.7847 - val_loss: 0.5199 - val_accuracy: 0.7344\n",
            "Epoch 35/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4554 - accuracy: 0.7847 - val_loss: 0.5197 - val_accuracy: 0.7344\n",
            "Epoch 36/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4549 - accuracy: 0.7865 - val_loss: 0.5196 - val_accuracy: 0.7344\n",
            "Epoch 37/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4547 - accuracy: 0.7865 - val_loss: 0.5194 - val_accuracy: 0.7344\n",
            "Epoch 38/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4542 - accuracy: 0.7847 - val_loss: 0.5193 - val_accuracy: 0.7344\n",
            "Epoch 39/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4539 - accuracy: 0.7830 - val_loss: 0.5192 - val_accuracy: 0.7344\n",
            "Epoch 40/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4535 - accuracy: 0.7847 - val_loss: 0.5192 - val_accuracy: 0.7344\n",
            "Epoch 41/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4531 - accuracy: 0.7830 - val_loss: 0.5191 - val_accuracy: 0.7396\n",
            "Epoch 42/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4529 - accuracy: 0.7847 - val_loss: 0.5190 - val_accuracy: 0.7396\n",
            "Epoch 43/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4525 - accuracy: 0.7830 - val_loss: 0.5189 - val_accuracy: 0.7396\n",
            "Epoch 44/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4521 - accuracy: 0.7847 - val_loss: 0.5189 - val_accuracy: 0.7396\n",
            "Epoch 45/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4518 - accuracy: 0.7830 - val_loss: 0.5188 - val_accuracy: 0.7396\n",
            "Epoch 46/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4514 - accuracy: 0.7830 - val_loss: 0.5188 - val_accuracy: 0.7396\n",
            "Epoch 47/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4512 - accuracy: 0.7865 - val_loss: 0.5188 - val_accuracy: 0.7396\n",
            "Epoch 48/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4508 - accuracy: 0.7865 - val_loss: 0.5187 - val_accuracy: 0.7396\n",
            "Epoch 49/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4505 - accuracy: 0.7847 - val_loss: 0.5187 - val_accuracy: 0.7396\n",
            "Epoch 50/1500\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 0.4503 - accuracy: 0.7865 - val_loss: 0.5186 - val_accuracy: 0.7344\n",
            "Epoch 51/1500\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.4499 - accuracy: 0.7865 - val_loss: 0.5186 - val_accuracy: 0.7344\n",
            "Epoch 52/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4496 - accuracy: 0.7865 - val_loss: 0.5185 - val_accuracy: 0.7344\n",
            "Epoch 53/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4494 - accuracy: 0.7865 - val_loss: 0.5185 - val_accuracy: 0.7344\n",
            "Epoch 54/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4491 - accuracy: 0.7882 - val_loss: 0.5184 - val_accuracy: 0.7344\n",
            "Epoch 55/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4487 - accuracy: 0.7865 - val_loss: 0.5184 - val_accuracy: 0.7344\n",
            "Epoch 56/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4484 - accuracy: 0.7899 - val_loss: 0.5183 - val_accuracy: 0.7344\n",
            "Epoch 57/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4482 - accuracy: 0.7899 - val_loss: 0.5183 - val_accuracy: 0.7344\n",
            "Epoch 58/1500\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.4479 - accuracy: 0.7899 - val_loss: 0.5182 - val_accuracy: 0.7344\n",
            "Epoch 59/1500\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.4475 - accuracy: 0.7899 - val_loss: 0.5182 - val_accuracy: 0.7344\n",
            "Epoch 60/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4472 - accuracy: 0.7899 - val_loss: 0.5182 - val_accuracy: 0.7344\n",
            "Epoch 61/1500\n",
            "18/18 [==============================] - 0s 19ms/step - loss: 0.4470 - accuracy: 0.7882 - val_loss: 0.5181 - val_accuracy: 0.7344\n",
            "Epoch 62/1500\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 0.4466 - accuracy: 0.7865 - val_loss: 0.5181 - val_accuracy: 0.7344\n",
            "Epoch 63/1500\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.4463 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.7344\n",
            "Epoch 64/1500\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 0.4459 - accuracy: 0.7865 - val_loss: 0.5182 - val_accuracy: 0.7344\n",
            "Epoch 65/1500\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.4456 - accuracy: 0.7934 - val_loss: 0.5182 - val_accuracy: 0.7344\n",
            "Epoch 66/1500\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.4453 - accuracy: 0.7934 - val_loss: 0.5182 - val_accuracy: 0.7344\n",
            "Epoch 67/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4450 - accuracy: 0.7951 - val_loss: 0.5182 - val_accuracy: 0.7344\n",
            "Epoch 68/1500\n",
            "18/18 [==============================] - 0s 28ms/step - loss: 0.4448 - accuracy: 0.7934 - val_loss: 0.5181 - val_accuracy: 0.7344\n",
            "Epoch 69/1500\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.4444 - accuracy: 0.7917 - val_loss: 0.5182 - val_accuracy: 0.7344\n",
            "Epoch 70/1500\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.4442 - accuracy: 0.7934 - val_loss: 0.5182 - val_accuracy: 0.7344\n",
            "Epoch 71/1500\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.4438 - accuracy: 0.7917 - val_loss: 0.5182 - val_accuracy: 0.7344\n",
            "Epoch 72/1500\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 0.4435 - accuracy: 0.7934 - val_loss: 0.5183 - val_accuracy: 0.7344\n",
            "Epoch 73/1500\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.4433 - accuracy: 0.7934 - val_loss: 0.5184 - val_accuracy: 0.7344\n",
            "Epoch 74/1500\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.4430 - accuracy: 0.7917 - val_loss: 0.5185 - val_accuracy: 0.7344\n",
            "Epoch 75/1500\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.4427 - accuracy: 0.7899 - val_loss: 0.5186 - val_accuracy: 0.7344\n",
            "Epoch 76/1500\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.4423 - accuracy: 0.7934 - val_loss: 0.5186 - val_accuracy: 0.7344\n",
            "Epoch 77/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4421 - accuracy: 0.7951 - val_loss: 0.5187 - val_accuracy: 0.7344\n",
            "Epoch 78/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4419 - accuracy: 0.7934 - val_loss: 0.5188 - val_accuracy: 0.7344\n",
            "Epoch 79/1500\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.4417 - accuracy: 0.7917 - val_loss: 0.5189 - val_accuracy: 0.7344\n",
            "Epoch 80/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4415 - accuracy: 0.7917 - val_loss: 0.5189 - val_accuracy: 0.7344\n",
            "Epoch 81/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4412 - accuracy: 0.7951 - val_loss: 0.5190 - val_accuracy: 0.7344\n",
            "Epoch 82/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4409 - accuracy: 0.7934 - val_loss: 0.5190 - val_accuracy: 0.7344\n",
            "Epoch 83/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4406 - accuracy: 0.7951 - val_loss: 0.5192 - val_accuracy: 0.7344\n",
            "Epoch 84/1500\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.4403 - accuracy: 0.7951 - val_loss: 0.5192 - val_accuracy: 0.7396\n",
            "Epoch 85/1500\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.4401 - accuracy: 0.7951 - val_loss: 0.5192 - val_accuracy: 0.7396\n",
            "Epoch 86/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4399 - accuracy: 0.7951 - val_loss: 0.5193 - val_accuracy: 0.7396\n",
            "Epoch 87/1500\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.4396 - accuracy: 0.7951 - val_loss: 0.5193 - val_accuracy: 0.7396\n",
            "Epoch 88/1500\n",
            "18/18 [==============================] - 0s 26ms/step - loss: 0.4393 - accuracy: 0.7951 - val_loss: 0.5193 - val_accuracy: 0.7396\n",
            "Epoch 89/1500\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.4391 - accuracy: 0.7969 - val_loss: 0.5193 - val_accuracy: 0.7396\n",
            "Epoch 90/1500\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.4387 - accuracy: 0.7969 - val_loss: 0.5194 - val_accuracy: 0.7396\n",
            "Epoch 91/1500\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.4386 - accuracy: 0.7986 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
            "Epoch 92/1500\n",
            "18/18 [==============================] - 0s 27ms/step - loss: 0.4383 - accuracy: 0.7969 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
            "Epoch 93/1500\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.4382 - accuracy: 0.7969 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
            "Epoch 94/1500\n",
            "18/18 [==============================] - 0s 20ms/step - loss: 0.4379 - accuracy: 0.7986 - val_loss: 0.5196 - val_accuracy: 0.7396\n",
            "Epoch 95/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4377 - accuracy: 0.7986 - val_loss: 0.5197 - val_accuracy: 0.7396\n",
            "Epoch 96/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4373 - accuracy: 0.8003 - val_loss: 0.5197 - val_accuracy: 0.7396\n",
            "Epoch 97/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4372 - accuracy: 0.7986 - val_loss: 0.5198 - val_accuracy: 0.7396\n",
            "Epoch 98/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4369 - accuracy: 0.7986 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
            "Epoch 99/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4369 - accuracy: 0.7986 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
            "Epoch 100/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4365 - accuracy: 0.7969 - val_loss: 0.5200 - val_accuracy: 0.7396\n",
            "Epoch 101/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4364 - accuracy: 0.7969 - val_loss: 0.5200 - val_accuracy: 0.7396\n",
            "Epoch 102/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4361 - accuracy: 0.7969 - val_loss: 0.5201 - val_accuracy: 0.7396\n",
            "Epoch 103/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4361 - accuracy: 0.7969 - val_loss: 0.5202 - val_accuracy: 0.7396\n",
            "Epoch 104/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4358 - accuracy: 0.7951 - val_loss: 0.5202 - val_accuracy: 0.7396\n",
            "Epoch 105/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4357 - accuracy: 0.7951 - val_loss: 0.5203 - val_accuracy: 0.7396\n",
            "Epoch 106/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4353 - accuracy: 0.7951 - val_loss: 0.5203 - val_accuracy: 0.7396\n",
            "Epoch 107/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4353 - accuracy: 0.7951 - val_loss: 0.5203 - val_accuracy: 0.7396\n",
            "Epoch 108/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4350 - accuracy: 0.7969 - val_loss: 0.5203 - val_accuracy: 0.7396\n",
            "Epoch 109/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4347 - accuracy: 0.7969 - val_loss: 0.5204 - val_accuracy: 0.7396\n",
            "Epoch 110/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4345 - accuracy: 0.7951 - val_loss: 0.5204 - val_accuracy: 0.7396\n",
            "Epoch 111/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4344 - accuracy: 0.7951 - val_loss: 0.5204 - val_accuracy: 0.7396\n",
            "Epoch 112/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4343 - accuracy: 0.7951 - val_loss: 0.5204 - val_accuracy: 0.7396\n",
            "Epoch 113/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4339 - accuracy: 0.7951 - val_loss: 0.5204 - val_accuracy: 0.7396\n",
            "Epoch 114/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4339 - accuracy: 0.7969 - val_loss: 0.5204 - val_accuracy: 0.7396\n",
            "Epoch 115/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4337 - accuracy: 0.7951 - val_loss: 0.5203 - val_accuracy: 0.7396\n",
            "Epoch 116/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4335 - accuracy: 0.7951 - val_loss: 0.5203 - val_accuracy: 0.7396\n",
            "Epoch 117/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4333 - accuracy: 0.7951 - val_loss: 0.5203 - val_accuracy: 0.7396\n",
            "Epoch 118/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4331 - accuracy: 0.7951 - val_loss: 0.5203 - val_accuracy: 0.7396\n",
            "Epoch 119/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4329 - accuracy: 0.7969 - val_loss: 0.5203 - val_accuracy: 0.7396\n",
            "Epoch 120/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4329 - accuracy: 0.7986 - val_loss: 0.5203 - val_accuracy: 0.7396\n",
            "Epoch 121/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4326 - accuracy: 0.7986 - val_loss: 0.5203 - val_accuracy: 0.7396\n",
            "Epoch 122/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4326 - accuracy: 0.7986 - val_loss: 0.5202 - val_accuracy: 0.7396\n",
            "Epoch 123/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4322 - accuracy: 0.7986 - val_loss: 0.5201 - val_accuracy: 0.7396\n",
            "Epoch 124/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4321 - accuracy: 0.7986 - val_loss: 0.5201 - val_accuracy: 0.7396\n",
            "Epoch 125/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4319 - accuracy: 0.7986 - val_loss: 0.5200 - val_accuracy: 0.7396\n",
            "Epoch 126/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4317 - accuracy: 0.7986 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
            "Epoch 127/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4315 - accuracy: 0.7986 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
            "Epoch 128/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4312 - accuracy: 0.7986 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
            "Epoch 129/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4311 - accuracy: 0.8003 - val_loss: 0.5198 - val_accuracy: 0.7396\n",
            "Epoch 130/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4309 - accuracy: 0.7986 - val_loss: 0.5197 - val_accuracy: 0.7396\n",
            "Epoch 131/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4308 - accuracy: 0.8021 - val_loss: 0.5198 - val_accuracy: 0.7396\n",
            "Epoch 132/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4306 - accuracy: 0.7986 - val_loss: 0.5197 - val_accuracy: 0.7396\n",
            "Epoch 133/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4305 - accuracy: 0.7986 - val_loss: 0.5197 - val_accuracy: 0.7396\n",
            "Epoch 134/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4303 - accuracy: 0.7934 - val_loss: 0.5196 - val_accuracy: 0.7396\n",
            "Epoch 135/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4300 - accuracy: 0.7969 - val_loss: 0.5196 - val_accuracy: 0.7396\n",
            "Epoch 136/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4299 - accuracy: 0.7969 - val_loss: 0.5196 - val_accuracy: 0.7396\n",
            "Epoch 137/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4297 - accuracy: 0.7969 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
            "Epoch 138/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4294 - accuracy: 0.7969 - val_loss: 0.5194 - val_accuracy: 0.7396\n",
            "Epoch 139/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4293 - accuracy: 0.8003 - val_loss: 0.5194 - val_accuracy: 0.7396\n",
            "Epoch 140/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4292 - accuracy: 0.7986 - val_loss: 0.5194 - val_accuracy: 0.7396\n",
            "Epoch 141/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4291 - accuracy: 0.8003 - val_loss: 0.5193 - val_accuracy: 0.7396\n",
            "Epoch 142/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4289 - accuracy: 0.8003 - val_loss: 0.5192 - val_accuracy: 0.7396\n",
            "Epoch 143/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4288 - accuracy: 0.8003 - val_loss: 0.5192 - val_accuracy: 0.7396\n",
            "Epoch 144/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4286 - accuracy: 0.7986 - val_loss: 0.5191 - val_accuracy: 0.7396\n",
            "Epoch 145/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4284 - accuracy: 0.8021 - val_loss: 0.5191 - val_accuracy: 0.7396\n",
            "Epoch 146/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4282 - accuracy: 0.7986 - val_loss: 0.5191 - val_accuracy: 0.7396\n",
            "Epoch 147/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4281 - accuracy: 0.7986 - val_loss: 0.5191 - val_accuracy: 0.7448\n",
            "Epoch 148/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4280 - accuracy: 0.7986 - val_loss: 0.5190 - val_accuracy: 0.7448\n",
            "Epoch 149/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4279 - accuracy: 0.7986 - val_loss: 0.5190 - val_accuracy: 0.7448\n",
            "Epoch 150/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4278 - accuracy: 0.7986 - val_loss: 0.5190 - val_accuracy: 0.7448\n",
            "Epoch 151/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4277 - accuracy: 0.7986 - val_loss: 0.5190 - val_accuracy: 0.7448\n",
            "Epoch 152/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4275 - accuracy: 0.7986 - val_loss: 0.5190 - val_accuracy: 0.7448\n",
            "Epoch 153/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4274 - accuracy: 0.7969 - val_loss: 0.5189 - val_accuracy: 0.7396\n",
            "Epoch 154/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4273 - accuracy: 0.7986 - val_loss: 0.5190 - val_accuracy: 0.7396\n",
            "Epoch 155/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4270 - accuracy: 0.7986 - val_loss: 0.5190 - val_accuracy: 0.7396\n",
            "Epoch 156/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4270 - accuracy: 0.7986 - val_loss: 0.5191 - val_accuracy: 0.7396\n",
            "Epoch 157/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4269 - accuracy: 0.7986 - val_loss: 0.5190 - val_accuracy: 0.7396\n",
            "Epoch 158/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4267 - accuracy: 0.7986 - val_loss: 0.5190 - val_accuracy: 0.7396\n",
            "Epoch 159/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4266 - accuracy: 0.7969 - val_loss: 0.5190 - val_accuracy: 0.7396\n",
            "Epoch 160/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4265 - accuracy: 0.7969 - val_loss: 0.5190 - val_accuracy: 0.7396\n",
            "Epoch 161/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4264 - accuracy: 0.7969 - val_loss: 0.5189 - val_accuracy: 0.7448\n",
            "Epoch 162/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4262 - accuracy: 0.7969 - val_loss: 0.5189 - val_accuracy: 0.7448\n",
            "Epoch 163/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4262 - accuracy: 0.7986 - val_loss: 0.5189 - val_accuracy: 0.7448\n",
            "Epoch 164/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4260 - accuracy: 0.7986 - val_loss: 0.5189 - val_accuracy: 0.7448\n",
            "Epoch 165/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4259 - accuracy: 0.7969 - val_loss: 0.5190 - val_accuracy: 0.7448\n",
            "Epoch 166/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4257 - accuracy: 0.7969 - val_loss: 0.5190 - val_accuracy: 0.7396\n",
            "Epoch 167/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4257 - accuracy: 0.7986 - val_loss: 0.5190 - val_accuracy: 0.7396\n",
            "Epoch 168/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4256 - accuracy: 0.7969 - val_loss: 0.5190 - val_accuracy: 0.7396\n",
            "Epoch 169/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4256 - accuracy: 0.7969 - val_loss: 0.5190 - val_accuracy: 0.7396\n",
            "Epoch 170/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4253 - accuracy: 0.7986 - val_loss: 0.5190 - val_accuracy: 0.7448\n",
            "Epoch 171/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4252 - accuracy: 0.7969 - val_loss: 0.5189 - val_accuracy: 0.7448\n",
            "Epoch 172/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4252 - accuracy: 0.7969 - val_loss: 0.5190 - val_accuracy: 0.7448\n",
            "Epoch 173/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4251 - accuracy: 0.7969 - val_loss: 0.5189 - val_accuracy: 0.7448\n",
            "Epoch 174/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4249 - accuracy: 0.7969 - val_loss: 0.5188 - val_accuracy: 0.7448\n",
            "Epoch 175/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4249 - accuracy: 0.7986 - val_loss: 0.5189 - val_accuracy: 0.7448\n",
            "Epoch 176/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4247 - accuracy: 0.8003 - val_loss: 0.5189 - val_accuracy: 0.7448\n",
            "Epoch 177/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4246 - accuracy: 0.7986 - val_loss: 0.5189 - val_accuracy: 0.7448\n",
            "Epoch 178/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4247 - accuracy: 0.8003 - val_loss: 0.5190 - val_accuracy: 0.7448\n",
            "Epoch 179/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4244 - accuracy: 0.7986 - val_loss: 0.5190 - val_accuracy: 0.7448\n",
            "Epoch 180/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4244 - accuracy: 0.7986 - val_loss: 0.5190 - val_accuracy: 0.7448\n",
            "Epoch 181/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4242 - accuracy: 0.7986 - val_loss: 0.5190 - val_accuracy: 0.7448\n",
            "Epoch 182/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4242 - accuracy: 0.7986 - val_loss: 0.5190 - val_accuracy: 0.7448\n",
            "Epoch 183/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4242 - accuracy: 0.7986 - val_loss: 0.5191 - val_accuracy: 0.7448\n",
            "Epoch 184/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4239 - accuracy: 0.7986 - val_loss: 0.5191 - val_accuracy: 0.7448\n",
            "Epoch 185/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4237 - accuracy: 0.7986 - val_loss: 0.5191 - val_accuracy: 0.7448\n",
            "Epoch 186/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4237 - accuracy: 0.7986 - val_loss: 0.5192 - val_accuracy: 0.7448\n",
            "Epoch 187/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4236 - accuracy: 0.7986 - val_loss: 0.5191 - val_accuracy: 0.7448\n",
            "Epoch 188/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4237 - accuracy: 0.7986 - val_loss: 0.5191 - val_accuracy: 0.7448\n",
            "Epoch 189/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4235 - accuracy: 0.7986 - val_loss: 0.5191 - val_accuracy: 0.7448\n",
            "Epoch 190/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4234 - accuracy: 0.7986 - val_loss: 0.5190 - val_accuracy: 0.7448\n",
            "Epoch 191/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4234 - accuracy: 0.7986 - val_loss: 0.5192 - val_accuracy: 0.7448\n",
            "Epoch 192/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4231 - accuracy: 0.7986 - val_loss: 0.5192 - val_accuracy: 0.7448\n",
            "Epoch 193/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4232 - accuracy: 0.7986 - val_loss: 0.5193 - val_accuracy: 0.7448\n",
            "Epoch 194/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4230 - accuracy: 0.7986 - val_loss: 0.5193 - val_accuracy: 0.7448\n",
            "Epoch 195/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4228 - accuracy: 0.7986 - val_loss: 0.5193 - val_accuracy: 0.7448\n",
            "Epoch 196/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4228 - accuracy: 0.7986 - val_loss: 0.5194 - val_accuracy: 0.7448\n",
            "Epoch 197/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4226 - accuracy: 0.7986 - val_loss: 0.5194 - val_accuracy: 0.7448\n",
            "Epoch 198/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4227 - accuracy: 0.7986 - val_loss: 0.5195 - val_accuracy: 0.7448\n",
            "Epoch 199/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4225 - accuracy: 0.7986 - val_loss: 0.5195 - val_accuracy: 0.7448\n",
            "Epoch 200/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4224 - accuracy: 0.7986 - val_loss: 0.5196 - val_accuracy: 0.7448\n",
            "Epoch 201/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4224 - accuracy: 0.7986 - val_loss: 0.5197 - val_accuracy: 0.7448\n",
            "Epoch 202/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4223 - accuracy: 0.7986 - val_loss: 0.5197 - val_accuracy: 0.7448\n",
            "Epoch 203/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4222 - accuracy: 0.7986 - val_loss: 0.5197 - val_accuracy: 0.7448\n",
            "Epoch 204/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4221 - accuracy: 0.7986 - val_loss: 0.5199 - val_accuracy: 0.7448\n",
            "Epoch 205/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4220 - accuracy: 0.7986 - val_loss: 0.5200 - val_accuracy: 0.7448\n",
            "Epoch 206/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4219 - accuracy: 0.7969 - val_loss: 0.5200 - val_accuracy: 0.7448\n",
            "Epoch 207/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4219 - accuracy: 0.7986 - val_loss: 0.5200 - val_accuracy: 0.7448\n",
            "Epoch 208/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4219 - accuracy: 0.7986 - val_loss: 0.5200 - val_accuracy: 0.7448\n",
            "Epoch 209/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4218 - accuracy: 0.7969 - val_loss: 0.5201 - val_accuracy: 0.7448\n",
            "Epoch 210/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4216 - accuracy: 0.7951 - val_loss: 0.5203 - val_accuracy: 0.7448\n",
            "Epoch 211/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4215 - accuracy: 0.7951 - val_loss: 0.5203 - val_accuracy: 0.7448\n",
            "Epoch 212/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4214 - accuracy: 0.7951 - val_loss: 0.5203 - val_accuracy: 0.7448\n",
            "Epoch 213/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4214 - accuracy: 0.7951 - val_loss: 0.5203 - val_accuracy: 0.7448\n",
            "Epoch 214/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4212 - accuracy: 0.7951 - val_loss: 0.5204 - val_accuracy: 0.7448\n",
            "Epoch 215/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4213 - accuracy: 0.7934 - val_loss: 0.5206 - val_accuracy: 0.7448\n",
            "Epoch 216/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4212 - accuracy: 0.7969 - val_loss: 0.5207 - val_accuracy: 0.7448\n",
            "Epoch 217/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4211 - accuracy: 0.7951 - val_loss: 0.5207 - val_accuracy: 0.7448\n",
            "Epoch 218/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4210 - accuracy: 0.7969 - val_loss: 0.5207 - val_accuracy: 0.7448\n",
            "Epoch 219/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4209 - accuracy: 0.7969 - val_loss: 0.5208 - val_accuracy: 0.7448\n",
            "Epoch 220/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4209 - accuracy: 0.7969 - val_loss: 0.5210 - val_accuracy: 0.7448\n",
            "Epoch 221/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4207 - accuracy: 0.7969 - val_loss: 0.5210 - val_accuracy: 0.7448\n",
            "Epoch 222/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4207 - accuracy: 0.7969 - val_loss: 0.5210 - val_accuracy: 0.7448\n",
            "Epoch 223/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4206 - accuracy: 0.7951 - val_loss: 0.5212 - val_accuracy: 0.7448\n",
            "Epoch 224/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4204 - accuracy: 0.7969 - val_loss: 0.5213 - val_accuracy: 0.7448\n",
            "Epoch 225/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4204 - accuracy: 0.7951 - val_loss: 0.5214 - val_accuracy: 0.7448\n",
            "Epoch 226/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4204 - accuracy: 0.7969 - val_loss: 0.5215 - val_accuracy: 0.7448\n",
            "Epoch 227/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4201 - accuracy: 0.7951 - val_loss: 0.5216 - val_accuracy: 0.7448\n",
            "Epoch 228/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4203 - accuracy: 0.7951 - val_loss: 0.5218 - val_accuracy: 0.7448\n",
            "Epoch 229/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4201 - accuracy: 0.7951 - val_loss: 0.5218 - val_accuracy: 0.7448\n",
            "Epoch 230/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4200 - accuracy: 0.7951 - val_loss: 0.5219 - val_accuracy: 0.7448\n",
            "Epoch 231/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4199 - accuracy: 0.7951 - val_loss: 0.5220 - val_accuracy: 0.7448\n",
            "Epoch 232/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4198 - accuracy: 0.7969 - val_loss: 0.5221 - val_accuracy: 0.7448\n",
            "Epoch 233/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4197 - accuracy: 0.7986 - val_loss: 0.5222 - val_accuracy: 0.7448\n",
            "Epoch 234/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4197 - accuracy: 0.7969 - val_loss: 0.5222 - val_accuracy: 0.7448\n",
            "Epoch 235/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4195 - accuracy: 0.7969 - val_loss: 0.5223 - val_accuracy: 0.7448\n",
            "Epoch 236/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4195 - accuracy: 0.7969 - val_loss: 0.5223 - val_accuracy: 0.7448\n",
            "Epoch 237/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4194 - accuracy: 0.7951 - val_loss: 0.5224 - val_accuracy: 0.7448\n",
            "Epoch 238/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4192 - accuracy: 0.7986 - val_loss: 0.5225 - val_accuracy: 0.7448\n",
            "Epoch 239/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4192 - accuracy: 0.7986 - val_loss: 0.5226 - val_accuracy: 0.7448\n",
            "Epoch 240/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4191 - accuracy: 0.7986 - val_loss: 0.5227 - val_accuracy: 0.7448\n",
            "Epoch 241/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4190 - accuracy: 0.7986 - val_loss: 0.5228 - val_accuracy: 0.7448\n",
            "Epoch 242/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4190 - accuracy: 0.7986 - val_loss: 0.5230 - val_accuracy: 0.7448\n",
            "Epoch 243/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4187 - accuracy: 0.7986 - val_loss: 0.5231 - val_accuracy: 0.7448\n",
            "Epoch 244/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4187 - accuracy: 0.7986 - val_loss: 0.5232 - val_accuracy: 0.7448\n",
            "Epoch 245/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4187 - accuracy: 0.7986 - val_loss: 0.5233 - val_accuracy: 0.7448\n",
            "Epoch 246/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4189 - accuracy: 0.7986 - val_loss: 0.5234 - val_accuracy: 0.7448\n",
            "Epoch 247/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4185 - accuracy: 0.7986 - val_loss: 0.5236 - val_accuracy: 0.7448\n",
            "Epoch 248/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4184 - accuracy: 0.8003 - val_loss: 0.5238 - val_accuracy: 0.7448\n",
            "Epoch 249/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4183 - accuracy: 0.7986 - val_loss: 0.5240 - val_accuracy: 0.7448\n",
            "Epoch 250/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4183 - accuracy: 0.8021 - val_loss: 0.5243 - val_accuracy: 0.7448\n",
            "Epoch 251/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4181 - accuracy: 0.8021 - val_loss: 0.5243 - val_accuracy: 0.7448\n",
            "Epoch 252/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4182 - accuracy: 0.8003 - val_loss: 0.5244 - val_accuracy: 0.7448\n",
            "Epoch 253/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4181 - accuracy: 0.8003 - val_loss: 0.5246 - val_accuracy: 0.7448\n",
            "Epoch 254/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4178 - accuracy: 0.7986 - val_loss: 0.5247 - val_accuracy: 0.7448\n",
            "Epoch 255/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4179 - accuracy: 0.7986 - val_loss: 0.5249 - val_accuracy: 0.7448\n",
            "Epoch 256/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4177 - accuracy: 0.7986 - val_loss: 0.5252 - val_accuracy: 0.7396\n",
            "Epoch 257/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4177 - accuracy: 0.8038 - val_loss: 0.5252 - val_accuracy: 0.7448\n",
            "Epoch 258/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4175 - accuracy: 0.8003 - val_loss: 0.5255 - val_accuracy: 0.7396\n",
            "Epoch 259/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4173 - accuracy: 0.8021 - val_loss: 0.5256 - val_accuracy: 0.7396\n",
            "Epoch 260/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4172 - accuracy: 0.8021 - val_loss: 0.5257 - val_accuracy: 0.7396\n",
            "Epoch 261/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4170 - accuracy: 0.8021 - val_loss: 0.5259 - val_accuracy: 0.7396\n",
            "Epoch 262/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4172 - accuracy: 0.8021 - val_loss: 0.5260 - val_accuracy: 0.7396\n",
            "Epoch 263/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4170 - accuracy: 0.8038 - val_loss: 0.5261 - val_accuracy: 0.7396\n",
            "Epoch 264/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4168 - accuracy: 0.8056 - val_loss: 0.5262 - val_accuracy: 0.7396\n",
            "Epoch 265/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4167 - accuracy: 0.8038 - val_loss: 0.5264 - val_accuracy: 0.7396\n",
            "Epoch 266/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4167 - accuracy: 0.8038 - val_loss: 0.5265 - val_accuracy: 0.7396\n",
            "Epoch 267/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4167 - accuracy: 0.8038 - val_loss: 0.5267 - val_accuracy: 0.7396\n",
            "Epoch 268/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4165 - accuracy: 0.8021 - val_loss: 0.5267 - val_accuracy: 0.7396\n",
            "Epoch 269/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4165 - accuracy: 0.8021 - val_loss: 0.5269 - val_accuracy: 0.7396\n",
            "Epoch 270/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4163 - accuracy: 0.8038 - val_loss: 0.5269 - val_accuracy: 0.7396\n",
            "Epoch 271/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4162 - accuracy: 0.8056 - val_loss: 0.5270 - val_accuracy: 0.7448\n",
            "Epoch 272/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4161 - accuracy: 0.8038 - val_loss: 0.5270 - val_accuracy: 0.7448\n",
            "Epoch 273/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4162 - accuracy: 0.8038 - val_loss: 0.5271 - val_accuracy: 0.7448\n",
            "Epoch 274/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4160 - accuracy: 0.8021 - val_loss: 0.5273 - val_accuracy: 0.7500\n",
            "Epoch 275/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4159 - accuracy: 0.8038 - val_loss: 0.5275 - val_accuracy: 0.7448\n",
            "Epoch 276/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4158 - accuracy: 0.8038 - val_loss: 0.5276 - val_accuracy: 0.7500\n",
            "Epoch 277/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4159 - accuracy: 0.8003 - val_loss: 0.5277 - val_accuracy: 0.7448\n",
            "Epoch 278/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4156 - accuracy: 0.8056 - val_loss: 0.5277 - val_accuracy: 0.7500\n",
            "Epoch 279/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4156 - accuracy: 0.8038 - val_loss: 0.5278 - val_accuracy: 0.7500\n",
            "Epoch 280/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4155 - accuracy: 0.8038 - val_loss: 0.5277 - val_accuracy: 0.7500\n",
            "Epoch 281/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4154 - accuracy: 0.8038 - val_loss: 0.5278 - val_accuracy: 0.7500\n",
            "Epoch 282/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4154 - accuracy: 0.8056 - val_loss: 0.5278 - val_accuracy: 0.7500\n",
            "Epoch 283/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4153 - accuracy: 0.8038 - val_loss: 0.5280 - val_accuracy: 0.7500\n",
            "Epoch 284/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4151 - accuracy: 0.8038 - val_loss: 0.5279 - val_accuracy: 0.7500\n",
            "Epoch 285/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4151 - accuracy: 0.8056 - val_loss: 0.5279 - val_accuracy: 0.7500\n",
            "Epoch 286/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4150 - accuracy: 0.8038 - val_loss: 0.5280 - val_accuracy: 0.7500\n",
            "Epoch 287/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4151 - accuracy: 0.8021 - val_loss: 0.5282 - val_accuracy: 0.7500\n",
            "Epoch 288/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4148 - accuracy: 0.8021 - val_loss: 0.5283 - val_accuracy: 0.7500\n",
            "Epoch 289/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4148 - accuracy: 0.8038 - val_loss: 0.5284 - val_accuracy: 0.7500\n",
            "Epoch 290/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4146 - accuracy: 0.8021 - val_loss: 0.5286 - val_accuracy: 0.7500\n",
            "Epoch 291/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4145 - accuracy: 0.8038 - val_loss: 0.5287 - val_accuracy: 0.7500\n",
            "Epoch 292/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4146 - accuracy: 0.8038 - val_loss: 0.5286 - val_accuracy: 0.7500\n",
            "Epoch 293/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4143 - accuracy: 0.8038 - val_loss: 0.5286 - val_accuracy: 0.7500\n",
            "Epoch 294/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4143 - accuracy: 0.8038 - val_loss: 0.5288 - val_accuracy: 0.7500\n",
            "Epoch 295/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4142 - accuracy: 0.8038 - val_loss: 0.5289 - val_accuracy: 0.7500\n",
            "Epoch 296/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4141 - accuracy: 0.8021 - val_loss: 0.5290 - val_accuracy: 0.7500\n",
            "Epoch 297/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4140 - accuracy: 0.8038 - val_loss: 0.5291 - val_accuracy: 0.7500\n",
            "Epoch 298/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4138 - accuracy: 0.8021 - val_loss: 0.5291 - val_accuracy: 0.7500\n",
            "Epoch 299/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4138 - accuracy: 0.8021 - val_loss: 0.5292 - val_accuracy: 0.7500\n",
            "Epoch 300/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4138 - accuracy: 0.8003 - val_loss: 0.5292 - val_accuracy: 0.7500\n",
            "Epoch 301/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4137 - accuracy: 0.8021 - val_loss: 0.5293 - val_accuracy: 0.7500\n",
            "Epoch 302/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4135 - accuracy: 0.8056 - val_loss: 0.5293 - val_accuracy: 0.7500\n",
            "Epoch 303/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4133 - accuracy: 0.8038 - val_loss: 0.5294 - val_accuracy: 0.7500\n",
            "Epoch 304/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4134 - accuracy: 0.8021 - val_loss: 0.5294 - val_accuracy: 0.7500\n",
            "Epoch 305/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4132 - accuracy: 0.8021 - val_loss: 0.5295 - val_accuracy: 0.7500\n",
            "Epoch 306/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4132 - accuracy: 0.8021 - val_loss: 0.5297 - val_accuracy: 0.7500\n",
            "Epoch 307/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4129 - accuracy: 0.8021 - val_loss: 0.5298 - val_accuracy: 0.7500\n",
            "Epoch 308/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4129 - accuracy: 0.8038 - val_loss: 0.5299 - val_accuracy: 0.7500\n",
            "Epoch 309/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4129 - accuracy: 0.8021 - val_loss: 0.5300 - val_accuracy: 0.7552\n",
            "Epoch 310/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4128 - accuracy: 0.8038 - val_loss: 0.5300 - val_accuracy: 0.7552\n",
            "Epoch 311/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4127 - accuracy: 0.8056 - val_loss: 0.5301 - val_accuracy: 0.7552\n",
            "Epoch 312/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4126 - accuracy: 0.8038 - val_loss: 0.5303 - val_accuracy: 0.7552\n",
            "Epoch 313/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4125 - accuracy: 0.8038 - val_loss: 0.5305 - val_accuracy: 0.7552\n",
            "Epoch 314/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4123 - accuracy: 0.8021 - val_loss: 0.5305 - val_accuracy: 0.7552\n",
            "Epoch 315/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4123 - accuracy: 0.8038 - val_loss: 0.5305 - val_accuracy: 0.7552\n",
            "Epoch 316/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4122 - accuracy: 0.8038 - val_loss: 0.5308 - val_accuracy: 0.7552\n",
            "Epoch 317/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4121 - accuracy: 0.8021 - val_loss: 0.5309 - val_accuracy: 0.7604\n",
            "Epoch 318/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4121 - accuracy: 0.8021 - val_loss: 0.5312 - val_accuracy: 0.7604\n",
            "Epoch 319/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4119 - accuracy: 0.8056 - val_loss: 0.5313 - val_accuracy: 0.7604\n",
            "Epoch 320/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4119 - accuracy: 0.8038 - val_loss: 0.5315 - val_accuracy: 0.7604\n",
            "Epoch 321/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4117 - accuracy: 0.8038 - val_loss: 0.5316 - val_accuracy: 0.7604\n",
            "Epoch 322/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4116 - accuracy: 0.8056 - val_loss: 0.5317 - val_accuracy: 0.7604\n",
            "Epoch 323/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4115 - accuracy: 0.8038 - val_loss: 0.5317 - val_accuracy: 0.7604\n",
            "Epoch 324/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4114 - accuracy: 0.8073 - val_loss: 0.5319 - val_accuracy: 0.7604\n",
            "Epoch 325/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4113 - accuracy: 0.8038 - val_loss: 0.5323 - val_accuracy: 0.7604\n",
            "Epoch 326/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4112 - accuracy: 0.8056 - val_loss: 0.5324 - val_accuracy: 0.7604\n",
            "Epoch 327/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4111 - accuracy: 0.8056 - val_loss: 0.5324 - val_accuracy: 0.7604\n",
            "Epoch 328/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4110 - accuracy: 0.8038 - val_loss: 0.5326 - val_accuracy: 0.7604\n",
            "Epoch 329/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4111 - accuracy: 0.8056 - val_loss: 0.5327 - val_accuracy: 0.7604\n",
            "Epoch 330/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4110 - accuracy: 0.8038 - val_loss: 0.5327 - val_accuracy: 0.7604\n",
            "Epoch 331/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4108 - accuracy: 0.8056 - val_loss: 0.5329 - val_accuracy: 0.7604\n",
            "Epoch 332/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4107 - accuracy: 0.8038 - val_loss: 0.5330 - val_accuracy: 0.7604\n",
            "Epoch 333/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4107 - accuracy: 0.8056 - val_loss: 0.5331 - val_accuracy: 0.7604\n",
            "Epoch 334/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8056 - val_loss: 0.5334 - val_accuracy: 0.7604\n",
            "Epoch 335/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8038 - val_loss: 0.5335 - val_accuracy: 0.7552\n",
            "Epoch 336/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4102 - accuracy: 0.8038 - val_loss: 0.5336 - val_accuracy: 0.7552\n",
            "Epoch 337/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4102 - accuracy: 0.8056 - val_loss: 0.5337 - val_accuracy: 0.7552\n",
            "Epoch 338/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4100 - accuracy: 0.8056 - val_loss: 0.5340 - val_accuracy: 0.7552\n",
            "Epoch 339/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4100 - accuracy: 0.8056 - val_loss: 0.5341 - val_accuracy: 0.7552\n",
            "Epoch 340/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4100 - accuracy: 0.8056 - val_loss: 0.5341 - val_accuracy: 0.7552\n",
            "Epoch 341/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4100 - accuracy: 0.8056 - val_loss: 0.5342 - val_accuracy: 0.7552\n",
            "Epoch 342/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4097 - accuracy: 0.8056 - val_loss: 0.5343 - val_accuracy: 0.7552\n",
            "Epoch 343/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4097 - accuracy: 0.8056 - val_loss: 0.5345 - val_accuracy: 0.7604\n",
            "Epoch 344/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4095 - accuracy: 0.8038 - val_loss: 0.5346 - val_accuracy: 0.7604\n",
            "Epoch 345/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4096 - accuracy: 0.8038 - val_loss: 0.5346 - val_accuracy: 0.7604\n",
            "Epoch 346/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4093 - accuracy: 0.8021 - val_loss: 0.5348 - val_accuracy: 0.7604\n",
            "Epoch 347/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4093 - accuracy: 0.8021 - val_loss: 0.5349 - val_accuracy: 0.7604\n",
            "Epoch 348/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4092 - accuracy: 0.8021 - val_loss: 0.5350 - val_accuracy: 0.7604\n",
            "Epoch 349/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4092 - accuracy: 0.8038 - val_loss: 0.5351 - val_accuracy: 0.7604\n",
            "Epoch 350/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4091 - accuracy: 0.8038 - val_loss: 0.5354 - val_accuracy: 0.7604\n",
            "Epoch 351/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4091 - accuracy: 0.8021 - val_loss: 0.5355 - val_accuracy: 0.7604\n",
            "Epoch 352/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4090 - accuracy: 0.8038 - val_loss: 0.5357 - val_accuracy: 0.7604\n",
            "Epoch 353/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4089 - accuracy: 0.8021 - val_loss: 0.5358 - val_accuracy: 0.7604\n",
            "Epoch 354/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4089 - accuracy: 0.8021 - val_loss: 0.5359 - val_accuracy: 0.7604\n",
            "Epoch 355/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4087 - accuracy: 0.8038 - val_loss: 0.5360 - val_accuracy: 0.7604\n",
            "Epoch 356/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4087 - accuracy: 0.8003 - val_loss: 0.5363 - val_accuracy: 0.7604\n",
            "Epoch 357/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4087 - accuracy: 0.8038 - val_loss: 0.5362 - val_accuracy: 0.7604\n",
            "Epoch 358/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4084 - accuracy: 0.8038 - val_loss: 0.5363 - val_accuracy: 0.7604\n",
            "Epoch 359/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4085 - accuracy: 0.8056 - val_loss: 0.5367 - val_accuracy: 0.7604\n",
            "Epoch 360/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4084 - accuracy: 0.8038 - val_loss: 0.5368 - val_accuracy: 0.7604\n",
            "Epoch 361/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4082 - accuracy: 0.8038 - val_loss: 0.5371 - val_accuracy: 0.7604\n",
            "Epoch 362/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4082 - accuracy: 0.8038 - val_loss: 0.5371 - val_accuracy: 0.7604\n",
            "Epoch 363/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4081 - accuracy: 0.8056 - val_loss: 0.5374 - val_accuracy: 0.7604\n",
            "Epoch 364/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4082 - accuracy: 0.8056 - val_loss: 0.5375 - val_accuracy: 0.7604\n",
            "Epoch 365/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4082 - accuracy: 0.8056 - val_loss: 0.5376 - val_accuracy: 0.7604\n",
            "Epoch 366/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4079 - accuracy: 0.8056 - val_loss: 0.5376 - val_accuracy: 0.7604\n",
            "Epoch 367/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4080 - accuracy: 0.8073 - val_loss: 0.5379 - val_accuracy: 0.7604\n",
            "Epoch 368/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4078 - accuracy: 0.8073 - val_loss: 0.5381 - val_accuracy: 0.7552\n",
            "Epoch 369/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4076 - accuracy: 0.8073 - val_loss: 0.5382 - val_accuracy: 0.7552\n",
            "Epoch 370/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4080 - accuracy: 0.8038 - val_loss: 0.5383 - val_accuracy: 0.7552\n",
            "Epoch 371/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4075 - accuracy: 0.8073 - val_loss: 0.5385 - val_accuracy: 0.7552\n",
            "Epoch 372/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4075 - accuracy: 0.8038 - val_loss: 0.5386 - val_accuracy: 0.7552\n",
            "Epoch 373/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4074 - accuracy: 0.8038 - val_loss: 0.5386 - val_accuracy: 0.7552\n",
            "Epoch 374/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4074 - accuracy: 0.8056 - val_loss: 0.5387 - val_accuracy: 0.7552\n",
            "Epoch 375/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4074 - accuracy: 0.8090 - val_loss: 0.5388 - val_accuracy: 0.7552\n",
            "Epoch 376/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4073 - accuracy: 0.8090 - val_loss: 0.5393 - val_accuracy: 0.7552\n",
            "Epoch 377/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4073 - accuracy: 0.8073 - val_loss: 0.5394 - val_accuracy: 0.7552\n",
            "Epoch 378/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4071 - accuracy: 0.8090 - val_loss: 0.5396 - val_accuracy: 0.7552\n",
            "Epoch 379/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4071 - accuracy: 0.8073 - val_loss: 0.5396 - val_accuracy: 0.7552\n",
            "Epoch 380/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4071 - accuracy: 0.8056 - val_loss: 0.5396 - val_accuracy: 0.7552\n",
            "Epoch 381/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4069 - accuracy: 0.8073 - val_loss: 0.5397 - val_accuracy: 0.7552\n",
            "Epoch 382/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4071 - accuracy: 0.8073 - val_loss: 0.5400 - val_accuracy: 0.7552\n",
            "Epoch 383/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4068 - accuracy: 0.8073 - val_loss: 0.5400 - val_accuracy: 0.7552\n",
            "Epoch 384/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4068 - accuracy: 0.8073 - val_loss: 0.5401 - val_accuracy: 0.7500\n",
            "Epoch 385/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4068 - accuracy: 0.8073 - val_loss: 0.5404 - val_accuracy: 0.7552\n",
            "Epoch 386/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4067 - accuracy: 0.8073 - val_loss: 0.5406 - val_accuracy: 0.7552\n",
            "Epoch 387/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4067 - accuracy: 0.8073 - val_loss: 0.5407 - val_accuracy: 0.7552\n",
            "Epoch 388/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4066 - accuracy: 0.8056 - val_loss: 0.5407 - val_accuracy: 0.7500\n",
            "Epoch 389/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4065 - accuracy: 0.8073 - val_loss: 0.5407 - val_accuracy: 0.7500\n",
            "Epoch 390/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4066 - accuracy: 0.8056 - val_loss: 0.5408 - val_accuracy: 0.7500\n",
            "Epoch 391/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4064 - accuracy: 0.8038 - val_loss: 0.5408 - val_accuracy: 0.7500\n",
            "Epoch 392/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4064 - accuracy: 0.8056 - val_loss: 0.5412 - val_accuracy: 0.7552\n",
            "Epoch 393/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4064 - accuracy: 0.8073 - val_loss: 0.5411 - val_accuracy: 0.7500\n",
            "Epoch 394/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4062 - accuracy: 0.8073 - val_loss: 0.5416 - val_accuracy: 0.7552\n",
            "Epoch 395/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4062 - accuracy: 0.8056 - val_loss: 0.5418 - val_accuracy: 0.7552\n",
            "Epoch 396/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4060 - accuracy: 0.8021 - val_loss: 0.5417 - val_accuracy: 0.7552\n",
            "Epoch 397/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4062 - accuracy: 0.8056 - val_loss: 0.5417 - val_accuracy: 0.7500\n",
            "Epoch 398/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4063 - accuracy: 0.8056 - val_loss: 0.5419 - val_accuracy: 0.7552\n",
            "Epoch 399/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4061 - accuracy: 0.8073 - val_loss: 0.5418 - val_accuracy: 0.7500\n",
            "Epoch 400/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4061 - accuracy: 0.8056 - val_loss: 0.5420 - val_accuracy: 0.7552\n",
            "Epoch 401/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4057 - accuracy: 0.8073 - val_loss: 0.5422 - val_accuracy: 0.7500\n",
            "Epoch 402/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4059 - accuracy: 0.8090 - val_loss: 0.5423 - val_accuracy: 0.7500\n",
            "Epoch 403/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4056 - accuracy: 0.8056 - val_loss: 0.5424 - val_accuracy: 0.7500\n",
            "Epoch 404/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4057 - accuracy: 0.8073 - val_loss: 0.5425 - val_accuracy: 0.7500\n",
            "Epoch 405/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4056 - accuracy: 0.8038 - val_loss: 0.5425 - val_accuracy: 0.7500\n",
            "Epoch 406/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4056 - accuracy: 0.8056 - val_loss: 0.5426 - val_accuracy: 0.7500\n",
            "Epoch 407/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4055 - accuracy: 0.8056 - val_loss: 0.5427 - val_accuracy: 0.7500\n",
            "Epoch 408/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4055 - accuracy: 0.8073 - val_loss: 0.5429 - val_accuracy: 0.7500\n",
            "Epoch 409/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4053 - accuracy: 0.8056 - val_loss: 0.5432 - val_accuracy: 0.7656\n",
            "Epoch 410/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4055 - accuracy: 0.8090 - val_loss: 0.5431 - val_accuracy: 0.7552\n",
            "Epoch 411/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4054 - accuracy: 0.8090 - val_loss: 0.5430 - val_accuracy: 0.7552\n",
            "Epoch 412/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4052 - accuracy: 0.8073 - val_loss: 0.5431 - val_accuracy: 0.7552\n",
            "Epoch 413/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4050 - accuracy: 0.8073 - val_loss: 0.5432 - val_accuracy: 0.7552\n",
            "Epoch 414/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4052 - accuracy: 0.8073 - val_loss: 0.5432 - val_accuracy: 0.7552\n",
            "Epoch 415/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4051 - accuracy: 0.8090 - val_loss: 0.5431 - val_accuracy: 0.7552\n",
            "Epoch 416/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4052 - accuracy: 0.8073 - val_loss: 0.5434 - val_accuracy: 0.7552\n",
            "Epoch 417/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4050 - accuracy: 0.8108 - val_loss: 0.5438 - val_accuracy: 0.7552\n",
            "Epoch 418/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4048 - accuracy: 0.8108 - val_loss: 0.5437 - val_accuracy: 0.7552\n",
            "Epoch 419/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4049 - accuracy: 0.8108 - val_loss: 0.5438 - val_accuracy: 0.7500\n",
            "Epoch 420/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4048 - accuracy: 0.8108 - val_loss: 0.5438 - val_accuracy: 0.7500\n",
            "Epoch 421/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4050 - accuracy: 0.8125 - val_loss: 0.5441 - val_accuracy: 0.7500\n",
            "Epoch 422/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4048 - accuracy: 0.8125 - val_loss: 0.5443 - val_accuracy: 0.7500\n",
            "Epoch 423/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4046 - accuracy: 0.8125 - val_loss: 0.5445 - val_accuracy: 0.7448\n",
            "Epoch 424/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4047 - accuracy: 0.8125 - val_loss: 0.5445 - val_accuracy: 0.7500\n",
            "Epoch 425/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4047 - accuracy: 0.8125 - val_loss: 0.5447 - val_accuracy: 0.7448\n",
            "Epoch 426/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4047 - accuracy: 0.8125 - val_loss: 0.5444 - val_accuracy: 0.7500\n",
            "Epoch 427/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4044 - accuracy: 0.8108 - val_loss: 0.5446 - val_accuracy: 0.7500\n",
            "Epoch 428/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4045 - accuracy: 0.8160 - val_loss: 0.5446 - val_accuracy: 0.7500\n",
            "Epoch 429/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4044 - accuracy: 0.8125 - val_loss: 0.5449 - val_accuracy: 0.7448\n",
            "Epoch 430/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4043 - accuracy: 0.8142 - val_loss: 0.5452 - val_accuracy: 0.7448\n",
            "Epoch 431/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4043 - accuracy: 0.8160 - val_loss: 0.5452 - val_accuracy: 0.7448\n",
            "Epoch 432/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4042 - accuracy: 0.8160 - val_loss: 0.5453 - val_accuracy: 0.7500\n",
            "Epoch 433/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4042 - accuracy: 0.8160 - val_loss: 0.5452 - val_accuracy: 0.7500\n",
            "Epoch 434/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4041 - accuracy: 0.8142 - val_loss: 0.5453 - val_accuracy: 0.7500\n",
            "Epoch 435/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4040 - accuracy: 0.8160 - val_loss: 0.5452 - val_accuracy: 0.7500\n",
            "Epoch 436/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4040 - accuracy: 0.8177 - val_loss: 0.5451 - val_accuracy: 0.7500\n",
            "Epoch 437/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4039 - accuracy: 0.8194 - val_loss: 0.5452 - val_accuracy: 0.7500\n",
            "Epoch 438/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4038 - accuracy: 0.8177 - val_loss: 0.5454 - val_accuracy: 0.7448\n",
            "Epoch 439/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4038 - accuracy: 0.8177 - val_loss: 0.5455 - val_accuracy: 0.7500\n",
            "Epoch 440/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4038 - accuracy: 0.8177 - val_loss: 0.5455 - val_accuracy: 0.7448\n",
            "Epoch 441/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4038 - accuracy: 0.8142 - val_loss: 0.5454 - val_accuracy: 0.7448\n",
            "Epoch 442/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4037 - accuracy: 0.8160 - val_loss: 0.5453 - val_accuracy: 0.7448\n",
            "Epoch 443/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4036 - accuracy: 0.8177 - val_loss: 0.5455 - val_accuracy: 0.7448\n",
            "Epoch 444/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4034 - accuracy: 0.8177 - val_loss: 0.5457 - val_accuracy: 0.7448\n",
            "Epoch 445/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4035 - accuracy: 0.8177 - val_loss: 0.5456 - val_accuracy: 0.7448\n",
            "Epoch 446/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4035 - accuracy: 0.8177 - val_loss: 0.5459 - val_accuracy: 0.7500\n",
            "Epoch 447/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4034 - accuracy: 0.8194 - val_loss: 0.5459 - val_accuracy: 0.7500\n",
            "Epoch 448/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4033 - accuracy: 0.8194 - val_loss: 0.5459 - val_accuracy: 0.7500\n",
            "Epoch 449/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4033 - accuracy: 0.8177 - val_loss: 0.5460 - val_accuracy: 0.7500\n",
            "Epoch 450/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4031 - accuracy: 0.8177 - val_loss: 0.5458 - val_accuracy: 0.7448\n",
            "Epoch 451/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4031 - accuracy: 0.8212 - val_loss: 0.5462 - val_accuracy: 0.7500\n",
            "Epoch 452/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4030 - accuracy: 0.8177 - val_loss: 0.5465 - val_accuracy: 0.7500\n",
            "Epoch 453/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4030 - accuracy: 0.8177 - val_loss: 0.5466 - val_accuracy: 0.7500\n",
            "Epoch 454/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4030 - accuracy: 0.8194 - val_loss: 0.5467 - val_accuracy: 0.7500\n",
            "Epoch 455/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4028 - accuracy: 0.8160 - val_loss: 0.5466 - val_accuracy: 0.7500\n",
            "Epoch 456/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4029 - accuracy: 0.8194 - val_loss: 0.5465 - val_accuracy: 0.7500\n",
            "Epoch 457/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4027 - accuracy: 0.8177 - val_loss: 0.5464 - val_accuracy: 0.7448\n",
            "Epoch 458/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4027 - accuracy: 0.8177 - val_loss: 0.5467 - val_accuracy: 0.7500\n",
            "Epoch 459/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4026 - accuracy: 0.8177 - val_loss: 0.5467 - val_accuracy: 0.7500\n",
            "Epoch 460/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4027 - accuracy: 0.8194 - val_loss: 0.5470 - val_accuracy: 0.7500\n",
            "Epoch 461/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4025 - accuracy: 0.8177 - val_loss: 0.5470 - val_accuracy: 0.7500\n",
            "Epoch 462/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4026 - accuracy: 0.8160 - val_loss: 0.5472 - val_accuracy: 0.7500\n",
            "Epoch 463/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4023 - accuracy: 0.8160 - val_loss: 0.5472 - val_accuracy: 0.7500\n",
            "Epoch 464/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4023 - accuracy: 0.8160 - val_loss: 0.5471 - val_accuracy: 0.7500\n",
            "Epoch 465/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4024 - accuracy: 0.8194 - val_loss: 0.5474 - val_accuracy: 0.7500\n",
            "Epoch 466/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4025 - accuracy: 0.8160 - val_loss: 0.5473 - val_accuracy: 0.7500\n",
            "Epoch 467/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4021 - accuracy: 0.8177 - val_loss: 0.5472 - val_accuracy: 0.7448\n",
            "Epoch 468/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4021 - accuracy: 0.8177 - val_loss: 0.5473 - val_accuracy: 0.7448\n",
            "Epoch 469/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4022 - accuracy: 0.8194 - val_loss: 0.5475 - val_accuracy: 0.7500\n",
            "Epoch 470/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4021 - accuracy: 0.8177 - val_loss: 0.5476 - val_accuracy: 0.7500\n",
            "Epoch 471/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4019 - accuracy: 0.8194 - val_loss: 0.5477 - val_accuracy: 0.7500\n",
            "Epoch 472/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4019 - accuracy: 0.8177 - val_loss: 0.5477 - val_accuracy: 0.7500\n",
            "Epoch 473/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4018 - accuracy: 0.8177 - val_loss: 0.5478 - val_accuracy: 0.7500\n",
            "Epoch 474/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4018 - accuracy: 0.8212 - val_loss: 0.5481 - val_accuracy: 0.7500\n",
            "Epoch 475/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4018 - accuracy: 0.8160 - val_loss: 0.5482 - val_accuracy: 0.7500\n",
            "Epoch 476/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4017 - accuracy: 0.8212 - val_loss: 0.5482 - val_accuracy: 0.7500\n",
            "Epoch 477/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4017 - accuracy: 0.8212 - val_loss: 0.5486 - val_accuracy: 0.7500\n",
            "Epoch 478/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4016 - accuracy: 0.8160 - val_loss: 0.5487 - val_accuracy: 0.7500\n",
            "Epoch 479/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4016 - accuracy: 0.8194 - val_loss: 0.5488 - val_accuracy: 0.7500\n",
            "Epoch 480/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4019 - accuracy: 0.8194 - val_loss: 0.5489 - val_accuracy: 0.7448\n",
            "Epoch 481/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4015 - accuracy: 0.8212 - val_loss: 0.5490 - val_accuracy: 0.7396\n",
            "Epoch 482/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4015 - accuracy: 0.8212 - val_loss: 0.5491 - val_accuracy: 0.7396\n",
            "Epoch 483/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4013 - accuracy: 0.8194 - val_loss: 0.5492 - val_accuracy: 0.7396\n",
            "Epoch 484/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4014 - accuracy: 0.8229 - val_loss: 0.5498 - val_accuracy: 0.7396\n",
            "Epoch 485/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4013 - accuracy: 0.8194 - val_loss: 0.5496 - val_accuracy: 0.7396\n",
            "Epoch 486/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4013 - accuracy: 0.8177 - val_loss: 0.5495 - val_accuracy: 0.7396\n",
            "Epoch 487/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4013 - accuracy: 0.8194 - val_loss: 0.5499 - val_accuracy: 0.7396\n",
            "Epoch 488/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4012 - accuracy: 0.8194 - val_loss: 0.5499 - val_accuracy: 0.7396\n",
            "Epoch 489/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4010 - accuracy: 0.8212 - val_loss: 0.5503 - val_accuracy: 0.7396\n",
            "Epoch 490/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4012 - accuracy: 0.8177 - val_loss: 0.5501 - val_accuracy: 0.7396\n",
            "Epoch 491/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4010 - accuracy: 0.8247 - val_loss: 0.5506 - val_accuracy: 0.7396\n",
            "Epoch 492/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4008 - accuracy: 0.8194 - val_loss: 0.5506 - val_accuracy: 0.7396\n",
            "Epoch 493/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4011 - accuracy: 0.8177 - val_loss: 0.5505 - val_accuracy: 0.7396\n",
            "Epoch 494/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4008 - accuracy: 0.8212 - val_loss: 0.5506 - val_accuracy: 0.7396\n",
            "Epoch 495/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4008 - accuracy: 0.8177 - val_loss: 0.5506 - val_accuracy: 0.7344\n",
            "Epoch 496/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4008 - accuracy: 0.8194 - val_loss: 0.5506 - val_accuracy: 0.7344\n",
            "Epoch 497/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4007 - accuracy: 0.8229 - val_loss: 0.5509 - val_accuracy: 0.7344\n",
            "Epoch 498/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4006 - accuracy: 0.8212 - val_loss: 0.5509 - val_accuracy: 0.7344\n",
            "Epoch 499/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4007 - accuracy: 0.8212 - val_loss: 0.5510 - val_accuracy: 0.7344\n",
            "Epoch 500/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4007 - accuracy: 0.8247 - val_loss: 0.5513 - val_accuracy: 0.7344\n",
            "Epoch 501/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4005 - accuracy: 0.8247 - val_loss: 0.5515 - val_accuracy: 0.7292\n",
            "Epoch 502/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4005 - accuracy: 0.8264 - val_loss: 0.5515 - val_accuracy: 0.7292\n",
            "Epoch 503/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4004 - accuracy: 0.8264 - val_loss: 0.5517 - val_accuracy: 0.7292\n",
            "Epoch 504/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4006 - accuracy: 0.8247 - val_loss: 0.5516 - val_accuracy: 0.7292\n",
            "Epoch 505/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4003 - accuracy: 0.8264 - val_loss: 0.5518 - val_accuracy: 0.7292\n",
            "Epoch 506/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4005 - accuracy: 0.8264 - val_loss: 0.5522 - val_accuracy: 0.7292\n",
            "Epoch 507/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4003 - accuracy: 0.8229 - val_loss: 0.5521 - val_accuracy: 0.7292\n",
            "Epoch 508/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4003 - accuracy: 0.8247 - val_loss: 0.5524 - val_accuracy: 0.7292\n",
            "Epoch 509/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4001 - accuracy: 0.8229 - val_loss: 0.5526 - val_accuracy: 0.7292\n",
            "Epoch 510/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4002 - accuracy: 0.8247 - val_loss: 0.5527 - val_accuracy: 0.7292\n",
            "Epoch 511/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4002 - accuracy: 0.8194 - val_loss: 0.5528 - val_accuracy: 0.7292\n",
            "Epoch 512/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3998 - accuracy: 0.8229 - val_loss: 0.5527 - val_accuracy: 0.7292\n",
            "Epoch 513/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3999 - accuracy: 0.8247 - val_loss: 0.5529 - val_accuracy: 0.7292\n",
            "Epoch 514/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3999 - accuracy: 0.8247 - val_loss: 0.5530 - val_accuracy: 0.7292\n",
            "Epoch 515/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3999 - accuracy: 0.8247 - val_loss: 0.5532 - val_accuracy: 0.7292\n",
            "Epoch 516/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3999 - accuracy: 0.8212 - val_loss: 0.5534 - val_accuracy: 0.7292\n",
            "Epoch 517/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3999 - accuracy: 0.8264 - val_loss: 0.5534 - val_accuracy: 0.7292\n",
            "Epoch 518/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3997 - accuracy: 0.8264 - val_loss: 0.5536 - val_accuracy: 0.7292\n",
            "Epoch 519/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3995 - accuracy: 0.8247 - val_loss: 0.5537 - val_accuracy: 0.7292\n",
            "Epoch 520/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3996 - accuracy: 0.8247 - val_loss: 0.5538 - val_accuracy: 0.7292\n",
            "Epoch 521/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3997 - accuracy: 0.8247 - val_loss: 0.5537 - val_accuracy: 0.7292\n",
            "Epoch 522/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3995 - accuracy: 0.8264 - val_loss: 0.5539 - val_accuracy: 0.7292\n",
            "Epoch 523/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3996 - accuracy: 0.8247 - val_loss: 0.5535 - val_accuracy: 0.7292\n",
            "Epoch 524/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3994 - accuracy: 0.8247 - val_loss: 0.5535 - val_accuracy: 0.7292\n",
            "Epoch 525/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3994 - accuracy: 0.8264 - val_loss: 0.5538 - val_accuracy: 0.7292\n",
            "Epoch 526/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3994 - accuracy: 0.8229 - val_loss: 0.5538 - val_accuracy: 0.7292\n",
            "Epoch 527/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3991 - accuracy: 0.8247 - val_loss: 0.5540 - val_accuracy: 0.7292\n",
            "Epoch 528/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3993 - accuracy: 0.8264 - val_loss: 0.5542 - val_accuracy: 0.7292\n",
            "Epoch 529/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3993 - accuracy: 0.8264 - val_loss: 0.5545 - val_accuracy: 0.7292\n",
            "Epoch 530/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3993 - accuracy: 0.8264 - val_loss: 0.5546 - val_accuracy: 0.7292\n",
            "Epoch 531/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3991 - accuracy: 0.8281 - val_loss: 0.5547 - val_accuracy: 0.7292\n",
            "Epoch 532/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3992 - accuracy: 0.8281 - val_loss: 0.5549 - val_accuracy: 0.7292\n",
            "Epoch 533/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3990 - accuracy: 0.8264 - val_loss: 0.5549 - val_accuracy: 0.7292\n",
            "Epoch 534/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3990 - accuracy: 0.8264 - val_loss: 0.5550 - val_accuracy: 0.7292\n",
            "Epoch 535/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3989 - accuracy: 0.8247 - val_loss: 0.5548 - val_accuracy: 0.7292\n",
            "Epoch 536/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3989 - accuracy: 0.8281 - val_loss: 0.5551 - val_accuracy: 0.7292\n",
            "Epoch 537/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3988 - accuracy: 0.8281 - val_loss: 0.5554 - val_accuracy: 0.7292\n",
            "Epoch 538/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3986 - accuracy: 0.8264 - val_loss: 0.5557 - val_accuracy: 0.7292\n",
            "Epoch 539/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3989 - accuracy: 0.8299 - val_loss: 0.5557 - val_accuracy: 0.7292\n",
            "Epoch 540/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3987 - accuracy: 0.8281 - val_loss: 0.5558 - val_accuracy: 0.7292\n",
            "Epoch 541/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3987 - accuracy: 0.8247 - val_loss: 0.5559 - val_accuracy: 0.7292\n",
            "Epoch 542/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3987 - accuracy: 0.8299 - val_loss: 0.5557 - val_accuracy: 0.7292\n",
            "Epoch 543/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3986 - accuracy: 0.8281 - val_loss: 0.5559 - val_accuracy: 0.7292\n",
            "Epoch 544/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3986 - accuracy: 0.8299 - val_loss: 0.5561 - val_accuracy: 0.7292\n",
            "Epoch 545/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3985 - accuracy: 0.8281 - val_loss: 0.5560 - val_accuracy: 0.7292\n",
            "Epoch 546/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3984 - accuracy: 0.8281 - val_loss: 0.5559 - val_accuracy: 0.7292\n",
            "Epoch 547/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3984 - accuracy: 0.8299 - val_loss: 0.5560 - val_accuracy: 0.7240\n",
            "Epoch 548/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3984 - accuracy: 0.8299 - val_loss: 0.5562 - val_accuracy: 0.7240\n",
            "Epoch 549/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3984 - accuracy: 0.8299 - val_loss: 0.5560 - val_accuracy: 0.7240\n",
            "Epoch 550/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3983 - accuracy: 0.8299 - val_loss: 0.5564 - val_accuracy: 0.7240\n",
            "Epoch 551/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3984 - accuracy: 0.8281 - val_loss: 0.5572 - val_accuracy: 0.7292\n",
            "Epoch 552/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3983 - accuracy: 0.8281 - val_loss: 0.5569 - val_accuracy: 0.7240\n",
            "Epoch 553/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3983 - accuracy: 0.8299 - val_loss: 0.5567 - val_accuracy: 0.7240\n",
            "Epoch 554/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3982 - accuracy: 0.8299 - val_loss: 0.5569 - val_accuracy: 0.7240\n",
            "Epoch 555/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3980 - accuracy: 0.8299 - val_loss: 0.5573 - val_accuracy: 0.7292\n",
            "Epoch 556/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3981 - accuracy: 0.8316 - val_loss: 0.5571 - val_accuracy: 0.7240\n",
            "Epoch 557/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3981 - accuracy: 0.8316 - val_loss: 0.5572 - val_accuracy: 0.7240\n",
            "Epoch 558/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3981 - accuracy: 0.8316 - val_loss: 0.5573 - val_accuracy: 0.7240\n",
            "Epoch 559/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3980 - accuracy: 0.8299 - val_loss: 0.5576 - val_accuracy: 0.7240\n",
            "Epoch 560/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3979 - accuracy: 0.8299 - val_loss: 0.5577 - val_accuracy: 0.7240\n",
            "Epoch 561/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3981 - accuracy: 0.8299 - val_loss: 0.5580 - val_accuracy: 0.7240\n",
            "Epoch 562/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3978 - accuracy: 0.8333 - val_loss: 0.5581 - val_accuracy: 0.7240\n",
            "Epoch 563/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3978 - accuracy: 0.8281 - val_loss: 0.5583 - val_accuracy: 0.7292\n",
            "Epoch 564/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3979 - accuracy: 0.8299 - val_loss: 0.5582 - val_accuracy: 0.7240\n",
            "Epoch 565/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3977 - accuracy: 0.8333 - val_loss: 0.5584 - val_accuracy: 0.7240\n",
            "Epoch 566/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3978 - accuracy: 0.8316 - val_loss: 0.5585 - val_accuracy: 0.7240\n",
            "Epoch 567/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3979 - accuracy: 0.8281 - val_loss: 0.5584 - val_accuracy: 0.7240\n",
            "Epoch 568/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3977 - accuracy: 0.8299 - val_loss: 0.5589 - val_accuracy: 0.7240\n",
            "Epoch 569/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3977 - accuracy: 0.8281 - val_loss: 0.5591 - val_accuracy: 0.7240\n",
            "Epoch 570/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3978 - accuracy: 0.8299 - val_loss: 0.5590 - val_accuracy: 0.7240\n",
            "Epoch 571/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3976 - accuracy: 0.8333 - val_loss: 0.5592 - val_accuracy: 0.7240\n",
            "Epoch 572/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3976 - accuracy: 0.8281 - val_loss: 0.5594 - val_accuracy: 0.7240\n",
            "Epoch 573/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3976 - accuracy: 0.8316 - val_loss: 0.5598 - val_accuracy: 0.7240\n",
            "Epoch 574/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3976 - accuracy: 0.8316 - val_loss: 0.5599 - val_accuracy: 0.7240\n",
            "Epoch 575/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3975 - accuracy: 0.8316 - val_loss: 0.5597 - val_accuracy: 0.7240\n",
            "Epoch 576/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3974 - accuracy: 0.8281 - val_loss: 0.5602 - val_accuracy: 0.7240\n",
            "Epoch 577/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3976 - accuracy: 0.8299 - val_loss: 0.5602 - val_accuracy: 0.7240\n",
            "Epoch 578/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3975 - accuracy: 0.8299 - val_loss: 0.5602 - val_accuracy: 0.7240\n",
            "Epoch 579/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3973 - accuracy: 0.8299 - val_loss: 0.5601 - val_accuracy: 0.7240\n",
            "Epoch 580/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3972 - accuracy: 0.8281 - val_loss: 0.5603 - val_accuracy: 0.7240\n",
            "Epoch 581/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3974 - accuracy: 0.8316 - val_loss: 0.5606 - val_accuracy: 0.7240\n",
            "Epoch 582/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3972 - accuracy: 0.8281 - val_loss: 0.5605 - val_accuracy: 0.7240\n",
            "Epoch 583/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3973 - accuracy: 0.8281 - val_loss: 0.5605 - val_accuracy: 0.7240\n",
            "Epoch 584/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3973 - accuracy: 0.8316 - val_loss: 0.5609 - val_accuracy: 0.7240\n",
            "Epoch 585/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3973 - accuracy: 0.8316 - val_loss: 0.5605 - val_accuracy: 0.7240\n",
            "Epoch 586/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3975 - accuracy: 0.8281 - val_loss: 0.5609 - val_accuracy: 0.7240\n",
            "Epoch 587/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3972 - accuracy: 0.8299 - val_loss: 0.5613 - val_accuracy: 0.7240\n",
            "Epoch 588/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3973 - accuracy: 0.8316 - val_loss: 0.5615 - val_accuracy: 0.7240\n",
            "Epoch 589/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3973 - accuracy: 0.8299 - val_loss: 0.5616 - val_accuracy: 0.7240\n",
            "Epoch 590/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3971 - accuracy: 0.8316 - val_loss: 0.5619 - val_accuracy: 0.7240\n",
            "Epoch 591/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3973 - accuracy: 0.8299 - val_loss: 0.5619 - val_accuracy: 0.7240\n",
            "Epoch 592/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3970 - accuracy: 0.8316 - val_loss: 0.5617 - val_accuracy: 0.7240\n",
            "Epoch 593/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3970 - accuracy: 0.8333 - val_loss: 0.5617 - val_accuracy: 0.7240\n",
            "Epoch 594/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3974 - accuracy: 0.8299 - val_loss: 0.5619 - val_accuracy: 0.7240\n",
            "Epoch 595/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3972 - accuracy: 0.8299 - val_loss: 0.5621 - val_accuracy: 0.7240\n",
            "Epoch 596/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3973 - accuracy: 0.8299 - val_loss: 0.5622 - val_accuracy: 0.7240\n",
            "Epoch 597/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3970 - accuracy: 0.8316 - val_loss: 0.5627 - val_accuracy: 0.7240\n",
            "Epoch 598/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3968 - accuracy: 0.8316 - val_loss: 0.5626 - val_accuracy: 0.7240\n",
            "Epoch 599/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3969 - accuracy: 0.8316 - val_loss: 0.5626 - val_accuracy: 0.7240\n",
            "Epoch 600/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3971 - accuracy: 0.8316 - val_loss: 0.5630 - val_accuracy: 0.7240\n",
            "Epoch 601/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3971 - accuracy: 0.8299 - val_loss: 0.5631 - val_accuracy: 0.7240\n",
            "Epoch 602/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3971 - accuracy: 0.8316 - val_loss: 0.5632 - val_accuracy: 0.7240\n",
            "Epoch 603/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3968 - accuracy: 0.8316 - val_loss: 0.5633 - val_accuracy: 0.7240\n",
            "Epoch 604/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3970 - accuracy: 0.8316 - val_loss: 0.5634 - val_accuracy: 0.7240\n",
            "Epoch 605/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3967 - accuracy: 0.8299 - val_loss: 0.5633 - val_accuracy: 0.7240\n",
            "Epoch 606/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3968 - accuracy: 0.8316 - val_loss: 0.5631 - val_accuracy: 0.7240\n",
            "Epoch 607/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3968 - accuracy: 0.8316 - val_loss: 0.5626 - val_accuracy: 0.7292\n",
            "Epoch 608/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3966 - accuracy: 0.8316 - val_loss: 0.5628 - val_accuracy: 0.7240\n",
            "Epoch 609/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3967 - accuracy: 0.8299 - val_loss: 0.5632 - val_accuracy: 0.7240\n",
            "Epoch 610/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3966 - accuracy: 0.8299 - val_loss: 0.5635 - val_accuracy: 0.7240\n",
            "Epoch 611/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3967 - accuracy: 0.8299 - val_loss: 0.5634 - val_accuracy: 0.7240\n",
            "Epoch 612/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3965 - accuracy: 0.8299 - val_loss: 0.5636 - val_accuracy: 0.7240\n",
            "Epoch 613/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3965 - accuracy: 0.8299 - val_loss: 0.5642 - val_accuracy: 0.7240\n",
            "Epoch 614/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3966 - accuracy: 0.8299 - val_loss: 0.5648 - val_accuracy: 0.7240\n",
            "Epoch 615/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3966 - accuracy: 0.8299 - val_loss: 0.5647 - val_accuracy: 0.7240\n",
            "Epoch 616/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3966 - accuracy: 0.8299 - val_loss: 0.5649 - val_accuracy: 0.7240\n",
            "Epoch 617/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3963 - accuracy: 0.8316 - val_loss: 0.5649 - val_accuracy: 0.7240\n",
            "Epoch 618/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3965 - accuracy: 0.8299 - val_loss: 0.5650 - val_accuracy: 0.7240\n",
            "Epoch 619/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3964 - accuracy: 0.8281 - val_loss: 0.5649 - val_accuracy: 0.7240\n",
            "Epoch 620/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3965 - accuracy: 0.8299 - val_loss: 0.5651 - val_accuracy: 0.7292\n",
            "Epoch 621/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3965 - accuracy: 0.8299 - val_loss: 0.5654 - val_accuracy: 0.7292\n",
            "Epoch 622/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3965 - accuracy: 0.8299 - val_loss: 0.5659 - val_accuracy: 0.7292\n",
            "Epoch 623/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3966 - accuracy: 0.8281 - val_loss: 0.5659 - val_accuracy: 0.7292\n",
            "Epoch 624/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3964 - accuracy: 0.8281 - val_loss: 0.5659 - val_accuracy: 0.7292\n",
            "Epoch 625/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3966 - accuracy: 0.8281 - val_loss: 0.5659 - val_accuracy: 0.7292\n",
            "Epoch 626/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3963 - accuracy: 0.8299 - val_loss: 0.5660 - val_accuracy: 0.7292\n",
            "Epoch 627/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3964 - accuracy: 0.8281 - val_loss: 0.5662 - val_accuracy: 0.7292\n",
            "Epoch 628/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3961 - accuracy: 0.8281 - val_loss: 0.5661 - val_accuracy: 0.7292\n",
            "Epoch 629/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3962 - accuracy: 0.8299 - val_loss: 0.5660 - val_accuracy: 0.7292\n",
            "Epoch 630/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3962 - accuracy: 0.8281 - val_loss: 0.5659 - val_accuracy: 0.7240\n",
            "Epoch 631/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3963 - accuracy: 0.8316 - val_loss: 0.5663 - val_accuracy: 0.7240\n",
            "Epoch 632/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3964 - accuracy: 0.8316 - val_loss: 0.5662 - val_accuracy: 0.7292\n",
            "Epoch 633/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3962 - accuracy: 0.8299 - val_loss: 0.5664 - val_accuracy: 0.7292\n",
            "Epoch 634/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3962 - accuracy: 0.8281 - val_loss: 0.5659 - val_accuracy: 0.7292\n",
            "Epoch 635/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3963 - accuracy: 0.8299 - val_loss: 0.5661 - val_accuracy: 0.7292\n",
            "Epoch 636/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3962 - accuracy: 0.8316 - val_loss: 0.5663 - val_accuracy: 0.7292\n",
            "Epoch 637/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3961 - accuracy: 0.8299 - val_loss: 0.5658 - val_accuracy: 0.7292\n",
            "Epoch 638/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3960 - accuracy: 0.8299 - val_loss: 0.5658 - val_accuracy: 0.7292\n",
            "Epoch 639/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3961 - accuracy: 0.8316 - val_loss: 0.5654 - val_accuracy: 0.7292\n",
            "Epoch 640/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3959 - accuracy: 0.8299 - val_loss: 0.5660 - val_accuracy: 0.7292\n",
            "Epoch 641/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3960 - accuracy: 0.8299 - val_loss: 0.5664 - val_accuracy: 0.7292\n",
            "Epoch 642/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3960 - accuracy: 0.8299 - val_loss: 0.5662 - val_accuracy: 0.7292\n",
            "Epoch 643/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3961 - accuracy: 0.8316 - val_loss: 0.5663 - val_accuracy: 0.7292\n",
            "Epoch 644/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3962 - accuracy: 0.8316 - val_loss: 0.5661 - val_accuracy: 0.7292\n",
            "Epoch 645/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3960 - accuracy: 0.8299 - val_loss: 0.5665 - val_accuracy: 0.7344\n",
            "Epoch 646/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3961 - accuracy: 0.8299 - val_loss: 0.5667 - val_accuracy: 0.7344\n",
            "Epoch 647/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3959 - accuracy: 0.8299 - val_loss: 0.5663 - val_accuracy: 0.7344\n",
            "Epoch 648/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3959 - accuracy: 0.8299 - val_loss: 0.5665 - val_accuracy: 0.7344\n",
            "Epoch 649/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3958 - accuracy: 0.8299 - val_loss: 0.5666 - val_accuracy: 0.7344\n",
            "Epoch 650/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.3958 - accuracy: 0.8316 - val_loss: 0.5670 - val_accuracy: 0.7344\n",
            "Epoch 651/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3958 - accuracy: 0.8281 - val_loss: 0.5663 - val_accuracy: 0.7344\n",
            "Epoch 652/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3958 - accuracy: 0.8299 - val_loss: 0.5663 - val_accuracy: 0.7344\n",
            "Epoch 653/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3958 - accuracy: 0.8316 - val_loss: 0.5664 - val_accuracy: 0.7344\n",
            "Epoch 654/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3958 - accuracy: 0.8299 - val_loss: 0.5667 - val_accuracy: 0.7344\n",
            "Epoch 655/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3959 - accuracy: 0.8299 - val_loss: 0.5670 - val_accuracy: 0.7344\n",
            "Epoch 656/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3958 - accuracy: 0.8316 - val_loss: 0.5673 - val_accuracy: 0.7344\n",
            "Epoch 657/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3959 - accuracy: 0.8333 - val_loss: 0.5669 - val_accuracy: 0.7344\n",
            "Epoch 658/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3959 - accuracy: 0.8299 - val_loss: 0.5668 - val_accuracy: 0.7344\n",
            "Epoch 659/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3959 - accuracy: 0.8299 - val_loss: 0.5671 - val_accuracy: 0.7344\n",
            "Epoch 660/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3958 - accuracy: 0.8281 - val_loss: 0.5670 - val_accuracy: 0.7344\n",
            "Epoch 661/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3956 - accuracy: 0.8299 - val_loss: 0.5665 - val_accuracy: 0.7344\n",
            "Epoch 662/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3959 - accuracy: 0.8299 - val_loss: 0.5663 - val_accuracy: 0.7344\n",
            "Epoch 663/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3959 - accuracy: 0.8299 - val_loss: 0.5658 - val_accuracy: 0.7344\n",
            "Epoch 664/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3955 - accuracy: 0.8316 - val_loss: 0.5662 - val_accuracy: 0.7344\n",
            "Epoch 665/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3958 - accuracy: 0.8316 - val_loss: 0.5669 - val_accuracy: 0.7344\n",
            "Epoch 666/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3957 - accuracy: 0.8281 - val_loss: 0.5665 - val_accuracy: 0.7344\n",
            "Epoch 667/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3957 - accuracy: 0.8316 - val_loss: 0.5664 - val_accuracy: 0.7344\n",
            "Epoch 668/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3957 - accuracy: 0.8299 - val_loss: 0.5666 - val_accuracy: 0.7344\n",
            "Epoch 669/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3956 - accuracy: 0.8316 - val_loss: 0.5667 - val_accuracy: 0.7344\n",
            "Epoch 670/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3955 - accuracy: 0.8299 - val_loss: 0.5667 - val_accuracy: 0.7344\n",
            "Epoch 671/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3954 - accuracy: 0.8316 - val_loss: 0.5669 - val_accuracy: 0.7344\n",
            "Epoch 672/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3953 - accuracy: 0.8299 - val_loss: 0.5673 - val_accuracy: 0.7344\n",
            "Epoch 673/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3957 - accuracy: 0.8316 - val_loss: 0.5667 - val_accuracy: 0.7344\n",
            "Epoch 674/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3955 - accuracy: 0.8281 - val_loss: 0.5662 - val_accuracy: 0.7344\n",
            "Epoch 675/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3955 - accuracy: 0.8316 - val_loss: 0.5665 - val_accuracy: 0.7292\n",
            "Epoch 676/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3955 - accuracy: 0.8281 - val_loss: 0.5668 - val_accuracy: 0.7292\n",
            "Epoch 677/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3954 - accuracy: 0.8299 - val_loss: 0.5673 - val_accuracy: 0.7344\n",
            "Epoch 678/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3955 - accuracy: 0.8299 - val_loss: 0.5673 - val_accuracy: 0.7292\n",
            "Epoch 679/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3955 - accuracy: 0.8281 - val_loss: 0.5676 - val_accuracy: 0.7292\n",
            "Epoch 680/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3953 - accuracy: 0.8281 - val_loss: 0.5671 - val_accuracy: 0.7292\n",
            "Epoch 681/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3953 - accuracy: 0.8316 - val_loss: 0.5669 - val_accuracy: 0.7292\n",
            "Epoch 682/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3953 - accuracy: 0.8299 - val_loss: 0.5669 - val_accuracy: 0.7292\n",
            "Epoch 683/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3953 - accuracy: 0.8281 - val_loss: 0.5667 - val_accuracy: 0.7292\n",
            "Epoch 684/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3954 - accuracy: 0.8316 - val_loss: 0.5672 - val_accuracy: 0.7292\n",
            "Epoch 685/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3953 - accuracy: 0.8316 - val_loss: 0.5677 - val_accuracy: 0.7292\n",
            "Epoch 686/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3953 - accuracy: 0.8299 - val_loss: 0.5682 - val_accuracy: 0.7292\n",
            "Epoch 687/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3952 - accuracy: 0.8281 - val_loss: 0.5677 - val_accuracy: 0.7292\n",
            "Epoch 688/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3954 - accuracy: 0.8316 - val_loss: 0.5681 - val_accuracy: 0.7292\n",
            "Epoch 689/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3953 - accuracy: 0.8299 - val_loss: 0.5680 - val_accuracy: 0.7292\n",
            "Epoch 690/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3952 - accuracy: 0.8281 - val_loss: 0.5685 - val_accuracy: 0.7292\n",
            "Epoch 691/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3952 - accuracy: 0.8281 - val_loss: 0.5683 - val_accuracy: 0.7292\n",
            "Epoch 692/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3952 - accuracy: 0.8281 - val_loss: 0.5684 - val_accuracy: 0.7292\n",
            "Epoch 693/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3952 - accuracy: 0.8299 - val_loss: 0.5682 - val_accuracy: 0.7292\n",
            "Epoch 694/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3950 - accuracy: 0.8299 - val_loss: 0.5677 - val_accuracy: 0.7292\n",
            "Epoch 695/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3951 - accuracy: 0.8281 - val_loss: 0.5680 - val_accuracy: 0.7292\n",
            "Epoch 696/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3949 - accuracy: 0.8299 - val_loss: 0.5683 - val_accuracy: 0.7292\n",
            "Epoch 697/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3949 - accuracy: 0.8281 - val_loss: 0.5679 - val_accuracy: 0.7292\n",
            "Epoch 698/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3950 - accuracy: 0.8264 - val_loss: 0.5677 - val_accuracy: 0.7292\n",
            "Epoch 699/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3949 - accuracy: 0.8316 - val_loss: 0.5680 - val_accuracy: 0.7292\n",
            "Epoch 700/1500\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.3954 - accuracy: 0.8281 - val_loss: 0.5684 - val_accuracy: 0.7292\n",
            "Epoch 701/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3951 - accuracy: 0.8281 - val_loss: 0.5690 - val_accuracy: 0.7292\n",
            "Epoch 702/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3948 - accuracy: 0.8281 - val_loss: 0.5686 - val_accuracy: 0.7292\n",
            "Epoch 703/1500\n",
            "18/18 [==============================] - 0s 19ms/step - loss: 0.3949 - accuracy: 0.8264 - val_loss: 0.5681 - val_accuracy: 0.7292\n",
            "Epoch 704/1500\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 0.3950 - accuracy: 0.8281 - val_loss: 0.5685 - val_accuracy: 0.7292\n",
            "Epoch 705/1500\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.3948 - accuracy: 0.8281 - val_loss: 0.5684 - val_accuracy: 0.7292\n",
            "Epoch 706/1500\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.3948 - accuracy: 0.8299 - val_loss: 0.5683 - val_accuracy: 0.7292\n",
            "Epoch 707/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3948 - accuracy: 0.8299 - val_loss: 0.5681 - val_accuracy: 0.7292\n",
            "Epoch 708/1500\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.3947 - accuracy: 0.8281 - val_loss: 0.5681 - val_accuracy: 0.7292\n",
            "Epoch 709/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3947 - accuracy: 0.8299 - val_loss: 0.5685 - val_accuracy: 0.7292\n",
            "Epoch 710/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.3947 - accuracy: 0.8299 - val_loss: 0.5687 - val_accuracy: 0.7292\n",
            "Epoch 711/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.3948 - accuracy: 0.8281 - val_loss: 0.5688 - val_accuracy: 0.7292\n",
            "Epoch 712/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3947 - accuracy: 0.8299 - val_loss: 0.5690 - val_accuracy: 0.7292\n",
            "Epoch 713/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.3948 - accuracy: 0.8281 - val_loss: 0.5687 - val_accuracy: 0.7292\n",
            "Epoch 714/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.3949 - accuracy: 0.8299 - val_loss: 0.5682 - val_accuracy: 0.7292\n",
            "Epoch 715/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3947 - accuracy: 0.8281 - val_loss: 0.5686 - val_accuracy: 0.7292\n",
            "Epoch 716/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3947 - accuracy: 0.8299 - val_loss: 0.5684 - val_accuracy: 0.7292\n",
            "Epoch 717/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3947 - accuracy: 0.8299 - val_loss: 0.5686 - val_accuracy: 0.7292\n",
            "Epoch 718/1500\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.3946 - accuracy: 0.8299 - val_loss: 0.5694 - val_accuracy: 0.7292\n",
            "Epoch 719/1500\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.3944 - accuracy: 0.8281 - val_loss: 0.5692 - val_accuracy: 0.7292\n",
            "Epoch 720/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3946 - accuracy: 0.8281 - val_loss: 0.5688 - val_accuracy: 0.7292\n",
            "Epoch 721/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3946 - accuracy: 0.8264 - val_loss: 0.5688 - val_accuracy: 0.7292\n",
            "Epoch 722/1500\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.3946 - accuracy: 0.8281 - val_loss: 0.5690 - val_accuracy: 0.7292\n",
            "Epoch 723/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3945 - accuracy: 0.8281 - val_loss: 0.5695 - val_accuracy: 0.7292\n",
            "Epoch 724/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3946 - accuracy: 0.8264 - val_loss: 0.5693 - val_accuracy: 0.7292\n",
            "Epoch 725/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3945 - accuracy: 0.8264 - val_loss: 0.5692 - val_accuracy: 0.7292\n",
            "Epoch 726/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3944 - accuracy: 0.8316 - val_loss: 0.5689 - val_accuracy: 0.7292\n",
            "Epoch 727/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3945 - accuracy: 0.8281 - val_loss: 0.5694 - val_accuracy: 0.7292\n",
            "Epoch 728/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3947 - accuracy: 0.8299 - val_loss: 0.5697 - val_accuracy: 0.7292\n",
            "Epoch 729/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3944 - accuracy: 0.8299 - val_loss: 0.5692 - val_accuracy: 0.7292\n",
            "Epoch 730/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3944 - accuracy: 0.8281 - val_loss: 0.5695 - val_accuracy: 0.7292\n",
            "Epoch 731/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3944 - accuracy: 0.8281 - val_loss: 0.5698 - val_accuracy: 0.7292\n",
            "Epoch 732/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3944 - accuracy: 0.8281 - val_loss: 0.5697 - val_accuracy: 0.7292\n",
            "Epoch 733/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3945 - accuracy: 0.8316 - val_loss: 0.5696 - val_accuracy: 0.7292\n",
            "Epoch 734/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3944 - accuracy: 0.8281 - val_loss: 0.5692 - val_accuracy: 0.7292\n",
            "Epoch 735/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3944 - accuracy: 0.8281 - val_loss: 0.5693 - val_accuracy: 0.7292\n",
            "Epoch 736/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3944 - accuracy: 0.8264 - val_loss: 0.5695 - val_accuracy: 0.7292\n",
            "Epoch 737/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3942 - accuracy: 0.8264 - val_loss: 0.5692 - val_accuracy: 0.7292\n",
            "Epoch 738/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3943 - accuracy: 0.8264 - val_loss: 0.5692 - val_accuracy: 0.7292\n",
            "Epoch 739/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3945 - accuracy: 0.8281 - val_loss: 0.5700 - val_accuracy: 0.7292\n",
            "Epoch 740/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3944 - accuracy: 0.8281 - val_loss: 0.5701 - val_accuracy: 0.7292\n",
            "Epoch 741/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3944 - accuracy: 0.8264 - val_loss: 0.5699 - val_accuracy: 0.7292\n",
            "Epoch 742/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3945 - accuracy: 0.8281 - val_loss: 0.5694 - val_accuracy: 0.7292\n",
            "Epoch 743/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3942 - accuracy: 0.8281 - val_loss: 0.5698 - val_accuracy: 0.7292\n",
            "Epoch 744/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3941 - accuracy: 0.8264 - val_loss: 0.5695 - val_accuracy: 0.7292\n",
            "Epoch 745/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3942 - accuracy: 0.8264 - val_loss: 0.5697 - val_accuracy: 0.7292\n",
            "Epoch 746/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3941 - accuracy: 0.8264 - val_loss: 0.5699 - val_accuracy: 0.7292\n",
            "Epoch 747/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3943 - accuracy: 0.8264 - val_loss: 0.5703 - val_accuracy: 0.7292\n",
            "Epoch 748/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3942 - accuracy: 0.8281 - val_loss: 0.5700 - val_accuracy: 0.7292\n",
            "Epoch 749/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3943 - accuracy: 0.8264 - val_loss: 0.5700 - val_accuracy: 0.7292\n",
            "Epoch 750/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3943 - accuracy: 0.8264 - val_loss: 0.5699 - val_accuracy: 0.7292\n",
            "Epoch 751/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3941 - accuracy: 0.8281 - val_loss: 0.5702 - val_accuracy: 0.7292\n",
            "Epoch 752/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3942 - accuracy: 0.8264 - val_loss: 0.5701 - val_accuracy: 0.7344\n",
            "Epoch 753/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3943 - accuracy: 0.8264 - val_loss: 0.5703 - val_accuracy: 0.7344\n",
            "Epoch 754/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3942 - accuracy: 0.8281 - val_loss: 0.5704 - val_accuracy: 0.7344\n",
            "Epoch 755/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3941 - accuracy: 0.8264 - val_loss: 0.5701 - val_accuracy: 0.7344\n",
            "Epoch 756/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3944 - accuracy: 0.8281 - val_loss: 0.5709 - val_accuracy: 0.7344\n",
            "Epoch 757/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3940 - accuracy: 0.8281 - val_loss: 0.5704 - val_accuracy: 0.7344\n",
            "Epoch 758/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3943 - accuracy: 0.8264 - val_loss: 0.5706 - val_accuracy: 0.7344\n",
            "Epoch 759/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3940 - accuracy: 0.8264 - val_loss: 0.5702 - val_accuracy: 0.7344\n",
            "Epoch 760/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3942 - accuracy: 0.8247 - val_loss: 0.5705 - val_accuracy: 0.7344\n",
            "Epoch 761/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3940 - accuracy: 0.8247 - val_loss: 0.5701 - val_accuracy: 0.7344\n",
            "Epoch 762/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3940 - accuracy: 0.8281 - val_loss: 0.5697 - val_accuracy: 0.7344\n",
            "Epoch 763/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3941 - accuracy: 0.8264 - val_loss: 0.5700 - val_accuracy: 0.7344\n",
            "Epoch 764/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3940 - accuracy: 0.8264 - val_loss: 0.5700 - val_accuracy: 0.7344\n",
            "Epoch 765/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3939 - accuracy: 0.8264 - val_loss: 0.5702 - val_accuracy: 0.7344\n",
            "Epoch 766/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3941 - accuracy: 0.8247 - val_loss: 0.5700 - val_accuracy: 0.7344\n",
            "Epoch 767/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3938 - accuracy: 0.8281 - val_loss: 0.5703 - val_accuracy: 0.7344\n",
            "Epoch 768/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3940 - accuracy: 0.8247 - val_loss: 0.5700 - val_accuracy: 0.7344\n",
            "Epoch 769/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3941 - accuracy: 0.8281 - val_loss: 0.5705 - val_accuracy: 0.7344\n",
            "Epoch 770/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3942 - accuracy: 0.8247 - val_loss: 0.5708 - val_accuracy: 0.7344\n",
            "Epoch 771/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3940 - accuracy: 0.8264 - val_loss: 0.5711 - val_accuracy: 0.7396\n",
            "Epoch 772/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3940 - accuracy: 0.8281 - val_loss: 0.5710 - val_accuracy: 0.7448\n",
            "Epoch 773/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3940 - accuracy: 0.8264 - val_loss: 0.5711 - val_accuracy: 0.7448\n",
            "Epoch 774/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3938 - accuracy: 0.8281 - val_loss: 0.5708 - val_accuracy: 0.7396\n",
            "Epoch 775/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3939 - accuracy: 0.8264 - val_loss: 0.5710 - val_accuracy: 0.7344\n",
            "Epoch 776/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3939 - accuracy: 0.8264 - val_loss: 0.5714 - val_accuracy: 0.7396\n",
            "Epoch 777/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3938 - accuracy: 0.8247 - val_loss: 0.5710 - val_accuracy: 0.7396\n",
            "Epoch 778/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3937 - accuracy: 0.8299 - val_loss: 0.5715 - val_accuracy: 0.7344\n",
            "Epoch 779/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3939 - accuracy: 0.8264 - val_loss: 0.5723 - val_accuracy: 0.7396\n",
            "Epoch 780/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3937 - accuracy: 0.8264 - val_loss: 0.5720 - val_accuracy: 0.7396\n",
            "Epoch 781/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3939 - accuracy: 0.8281 - val_loss: 0.5715 - val_accuracy: 0.7500\n",
            "Epoch 782/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3938 - accuracy: 0.8281 - val_loss: 0.5717 - val_accuracy: 0.7500\n",
            "Epoch 783/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3937 - accuracy: 0.8264 - val_loss: 0.5716 - val_accuracy: 0.7396\n",
            "Epoch 784/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3937 - accuracy: 0.8247 - val_loss: 0.5717 - val_accuracy: 0.7552\n",
            "Epoch 785/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3937 - accuracy: 0.8264 - val_loss: 0.5723 - val_accuracy: 0.7500\n",
            "Epoch 786/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3937 - accuracy: 0.8247 - val_loss: 0.5722 - val_accuracy: 0.7448\n",
            "Epoch 787/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3936 - accuracy: 0.8264 - val_loss: 0.5721 - val_accuracy: 0.7500\n",
            "Epoch 788/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3935 - accuracy: 0.8247 - val_loss: 0.5722 - val_accuracy: 0.7448\n",
            "Epoch 789/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3935 - accuracy: 0.8264 - val_loss: 0.5721 - val_accuracy: 0.7448\n",
            "Epoch 790/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3936 - accuracy: 0.8281 - val_loss: 0.5725 - val_accuracy: 0.7448\n",
            "Epoch 791/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3935 - accuracy: 0.8264 - val_loss: 0.5721 - val_accuracy: 0.7500\n",
            "Epoch 792/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3936 - accuracy: 0.8264 - val_loss: 0.5724 - val_accuracy: 0.7448\n",
            "Epoch 793/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3934 - accuracy: 0.8264 - val_loss: 0.5721 - val_accuracy: 0.7448\n",
            "Epoch 794/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3935 - accuracy: 0.8264 - val_loss: 0.5724 - val_accuracy: 0.7500\n",
            "Epoch 795/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3936 - accuracy: 0.8264 - val_loss: 0.5720 - val_accuracy: 0.7500\n",
            "Epoch 796/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3935 - accuracy: 0.8299 - val_loss: 0.5729 - val_accuracy: 0.7448\n",
            "Epoch 797/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3935 - accuracy: 0.8316 - val_loss: 0.5731 - val_accuracy: 0.7448\n",
            "Epoch 798/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3936 - accuracy: 0.8247 - val_loss: 0.5731 - val_accuracy: 0.7500\n",
            "Epoch 799/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3934 - accuracy: 0.8281 - val_loss: 0.5727 - val_accuracy: 0.7500\n",
            "Epoch 800/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3933 - accuracy: 0.8281 - val_loss: 0.5727 - val_accuracy: 0.7500\n",
            "Epoch 801/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3934 - accuracy: 0.8281 - val_loss: 0.5732 - val_accuracy: 0.7500\n",
            "Epoch 802/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3935 - accuracy: 0.8264 - val_loss: 0.5732 - val_accuracy: 0.7500\n",
            "Epoch 803/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3936 - accuracy: 0.8281 - val_loss: 0.5729 - val_accuracy: 0.7500\n",
            "Epoch 804/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3934 - accuracy: 0.8299 - val_loss: 0.5733 - val_accuracy: 0.7500\n",
            "Epoch 805/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3934 - accuracy: 0.8316 - val_loss: 0.5741 - val_accuracy: 0.7500\n",
            "Epoch 806/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3933 - accuracy: 0.8281 - val_loss: 0.5736 - val_accuracy: 0.7500\n",
            "Epoch 807/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3935 - accuracy: 0.8281 - val_loss: 0.5729 - val_accuracy: 0.7500\n",
            "Epoch 808/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3937 - accuracy: 0.8264 - val_loss: 0.5734 - val_accuracy: 0.7500\n",
            "Epoch 809/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3932 - accuracy: 0.8281 - val_loss: 0.5740 - val_accuracy: 0.7500\n",
            "Epoch 810/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3933 - accuracy: 0.8281 - val_loss: 0.5745 - val_accuracy: 0.7500\n",
            "Epoch 811/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3932 - accuracy: 0.8281 - val_loss: 0.5745 - val_accuracy: 0.7500\n",
            "Epoch 812/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3932 - accuracy: 0.8281 - val_loss: 0.5748 - val_accuracy: 0.7500\n",
            "Epoch 813/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3933 - accuracy: 0.8281 - val_loss: 0.5748 - val_accuracy: 0.7500\n",
            "Epoch 814/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3933 - accuracy: 0.8299 - val_loss: 0.5748 - val_accuracy: 0.7500\n",
            "Epoch 815/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3931 - accuracy: 0.8281 - val_loss: 0.5747 - val_accuracy: 0.7500\n",
            "Epoch 816/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3933 - accuracy: 0.8299 - val_loss: 0.5748 - val_accuracy: 0.7500\n",
            "Epoch 817/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3934 - accuracy: 0.8281 - val_loss: 0.5748 - val_accuracy: 0.7500\n",
            "Epoch 818/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3932 - accuracy: 0.8281 - val_loss: 0.5746 - val_accuracy: 0.7500\n",
            "Epoch 819/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3932 - accuracy: 0.8299 - val_loss: 0.5749 - val_accuracy: 0.7500\n",
            "Epoch 820/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3930 - accuracy: 0.8299 - val_loss: 0.5746 - val_accuracy: 0.7500\n",
            "Epoch 821/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3931 - accuracy: 0.8264 - val_loss: 0.5744 - val_accuracy: 0.7500\n",
            "Epoch 822/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3931 - accuracy: 0.8281 - val_loss: 0.5745 - val_accuracy: 0.7500\n",
            "Epoch 823/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3931 - accuracy: 0.8264 - val_loss: 0.5743 - val_accuracy: 0.7500\n",
            "Epoch 824/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3930 - accuracy: 0.8299 - val_loss: 0.5745 - val_accuracy: 0.7500\n",
            "Epoch 825/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3930 - accuracy: 0.8299 - val_loss: 0.5747 - val_accuracy: 0.7500\n",
            "Epoch 826/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3931 - accuracy: 0.8299 - val_loss: 0.5745 - val_accuracy: 0.7500\n",
            "Epoch 827/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3929 - accuracy: 0.8281 - val_loss: 0.5752 - val_accuracy: 0.7500\n",
            "Epoch 828/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3931 - accuracy: 0.8264 - val_loss: 0.5748 - val_accuracy: 0.7500\n",
            "Epoch 829/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3930 - accuracy: 0.8299 - val_loss: 0.5750 - val_accuracy: 0.7500\n",
            "Epoch 830/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3928 - accuracy: 0.8299 - val_loss: 0.5752 - val_accuracy: 0.7500\n",
            "Epoch 831/1500\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.3928 - accuracy: 0.8281 - val_loss: 0.5757 - val_accuracy: 0.7500\n",
            "Epoch 832/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3929 - accuracy: 0.8281 - val_loss: 0.5760 - val_accuracy: 0.7500\n",
            "Epoch 833/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3928 - accuracy: 0.8281 - val_loss: 0.5753 - val_accuracy: 0.7500\n",
            "Epoch 834/1500\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.3930 - accuracy: 0.8316 - val_loss: 0.5755 - val_accuracy: 0.7500\n",
            "Epoch 835/1500\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.3928 - accuracy: 0.8281 - val_loss: 0.5759 - val_accuracy: 0.7500\n",
            "Epoch 836/1500\n",
            "18/18 [==============================] - 0s 20ms/step - loss: 0.3928 - accuracy: 0.8281 - val_loss: 0.5760 - val_accuracy: 0.7500\n",
            "Epoch 837/1500\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.3928 - accuracy: 0.8299 - val_loss: 0.5761 - val_accuracy: 0.7500\n",
            "Epoch 838/1500\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.3929 - accuracy: 0.8281 - val_loss: 0.5758 - val_accuracy: 0.7500\n",
            "Epoch 839/1500\n",
            "18/18 [==============================] - 0s 19ms/step - loss: 0.3926 - accuracy: 0.8299 - val_loss: 0.5758 - val_accuracy: 0.7448\n",
            "Epoch 840/1500\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.3927 - accuracy: 0.8316 - val_loss: 0.5763 - val_accuracy: 0.7500\n",
            "Epoch 841/1500\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.3928 - accuracy: 0.8281 - val_loss: 0.5764 - val_accuracy: 0.7500\n",
            "Epoch 842/1500\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.3929 - accuracy: 0.8316 - val_loss: 0.5763 - val_accuracy: 0.7500\n",
            "Epoch 843/1500\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.3927 - accuracy: 0.8299 - val_loss: 0.5760 - val_accuracy: 0.7500\n",
            "Epoch 844/1500\n",
            "18/18 [==============================] - 0s 20ms/step - loss: 0.3926 - accuracy: 0.8316 - val_loss: 0.5759 - val_accuracy: 0.7500\n",
            "Epoch 845/1500\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.3925 - accuracy: 0.8316 - val_loss: 0.5756 - val_accuracy: 0.7500\n",
            "Epoch 846/1500\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.3927 - accuracy: 0.8281 - val_loss: 0.5763 - val_accuracy: 0.7500\n",
            "Epoch 847/1500\n",
            "18/18 [==============================] - 0s 19ms/step - loss: 0.3927 - accuracy: 0.8299 - val_loss: 0.5764 - val_accuracy: 0.7500\n",
            "Epoch 848/1500\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.3926 - accuracy: 0.8281 - val_loss: 0.5765 - val_accuracy: 0.7500\n",
            "Epoch 849/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3926 - accuracy: 0.8299 - val_loss: 0.5765 - val_accuracy: 0.7500\n",
            "Epoch 850/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3927 - accuracy: 0.8316 - val_loss: 0.5769 - val_accuracy: 0.7500\n",
            "Epoch 851/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3925 - accuracy: 0.8299 - val_loss: 0.5766 - val_accuracy: 0.7500\n",
            "Epoch 852/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3927 - accuracy: 0.8299 - val_loss: 0.5764 - val_accuracy: 0.7500\n",
            "Epoch 853/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3927 - accuracy: 0.8281 - val_loss: 0.5770 - val_accuracy: 0.7500\n",
            "Epoch 854/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3926 - accuracy: 0.8316 - val_loss: 0.5778 - val_accuracy: 0.7500\n",
            "Epoch 855/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3923 - accuracy: 0.8299 - val_loss: 0.5771 - val_accuracy: 0.7500\n",
            "Epoch 856/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3925 - accuracy: 0.8299 - val_loss: 0.5771 - val_accuracy: 0.7448\n",
            "Epoch 857/1500\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.3926 - accuracy: 0.8281 - val_loss: 0.5772 - val_accuracy: 0.7448\n",
            "Epoch 858/1500\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.3927 - accuracy: 0.8316 - val_loss: 0.5777 - val_accuracy: 0.7500\n",
            "Epoch 859/1500\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.3923 - accuracy: 0.8299 - val_loss: 0.5772 - val_accuracy: 0.7448\n",
            "Epoch 860/1500\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.3924 - accuracy: 0.8316 - val_loss: 0.5769 - val_accuracy: 0.7448\n",
            "Epoch 861/1500\n",
            "18/18 [==============================] - 0s 19ms/step - loss: 0.3925 - accuracy: 0.8299 - val_loss: 0.5765 - val_accuracy: 0.7448\n",
            "Epoch 862/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3924 - accuracy: 0.8316 - val_loss: 0.5772 - val_accuracy: 0.7448\n",
            "Epoch 863/1500\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.3922 - accuracy: 0.8281 - val_loss: 0.5770 - val_accuracy: 0.7448\n",
            "Epoch 864/1500\n",
            "18/18 [==============================] - 1s 29ms/step - loss: 0.3924 - accuracy: 0.8281 - val_loss: 0.5772 - val_accuracy: 0.7448\n",
            "Epoch 865/1500\n",
            "18/18 [==============================] - 0s 25ms/step - loss: 0.3925 - accuracy: 0.8281 - val_loss: 0.5779 - val_accuracy: 0.7448\n",
            "Epoch 866/1500\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.3922 - accuracy: 0.8281 - val_loss: 0.5773 - val_accuracy: 0.7448\n",
            "Epoch 867/1500\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.3923 - accuracy: 0.8264 - val_loss: 0.5772 - val_accuracy: 0.7448\n",
            "Epoch 868/1500\n",
            "18/18 [==============================] - 0s 27ms/step - loss: 0.3923 - accuracy: 0.8299 - val_loss: 0.5767 - val_accuracy: 0.7448\n",
            "Epoch 869/1500\n",
            "18/18 [==============================] - 0s 19ms/step - loss: 0.3922 - accuracy: 0.8299 - val_loss: 0.5771 - val_accuracy: 0.7448\n",
            "Epoch 870/1500\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.3922 - accuracy: 0.8281 - val_loss: 0.5771 - val_accuracy: 0.7448\n",
            "Epoch 871/1500\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.3921 - accuracy: 0.8299 - val_loss: 0.5774 - val_accuracy: 0.7448\n",
            "Epoch 872/1500\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.3923 - accuracy: 0.8299 - val_loss: 0.5768 - val_accuracy: 0.7448\n",
            "Epoch 873/1500\n",
            "18/18 [==============================] - 0s 19ms/step - loss: 0.3921 - accuracy: 0.8316 - val_loss: 0.5776 - val_accuracy: 0.7396\n",
            "Epoch 874/1500\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.3920 - accuracy: 0.8299 - val_loss: 0.5776 - val_accuracy: 0.7448\n",
            "Epoch 875/1500\n",
            "18/18 [==============================] - 0s 28ms/step - loss: 0.3922 - accuracy: 0.8264 - val_loss: 0.5774 - val_accuracy: 0.7448\n",
            "Epoch 876/1500\n",
            "18/18 [==============================] - 1s 36ms/step - loss: 0.3922 - accuracy: 0.8333 - val_loss: 0.5778 - val_accuracy: 0.7448\n",
            "Epoch 877/1500\n",
            "18/18 [==============================] - 0s 19ms/step - loss: 0.3922 - accuracy: 0.8316 - val_loss: 0.5781 - val_accuracy: 0.7448\n",
            "Epoch 878/1500\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.3921 - accuracy: 0.8281 - val_loss: 0.5778 - val_accuracy: 0.7448\n",
            "Epoch 879/1500\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 0.3922 - accuracy: 0.8281 - val_loss: 0.5778 - val_accuracy: 0.7448\n",
            "Epoch 880/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3921 - accuracy: 0.8281 - val_loss: 0.5785 - val_accuracy: 0.7396\n",
            "Epoch 881/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3920 - accuracy: 0.8299 - val_loss: 0.5790 - val_accuracy: 0.7396\n",
            "Epoch 882/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.3920 - accuracy: 0.8281 - val_loss: 0.5784 - val_accuracy: 0.7448\n",
            "Epoch 883/1500\n",
            "18/18 [==============================] - 0s 20ms/step - loss: 0.3920 - accuracy: 0.8264 - val_loss: 0.5785 - val_accuracy: 0.7448\n",
            "Epoch 884/1500\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 0.3920 - accuracy: 0.8281 - val_loss: 0.5786 - val_accuracy: 0.7448\n",
            "Epoch 885/1500\n",
            "18/18 [==============================] - 0s 28ms/step - loss: 0.3920 - accuracy: 0.8281 - val_loss: 0.5782 - val_accuracy: 0.7448\n",
            "Epoch 886/1500\n",
            "18/18 [==============================] - 1s 40ms/step - loss: 0.3921 - accuracy: 0.8281 - val_loss: 0.5780 - val_accuracy: 0.7448\n",
            "Epoch 887/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.3918 - accuracy: 0.8264 - val_loss: 0.5776 - val_accuracy: 0.7448\n",
            "Epoch 888/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3921 - accuracy: 0.8281 - val_loss: 0.5778 - val_accuracy: 0.7448\n",
            "Epoch 889/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3919 - accuracy: 0.8281 - val_loss: 0.5776 - val_accuracy: 0.7448\n",
            "Epoch 890/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3920 - accuracy: 0.8316 - val_loss: 0.5778 - val_accuracy: 0.7448\n",
            "Epoch 891/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3919 - accuracy: 0.8281 - val_loss: 0.5784 - val_accuracy: 0.7448\n",
            "Epoch 892/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3918 - accuracy: 0.8281 - val_loss: 0.5790 - val_accuracy: 0.7448\n",
            "Epoch 893/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3918 - accuracy: 0.8247 - val_loss: 0.5787 - val_accuracy: 0.7448\n",
            "Epoch 894/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3917 - accuracy: 0.8316 - val_loss: 0.5788 - val_accuracy: 0.7448\n",
            "Epoch 895/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3918 - accuracy: 0.8316 - val_loss: 0.5793 - val_accuracy: 0.7448\n",
            "Epoch 896/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3918 - accuracy: 0.8316 - val_loss: 0.5795 - val_accuracy: 0.7448\n",
            "Epoch 897/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3918 - accuracy: 0.8281 - val_loss: 0.5790 - val_accuracy: 0.7448\n",
            "Epoch 898/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3918 - accuracy: 0.8281 - val_loss: 0.5792 - val_accuracy: 0.7448\n",
            "Epoch 899/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3916 - accuracy: 0.8281 - val_loss: 0.5786 - val_accuracy: 0.7448\n",
            "Epoch 900/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3916 - accuracy: 0.8299 - val_loss: 0.5787 - val_accuracy: 0.7448\n",
            "Epoch 901/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3917 - accuracy: 0.8316 - val_loss: 0.5792 - val_accuracy: 0.7448\n",
            "Epoch 902/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3916 - accuracy: 0.8299 - val_loss: 0.5798 - val_accuracy: 0.7448\n",
            "Epoch 903/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3917 - accuracy: 0.8247 - val_loss: 0.5799 - val_accuracy: 0.7448\n",
            "Epoch 904/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.3916 - accuracy: 0.8299 - val_loss: 0.5807 - val_accuracy: 0.7448\n",
            "Epoch 905/1500\n",
            "18/18 [==============================] - 0s 26ms/step - loss: 0.3915 - accuracy: 0.8281 - val_loss: 0.5801 - val_accuracy: 0.7448\n",
            "Epoch 906/1500\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 0.3915 - accuracy: 0.8281 - val_loss: 0.5803 - val_accuracy: 0.7448\n",
            "Epoch 907/1500\n",
            "18/18 [==============================] - 0s 19ms/step - loss: 0.3917 - accuracy: 0.8299 - val_loss: 0.5799 - val_accuracy: 0.7448\n",
            "Epoch 908/1500\n",
            "18/18 [==============================] - 0s 25ms/step - loss: 0.3916 - accuracy: 0.8299 - val_loss: 0.5802 - val_accuracy: 0.7448\n",
            "Epoch 909/1500\n",
            "18/18 [==============================] - 0s 24ms/step - loss: 0.3917 - accuracy: 0.8316 - val_loss: 0.5803 - val_accuracy: 0.7448\n",
            "Epoch 910/1500\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.3914 - accuracy: 0.8281 - val_loss: 0.5797 - val_accuracy: 0.7448\n",
            "Epoch 911/1500\n",
            "18/18 [==============================] - 0s 24ms/step - loss: 0.3914 - accuracy: 0.8281 - val_loss: 0.5799 - val_accuracy: 0.7448\n",
            "Epoch 912/1500\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.3915 - accuracy: 0.8299 - val_loss: 0.5803 - val_accuracy: 0.7448\n",
            "Epoch 913/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.3917 - accuracy: 0.8299 - val_loss: 0.5800 - val_accuracy: 0.7448\n",
            "Epoch 914/1500\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.3914 - accuracy: 0.8316 - val_loss: 0.5800 - val_accuracy: 0.7448\n",
            "Epoch 915/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3916 - accuracy: 0.8281 - val_loss: 0.5802 - val_accuracy: 0.7448\n",
            "Epoch 916/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3913 - accuracy: 0.8316 - val_loss: 0.5802 - val_accuracy: 0.7448\n",
            "Epoch 917/1500\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.3914 - accuracy: 0.8281 - val_loss: 0.5799 - val_accuracy: 0.7448\n",
            "Epoch 918/1500\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.3913 - accuracy: 0.8316 - val_loss: 0.5803 - val_accuracy: 0.7448\n",
            "Epoch 919/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3913 - accuracy: 0.8264 - val_loss: 0.5802 - val_accuracy: 0.7448\n",
            "Epoch 920/1500\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.3913 - accuracy: 0.8299 - val_loss: 0.5805 - val_accuracy: 0.7448\n",
            "Epoch 921/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3913 - accuracy: 0.8316 - val_loss: 0.5809 - val_accuracy: 0.7448\n",
            "Epoch 922/1500\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.3913 - accuracy: 0.8299 - val_loss: 0.5806 - val_accuracy: 0.7448\n",
            "Epoch 923/1500\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 0.3914 - accuracy: 0.8247 - val_loss: 0.5810 - val_accuracy: 0.7448\n",
            "Epoch 924/1500\n",
            "18/18 [==============================] - 0s 20ms/step - loss: 0.3914 - accuracy: 0.8264 - val_loss: 0.5811 - val_accuracy: 0.7448\n",
            "Epoch 925/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3913 - accuracy: 0.8316 - val_loss: 0.5811 - val_accuracy: 0.7448\n",
            "Epoch 926/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3912 - accuracy: 0.8264 - val_loss: 0.5813 - val_accuracy: 0.7448\n",
            "Epoch 927/1500\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.3912 - accuracy: 0.8281 - val_loss: 0.5815 - val_accuracy: 0.7448\n",
            "Epoch 928/1500\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.3914 - accuracy: 0.8281 - val_loss: 0.5809 - val_accuracy: 0.7448\n",
            "Epoch 929/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3911 - accuracy: 0.8299 - val_loss: 0.5812 - val_accuracy: 0.7448\n",
            "Epoch 930/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3910 - accuracy: 0.8316 - val_loss: 0.5816 - val_accuracy: 0.7448\n",
            "Epoch 931/1500\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.3911 - accuracy: 0.8299 - val_loss: 0.5814 - val_accuracy: 0.7448\n",
            "Epoch 932/1500\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.3911 - accuracy: 0.8264 - val_loss: 0.5815 - val_accuracy: 0.7448\n",
            "Epoch 933/1500\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.3910 - accuracy: 0.8299 - val_loss: 0.5816 - val_accuracy: 0.7448\n",
            "Epoch 934/1500\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.3911 - accuracy: 0.8299 - val_loss: 0.5812 - val_accuracy: 0.7448\n",
            "Epoch 935/1500\n",
            "18/18 [==============================] - 0s 27ms/step - loss: 0.3909 - accuracy: 0.8264 - val_loss: 0.5807 - val_accuracy: 0.7448\n",
            "Epoch 936/1500\n",
            "18/18 [==============================] - 0s 26ms/step - loss: 0.3910 - accuracy: 0.8281 - val_loss: 0.5811 - val_accuracy: 0.7396\n",
            "Epoch 937/1500\n",
            "18/18 [==============================] - 0s 19ms/step - loss: 0.3909 - accuracy: 0.8299 - val_loss: 0.5813 - val_accuracy: 0.7448\n",
            "Epoch 938/1500\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.3909 - accuracy: 0.8281 - val_loss: 0.5813 - val_accuracy: 0.7448\n",
            "Epoch 939/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3910 - accuracy: 0.8281 - val_loss: 0.5813 - val_accuracy: 0.7448\n",
            "Epoch 940/1500\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.3908 - accuracy: 0.8264 - val_loss: 0.5818 - val_accuracy: 0.7448\n",
            "Epoch 941/1500\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 0.3908 - accuracy: 0.8264 - val_loss: 0.5817 - val_accuracy: 0.7448\n",
            "Epoch 942/1500\n",
            "18/18 [==============================] - 0s 20ms/step - loss: 0.3909 - accuracy: 0.8299 - val_loss: 0.5823 - val_accuracy: 0.7396\n",
            "Epoch 943/1500\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.3907 - accuracy: 0.8229 - val_loss: 0.5822 - val_accuracy: 0.7448\n",
            "Epoch 944/1500\n",
            "18/18 [==============================] - 0s 28ms/step - loss: 0.3908 - accuracy: 0.8264 - val_loss: 0.5817 - val_accuracy: 0.7448\n",
            "Epoch 945/1500\n",
            "18/18 [==============================] - 0s 27ms/step - loss: 0.3907 - accuracy: 0.8264 - val_loss: 0.5819 - val_accuracy: 0.7448\n",
            "Epoch 946/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3907 - accuracy: 0.8281 - val_loss: 0.5823 - val_accuracy: 0.7448\n",
            "Epoch 947/1500\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.3907 - accuracy: 0.8299 - val_loss: 0.5818 - val_accuracy: 0.7448\n",
            "Epoch 948/1500\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.3907 - accuracy: 0.8264 - val_loss: 0.5820 - val_accuracy: 0.7448\n",
            "Epoch 949/1500\n",
            "18/18 [==============================] - 0s 24ms/step - loss: 0.3907 - accuracy: 0.8264 - val_loss: 0.5820 - val_accuracy: 0.7552\n",
            "Epoch 950/1500\n",
            "18/18 [==============================] - 1s 29ms/step - loss: 0.3910 - accuracy: 0.8281 - val_loss: 0.5818 - val_accuracy: 0.7552\n",
            "Epoch 951/1500\n",
            "18/18 [==============================] - 1s 39ms/step - loss: 0.3908 - accuracy: 0.8299 - val_loss: 0.5819 - val_accuracy: 0.7552\n",
            "Epoch 952/1500\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.3905 - accuracy: 0.8316 - val_loss: 0.5822 - val_accuracy: 0.7552\n",
            "Epoch 953/1500\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.3905 - accuracy: 0.8351 - val_loss: 0.5825 - val_accuracy: 0.7552\n",
            "Epoch 954/1500\n",
            "18/18 [==============================] - 1s 39ms/step - loss: 0.3906 - accuracy: 0.8333 - val_loss: 0.5821 - val_accuracy: 0.7500\n",
            "Epoch 955/1500\n",
            "18/18 [==============================] - 1s 35ms/step - loss: 0.3904 - accuracy: 0.8333 - val_loss: 0.5825 - val_accuracy: 0.7552\n",
            "Epoch 956/1500\n",
            "18/18 [==============================] - 0s 24ms/step - loss: 0.3908 - accuracy: 0.8281 - val_loss: 0.5826 - val_accuracy: 0.7500\n",
            "Epoch 957/1500\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.3907 - accuracy: 0.8299 - val_loss: 0.5824 - val_accuracy: 0.7500\n",
            "Epoch 958/1500\n",
            "18/18 [==============================] - 0s 27ms/step - loss: 0.3905 - accuracy: 0.8299 - val_loss: 0.5825 - val_accuracy: 0.7500\n",
            "Epoch 959/1500\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.3905 - accuracy: 0.8299 - val_loss: 0.5826 - val_accuracy: 0.7448\n",
            "Epoch 960/1500\n",
            "18/18 [==============================] - 0s 26ms/step - loss: 0.3905 - accuracy: 0.8316 - val_loss: 0.5831 - val_accuracy: 0.7448\n",
            "Epoch 961/1500\n",
            "18/18 [==============================] - 0s 24ms/step - loss: 0.3905 - accuracy: 0.8281 - val_loss: 0.5825 - val_accuracy: 0.7448\n",
            "Epoch 962/1500\n",
            "18/18 [==============================] - 0s 20ms/step - loss: 0.3906 - accuracy: 0.8299 - val_loss: 0.5822 - val_accuracy: 0.7448\n",
            "Epoch 963/1500\n",
            "18/18 [==============================] - 0s 20ms/step - loss: 0.3903 - accuracy: 0.8316 - val_loss: 0.5823 - val_accuracy: 0.7448\n",
            "Epoch 964/1500\n",
            "18/18 [==============================] - 0s 25ms/step - loss: 0.3905 - accuracy: 0.8316 - val_loss: 0.5825 - val_accuracy: 0.7448\n",
            "Epoch 965/1500\n",
            "18/18 [==============================] - 0s 20ms/step - loss: 0.3903 - accuracy: 0.8333 - val_loss: 0.5831 - val_accuracy: 0.7448\n",
            "Epoch 966/1500\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.3903 - accuracy: 0.8299 - val_loss: 0.5829 - val_accuracy: 0.7448\n",
            "Epoch 967/1500\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.3903 - accuracy: 0.8316 - val_loss: 0.5834 - val_accuracy: 0.7448\n",
            "Epoch 968/1500\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.3901 - accuracy: 0.8299 - val_loss: 0.5832 - val_accuracy: 0.7448\n",
            "Epoch 969/1500\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.3903 - accuracy: 0.8333 - val_loss: 0.5830 - val_accuracy: 0.7448\n",
            "Epoch 970/1500\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 0.3904 - accuracy: 0.8299 - val_loss: 0.5825 - val_accuracy: 0.7448\n",
            "Epoch 971/1500\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.3903 - accuracy: 0.8316 - val_loss: 0.5825 - val_accuracy: 0.7448\n",
            "Epoch 972/1500\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.3903 - accuracy: 0.8316 - val_loss: 0.5830 - val_accuracy: 0.7500\n",
            "Epoch 973/1500\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.3901 - accuracy: 0.8316 - val_loss: 0.5829 - val_accuracy: 0.7500\n",
            "Epoch 974/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3902 - accuracy: 0.8281 - val_loss: 0.5831 - val_accuracy: 0.7500\n",
            "Epoch 975/1500\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.3902 - accuracy: 0.8316 - val_loss: 0.5829 - val_accuracy: 0.7500\n",
            "Epoch 976/1500\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.3902 - accuracy: 0.8281 - val_loss: 0.5826 - val_accuracy: 0.7500\n",
            "Epoch 977/1500\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.3902 - accuracy: 0.8299 - val_loss: 0.5828 - val_accuracy: 0.7500\n",
            "Epoch 978/1500\n",
            "18/18 [==============================] - 0s 20ms/step - loss: 0.3900 - accuracy: 0.8281 - val_loss: 0.5827 - val_accuracy: 0.7500\n",
            "Epoch 979/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3901 - accuracy: 0.8316 - val_loss: 0.5829 - val_accuracy: 0.7500\n",
            "Epoch 980/1500\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.3903 - accuracy: 0.8316 - val_loss: 0.5834 - val_accuracy: 0.7500\n",
            "Epoch 981/1500\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.3902 - accuracy: 0.8281 - val_loss: 0.5833 - val_accuracy: 0.7500\n",
            "Epoch 982/1500\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.3900 - accuracy: 0.8333 - val_loss: 0.5835 - val_accuracy: 0.7500\n",
            "Epoch 983/1500\n",
            "18/18 [==============================] - 0s 28ms/step - loss: 0.3900 - accuracy: 0.8316 - val_loss: 0.5836 - val_accuracy: 0.7500\n",
            "Epoch 984/1500\n",
            "18/18 [==============================] - 0s 28ms/step - loss: 0.3899 - accuracy: 0.8299 - val_loss: 0.5834 - val_accuracy: 0.7500\n",
            "Epoch 985/1500\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.3900 - accuracy: 0.8333 - val_loss: 0.5830 - val_accuracy: 0.7500\n",
            "Epoch 986/1500\n",
            "18/18 [==============================] - 0s 26ms/step - loss: 0.3901 - accuracy: 0.8316 - val_loss: 0.5834 - val_accuracy: 0.7500\n",
            "Epoch 987/1500\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.3899 - accuracy: 0.8316 - val_loss: 0.5837 - val_accuracy: 0.7500\n",
            "Epoch 988/1500\n",
            "18/18 [==============================] - 0s 27ms/step - loss: 0.3900 - accuracy: 0.8333 - val_loss: 0.5829 - val_accuracy: 0.7500\n",
            "Epoch 989/1500\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.3900 - accuracy: 0.8333 - val_loss: 0.5833 - val_accuracy: 0.7500\n",
            "Epoch 990/1500\n",
            "18/18 [==============================] - 0s 26ms/step - loss: 0.3901 - accuracy: 0.8299 - val_loss: 0.5835 - val_accuracy: 0.7500\n",
            "Epoch 991/1500\n",
            "18/18 [==============================] - 0s 27ms/step - loss: 0.3900 - accuracy: 0.8316 - val_loss: 0.5837 - val_accuracy: 0.7500\n",
            "Epoch 992/1500\n",
            "18/18 [==============================] - 1s 37ms/step - loss: 0.3899 - accuracy: 0.8333 - val_loss: 0.5838 - val_accuracy: 0.7500\n",
            "Epoch 993/1500\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.3900 - accuracy: 0.8333 - val_loss: 0.5841 - val_accuracy: 0.7500\n",
            "Epoch 994/1500\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.3899 - accuracy: 0.8351 - val_loss: 0.5842 - val_accuracy: 0.7500\n",
            "Epoch 995/1500\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.3901 - accuracy: 0.8351 - val_loss: 0.5834 - val_accuracy: 0.7448\n",
            "Epoch 996/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3898 - accuracy: 0.8351 - val_loss: 0.5836 - val_accuracy: 0.7448\n",
            "Epoch 997/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3899 - accuracy: 0.8351 - val_loss: 0.5840 - val_accuracy: 0.7448\n",
            "Epoch 998/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3897 - accuracy: 0.8316 - val_loss: 0.5845 - val_accuracy: 0.7448\n",
            "Epoch 999/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3899 - accuracy: 0.8333 - val_loss: 0.5845 - val_accuracy: 0.7396\n",
            "Epoch 1000/1500\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.3899 - accuracy: 0.8299 - val_loss: 0.5845 - val_accuracy: 0.7396\n",
            "Epoch 1001/1500\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.3898 - accuracy: 0.8333 - val_loss: 0.5845 - val_accuracy: 0.7396\n",
            "Epoch 1002/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3897 - accuracy: 0.8351 - val_loss: 0.5847 - val_accuracy: 0.7396\n",
            "Epoch 1003/1500\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.3896 - accuracy: 0.8316 - val_loss: 0.5849 - val_accuracy: 0.7396\n",
            "Epoch 1004/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3895 - accuracy: 0.8333 - val_loss: 0.5848 - val_accuracy: 0.7396\n",
            "Epoch 1005/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3897 - accuracy: 0.8333 - val_loss: 0.5842 - val_accuracy: 0.7396\n",
            "Epoch 1006/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3896 - accuracy: 0.8351 - val_loss: 0.5846 - val_accuracy: 0.7396\n",
            "Epoch 1007/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3896 - accuracy: 0.8333 - val_loss: 0.5848 - val_accuracy: 0.7396\n",
            "Epoch 1008/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3895 - accuracy: 0.8351 - val_loss: 0.5844 - val_accuracy: 0.7396\n",
            "Epoch 1009/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3899 - accuracy: 0.8351 - val_loss: 0.5844 - val_accuracy: 0.7396\n",
            "Epoch 1010/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3896 - accuracy: 0.8351 - val_loss: 0.5845 - val_accuracy: 0.7396\n",
            "Epoch 1011/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3895 - accuracy: 0.8333 - val_loss: 0.5841 - val_accuracy: 0.7396\n",
            "Epoch 1012/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3898 - accuracy: 0.8351 - val_loss: 0.5847 - val_accuracy: 0.7396\n",
            "Epoch 1013/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3895 - accuracy: 0.8333 - val_loss: 0.5851 - val_accuracy: 0.7396\n",
            "Epoch 1014/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3892 - accuracy: 0.8351 - val_loss: 0.5849 - val_accuracy: 0.7396\n",
            "Epoch 1015/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3894 - accuracy: 0.8351 - val_loss: 0.5853 - val_accuracy: 0.7396\n",
            "Epoch 1016/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3895 - accuracy: 0.8333 - val_loss: 0.5855 - val_accuracy: 0.7448\n",
            "Epoch 1017/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3893 - accuracy: 0.8351 - val_loss: 0.5857 - val_accuracy: 0.7396\n",
            "Epoch 1018/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3895 - accuracy: 0.8333 - val_loss: 0.5856 - val_accuracy: 0.7396\n",
            "Epoch 1019/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3893 - accuracy: 0.8333 - val_loss: 0.5854 - val_accuracy: 0.7396\n",
            "Epoch 1020/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3895 - accuracy: 0.8333 - val_loss: 0.5853 - val_accuracy: 0.7396\n",
            "Epoch 1021/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3893 - accuracy: 0.8333 - val_loss: 0.5855 - val_accuracy: 0.7396\n",
            "Epoch 1022/1500\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.3895 - accuracy: 0.8351 - val_loss: 0.5851 - val_accuracy: 0.7396\n",
            "Epoch 1023/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.3891 - accuracy: 0.8351 - val_loss: 0.5853 - val_accuracy: 0.7396\n",
            "Epoch 1024/1500\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.3892 - accuracy: 0.8316 - val_loss: 0.5851 - val_accuracy: 0.7396\n",
            "Epoch 1025/1500\n",
            "18/18 [==============================] - 1s 29ms/step - loss: 0.3894 - accuracy: 0.8368 - val_loss: 0.5852 - val_accuracy: 0.7396\n",
            "Epoch 1026/1500\n",
            "18/18 [==============================] - 0s 25ms/step - loss: 0.3893 - accuracy: 0.8368 - val_loss: 0.5857 - val_accuracy: 0.7396\n",
            "Epoch 1027/1500\n",
            "18/18 [==============================] - 0s 20ms/step - loss: 0.3892 - accuracy: 0.8351 - val_loss: 0.5853 - val_accuracy: 0.7396\n",
            "Epoch 1028/1500\n",
            "18/18 [==============================] - 0s 20ms/step - loss: 0.3892 - accuracy: 0.8333 - val_loss: 0.5849 - val_accuracy: 0.7396\n",
            "Epoch 1029/1500\n",
            "18/18 [==============================] - 0s 20ms/step - loss: 0.3892 - accuracy: 0.8333 - val_loss: 0.5847 - val_accuracy: 0.7396\n",
            "Epoch 1030/1500\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.3893 - accuracy: 0.8333 - val_loss: 0.5846 - val_accuracy: 0.7396\n",
            "Epoch 1031/1500\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.3892 - accuracy: 0.8351 - val_loss: 0.5849 - val_accuracy: 0.7396\n",
            "Epoch 1032/1500\n",
            "18/18 [==============================] - 0s 19ms/step - loss: 0.3892 - accuracy: 0.8368 - val_loss: 0.5848 - val_accuracy: 0.7396\n",
            "Epoch 1033/1500\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.3891 - accuracy: 0.8351 - val_loss: 0.5849 - val_accuracy: 0.7396\n",
            "Epoch 1034/1500\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.3891 - accuracy: 0.8351 - val_loss: 0.5850 - val_accuracy: 0.7396\n",
            "Epoch 1035/1500\n",
            "18/18 [==============================] - 0s 20ms/step - loss: 0.3890 - accuracy: 0.8351 - val_loss: 0.5850 - val_accuracy: 0.7396\n",
            "Epoch 1036/1500\n",
            "18/18 [==============================] - 0s 19ms/step - loss: 0.3892 - accuracy: 0.8368 - val_loss: 0.5858 - val_accuracy: 0.7396\n",
            "Epoch 1037/1500\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.3891 - accuracy: 0.8368 - val_loss: 0.5857 - val_accuracy: 0.7396\n",
            "Epoch 1038/1500\n",
            "18/18 [==============================] - 1s 35ms/step - loss: 0.3890 - accuracy: 0.8333 - val_loss: 0.5859 - val_accuracy: 0.7396\n",
            "Epoch 1039/1500\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.3890 - accuracy: 0.8368 - val_loss: 0.5852 - val_accuracy: 0.7396\n",
            "Epoch 1040/1500\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 0.3890 - accuracy: 0.8351 - val_loss: 0.5849 - val_accuracy: 0.7396\n",
            "Epoch 1041/1500\n",
            "18/18 [==============================] - 0s 19ms/step - loss: 0.3888 - accuracy: 0.8368 - val_loss: 0.5852 - val_accuracy: 0.7396\n",
            "Epoch 1042/1500\n",
            "18/18 [==============================] - 1s 42ms/step - loss: 0.3889 - accuracy: 0.8368 - val_loss: 0.5853 - val_accuracy: 0.7396\n",
            "Epoch 1043/1500\n",
            "18/18 [==============================] - 1s 42ms/step - loss: 0.3891 - accuracy: 0.8333 - val_loss: 0.5852 - val_accuracy: 0.7396\n",
            "Epoch 1044/1500\n",
            "18/18 [==============================] - 0s 20ms/step - loss: 0.3889 - accuracy: 0.8351 - val_loss: 0.5858 - val_accuracy: 0.7396\n",
            "Epoch 1045/1500\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.3890 - accuracy: 0.8368 - val_loss: 0.5859 - val_accuracy: 0.7396\n",
            "Epoch 1046/1500\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.3888 - accuracy: 0.8385 - val_loss: 0.5855 - val_accuracy: 0.7396\n",
            "Epoch 1047/1500\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.3889 - accuracy: 0.8351 - val_loss: 0.5856 - val_accuracy: 0.7396\n",
            "Epoch 1048/1500\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.3888 - accuracy: 0.8351 - val_loss: 0.5855 - val_accuracy: 0.7396\n",
            "Epoch 1049/1500\n",
            "18/18 [==============================] - 0s 28ms/step - loss: 0.3890 - accuracy: 0.8351 - val_loss: 0.5857 - val_accuracy: 0.7396\n",
            "Epoch 1050/1500\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.3888 - accuracy: 0.8351 - val_loss: 0.5856 - val_accuracy: 0.7396\n",
            "Epoch 1051/1500\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.3888 - accuracy: 0.8368 - val_loss: 0.5853 - val_accuracy: 0.7396\n",
            "Epoch 1052/1500\n",
            "18/18 [==============================] - 0s 20ms/step - loss: 0.3888 - accuracy: 0.8351 - val_loss: 0.5857 - val_accuracy: 0.7396\n",
            "Epoch 1053/1500\n",
            "18/18 [==============================] - 0s 29ms/step - loss: 0.3886 - accuracy: 0.8368 - val_loss: 0.5852 - val_accuracy: 0.7396\n",
            "Epoch 1054/1500\n",
            "18/18 [==============================] - 0s 25ms/step - loss: 0.3887 - accuracy: 0.8368 - val_loss: 0.5853 - val_accuracy: 0.7396\n",
            "Epoch 1055/1500\n",
            "18/18 [==============================] - 0s 28ms/step - loss: 0.3886 - accuracy: 0.8333 - val_loss: 0.5853 - val_accuracy: 0.7396\n",
            "Epoch 1056/1500\n",
            "18/18 [==============================] - 1s 36ms/step - loss: 0.3887 - accuracy: 0.8351 - val_loss: 0.5853 - val_accuracy: 0.7396\n",
            "Epoch 1057/1500\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.3887 - accuracy: 0.8368 - val_loss: 0.5861 - val_accuracy: 0.7396\n",
            "Epoch 1058/1500\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.3887 - accuracy: 0.8351 - val_loss: 0.5857 - val_accuracy: 0.7396\n",
            "Epoch 1059/1500\n",
            "18/18 [==============================] - 0s 26ms/step - loss: 0.3887 - accuracy: 0.8351 - val_loss: 0.5851 - val_accuracy: 0.7396\n",
            "Epoch 1060/1500\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.3886 - accuracy: 0.8351 - val_loss: 0.5852 - val_accuracy: 0.7396\n",
            "Epoch 1061/1500\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.3885 - accuracy: 0.8368 - val_loss: 0.5852 - val_accuracy: 0.7396\n",
            "Epoch 1062/1500\n",
            "18/18 [==============================] - 0s 20ms/step - loss: 0.3887 - accuracy: 0.8351 - val_loss: 0.5852 - val_accuracy: 0.7396\n",
            "Epoch 1063/1500\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.3890 - accuracy: 0.8333 - val_loss: 0.5856 - val_accuracy: 0.7396\n",
            "Epoch 1064/1500\n",
            "18/18 [==============================] - 0s 24ms/step - loss: 0.3888 - accuracy: 0.8368 - val_loss: 0.5858 - val_accuracy: 0.7396\n",
            "Epoch 1065/1500\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.3885 - accuracy: 0.8351 - val_loss: 0.5853 - val_accuracy: 0.7396\n",
            "Epoch 1066/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3887 - accuracy: 0.8368 - val_loss: 0.5858 - val_accuracy: 0.7396\n",
            "Epoch 1067/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3886 - accuracy: 0.8385 - val_loss: 0.5853 - val_accuracy: 0.7396\n",
            "Epoch 1068/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3886 - accuracy: 0.8316 - val_loss: 0.5850 - val_accuracy: 0.7396\n",
            "Epoch 1069/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3885 - accuracy: 0.8351 - val_loss: 0.5845 - val_accuracy: 0.7396\n",
            "Epoch 1070/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3885 - accuracy: 0.8333 - val_loss: 0.5853 - val_accuracy: 0.7396\n",
            "Epoch 1071/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3884 - accuracy: 0.8351 - val_loss: 0.5853 - val_accuracy: 0.7396\n",
            "Epoch 1072/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3885 - accuracy: 0.8333 - val_loss: 0.5858 - val_accuracy: 0.7396\n",
            "Epoch 1073/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3886 - accuracy: 0.8351 - val_loss: 0.5855 - val_accuracy: 0.7396\n",
            "Epoch 1074/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3883 - accuracy: 0.8351 - val_loss: 0.5851 - val_accuracy: 0.7396\n",
            "Epoch 1075/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3885 - accuracy: 0.8351 - val_loss: 0.5855 - val_accuracy: 0.7396\n",
            "Epoch 1076/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3885 - accuracy: 0.8333 - val_loss: 0.5853 - val_accuracy: 0.7396\n",
            "Epoch 1077/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3885 - accuracy: 0.8351 - val_loss: 0.5853 - val_accuracy: 0.7396\n",
            "Epoch 1078/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3884 - accuracy: 0.8316 - val_loss: 0.5847 - val_accuracy: 0.7396\n",
            "Epoch 1079/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3886 - accuracy: 0.8333 - val_loss: 0.5849 - val_accuracy: 0.7396\n",
            "Epoch 1080/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3884 - accuracy: 0.8333 - val_loss: 0.5845 - val_accuracy: 0.7396\n",
            "Epoch 1081/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3885 - accuracy: 0.8385 - val_loss: 0.5852 - val_accuracy: 0.7396\n",
            "Epoch 1082/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3884 - accuracy: 0.8368 - val_loss: 0.5852 - val_accuracy: 0.7396\n",
            "Epoch 1083/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3884 - accuracy: 0.8333 - val_loss: 0.5850 - val_accuracy: 0.7396\n",
            "Epoch 1084/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3884 - accuracy: 0.8351 - val_loss: 0.5851 - val_accuracy: 0.7396\n",
            "Epoch 1085/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3883 - accuracy: 0.8333 - val_loss: 0.5848 - val_accuracy: 0.7396\n",
            "Epoch 1086/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3884 - accuracy: 0.8351 - val_loss: 0.5849 - val_accuracy: 0.7396\n",
            "Epoch 1087/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3883 - accuracy: 0.8333 - val_loss: 0.5849 - val_accuracy: 0.7396\n",
            "Epoch 1088/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3883 - accuracy: 0.8351 - val_loss: 0.5852 - val_accuracy: 0.7396\n",
            "Epoch 1089/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3887 - accuracy: 0.8368 - val_loss: 0.5851 - val_accuracy: 0.7396\n",
            "Epoch 1090/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3881 - accuracy: 0.8351 - val_loss: 0.5855 - val_accuracy: 0.7396\n",
            "Epoch 1091/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3885 - accuracy: 0.8333 - val_loss: 0.5861 - val_accuracy: 0.7396\n",
            "Epoch 1092/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.3883 - accuracy: 0.8351 - val_loss: 0.5861 - val_accuracy: 0.7396\n",
            "Epoch 1093/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3885 - accuracy: 0.8385 - val_loss: 0.5857 - val_accuracy: 0.7396\n",
            "Epoch 1094/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3882 - accuracy: 0.8351 - val_loss: 0.5858 - val_accuracy: 0.7396\n",
            "Epoch 1095/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3885 - accuracy: 0.8333 - val_loss: 0.5860 - val_accuracy: 0.7396\n",
            "Epoch 1096/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3881 - accuracy: 0.8368 - val_loss: 0.5864 - val_accuracy: 0.7396\n",
            "Epoch 1097/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3882 - accuracy: 0.8351 - val_loss: 0.5861 - val_accuracy: 0.7396\n",
            "Epoch 1098/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3882 - accuracy: 0.8351 - val_loss: 0.5864 - val_accuracy: 0.7396\n",
            "Epoch 1099/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3882 - accuracy: 0.8351 - val_loss: 0.5863 - val_accuracy: 0.7396\n",
            "Epoch 1100/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3882 - accuracy: 0.8368 - val_loss: 0.5858 - val_accuracy: 0.7396\n",
            "Epoch 1101/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3882 - accuracy: 0.8368 - val_loss: 0.5858 - val_accuracy: 0.7396\n",
            "Epoch 1102/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3882 - accuracy: 0.8351 - val_loss: 0.5856 - val_accuracy: 0.7396\n",
            "Epoch 1103/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3879 - accuracy: 0.8403 - val_loss: 0.5860 - val_accuracy: 0.7396\n",
            "Epoch 1104/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3879 - accuracy: 0.8368 - val_loss: 0.5859 - val_accuracy: 0.7396\n",
            "Epoch 1105/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3881 - accuracy: 0.8351 - val_loss: 0.5861 - val_accuracy: 0.7396\n",
            "Epoch 1106/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3881 - accuracy: 0.8351 - val_loss: 0.5860 - val_accuracy: 0.7396\n",
            "Epoch 1107/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3883 - accuracy: 0.8351 - val_loss: 0.5858 - val_accuracy: 0.7396\n",
            "Epoch 1108/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3881 - accuracy: 0.8368 - val_loss: 0.5858 - val_accuracy: 0.7396\n",
            "Epoch 1109/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3880 - accuracy: 0.8385 - val_loss: 0.5862 - val_accuracy: 0.7396\n",
            "Epoch 1110/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3880 - accuracy: 0.8351 - val_loss: 0.5858 - val_accuracy: 0.7396\n",
            "Epoch 1111/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3880 - accuracy: 0.8333 - val_loss: 0.5856 - val_accuracy: 0.7396\n",
            "Epoch 1112/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3880 - accuracy: 0.8351 - val_loss: 0.5859 - val_accuracy: 0.7396\n",
            "Epoch 1113/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3878 - accuracy: 0.8368 - val_loss: 0.5862 - val_accuracy: 0.7396\n",
            "Epoch 1114/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3881 - accuracy: 0.8385 - val_loss: 0.5859 - val_accuracy: 0.7396\n",
            "Epoch 1115/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3881 - accuracy: 0.8368 - val_loss: 0.5862 - val_accuracy: 0.7396\n",
            "Epoch 1116/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3880 - accuracy: 0.8368 - val_loss: 0.5863 - val_accuracy: 0.7448\n",
            "Epoch 1117/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3880 - accuracy: 0.8403 - val_loss: 0.5858 - val_accuracy: 0.7396\n",
            "Epoch 1118/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3880 - accuracy: 0.8368 - val_loss: 0.5859 - val_accuracy: 0.7396\n",
            "Epoch 1119/1500\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.3880 - accuracy: 0.8368 - val_loss: 0.5858 - val_accuracy: 0.7396\n",
            "Epoch 1120/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3882 - accuracy: 0.8385 - val_loss: 0.5859 - val_accuracy: 0.7396\n",
            "Epoch 1121/1500\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.3879 - accuracy: 0.8333 - val_loss: 0.5856 - val_accuracy: 0.7396\n",
            "Epoch 1122/1500\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.3877 - accuracy: 0.8368 - val_loss: 0.5857 - val_accuracy: 0.7396\n",
            "Epoch 1123/1500\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.3878 - accuracy: 0.8351 - val_loss: 0.5856 - val_accuracy: 0.7396\n",
            "Epoch 1124/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3878 - accuracy: 0.8368 - val_loss: 0.5856 - val_accuracy: 0.7396\n",
            "Epoch 1125/1500\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.3876 - accuracy: 0.8368 - val_loss: 0.5862 - val_accuracy: 0.7396\n",
            "Epoch 1126/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3879 - accuracy: 0.8351 - val_loss: 0.5861 - val_accuracy: 0.7396\n",
            "Epoch 1127/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3878 - accuracy: 0.8351 - val_loss: 0.5857 - val_accuracy: 0.7396\n",
            "Epoch 1128/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3879 - accuracy: 0.8368 - val_loss: 0.5858 - val_accuracy: 0.7396\n",
            "Epoch 1129/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3878 - accuracy: 0.8368 - val_loss: 0.5854 - val_accuracy: 0.7396\n",
            "Epoch 1130/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3878 - accuracy: 0.8368 - val_loss: 0.5854 - val_accuracy: 0.7396\n",
            "Epoch 1131/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3878 - accuracy: 0.8385 - val_loss: 0.5859 - val_accuracy: 0.7396\n",
            "Epoch 1132/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3876 - accuracy: 0.8368 - val_loss: 0.5859 - val_accuracy: 0.7396\n",
            "Epoch 1133/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3876 - accuracy: 0.8351 - val_loss: 0.5864 - val_accuracy: 0.7396\n",
            "Epoch 1134/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.3880 - accuracy: 0.8368 - val_loss: 0.5862 - val_accuracy: 0.7396\n",
            "Epoch 1135/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.3876 - accuracy: 0.8385 - val_loss: 0.5859 - val_accuracy: 0.7396\n",
            "Epoch 1136/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.3879 - accuracy: 0.8368 - val_loss: 0.5867 - val_accuracy: 0.7396\n",
            "Epoch 1137/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3878 - accuracy: 0.8351 - val_loss: 0.5869 - val_accuracy: 0.7396\n",
            "Epoch 1138/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3879 - accuracy: 0.8385 - val_loss: 0.5869 - val_accuracy: 0.7396\n",
            "Epoch 1139/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3877 - accuracy: 0.8385 - val_loss: 0.5863 - val_accuracy: 0.7396\n",
            "Epoch 1140/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3878 - accuracy: 0.8351 - val_loss: 0.5865 - val_accuracy: 0.7396\n",
            "Epoch 1141/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3878 - accuracy: 0.8351 - val_loss: 0.5864 - val_accuracy: 0.7396\n",
            "Epoch 1142/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3875 - accuracy: 0.8385 - val_loss: 0.5862 - val_accuracy: 0.7396\n",
            "Epoch 1143/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3878 - accuracy: 0.8368 - val_loss: 0.5861 - val_accuracy: 0.7396\n",
            "Epoch 1144/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3877 - accuracy: 0.8333 - val_loss: 0.5857 - val_accuracy: 0.7396\n",
            "Epoch 1145/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3879 - accuracy: 0.8368 - val_loss: 0.5863 - val_accuracy: 0.7396\n",
            "Epoch 1146/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3876 - accuracy: 0.8385 - val_loss: 0.5865 - val_accuracy: 0.7396\n",
            "Epoch 1147/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3876 - accuracy: 0.8385 - val_loss: 0.5858 - val_accuracy: 0.7396\n",
            "Epoch 1148/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3875 - accuracy: 0.8368 - val_loss: 0.5856 - val_accuracy: 0.7396\n",
            "Epoch 1149/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3880 - accuracy: 0.8333 - val_loss: 0.5855 - val_accuracy: 0.7396\n",
            "Epoch 1150/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3875 - accuracy: 0.8385 - val_loss: 0.5854 - val_accuracy: 0.7396\n",
            "Epoch 1151/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3877 - accuracy: 0.8368 - val_loss: 0.5857 - val_accuracy: 0.7396\n",
            "Epoch 1152/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3874 - accuracy: 0.8385 - val_loss: 0.5854 - val_accuracy: 0.7396\n",
            "Epoch 1153/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3877 - accuracy: 0.8368 - val_loss: 0.5859 - val_accuracy: 0.7396\n",
            "Epoch 1154/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3876 - accuracy: 0.8351 - val_loss: 0.5858 - val_accuracy: 0.7396\n",
            "Epoch 1155/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3876 - accuracy: 0.8368 - val_loss: 0.5862 - val_accuracy: 0.7396\n",
            "Epoch 1156/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3875 - accuracy: 0.8368 - val_loss: 0.5863 - val_accuracy: 0.7396\n",
            "Epoch 1157/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3877 - accuracy: 0.8368 - val_loss: 0.5868 - val_accuracy: 0.7396\n",
            "Epoch 1158/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3876 - accuracy: 0.8368 - val_loss: 0.5869 - val_accuracy: 0.7396\n",
            "Epoch 1159/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3878 - accuracy: 0.8403 - val_loss: 0.5867 - val_accuracy: 0.7396\n",
            "Epoch 1160/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3876 - accuracy: 0.8385 - val_loss: 0.5862 - val_accuracy: 0.7396\n",
            "Epoch 1161/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3873 - accuracy: 0.8368 - val_loss: 0.5866 - val_accuracy: 0.7396\n",
            "Epoch 1162/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3872 - accuracy: 0.8351 - val_loss: 0.5867 - val_accuracy: 0.7396\n",
            "Epoch 1163/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3874 - accuracy: 0.8333 - val_loss: 0.5863 - val_accuracy: 0.7396\n",
            "Epoch 1164/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3875 - accuracy: 0.8368 - val_loss: 0.5864 - val_accuracy: 0.7396\n",
            "Epoch 1165/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3875 - accuracy: 0.8351 - val_loss: 0.5869 - val_accuracy: 0.7396\n",
            "Epoch 1166/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3874 - accuracy: 0.8351 - val_loss: 0.5865 - val_accuracy: 0.7396\n",
            "Epoch 1167/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3874 - accuracy: 0.8333 - val_loss: 0.5861 - val_accuracy: 0.7396\n",
            "Epoch 1168/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3874 - accuracy: 0.8351 - val_loss: 0.5868 - val_accuracy: 0.7396\n",
            "Epoch 1169/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3872 - accuracy: 0.8351 - val_loss: 0.5869 - val_accuracy: 0.7396\n",
            "Epoch 1170/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3875 - accuracy: 0.8351 - val_loss: 0.5870 - val_accuracy: 0.7396\n",
            "Epoch 1171/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3873 - accuracy: 0.8368 - val_loss: 0.5871 - val_accuracy: 0.7396\n",
            "Epoch 1172/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3875 - accuracy: 0.8368 - val_loss: 0.5876 - val_accuracy: 0.7396\n",
            "Epoch 1173/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3874 - accuracy: 0.8351 - val_loss: 0.5873 - val_accuracy: 0.7396\n",
            "Epoch 1174/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3873 - accuracy: 0.8351 - val_loss: 0.5873 - val_accuracy: 0.7396\n",
            "Epoch 1175/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3873 - accuracy: 0.8385 - val_loss: 0.5873 - val_accuracy: 0.7396\n",
            "Epoch 1176/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3874 - accuracy: 0.8368 - val_loss: 0.5873 - val_accuracy: 0.7396\n",
            "Epoch 1177/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3874 - accuracy: 0.8368 - val_loss: 0.5867 - val_accuracy: 0.7396\n",
            "Epoch 1178/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3872 - accuracy: 0.8351 - val_loss: 0.5867 - val_accuracy: 0.7396\n",
            "Epoch 1179/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3873 - accuracy: 0.8351 - val_loss: 0.5868 - val_accuracy: 0.7396\n",
            "Epoch 1180/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3873 - accuracy: 0.8385 - val_loss: 0.5871 - val_accuracy: 0.7396\n",
            "Epoch 1181/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3874 - accuracy: 0.8368 - val_loss: 0.5866 - val_accuracy: 0.7396\n",
            "Epoch 1182/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3872 - accuracy: 0.8351 - val_loss: 0.5868 - val_accuracy: 0.7396\n",
            "Epoch 1183/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3872 - accuracy: 0.8385 - val_loss: 0.5869 - val_accuracy: 0.7396\n",
            "Epoch 1184/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3872 - accuracy: 0.8333 - val_loss: 0.5874 - val_accuracy: 0.7396\n",
            "Epoch 1185/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3872 - accuracy: 0.8368 - val_loss: 0.5875 - val_accuracy: 0.7396\n",
            "Epoch 1186/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3872 - accuracy: 0.8385 - val_loss: 0.5872 - val_accuracy: 0.7396\n",
            "Epoch 1187/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3871 - accuracy: 0.8351 - val_loss: 0.5872 - val_accuracy: 0.7396\n",
            "Epoch 1188/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3869 - accuracy: 0.8351 - val_loss: 0.5872 - val_accuracy: 0.7396\n",
            "Epoch 1189/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3871 - accuracy: 0.8385 - val_loss: 0.5868 - val_accuracy: 0.7396\n",
            "Epoch 1190/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3872 - accuracy: 0.8368 - val_loss: 0.5872 - val_accuracy: 0.7396\n",
            "Epoch 1191/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3871 - accuracy: 0.8403 - val_loss: 0.5874 - val_accuracy: 0.7396\n",
            "Epoch 1192/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3871 - accuracy: 0.8368 - val_loss: 0.5872 - val_accuracy: 0.7396\n",
            "Epoch 1193/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3871 - accuracy: 0.8368 - val_loss: 0.5868 - val_accuracy: 0.7396\n",
            "Epoch 1194/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3872 - accuracy: 0.8316 - val_loss: 0.5878 - val_accuracy: 0.7396\n",
            "Epoch 1195/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3871 - accuracy: 0.8333 - val_loss: 0.5877 - val_accuracy: 0.7396\n",
            "Epoch 1196/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3871 - accuracy: 0.8368 - val_loss: 0.5878 - val_accuracy: 0.7396\n",
            "Epoch 1197/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3869 - accuracy: 0.8351 - val_loss: 0.5879 - val_accuracy: 0.7396\n",
            "Epoch 1198/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3867 - accuracy: 0.8368 - val_loss: 0.5877 - val_accuracy: 0.7396\n",
            "Epoch 1199/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3869 - accuracy: 0.8333 - val_loss: 0.5873 - val_accuracy: 0.7396\n",
            "Epoch 1200/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3870 - accuracy: 0.8368 - val_loss: 0.5875 - val_accuracy: 0.7396\n",
            "Epoch 1201/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3870 - accuracy: 0.8368 - val_loss: 0.5876 - val_accuracy: 0.7396\n",
            "Epoch 1202/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3871 - accuracy: 0.8368 - val_loss: 0.5878 - val_accuracy: 0.7396\n",
            "Epoch 1203/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3867 - accuracy: 0.8368 - val_loss: 0.5876 - val_accuracy: 0.7396\n",
            "Epoch 1204/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3868 - accuracy: 0.8385 - val_loss: 0.5879 - val_accuracy: 0.7396\n",
            "Epoch 1205/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3869 - accuracy: 0.8351 - val_loss: 0.5881 - val_accuracy: 0.7396\n",
            "Epoch 1206/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3868 - accuracy: 0.8351 - val_loss: 0.5884 - val_accuracy: 0.7396\n",
            "Epoch 1207/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3868 - accuracy: 0.8351 - val_loss: 0.5882 - val_accuracy: 0.7396\n",
            "Epoch 1208/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3870 - accuracy: 0.8333 - val_loss: 0.5883 - val_accuracy: 0.7448\n",
            "Epoch 1209/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3869 - accuracy: 0.8351 - val_loss: 0.5885 - val_accuracy: 0.7448\n",
            "Epoch 1210/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3868 - accuracy: 0.8368 - val_loss: 0.5876 - val_accuracy: 0.7396\n",
            "Epoch 1211/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3869 - accuracy: 0.8368 - val_loss: 0.5882 - val_accuracy: 0.7396\n",
            "Epoch 1212/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3869 - accuracy: 0.8385 - val_loss: 0.5879 - val_accuracy: 0.7396\n",
            "Epoch 1213/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3867 - accuracy: 0.8351 - val_loss: 0.5880 - val_accuracy: 0.7396\n",
            "Epoch 1214/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3868 - accuracy: 0.8368 - val_loss: 0.5882 - val_accuracy: 0.7448\n",
            "Epoch 1215/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3867 - accuracy: 0.8368 - val_loss: 0.5883 - val_accuracy: 0.7448\n",
            "Epoch 1216/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3864 - accuracy: 0.8351 - val_loss: 0.5880 - val_accuracy: 0.7448\n",
            "Epoch 1217/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3866 - accuracy: 0.8368 - val_loss: 0.5877 - val_accuracy: 0.7396\n",
            "Epoch 1218/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3867 - accuracy: 0.8368 - val_loss: 0.5881 - val_accuracy: 0.7448\n",
            "Epoch 1219/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3865 - accuracy: 0.8351 - val_loss: 0.5881 - val_accuracy: 0.7448\n",
            "Epoch 1220/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3867 - accuracy: 0.8368 - val_loss: 0.5883 - val_accuracy: 0.7448\n",
            "Epoch 1221/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3865 - accuracy: 0.8368 - val_loss: 0.5881 - val_accuracy: 0.7448\n",
            "Epoch 1222/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3865 - accuracy: 0.8368 - val_loss: 0.5876 - val_accuracy: 0.7448\n",
            "Epoch 1223/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3866 - accuracy: 0.8368 - val_loss: 0.5881 - val_accuracy: 0.7448\n",
            "Epoch 1224/1500\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 0.3865 - accuracy: 0.8351 - val_loss: 0.5881 - val_accuracy: 0.7448\n",
            "Epoch 1225/1500\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.3865 - accuracy: 0.8351 - val_loss: 0.5878 - val_accuracy: 0.7448\n",
            "Epoch 1226/1500\n",
            "18/18 [==============================] - 0s 20ms/step - loss: 0.3864 - accuracy: 0.8368 - val_loss: 0.5885 - val_accuracy: 0.7448\n",
            "Epoch 1227/1500\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.3863 - accuracy: 0.8368 - val_loss: 0.5883 - val_accuracy: 0.7448\n",
            "Epoch 1228/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3867 - accuracy: 0.8368 - val_loss: 0.5881 - val_accuracy: 0.7448\n",
            "Epoch 1229/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3864 - accuracy: 0.8368 - val_loss: 0.5877 - val_accuracy: 0.7448\n",
            "Epoch 1230/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3865 - accuracy: 0.8351 - val_loss: 0.5876 - val_accuracy: 0.7448\n",
            "Epoch 1231/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3863 - accuracy: 0.8368 - val_loss: 0.5875 - val_accuracy: 0.7448\n",
            "Epoch 1232/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3863 - accuracy: 0.8368 - val_loss: 0.5874 - val_accuracy: 0.7448\n",
            "Epoch 1233/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3864 - accuracy: 0.8368 - val_loss: 0.5877 - val_accuracy: 0.7448\n",
            "Epoch 1234/1500\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.3864 - accuracy: 0.8351 - val_loss: 0.5879 - val_accuracy: 0.7448\n",
            "Epoch 1235/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3866 - accuracy: 0.8351 - val_loss: 0.5879 - val_accuracy: 0.7448\n",
            "Epoch 1236/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3866 - accuracy: 0.8368 - val_loss: 0.5877 - val_accuracy: 0.7448\n",
            "Epoch 1237/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3862 - accuracy: 0.8333 - val_loss: 0.5877 - val_accuracy: 0.7448\n",
            "Epoch 1238/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3865 - accuracy: 0.8368 - val_loss: 0.5879 - val_accuracy: 0.7448\n",
            "Epoch 1239/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.3863 - accuracy: 0.8316 - val_loss: 0.5884 - val_accuracy: 0.7448\n",
            "Epoch 1240/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.3862 - accuracy: 0.8351 - val_loss: 0.5887 - val_accuracy: 0.7448\n",
            "Epoch 1241/1500\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.3864 - accuracy: 0.8368 - val_loss: 0.5886 - val_accuracy: 0.7448\n",
            "Epoch 1242/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3866 - accuracy: 0.8368 - val_loss: 0.5880 - val_accuracy: 0.7448\n",
            "Epoch 1243/1500\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.3861 - accuracy: 0.8368 - val_loss: 0.5882 - val_accuracy: 0.7448\n",
            "Epoch 1244/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3865 - accuracy: 0.8368 - val_loss: 0.5877 - val_accuracy: 0.7448\n",
            "Epoch 1245/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3863 - accuracy: 0.8333 - val_loss: 0.5878 - val_accuracy: 0.7448\n",
            "Epoch 1246/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3863 - accuracy: 0.8351 - val_loss: 0.5879 - val_accuracy: 0.7448\n",
            "Epoch 1247/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3862 - accuracy: 0.8351 - val_loss: 0.5876 - val_accuracy: 0.7448\n",
            "Epoch 1248/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3860 - accuracy: 0.8368 - val_loss: 0.5883 - val_accuracy: 0.7448\n",
            "Epoch 1249/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3861 - accuracy: 0.8351 - val_loss: 0.5885 - val_accuracy: 0.7448\n",
            "Epoch 1250/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3862 - accuracy: 0.8333 - val_loss: 0.5887 - val_accuracy: 0.7448\n",
            "Epoch 1251/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3863 - accuracy: 0.8368 - val_loss: 0.5883 - val_accuracy: 0.7448\n",
            "Epoch 1252/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3860 - accuracy: 0.8368 - val_loss: 0.5882 - val_accuracy: 0.7448\n",
            "Epoch 1253/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3860 - accuracy: 0.8351 - val_loss: 0.5884 - val_accuracy: 0.7448\n",
            "Epoch 1254/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3861 - accuracy: 0.8368 - val_loss: 0.5884 - val_accuracy: 0.7448\n",
            "Epoch 1255/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3862 - accuracy: 0.8368 - val_loss: 0.5881 - val_accuracy: 0.7448\n",
            "Epoch 1256/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3860 - accuracy: 0.8351 - val_loss: 0.5881 - val_accuracy: 0.7448\n",
            "Epoch 1257/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3860 - accuracy: 0.8316 - val_loss: 0.5885 - val_accuracy: 0.7448\n",
            "Epoch 1258/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3860 - accuracy: 0.8368 - val_loss: 0.5882 - val_accuracy: 0.7448\n",
            "Epoch 1259/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3861 - accuracy: 0.8368 - val_loss: 0.5879 - val_accuracy: 0.7448\n",
            "Epoch 1260/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3861 - accuracy: 0.8368 - val_loss: 0.5877 - val_accuracy: 0.7448\n",
            "Epoch 1261/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3864 - accuracy: 0.8368 - val_loss: 0.5881 - val_accuracy: 0.7448\n",
            "Epoch 1262/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3862 - accuracy: 0.8351 - val_loss: 0.5886 - val_accuracy: 0.7448\n",
            "Epoch 1263/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3862 - accuracy: 0.8351 - val_loss: 0.5889 - val_accuracy: 0.7448\n",
            "Epoch 1264/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3859 - accuracy: 0.8368 - val_loss: 0.5886 - val_accuracy: 0.7448\n",
            "Epoch 1265/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3862 - accuracy: 0.8351 - val_loss: 0.5891 - val_accuracy: 0.7448\n",
            "Epoch 1266/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3859 - accuracy: 0.8351 - val_loss: 0.5894 - val_accuracy: 0.7448\n",
            "Epoch 1267/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3861 - accuracy: 0.8333 - val_loss: 0.5895 - val_accuracy: 0.7448\n",
            "Epoch 1268/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3861 - accuracy: 0.8351 - val_loss: 0.5888 - val_accuracy: 0.7448\n",
            "Epoch 1269/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3861 - accuracy: 0.8368 - val_loss: 0.5885 - val_accuracy: 0.7448\n",
            "Epoch 1270/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3860 - accuracy: 0.8368 - val_loss: 0.5884 - val_accuracy: 0.7448\n",
            "Epoch 1271/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3857 - accuracy: 0.8368 - val_loss: 0.5885 - val_accuracy: 0.7448\n",
            "Epoch 1272/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3859 - accuracy: 0.8351 - val_loss: 0.5887 - val_accuracy: 0.7448\n",
            "Epoch 1273/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3861 - accuracy: 0.8351 - val_loss: 0.5888 - val_accuracy: 0.7448\n",
            "Epoch 1274/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3859 - accuracy: 0.8333 - val_loss: 0.5891 - val_accuracy: 0.7448\n",
            "Epoch 1275/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3859 - accuracy: 0.8368 - val_loss: 0.5881 - val_accuracy: 0.7448\n",
            "Epoch 1276/1500\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.3858 - accuracy: 0.8351 - val_loss: 0.5880 - val_accuracy: 0.7396\n",
            "Epoch 1277/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3861 - accuracy: 0.8333 - val_loss: 0.5882 - val_accuracy: 0.7396\n",
            "Epoch 1278/1500\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.3858 - accuracy: 0.8333 - val_loss: 0.5884 - val_accuracy: 0.7396\n",
            "Epoch 1279/1500\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.3861 - accuracy: 0.8368 - val_loss: 0.5880 - val_accuracy: 0.7396\n",
            "Epoch 1280/1500\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.3859 - accuracy: 0.8351 - val_loss: 0.5883 - val_accuracy: 0.7396\n",
            "Epoch 1281/1500\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.3860 - accuracy: 0.8351 - val_loss: 0.5885 - val_accuracy: 0.7396\n",
            "Epoch 1282/1500\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.3857 - accuracy: 0.8351 - val_loss: 0.5888 - val_accuracy: 0.7396\n",
            "Epoch 1283/1500\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.3860 - accuracy: 0.8333 - val_loss: 0.5890 - val_accuracy: 0.7396\n",
            "Epoch 1284/1500\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.3858 - accuracy: 0.8333 - val_loss: 0.5890 - val_accuracy: 0.7396\n",
            "Epoch 1285/1500\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.3857 - accuracy: 0.8351 - val_loss: 0.5890 - val_accuracy: 0.7396\n",
            "Epoch 1286/1500\n",
            "18/18 [==============================] - 0s 19ms/step - loss: 0.3857 - accuracy: 0.8333 - val_loss: 0.5890 - val_accuracy: 0.7396\n",
            "Epoch 1287/1500\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.3858 - accuracy: 0.8368 - val_loss: 0.5887 - val_accuracy: 0.7396\n",
            "Epoch 1288/1500\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.3859 - accuracy: 0.8333 - val_loss: 0.5886 - val_accuracy: 0.7396\n",
            "Epoch 1289/1500\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.3854 - accuracy: 0.8351 - val_loss: 0.5887 - val_accuracy: 0.7396\n",
            "Epoch 1290/1500\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.3858 - accuracy: 0.8333 - val_loss: 0.5892 - val_accuracy: 0.7396\n",
            "Epoch 1291/1500\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.3857 - accuracy: 0.8351 - val_loss: 0.5888 - val_accuracy: 0.7396\n",
            "Epoch 1292/1500\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.3857 - accuracy: 0.8368 - val_loss: 0.5884 - val_accuracy: 0.7396\n",
            "Epoch 1293/1500\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.3857 - accuracy: 0.8316 - val_loss: 0.5886 - val_accuracy: 0.7396\n",
            "Epoch 1294/1500\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.3857 - accuracy: 0.8333 - val_loss: 0.5892 - val_accuracy: 0.7396\n",
            "Epoch 1295/1500\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.3857 - accuracy: 0.8333 - val_loss: 0.5890 - val_accuracy: 0.7396\n",
            "Epoch 1296/1500\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.3856 - accuracy: 0.8316 - val_loss: 0.5893 - val_accuracy: 0.7396\n",
            "Epoch 1297/1500\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.3854 - accuracy: 0.8351 - val_loss: 0.5893 - val_accuracy: 0.7396\n",
            "Epoch 1298/1500\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.3857 - accuracy: 0.8351 - val_loss: 0.5888 - val_accuracy: 0.7396\n",
            "Epoch 1299/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3858 - accuracy: 0.8316 - val_loss: 0.5895 - val_accuracy: 0.7396\n",
            "Epoch 1300/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3859 - accuracy: 0.8316 - val_loss: 0.5894 - val_accuracy: 0.7396\n",
            "Epoch 1301/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3856 - accuracy: 0.8333 - val_loss: 0.5896 - val_accuracy: 0.7396\n",
            "Epoch 1302/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3855 - accuracy: 0.8351 - val_loss: 0.5896 - val_accuracy: 0.7396\n",
            "Epoch 1303/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3855 - accuracy: 0.8351 - val_loss: 0.5896 - val_accuracy: 0.7396\n",
            "Epoch 1304/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3855 - accuracy: 0.8351 - val_loss: 0.5892 - val_accuracy: 0.7396\n",
            "Epoch 1305/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3855 - accuracy: 0.8333 - val_loss: 0.5893 - val_accuracy: 0.7396\n",
            "Epoch 1306/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3854 - accuracy: 0.8333 - val_loss: 0.5893 - val_accuracy: 0.7396\n",
            "Epoch 1307/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3860 - accuracy: 0.8351 - val_loss: 0.5888 - val_accuracy: 0.7396\n",
            "Epoch 1308/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3856 - accuracy: 0.8316 - val_loss: 0.5892 - val_accuracy: 0.7396\n",
            "Epoch 1309/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3857 - accuracy: 0.8368 - val_loss: 0.5886 - val_accuracy: 0.7396\n",
            "Epoch 1310/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3855 - accuracy: 0.8333 - val_loss: 0.5885 - val_accuracy: 0.7396\n",
            "Epoch 1311/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3854 - accuracy: 0.8316 - val_loss: 0.5892 - val_accuracy: 0.7396\n",
            "Epoch 1312/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3853 - accuracy: 0.8333 - val_loss: 0.5900 - val_accuracy: 0.7396\n",
            "Epoch 1313/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3853 - accuracy: 0.8316 - val_loss: 0.5901 - val_accuracy: 0.7448\n",
            "Epoch 1314/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3854 - accuracy: 0.8368 - val_loss: 0.5896 - val_accuracy: 0.7448\n",
            "Epoch 1315/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3854 - accuracy: 0.8368 - val_loss: 0.5895 - val_accuracy: 0.7396\n",
            "Epoch 1316/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3858 - accuracy: 0.8368 - val_loss: 0.5893 - val_accuracy: 0.7396\n",
            "Epoch 1317/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3857 - accuracy: 0.8333 - val_loss: 0.5897 - val_accuracy: 0.7396\n",
            "Epoch 1318/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3856 - accuracy: 0.8333 - val_loss: 0.5898 - val_accuracy: 0.7396\n",
            "Epoch 1319/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3857 - accuracy: 0.8333 - val_loss: 0.5898 - val_accuracy: 0.7396\n",
            "Epoch 1320/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3855 - accuracy: 0.8333 - val_loss: 0.5899 - val_accuracy: 0.7396\n",
            "Epoch 1321/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3856 - accuracy: 0.8333 - val_loss: 0.5901 - val_accuracy: 0.7396\n",
            "Epoch 1322/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3856 - accuracy: 0.8351 - val_loss: 0.5901 - val_accuracy: 0.7396\n",
            "Epoch 1323/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3856 - accuracy: 0.8333 - val_loss: 0.5904 - val_accuracy: 0.7448\n",
            "Epoch 1324/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3854 - accuracy: 0.8351 - val_loss: 0.5905 - val_accuracy: 0.7448\n",
            "Epoch 1325/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3853 - accuracy: 0.8333 - val_loss: 0.5905 - val_accuracy: 0.7448\n",
            "Epoch 1326/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3856 - accuracy: 0.8368 - val_loss: 0.5903 - val_accuracy: 0.7396\n",
            "Epoch 1327/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3855 - accuracy: 0.8333 - val_loss: 0.5901 - val_accuracy: 0.7396\n",
            "Epoch 1328/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3853 - accuracy: 0.8316 - val_loss: 0.5903 - val_accuracy: 0.7396\n",
            "Epoch 1329/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3853 - accuracy: 0.8333 - val_loss: 0.5899 - val_accuracy: 0.7396\n",
            "Epoch 1330/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3853 - accuracy: 0.8351 - val_loss: 0.5897 - val_accuracy: 0.7396\n",
            "Epoch 1331/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3853 - accuracy: 0.8333 - val_loss: 0.5902 - val_accuracy: 0.7448\n",
            "Epoch 1332/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3853 - accuracy: 0.8333 - val_loss: 0.5903 - val_accuracy: 0.7396\n",
            "Epoch 1333/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3854 - accuracy: 0.8351 - val_loss: 0.5902 - val_accuracy: 0.7396\n",
            "Epoch 1334/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3853 - accuracy: 0.8351 - val_loss: 0.5901 - val_accuracy: 0.7396\n",
            "Epoch 1335/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3853 - accuracy: 0.8333 - val_loss: 0.5900 - val_accuracy: 0.7396\n",
            "Epoch 1336/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3853 - accuracy: 0.8351 - val_loss: 0.5898 - val_accuracy: 0.7396\n",
            "Epoch 1337/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3855 - accuracy: 0.8351 - val_loss: 0.5903 - val_accuracy: 0.7396\n",
            "Epoch 1338/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3853 - accuracy: 0.8316 - val_loss: 0.5907 - val_accuracy: 0.7396\n",
            "Epoch 1339/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3853 - accuracy: 0.8299 - val_loss: 0.5903 - val_accuracy: 0.7396\n",
            "Epoch 1340/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3852 - accuracy: 0.8333 - val_loss: 0.5905 - val_accuracy: 0.7396\n",
            "Epoch 1341/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3852 - accuracy: 0.8333 - val_loss: 0.5904 - val_accuracy: 0.7396\n",
            "Epoch 1342/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3852 - accuracy: 0.8351 - val_loss: 0.5902 - val_accuracy: 0.7396\n",
            "Epoch 1343/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3854 - accuracy: 0.8316 - val_loss: 0.5908 - val_accuracy: 0.7448\n",
            "Epoch 1344/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3852 - accuracy: 0.8333 - val_loss: 0.5907 - val_accuracy: 0.7396\n",
            "Epoch 1345/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3855 - accuracy: 0.8351 - val_loss: 0.5902 - val_accuracy: 0.7396\n",
            "Epoch 1346/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3854 - accuracy: 0.8333 - val_loss: 0.5907 - val_accuracy: 0.7396\n",
            "Epoch 1347/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3850 - accuracy: 0.8333 - val_loss: 0.5911 - val_accuracy: 0.7396\n",
            "Epoch 1348/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3852 - accuracy: 0.8333 - val_loss: 0.5912 - val_accuracy: 0.7396\n",
            "Epoch 1349/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3852 - accuracy: 0.8351 - val_loss: 0.5913 - val_accuracy: 0.7396\n",
            "Epoch 1350/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3853 - accuracy: 0.8333 - val_loss: 0.5915 - val_accuracy: 0.7396\n",
            "Epoch 1351/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3853 - accuracy: 0.8351 - val_loss: 0.5914 - val_accuracy: 0.7396\n",
            "Epoch 1352/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3852 - accuracy: 0.8351 - val_loss: 0.5907 - val_accuracy: 0.7396\n",
            "Epoch 1353/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3854 - accuracy: 0.8351 - val_loss: 0.5901 - val_accuracy: 0.7396\n",
            "Epoch 1354/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3853 - accuracy: 0.8351 - val_loss: 0.5901 - val_accuracy: 0.7396\n",
            "Epoch 1355/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3853 - accuracy: 0.8333 - val_loss: 0.5901 - val_accuracy: 0.7396\n",
            "Epoch 1356/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3853 - accuracy: 0.8333 - val_loss: 0.5900 - val_accuracy: 0.7396\n",
            "Epoch 1357/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3851 - accuracy: 0.8316 - val_loss: 0.5903 - val_accuracy: 0.7396\n",
            "Epoch 1358/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3852 - accuracy: 0.8316 - val_loss: 0.5910 - val_accuracy: 0.7448\n",
            "Epoch 1359/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3856 - accuracy: 0.8333 - val_loss: 0.5906 - val_accuracy: 0.7396\n",
            "Epoch 1360/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3852 - accuracy: 0.8351 - val_loss: 0.5905 - val_accuracy: 0.7396\n",
            "Epoch 1361/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3852 - accuracy: 0.8333 - val_loss: 0.5909 - val_accuracy: 0.7396\n",
            "Epoch 1362/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3854 - accuracy: 0.8333 - val_loss: 0.5910 - val_accuracy: 0.7396\n",
            "Epoch 1363/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3851 - accuracy: 0.8333 - val_loss: 0.5908 - val_accuracy: 0.7396\n",
            "Epoch 1364/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3852 - accuracy: 0.8351 - val_loss: 0.5904 - val_accuracy: 0.7396\n",
            "Epoch 1365/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3852 - accuracy: 0.8333 - val_loss: 0.5908 - val_accuracy: 0.7396\n",
            "Epoch 1366/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3851 - accuracy: 0.8316 - val_loss: 0.5917 - val_accuracy: 0.7448\n",
            "Epoch 1367/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3852 - accuracy: 0.8316 - val_loss: 0.5915 - val_accuracy: 0.7396\n",
            "Epoch 1368/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3852 - accuracy: 0.8351 - val_loss: 0.5916 - val_accuracy: 0.7396\n",
            "Epoch 1369/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3850 - accuracy: 0.8333 - val_loss: 0.5915 - val_accuracy: 0.7396\n",
            "Epoch 1370/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3851 - accuracy: 0.8316 - val_loss: 0.5911 - val_accuracy: 0.7396\n",
            "Epoch 1371/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3851 - accuracy: 0.8351 - val_loss: 0.5911 - val_accuracy: 0.7396\n",
            "Epoch 1372/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3850 - accuracy: 0.8316 - val_loss: 0.5910 - val_accuracy: 0.7396\n",
            "Epoch 1373/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3853 - accuracy: 0.8333 - val_loss: 0.5919 - val_accuracy: 0.7396\n",
            "Epoch 1374/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3848 - accuracy: 0.8299 - val_loss: 0.5920 - val_accuracy: 0.7448\n",
            "Epoch 1375/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3851 - accuracy: 0.8333 - val_loss: 0.5920 - val_accuracy: 0.7448\n",
            "Epoch 1376/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3850 - accuracy: 0.8333 - val_loss: 0.5916 - val_accuracy: 0.7448\n",
            "Epoch 1377/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3851 - accuracy: 0.8333 - val_loss: 0.5915 - val_accuracy: 0.7448\n",
            "Epoch 1378/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3849 - accuracy: 0.8333 - val_loss: 0.5908 - val_accuracy: 0.7396\n",
            "Epoch 1379/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3849 - accuracy: 0.8333 - val_loss: 0.5911 - val_accuracy: 0.7396\n",
            "Epoch 1380/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3850 - accuracy: 0.8333 - val_loss: 0.5905 - val_accuracy: 0.7396\n",
            "Epoch 1381/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3851 - accuracy: 0.8299 - val_loss: 0.5904 - val_accuracy: 0.7396\n",
            "Epoch 1382/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3849 - accuracy: 0.8333 - val_loss: 0.5911 - val_accuracy: 0.7448\n",
            "Epoch 1383/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3850 - accuracy: 0.8316 - val_loss: 0.5913 - val_accuracy: 0.7448\n",
            "Epoch 1384/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3850 - accuracy: 0.8333 - val_loss: 0.5911 - val_accuracy: 0.7396\n",
            "Epoch 1385/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3849 - accuracy: 0.8351 - val_loss: 0.5910 - val_accuracy: 0.7396\n",
            "Epoch 1386/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3849 - accuracy: 0.8368 - val_loss: 0.5910 - val_accuracy: 0.7396\n",
            "Epoch 1387/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3851 - accuracy: 0.8333 - val_loss: 0.5913 - val_accuracy: 0.7448\n",
            "Epoch 1388/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3849 - accuracy: 0.8333 - val_loss: 0.5911 - val_accuracy: 0.7396\n",
            "Epoch 1389/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3850 - accuracy: 0.8333 - val_loss: 0.5915 - val_accuracy: 0.7448\n",
            "Epoch 1390/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3849 - accuracy: 0.8351 - val_loss: 0.5916 - val_accuracy: 0.7448\n",
            "Epoch 1391/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3848 - accuracy: 0.8333 - val_loss: 0.5919 - val_accuracy: 0.7448\n",
            "Epoch 1392/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3848 - accuracy: 0.8333 - val_loss: 0.5920 - val_accuracy: 0.7448\n",
            "Epoch 1393/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3851 - accuracy: 0.8333 - val_loss: 0.5920 - val_accuracy: 0.7448\n",
            "Epoch 1394/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3851 - accuracy: 0.8351 - val_loss: 0.5919 - val_accuracy: 0.7448\n",
            "Epoch 1395/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3852 - accuracy: 0.8333 - val_loss: 0.5921 - val_accuracy: 0.7448\n",
            "Epoch 1396/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3850 - accuracy: 0.8351 - val_loss: 0.5915 - val_accuracy: 0.7396\n",
            "Epoch 1397/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3848 - accuracy: 0.8299 - val_loss: 0.5915 - val_accuracy: 0.7396\n",
            "Epoch 1398/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3850 - accuracy: 0.8351 - val_loss: 0.5912 - val_accuracy: 0.7448\n",
            "Epoch 1399/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3849 - accuracy: 0.8316 - val_loss: 0.5919 - val_accuracy: 0.7448\n",
            "Epoch 1400/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3848 - accuracy: 0.8351 - val_loss: 0.5915 - val_accuracy: 0.7396\n",
            "Epoch 1401/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3849 - accuracy: 0.8368 - val_loss: 0.5912 - val_accuracy: 0.7396\n",
            "Epoch 1402/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.3847 - accuracy: 0.8333 - val_loss: 0.5911 - val_accuracy: 0.7396\n",
            "Epoch 1403/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3850 - accuracy: 0.8316 - val_loss: 0.5922 - val_accuracy: 0.7448\n",
            "Epoch 1404/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3850 - accuracy: 0.8333 - val_loss: 0.5926 - val_accuracy: 0.7448\n",
            "Epoch 1405/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3850 - accuracy: 0.8333 - val_loss: 0.5920 - val_accuracy: 0.7448\n",
            "Epoch 1406/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3851 - accuracy: 0.8333 - val_loss: 0.5923 - val_accuracy: 0.7448\n",
            "Epoch 1407/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3847 - accuracy: 0.8368 - val_loss: 0.5918 - val_accuracy: 0.7396\n",
            "Epoch 1408/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3847 - accuracy: 0.8351 - val_loss: 0.5915 - val_accuracy: 0.7396\n",
            "Epoch 1409/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3848 - accuracy: 0.8316 - val_loss: 0.5918 - val_accuracy: 0.7448\n",
            "Epoch 1410/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3847 - accuracy: 0.8333 - val_loss: 0.5917 - val_accuracy: 0.7448\n",
            "Epoch 1411/1500\n",
            "18/18 [==============================] - 1s 37ms/step - loss: 0.3848 - accuracy: 0.8316 - val_loss: 0.5922 - val_accuracy: 0.7396\n",
            "Epoch 1412/1500\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.3848 - accuracy: 0.8333 - val_loss: 0.5919 - val_accuracy: 0.7396\n",
            "Epoch 1413/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3846 - accuracy: 0.8368 - val_loss: 0.5919 - val_accuracy: 0.7448\n",
            "Epoch 1414/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3849 - accuracy: 0.8351 - val_loss: 0.5910 - val_accuracy: 0.7396\n",
            "Epoch 1415/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3847 - accuracy: 0.8333 - val_loss: 0.5912 - val_accuracy: 0.7396\n",
            "Epoch 1416/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3848 - accuracy: 0.8316 - val_loss: 0.5913 - val_accuracy: 0.7396\n",
            "Epoch 1417/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3849 - accuracy: 0.8333 - val_loss: 0.5918 - val_accuracy: 0.7396\n",
            "Epoch 1418/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3847 - accuracy: 0.8351 - val_loss: 0.5916 - val_accuracy: 0.7396\n",
            "Epoch 1419/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3846 - accuracy: 0.8316 - val_loss: 0.5916 - val_accuracy: 0.7396\n",
            "Epoch 1420/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3845 - accuracy: 0.8333 - val_loss: 0.5918 - val_accuracy: 0.7396\n",
            "Epoch 1421/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3847 - accuracy: 0.8351 - val_loss: 0.5920 - val_accuracy: 0.7396\n",
            "Epoch 1422/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3847 - accuracy: 0.8333 - val_loss: 0.5921 - val_accuracy: 0.7448\n",
            "Epoch 1423/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3845 - accuracy: 0.8333 - val_loss: 0.5920 - val_accuracy: 0.7448\n",
            "Epoch 1424/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3845 - accuracy: 0.8333 - val_loss: 0.5918 - val_accuracy: 0.7396\n",
            "Epoch 1425/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3846 - accuracy: 0.8333 - val_loss: 0.5919 - val_accuracy: 0.7396\n",
            "Epoch 1426/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3849 - accuracy: 0.8316 - val_loss: 0.5919 - val_accuracy: 0.7396\n",
            "Epoch 1427/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3846 - accuracy: 0.8333 - val_loss: 0.5912 - val_accuracy: 0.7396\n",
            "Epoch 1428/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3845 - accuracy: 0.8333 - val_loss: 0.5915 - val_accuracy: 0.7396\n",
            "Epoch 1429/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3848 - accuracy: 0.8333 - val_loss: 0.5917 - val_accuracy: 0.7396\n",
            "Epoch 1430/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3844 - accuracy: 0.8333 - val_loss: 0.5920 - val_accuracy: 0.7396\n",
            "Epoch 1431/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3846 - accuracy: 0.8333 - val_loss: 0.5920 - val_accuracy: 0.7396\n",
            "Epoch 1432/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3844 - accuracy: 0.8333 - val_loss: 0.5913 - val_accuracy: 0.7396\n",
            "Epoch 1433/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3844 - accuracy: 0.8333 - val_loss: 0.5918 - val_accuracy: 0.7448\n",
            "Epoch 1434/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3845 - accuracy: 0.8316 - val_loss: 0.5922 - val_accuracy: 0.7448\n",
            "Epoch 1435/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3845 - accuracy: 0.8316 - val_loss: 0.5918 - val_accuracy: 0.7396\n",
            "Epoch 1436/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3846 - accuracy: 0.8333 - val_loss: 0.5922 - val_accuracy: 0.7448\n",
            "Epoch 1437/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3848 - accuracy: 0.8333 - val_loss: 0.5923 - val_accuracy: 0.7448\n",
            "Epoch 1438/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3847 - accuracy: 0.8316 - val_loss: 0.5923 - val_accuracy: 0.7448\n",
            "Epoch 1439/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3844 - accuracy: 0.8333 - val_loss: 0.5924 - val_accuracy: 0.7448\n",
            "Epoch 1440/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3845 - accuracy: 0.8333 - val_loss: 0.5923 - val_accuracy: 0.7448\n",
            "Epoch 1441/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3845 - accuracy: 0.8316 - val_loss: 0.5925 - val_accuracy: 0.7448\n",
            "Epoch 1442/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3845 - accuracy: 0.8333 - val_loss: 0.5926 - val_accuracy: 0.7448\n",
            "Epoch 1443/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3843 - accuracy: 0.8333 - val_loss: 0.5924 - val_accuracy: 0.7448\n",
            "Epoch 1444/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3845 - accuracy: 0.8333 - val_loss: 0.5914 - val_accuracy: 0.7396\n",
            "Epoch 1445/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3845 - accuracy: 0.8333 - val_loss: 0.5918 - val_accuracy: 0.7448\n",
            "Epoch 1446/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3844 - accuracy: 0.8333 - val_loss: 0.5918 - val_accuracy: 0.7448\n",
            "Epoch 1447/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3843 - accuracy: 0.8333 - val_loss: 0.5921 - val_accuracy: 0.7448\n",
            "Epoch 1448/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3843 - accuracy: 0.8333 - val_loss: 0.5915 - val_accuracy: 0.7396\n",
            "Epoch 1449/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3843 - accuracy: 0.8333 - val_loss: 0.5913 - val_accuracy: 0.7396\n",
            "Epoch 1450/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3846 - accuracy: 0.8333 - val_loss: 0.5922 - val_accuracy: 0.7396\n",
            "Epoch 1451/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3844 - accuracy: 0.8316 - val_loss: 0.5923 - val_accuracy: 0.7396\n",
            "Epoch 1452/1500\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.3842 - accuracy: 0.8333 - val_loss: 0.5934 - val_accuracy: 0.7448\n",
            "Epoch 1453/1500\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.3844 - accuracy: 0.8333 - val_loss: 0.5927 - val_accuracy: 0.7448\n",
            "Epoch 1454/1500\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.3843 - accuracy: 0.8333 - val_loss: 0.5922 - val_accuracy: 0.7448\n",
            "Epoch 1455/1500\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.3843 - accuracy: 0.8333 - val_loss: 0.5924 - val_accuracy: 0.7448\n",
            "Epoch 1456/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.3844 - accuracy: 0.8333 - val_loss: 0.5923 - val_accuracy: 0.7396\n",
            "Epoch 1457/1500\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.3841 - accuracy: 0.8333 - val_loss: 0.5931 - val_accuracy: 0.7448\n",
            "Epoch 1458/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3844 - accuracy: 0.8316 - val_loss: 0.5929 - val_accuracy: 0.7396\n",
            "Epoch 1459/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3844 - accuracy: 0.8333 - val_loss: 0.5927 - val_accuracy: 0.7396\n",
            "Epoch 1460/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.3842 - accuracy: 0.8316 - val_loss: 0.5928 - val_accuracy: 0.7396\n",
            "Epoch 1461/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3840 - accuracy: 0.8333 - val_loss: 0.5927 - val_accuracy: 0.7396\n",
            "Epoch 1462/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3842 - accuracy: 0.8333 - val_loss: 0.5924 - val_accuracy: 0.7396\n",
            "Epoch 1463/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3841 - accuracy: 0.8333 - val_loss: 0.5919 - val_accuracy: 0.7396\n",
            "Epoch 1464/1500\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.3842 - accuracy: 0.8333 - val_loss: 0.5922 - val_accuracy: 0.7396\n",
            "Epoch 1465/1500\n",
            "18/18 [==============================] - 0s 20ms/step - loss: 0.3843 - accuracy: 0.8316 - val_loss: 0.5929 - val_accuracy: 0.7396\n",
            "Epoch 1466/1500\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.3841 - accuracy: 0.8333 - val_loss: 0.5933 - val_accuracy: 0.7448\n",
            "Epoch 1467/1500\n",
            "18/18 [==============================] - 0s 25ms/step - loss: 0.3841 - accuracy: 0.8333 - val_loss: 0.5932 - val_accuracy: 0.7448\n",
            "Epoch 1468/1500\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.3841 - accuracy: 0.8333 - val_loss: 0.5932 - val_accuracy: 0.7448\n",
            "Epoch 1469/1500\n",
            "18/18 [==============================] - 0s 20ms/step - loss: 0.3843 - accuracy: 0.8333 - val_loss: 0.5929 - val_accuracy: 0.7448\n",
            "Epoch 1470/1500\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.3841 - accuracy: 0.8333 - val_loss: 0.5930 - val_accuracy: 0.7448\n",
            "Epoch 1471/1500\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.3840 - accuracy: 0.8333 - val_loss: 0.5929 - val_accuracy: 0.7448\n",
            "Epoch 1472/1500\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.3841 - accuracy: 0.8333 - val_loss: 0.5931 - val_accuracy: 0.7448\n",
            "Epoch 1473/1500\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.3843 - accuracy: 0.8333 - val_loss: 0.5931 - val_accuracy: 0.7448\n",
            "Epoch 1474/1500\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.3840 - accuracy: 0.8333 - val_loss: 0.5927 - val_accuracy: 0.7448\n",
            "Epoch 1475/1500\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.3839 - accuracy: 0.8316 - val_loss: 0.5933 - val_accuracy: 0.7448\n",
            "Epoch 1476/1500\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.3840 - accuracy: 0.8333 - val_loss: 0.5930 - val_accuracy: 0.7396\n",
            "Epoch 1477/1500\n",
            "18/18 [==============================] - 0s 24ms/step - loss: 0.3841 - accuracy: 0.8333 - val_loss: 0.5936 - val_accuracy: 0.7448\n",
            "Epoch 1478/1500\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.3840 - accuracy: 0.8333 - val_loss: 0.5933 - val_accuracy: 0.7448\n",
            "Epoch 1479/1500\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 0.3841 - accuracy: 0.8333 - val_loss: 0.5927 - val_accuracy: 0.7448\n",
            "Epoch 1480/1500\n",
            "18/18 [==============================] - 0s 27ms/step - loss: 0.3842 - accuracy: 0.8333 - val_loss: 0.5923 - val_accuracy: 0.7448\n",
            "Epoch 1481/1500\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.3839 - accuracy: 0.8333 - val_loss: 0.5929 - val_accuracy: 0.7448\n",
            "Epoch 1482/1500\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.3840 - accuracy: 0.8333 - val_loss: 0.5926 - val_accuracy: 0.7448\n",
            "Epoch 1483/1500\n",
            "18/18 [==============================] - 0s 19ms/step - loss: 0.3838 - accuracy: 0.8333 - val_loss: 0.5931 - val_accuracy: 0.7448\n",
            "Epoch 1484/1500\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.3840 - accuracy: 0.8333 - val_loss: 0.5938 - val_accuracy: 0.7448\n",
            "Epoch 1485/1500\n",
            "18/18 [==============================] - 0s 20ms/step - loss: 0.3840 - accuracy: 0.8333 - val_loss: 0.5937 - val_accuracy: 0.7448\n",
            "Epoch 1486/1500\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.3842 - accuracy: 0.8333 - val_loss: 0.5934 - val_accuracy: 0.7448\n",
            "Epoch 1487/1500\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.3839 - accuracy: 0.8333 - val_loss: 0.5930 - val_accuracy: 0.7448\n",
            "Epoch 1488/1500\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.3840 - accuracy: 0.8333 - val_loss: 0.5940 - val_accuracy: 0.7448\n",
            "Epoch 1489/1500\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.3836 - accuracy: 0.8333 - val_loss: 0.5935 - val_accuracy: 0.7448\n",
            "Epoch 1490/1500\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.3837 - accuracy: 0.8333 - val_loss: 0.5930 - val_accuracy: 0.7448\n",
            "Epoch 1491/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3839 - accuracy: 0.8333 - val_loss: 0.5934 - val_accuracy: 0.7396\n",
            "Epoch 1492/1500\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.3836 - accuracy: 0.8333 - val_loss: 0.5933 - val_accuracy: 0.7448\n",
            "Epoch 1493/1500\n",
            "18/18 [==============================] - 0s 26ms/step - loss: 0.3839 - accuracy: 0.8333 - val_loss: 0.5924 - val_accuracy: 0.7448\n",
            "Epoch 1494/1500\n",
            "18/18 [==============================] - 0s 24ms/step - loss: 0.3840 - accuracy: 0.8333 - val_loss: 0.5929 - val_accuracy: 0.7448\n",
            "Epoch 1495/1500\n",
            "18/18 [==============================] - 0s 27ms/step - loss: 0.3840 - accuracy: 0.8333 - val_loss: 0.5925 - val_accuracy: 0.7448\n",
            "Epoch 1496/1500\n",
            "18/18 [==============================] - 0s 24ms/step - loss: 0.3839 - accuracy: 0.8333 - val_loss: 0.5927 - val_accuracy: 0.7448\n",
            "Epoch 1497/1500\n",
            "18/18 [==============================] - 0s 20ms/step - loss: 0.3839 - accuracy: 0.8333 - val_loss: 0.5931 - val_accuracy: 0.7396\n",
            "Epoch 1498/1500\n",
            "18/18 [==============================] - 0s 19ms/step - loss: 0.3836 - accuracy: 0.8333 - val_loss: 0.5939 - val_accuracy: 0.7448\n",
            "Epoch 1499/1500\n",
            "18/18 [==============================] - 0s 26ms/step - loss: 0.3837 - accuracy: 0.8333 - val_loss: 0.5934 - val_accuracy: 0.7448\n",
            "Epoch 1500/1500\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.3838 - accuracy: 0.8333 - val_loss: 0.5937 - val_accuracy: 0.7448\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrQBgMbNANVn",
        "outputId": "174631f8-45c3-4d59-8508-57871f98a8d8"
      },
      "id": "XrQBgMbNANVn",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_18 (Dense)            (None, 6)                 54        \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 6)                 42        \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 1)                 7         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 103 (412.00 Byte)\n",
            "Trainable params: 103 (412.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_class_nn_1 = (model_1.predict(X_test_norm)> 0.5 ).astype('int32')\n",
        "y_pred_prob_nn_1 = model_1.predict(X_test_norm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uj1T_VZOBuJs",
        "outputId": "1a4b29c7-3386-4c44-9e59-34275239b608"
      },
      "id": "uj1T_VZOBuJs",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 2ms/step\n",
            "6/6 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_hist_2.history.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuHpbRbjDcs4",
        "outputId": "dd2b3833-522d-43b1-e7ea-c456cc58b7d1"
      },
      "id": "xuHpbRbjDcs4",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_2.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist_2.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "AgZD6VLRDiSK",
        "outputId": "90f694a9-4f71-4ad7-9e4d-90df1eba2ec8"
      },
      "id": "AgZD6VLRDiSK",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7dd348ac4670>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that there is a significant different between the training loss and the valdation loss. With validation loss only going above 50% but the training loss to go all the way below 40%"
      ],
      "metadata": {
        "id": "tG4CyG6WXt0U"
      },
      "id": "tG4CyG6WXt0U"
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_2.history[\"accuracy\"],'r', label=\"Accuracy\")\n",
        "ax.plot(run_hist_2.history[\"val_accuracy\"],'b', label=\"Validation Accuracy\")\n",
        "ax.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "yKJ1MC6cDmtT",
        "outputId": "d926080f-ffeb-4afb-b6d1-7c22f34dbbd0"
      },
      "id": "yKJ1MC6cDmtT",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7dd34a7cc490>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In contrast to this the accuracy of the training set was alot higher than those in the testing set or rather the validation accuracy."
      ],
      "metadata": {
        "id": "U5BKekSnX5uC"
      },
      "id": "U5BKekSnX5uC"
    },
    {
      "cell_type": "code",
      "source": [
        "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
        "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))\n",
        "\n",
        "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 735
        },
        "id": "TsN0YdepHjZz",
        "outputId": "5a126061-9cf1-4dee-a7f1-6fc9ba0ab26d"
      },
      "id": "TsN0YdepHjZz",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy is 0.729\n",
            "roc-auc is 0.800\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Additional Layer (Different Number of Node for the additional Layer), Same Number of Epochs"
      ],
      "metadata": {
        "id": "-v3nc1-LBAWh"
      },
      "id": "-v3nc1-LBAWh"
    },
    {
      "cell_type": "code",
      "source": [
        "#Model with two hidden layers each having 6 nodes\n",
        "model_2 = Sequential ([\n",
        "    #Layer 1\n",
        "    Dense(8, input_shape=(8,),activation=\"relu\"),\n",
        "\n",
        "    #Layer 2\n",
        "    Dense(8,activation=\"relu\"),\n",
        "\n",
        "    #Layer 3\n",
        "    #For this part of the activity, I wanted to see if adding another layer\n",
        "    #and having a different number of node would affect the accuracy or\n",
        "    #would it remain stagnant.\n",
        "    Dense(8,activation=\"relu\"),\n",
        "\n",
        "    #Output/Final Layer\n",
        "    Dense(1,activation=\"sigmoid\")\n",
        "])\n",
        "y_pred_class_nn_1 = (model_2.predict(X_test_norm)> 0.5 ).astype('int32')\n",
        "y_pred_prob_nn_1 = model_2.predict(X_test_norm)\n",
        "\n",
        "model_2.compile(SGD(lr = .001), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "run_hist_3 = model_2.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=800)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xx0vFxysAQ18",
        "outputId": "ed90a206-4f26-47a7-de0e-8190e51eadc8"
      },
      "id": "xx0vFxysAQ18",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 2ms/step\n",
            "6/6 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/800\n",
            "18/18 [==============================] - 1s 13ms/step - loss: 0.6627 - accuracy: 0.6719 - val_loss: 0.6583 - val_accuracy: 0.6719\n",
            "Epoch 2/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6516 - accuracy: 0.6632 - val_loss: 0.6506 - val_accuracy: 0.6458\n",
            "Epoch 3/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6430 - accuracy: 0.6528 - val_loss: 0.6448 - val_accuracy: 0.6406\n",
            "Epoch 4/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6362 - accuracy: 0.6545 - val_loss: 0.6401 - val_accuracy: 0.6406\n",
            "Epoch 5/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6305 - accuracy: 0.6545 - val_loss: 0.6362 - val_accuracy: 0.6406\n",
            "Epoch 6/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6255 - accuracy: 0.6545 - val_loss: 0.6328 - val_accuracy: 0.6406\n",
            "Epoch 7/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6210 - accuracy: 0.6545 - val_loss: 0.6299 - val_accuracy: 0.6406\n",
            "Epoch 8/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6169 - accuracy: 0.6545 - val_loss: 0.6270 - val_accuracy: 0.6406\n",
            "Epoch 9/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6131 - accuracy: 0.6545 - val_loss: 0.6243 - val_accuracy: 0.6406\n",
            "Epoch 10/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6095 - accuracy: 0.6545 - val_loss: 0.6217 - val_accuracy: 0.6406\n",
            "Epoch 11/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6060 - accuracy: 0.6545 - val_loss: 0.6192 - val_accuracy: 0.6406\n",
            "Epoch 12/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6027 - accuracy: 0.6545 - val_loss: 0.6168 - val_accuracy: 0.6406\n",
            "Epoch 13/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5996 - accuracy: 0.6545 - val_loss: 0.6144 - val_accuracy: 0.6406\n",
            "Epoch 14/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5963 - accuracy: 0.6545 - val_loss: 0.6122 - val_accuracy: 0.6406\n",
            "Epoch 15/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5932 - accuracy: 0.6545 - val_loss: 0.6101 - val_accuracy: 0.6406\n",
            "Epoch 16/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5902 - accuracy: 0.6545 - val_loss: 0.6080 - val_accuracy: 0.6406\n",
            "Epoch 17/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5873 - accuracy: 0.6545 - val_loss: 0.6059 - val_accuracy: 0.6406\n",
            "Epoch 18/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5844 - accuracy: 0.6545 - val_loss: 0.6038 - val_accuracy: 0.6406\n",
            "Epoch 19/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5816 - accuracy: 0.6545 - val_loss: 0.6017 - val_accuracy: 0.6406\n",
            "Epoch 20/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5787 - accuracy: 0.6545 - val_loss: 0.5997 - val_accuracy: 0.6406\n",
            "Epoch 21/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5761 - accuracy: 0.6545 - val_loss: 0.5977 - val_accuracy: 0.6406\n",
            "Epoch 22/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5732 - accuracy: 0.6545 - val_loss: 0.5958 - val_accuracy: 0.6406\n",
            "Epoch 23/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5707 - accuracy: 0.6545 - val_loss: 0.5939 - val_accuracy: 0.6406\n",
            "Epoch 24/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5680 - accuracy: 0.6545 - val_loss: 0.5920 - val_accuracy: 0.6406\n",
            "Epoch 25/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5653 - accuracy: 0.6545 - val_loss: 0.5903 - val_accuracy: 0.6406\n",
            "Epoch 26/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5628 - accuracy: 0.6545 - val_loss: 0.5887 - val_accuracy: 0.6406\n",
            "Epoch 27/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5603 - accuracy: 0.6545 - val_loss: 0.5870 - val_accuracy: 0.6406\n",
            "Epoch 28/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5579 - accuracy: 0.6545 - val_loss: 0.5855 - val_accuracy: 0.6406\n",
            "Epoch 29/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5554 - accuracy: 0.6545 - val_loss: 0.5839 - val_accuracy: 0.6406\n",
            "Epoch 30/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5530 - accuracy: 0.6545 - val_loss: 0.5824 - val_accuracy: 0.6406\n",
            "Epoch 31/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5508 - accuracy: 0.6545 - val_loss: 0.5809 - val_accuracy: 0.6406\n",
            "Epoch 32/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5484 - accuracy: 0.6545 - val_loss: 0.5794 - val_accuracy: 0.6406\n",
            "Epoch 33/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5464 - accuracy: 0.6615 - val_loss: 0.5779 - val_accuracy: 0.6510\n",
            "Epoch 34/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5442 - accuracy: 0.6979 - val_loss: 0.5764 - val_accuracy: 0.6562\n",
            "Epoch 35/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5419 - accuracy: 0.7240 - val_loss: 0.5750 - val_accuracy: 0.6823\n",
            "Epoch 36/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5400 - accuracy: 0.7309 - val_loss: 0.5737 - val_accuracy: 0.6875\n",
            "Epoch 37/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5379 - accuracy: 0.7448 - val_loss: 0.5725 - val_accuracy: 0.7083\n",
            "Epoch 38/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5359 - accuracy: 0.7500 - val_loss: 0.5712 - val_accuracy: 0.7135\n",
            "Epoch 39/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5341 - accuracy: 0.7517 - val_loss: 0.5700 - val_accuracy: 0.7083\n",
            "Epoch 40/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5322 - accuracy: 0.7517 - val_loss: 0.5686 - val_accuracy: 0.7083\n",
            "Epoch 41/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5303 - accuracy: 0.7535 - val_loss: 0.5674 - val_accuracy: 0.7188\n",
            "Epoch 42/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5286 - accuracy: 0.7535 - val_loss: 0.5663 - val_accuracy: 0.7135\n",
            "Epoch 43/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5268 - accuracy: 0.7552 - val_loss: 0.5650 - val_accuracy: 0.7188\n",
            "Epoch 44/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5251 - accuracy: 0.7535 - val_loss: 0.5639 - val_accuracy: 0.7188\n",
            "Epoch 45/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5235 - accuracy: 0.7587 - val_loss: 0.5629 - val_accuracy: 0.7135\n",
            "Epoch 46/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5220 - accuracy: 0.7622 - val_loss: 0.5618 - val_accuracy: 0.7240\n",
            "Epoch 47/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5205 - accuracy: 0.7639 - val_loss: 0.5606 - val_accuracy: 0.7188\n",
            "Epoch 48/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5188 - accuracy: 0.7639 - val_loss: 0.5598 - val_accuracy: 0.7240\n",
            "Epoch 49/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5174 - accuracy: 0.7639 - val_loss: 0.5590 - val_accuracy: 0.7292\n",
            "Epoch 50/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5159 - accuracy: 0.7639 - val_loss: 0.5583 - val_accuracy: 0.7344\n",
            "Epoch 51/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5146 - accuracy: 0.7639 - val_loss: 0.5576 - val_accuracy: 0.7344\n",
            "Epoch 52/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5133 - accuracy: 0.7656 - val_loss: 0.5567 - val_accuracy: 0.7344\n",
            "Epoch 53/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5118 - accuracy: 0.7674 - val_loss: 0.5558 - val_accuracy: 0.7292\n",
            "Epoch 54/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5106 - accuracy: 0.7674 - val_loss: 0.5551 - val_accuracy: 0.7344\n",
            "Epoch 55/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5093 - accuracy: 0.7726 - val_loss: 0.5545 - val_accuracy: 0.7240\n",
            "Epoch 56/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5080 - accuracy: 0.7743 - val_loss: 0.5538 - val_accuracy: 0.7240\n",
            "Epoch 57/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5070 - accuracy: 0.7743 - val_loss: 0.5531 - val_accuracy: 0.7240\n",
            "Epoch 58/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5058 - accuracy: 0.7743 - val_loss: 0.5523 - val_accuracy: 0.7292\n",
            "Epoch 59/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5046 - accuracy: 0.7778 - val_loss: 0.5516 - val_accuracy: 0.7344\n",
            "Epoch 60/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5034 - accuracy: 0.7778 - val_loss: 0.5509 - val_accuracy: 0.7396\n",
            "Epoch 61/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5025 - accuracy: 0.7743 - val_loss: 0.5503 - val_accuracy: 0.7396\n",
            "Epoch 62/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5014 - accuracy: 0.7743 - val_loss: 0.5498 - val_accuracy: 0.7396\n",
            "Epoch 63/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5006 - accuracy: 0.7743 - val_loss: 0.5493 - val_accuracy: 0.7344\n",
            "Epoch 64/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4994 - accuracy: 0.7795 - val_loss: 0.5489 - val_accuracy: 0.7292\n",
            "Epoch 65/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4986 - accuracy: 0.7795 - val_loss: 0.5484 - val_accuracy: 0.7292\n",
            "Epoch 66/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4976 - accuracy: 0.7830 - val_loss: 0.5481 - val_accuracy: 0.7292\n",
            "Epoch 67/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4969 - accuracy: 0.7830 - val_loss: 0.5475 - val_accuracy: 0.7292\n",
            "Epoch 68/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4957 - accuracy: 0.7830 - val_loss: 0.5470 - val_accuracy: 0.7292\n",
            "Epoch 69/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4949 - accuracy: 0.7830 - val_loss: 0.5464 - val_accuracy: 0.7344\n",
            "Epoch 70/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4943 - accuracy: 0.7830 - val_loss: 0.5461 - val_accuracy: 0.7344\n",
            "Epoch 71/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4934 - accuracy: 0.7830 - val_loss: 0.5455 - val_accuracy: 0.7344\n",
            "Epoch 72/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4926 - accuracy: 0.7865 - val_loss: 0.5454 - val_accuracy: 0.7344\n",
            "Epoch 73/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4919 - accuracy: 0.7865 - val_loss: 0.5449 - val_accuracy: 0.7344\n",
            "Epoch 74/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4913 - accuracy: 0.7882 - val_loss: 0.5445 - val_accuracy: 0.7344\n",
            "Epoch 75/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4904 - accuracy: 0.7899 - val_loss: 0.5442 - val_accuracy: 0.7292\n",
            "Epoch 76/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4899 - accuracy: 0.7917 - val_loss: 0.5439 - val_accuracy: 0.7292\n",
            "Epoch 77/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4891 - accuracy: 0.7917 - val_loss: 0.5433 - val_accuracy: 0.7344\n",
            "Epoch 78/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4884 - accuracy: 0.7899 - val_loss: 0.5429 - val_accuracy: 0.7344\n",
            "Epoch 79/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4878 - accuracy: 0.7917 - val_loss: 0.5428 - val_accuracy: 0.7344\n",
            "Epoch 80/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4873 - accuracy: 0.7934 - val_loss: 0.5425 - val_accuracy: 0.7344\n",
            "Epoch 81/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4866 - accuracy: 0.7951 - val_loss: 0.5422 - val_accuracy: 0.7344\n",
            "Epoch 82/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4860 - accuracy: 0.7934 - val_loss: 0.5418 - val_accuracy: 0.7344\n",
            "Epoch 83/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4852 - accuracy: 0.7934 - val_loss: 0.5414 - val_accuracy: 0.7344\n",
            "Epoch 84/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4846 - accuracy: 0.7917 - val_loss: 0.5413 - val_accuracy: 0.7344\n",
            "Epoch 85/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7934 - val_loss: 0.5411 - val_accuracy: 0.7344\n",
            "Epoch 86/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4833 - accuracy: 0.7917 - val_loss: 0.5407 - val_accuracy: 0.7344\n",
            "Epoch 87/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4829 - accuracy: 0.7917 - val_loss: 0.5404 - val_accuracy: 0.7344\n",
            "Epoch 88/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4823 - accuracy: 0.7917 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
            "Epoch 89/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4817 - accuracy: 0.7917 - val_loss: 0.5401 - val_accuracy: 0.7344\n",
            "Epoch 90/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4812 - accuracy: 0.7951 - val_loss: 0.5399 - val_accuracy: 0.7344\n",
            "Epoch 91/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4806 - accuracy: 0.7934 - val_loss: 0.5396 - val_accuracy: 0.7344\n",
            "Epoch 92/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4802 - accuracy: 0.7969 - val_loss: 0.5393 - val_accuracy: 0.7344\n",
            "Epoch 93/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4797 - accuracy: 0.7917 - val_loss: 0.5389 - val_accuracy: 0.7396\n",
            "Epoch 94/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4793 - accuracy: 0.7917 - val_loss: 0.5389 - val_accuracy: 0.7396\n",
            "Epoch 95/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4786 - accuracy: 0.7951 - val_loss: 0.5386 - val_accuracy: 0.7396\n",
            "Epoch 96/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4786 - accuracy: 0.7934 - val_loss: 0.5384 - val_accuracy: 0.7396\n",
            "Epoch 97/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4777 - accuracy: 0.7934 - val_loss: 0.5381 - val_accuracy: 0.7396\n",
            "Epoch 98/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4772 - accuracy: 0.7951 - val_loss: 0.5378 - val_accuracy: 0.7396\n",
            "Epoch 99/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4766 - accuracy: 0.7934 - val_loss: 0.5377 - val_accuracy: 0.7396\n",
            "Epoch 100/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4764 - accuracy: 0.7934 - val_loss: 0.5375 - val_accuracy: 0.7448\n",
            "Epoch 101/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4762 - accuracy: 0.7986 - val_loss: 0.5374 - val_accuracy: 0.7448\n",
            "Epoch 102/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4756 - accuracy: 0.7969 - val_loss: 0.5371 - val_accuracy: 0.7448\n",
            "Epoch 103/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4752 - accuracy: 0.7986 - val_loss: 0.5366 - val_accuracy: 0.7500\n",
            "Epoch 104/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4744 - accuracy: 0.7986 - val_loss: 0.5365 - val_accuracy: 0.7500\n",
            "Epoch 105/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4742 - accuracy: 0.7951 - val_loss: 0.5363 - val_accuracy: 0.7500\n",
            "Epoch 106/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4736 - accuracy: 0.7969 - val_loss: 0.5360 - val_accuracy: 0.7552\n",
            "Epoch 107/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4733 - accuracy: 0.7882 - val_loss: 0.5358 - val_accuracy: 0.7552\n",
            "Epoch 108/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4730 - accuracy: 0.7917 - val_loss: 0.5357 - val_accuracy: 0.7500\n",
            "Epoch 109/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4725 - accuracy: 0.7882 - val_loss: 0.5356 - val_accuracy: 0.7500\n",
            "Epoch 110/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4720 - accuracy: 0.7760 - val_loss: 0.5357 - val_accuracy: 0.7500\n",
            "Epoch 111/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4719 - accuracy: 0.7951 - val_loss: 0.5353 - val_accuracy: 0.7500\n",
            "Epoch 112/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4713 - accuracy: 0.7865 - val_loss: 0.5351 - val_accuracy: 0.7500\n",
            "Epoch 113/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4710 - accuracy: 0.7882 - val_loss: 0.5350 - val_accuracy: 0.7500\n",
            "Epoch 114/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4704 - accuracy: 0.7830 - val_loss: 0.5350 - val_accuracy: 0.7500\n",
            "Epoch 115/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4703 - accuracy: 0.7847 - val_loss: 0.5348 - val_accuracy: 0.7500\n",
            "Epoch 116/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4698 - accuracy: 0.7830 - val_loss: 0.5344 - val_accuracy: 0.7500\n",
            "Epoch 117/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4694 - accuracy: 0.7865 - val_loss: 0.5342 - val_accuracy: 0.7500\n",
            "Epoch 118/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4690 - accuracy: 0.7847 - val_loss: 0.5341 - val_accuracy: 0.7500\n",
            "Epoch 119/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4688 - accuracy: 0.7899 - val_loss: 0.5337 - val_accuracy: 0.7552\n",
            "Epoch 120/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4682 - accuracy: 0.7778 - val_loss: 0.5335 - val_accuracy: 0.7552\n",
            "Epoch 121/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4680 - accuracy: 0.7760 - val_loss: 0.5333 - val_accuracy: 0.7552\n",
            "Epoch 122/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4677 - accuracy: 0.7778 - val_loss: 0.5333 - val_accuracy: 0.7500\n",
            "Epoch 123/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7778 - val_loss: 0.5331 - val_accuracy: 0.7500\n",
            "Epoch 124/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4668 - accuracy: 0.7812 - val_loss: 0.5328 - val_accuracy: 0.7500\n",
            "Epoch 125/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4663 - accuracy: 0.7778 - val_loss: 0.5326 - val_accuracy: 0.7500\n",
            "Epoch 126/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4661 - accuracy: 0.7812 - val_loss: 0.5323 - val_accuracy: 0.7500\n",
            "Epoch 127/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4659 - accuracy: 0.7795 - val_loss: 0.5321 - val_accuracy: 0.7500\n",
            "Epoch 128/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4655 - accuracy: 0.7865 - val_loss: 0.5318 - val_accuracy: 0.7552\n",
            "Epoch 129/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4650 - accuracy: 0.7778 - val_loss: 0.5318 - val_accuracy: 0.7500\n",
            "Epoch 130/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4647 - accuracy: 0.7743 - val_loss: 0.5318 - val_accuracy: 0.7500\n",
            "Epoch 131/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4642 - accuracy: 0.7812 - val_loss: 0.5318 - val_accuracy: 0.7500\n",
            "Epoch 132/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4640 - accuracy: 0.7778 - val_loss: 0.5315 - val_accuracy: 0.7552\n",
            "Epoch 133/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4637 - accuracy: 0.7812 - val_loss: 0.5313 - val_accuracy: 0.7552\n",
            "Epoch 134/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4633 - accuracy: 0.7830 - val_loss: 0.5311 - val_accuracy: 0.7552\n",
            "Epoch 135/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4628 - accuracy: 0.7778 - val_loss: 0.5312 - val_accuracy: 0.7500\n",
            "Epoch 136/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4625 - accuracy: 0.7830 - val_loss: 0.5312 - val_accuracy: 0.7500\n",
            "Epoch 137/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4619 - accuracy: 0.7812 - val_loss: 0.5310 - val_accuracy: 0.7500\n",
            "Epoch 138/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4617 - accuracy: 0.7812 - val_loss: 0.5309 - val_accuracy: 0.7500\n",
            "Epoch 139/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4611 - accuracy: 0.7830 - val_loss: 0.5308 - val_accuracy: 0.7500\n",
            "Epoch 140/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4607 - accuracy: 0.7795 - val_loss: 0.5308 - val_accuracy: 0.7500\n",
            "Epoch 141/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4602 - accuracy: 0.7830 - val_loss: 0.5307 - val_accuracy: 0.7552\n",
            "Epoch 142/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4601 - accuracy: 0.7830 - val_loss: 0.5306 - val_accuracy: 0.7552\n",
            "Epoch 143/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4596 - accuracy: 0.7795 - val_loss: 0.5307 - val_accuracy: 0.7604\n",
            "Epoch 144/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4588 - accuracy: 0.7812 - val_loss: 0.5308 - val_accuracy: 0.7552\n",
            "Epoch 145/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4586 - accuracy: 0.7865 - val_loss: 0.5308 - val_accuracy: 0.7604\n",
            "Epoch 146/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4577 - accuracy: 0.7847 - val_loss: 0.5310 - val_accuracy: 0.7552\n",
            "Epoch 147/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4574 - accuracy: 0.7847 - val_loss: 0.5310 - val_accuracy: 0.7604\n",
            "Epoch 148/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4568 - accuracy: 0.7830 - val_loss: 0.5312 - val_accuracy: 0.7604\n",
            "Epoch 149/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4563 - accuracy: 0.7830 - val_loss: 0.5313 - val_accuracy: 0.7552\n",
            "Epoch 150/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4559 - accuracy: 0.7830 - val_loss: 0.5315 - val_accuracy: 0.7552\n",
            "Epoch 151/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4555 - accuracy: 0.7847 - val_loss: 0.5316 - val_accuracy: 0.7552\n",
            "Epoch 152/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4553 - accuracy: 0.7830 - val_loss: 0.5317 - val_accuracy: 0.7604\n",
            "Epoch 153/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4548 - accuracy: 0.7847 - val_loss: 0.5319 - val_accuracy: 0.7552\n",
            "Epoch 154/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4541 - accuracy: 0.7847 - val_loss: 0.5321 - val_accuracy: 0.7552\n",
            "Epoch 155/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4538 - accuracy: 0.7847 - val_loss: 0.5322 - val_accuracy: 0.7552\n",
            "Epoch 156/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4532 - accuracy: 0.7830 - val_loss: 0.5322 - val_accuracy: 0.7552\n",
            "Epoch 157/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4531 - accuracy: 0.7847 - val_loss: 0.5322 - val_accuracy: 0.7552\n",
            "Epoch 158/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4523 - accuracy: 0.7865 - val_loss: 0.5323 - val_accuracy: 0.7500\n",
            "Epoch 159/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4520 - accuracy: 0.7847 - val_loss: 0.5324 - val_accuracy: 0.7500\n",
            "Epoch 160/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4513 - accuracy: 0.7865 - val_loss: 0.5323 - val_accuracy: 0.7500\n",
            "Epoch 161/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4512 - accuracy: 0.7882 - val_loss: 0.5324 - val_accuracy: 0.7500\n",
            "Epoch 162/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.7882 - val_loss: 0.5322 - val_accuracy: 0.7500\n",
            "Epoch 163/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4502 - accuracy: 0.7882 - val_loss: 0.5324 - val_accuracy: 0.7448\n",
            "Epoch 164/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4497 - accuracy: 0.7899 - val_loss: 0.5323 - val_accuracy: 0.7448\n",
            "Epoch 165/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4492 - accuracy: 0.7882 - val_loss: 0.5324 - val_accuracy: 0.7448\n",
            "Epoch 166/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4488 - accuracy: 0.7917 - val_loss: 0.5322 - val_accuracy: 0.7448\n",
            "Epoch 167/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4484 - accuracy: 0.7882 - val_loss: 0.5323 - val_accuracy: 0.7448\n",
            "Epoch 168/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4483 - accuracy: 0.7899 - val_loss: 0.5324 - val_accuracy: 0.7448\n",
            "Epoch 169/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4476 - accuracy: 0.7882 - val_loss: 0.5326 - val_accuracy: 0.7448\n",
            "Epoch 170/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4474 - accuracy: 0.7899 - val_loss: 0.5327 - val_accuracy: 0.7448\n",
            "Epoch 171/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4470 - accuracy: 0.7882 - val_loss: 0.5327 - val_accuracy: 0.7448\n",
            "Epoch 172/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4465 - accuracy: 0.7934 - val_loss: 0.5326 - val_accuracy: 0.7448\n",
            "Epoch 173/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4461 - accuracy: 0.7882 - val_loss: 0.5326 - val_accuracy: 0.7448\n",
            "Epoch 174/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.7917 - val_loss: 0.5328 - val_accuracy: 0.7448\n",
            "Epoch 175/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4456 - accuracy: 0.7917 - val_loss: 0.5330 - val_accuracy: 0.7448\n",
            "Epoch 176/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4450 - accuracy: 0.7882 - val_loss: 0.5331 - val_accuracy: 0.7448\n",
            "Epoch 177/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4449 - accuracy: 0.7882 - val_loss: 0.5330 - val_accuracy: 0.7448\n",
            "Epoch 178/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4441 - accuracy: 0.7882 - val_loss: 0.5330 - val_accuracy: 0.7448\n",
            "Epoch 179/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4437 - accuracy: 0.7899 - val_loss: 0.5328 - val_accuracy: 0.7448\n",
            "Epoch 180/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4436 - accuracy: 0.7951 - val_loss: 0.5328 - val_accuracy: 0.7448\n",
            "Epoch 181/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4433 - accuracy: 0.7882 - val_loss: 0.5325 - val_accuracy: 0.7500\n",
            "Epoch 182/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4429 - accuracy: 0.7934 - val_loss: 0.5324 - val_accuracy: 0.7448\n",
            "Epoch 183/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4426 - accuracy: 0.7917 - val_loss: 0.5325 - val_accuracy: 0.7448\n",
            "Epoch 184/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4421 - accuracy: 0.7934 - val_loss: 0.5323 - val_accuracy: 0.7448\n",
            "Epoch 185/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4418 - accuracy: 0.7934 - val_loss: 0.5324 - val_accuracy: 0.7448\n",
            "Epoch 186/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.7917 - val_loss: 0.5325 - val_accuracy: 0.7500\n",
            "Epoch 187/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4411 - accuracy: 0.7934 - val_loss: 0.5323 - val_accuracy: 0.7500\n",
            "Epoch 188/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4407 - accuracy: 0.7934 - val_loss: 0.5322 - val_accuracy: 0.7500\n",
            "Epoch 189/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.7934 - val_loss: 0.5325 - val_accuracy: 0.7500\n",
            "Epoch 190/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4402 - accuracy: 0.7986 - val_loss: 0.5321 - val_accuracy: 0.7500\n",
            "Epoch 191/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4397 - accuracy: 0.7917 - val_loss: 0.5322 - val_accuracy: 0.7500\n",
            "Epoch 192/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4397 - accuracy: 0.7951 - val_loss: 0.5320 - val_accuracy: 0.7500\n",
            "Epoch 193/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4390 - accuracy: 0.7969 - val_loss: 0.5321 - val_accuracy: 0.7552\n",
            "Epoch 194/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4385 - accuracy: 0.7951 - val_loss: 0.5321 - val_accuracy: 0.7552\n",
            "Epoch 195/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4382 - accuracy: 0.7951 - val_loss: 0.5319 - val_accuracy: 0.7552\n",
            "Epoch 196/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4379 - accuracy: 0.7934 - val_loss: 0.5318 - val_accuracy: 0.7552\n",
            "Epoch 197/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4374 - accuracy: 0.8003 - val_loss: 0.5317 - val_accuracy: 0.7552\n",
            "Epoch 198/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4370 - accuracy: 0.7986 - val_loss: 0.5317 - val_accuracy: 0.7552\n",
            "Epoch 199/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4367 - accuracy: 0.7986 - val_loss: 0.5318 - val_accuracy: 0.7552\n",
            "Epoch 200/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4366 - accuracy: 0.8003 - val_loss: 0.5316 - val_accuracy: 0.7604\n",
            "Epoch 201/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4363 - accuracy: 0.8021 - val_loss: 0.5312 - val_accuracy: 0.7604\n",
            "Epoch 202/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4357 - accuracy: 0.8021 - val_loss: 0.5312 - val_accuracy: 0.7604\n",
            "Epoch 203/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4354 - accuracy: 0.7969 - val_loss: 0.5312 - val_accuracy: 0.7604\n",
            "Epoch 204/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4350 - accuracy: 0.8038 - val_loss: 0.5315 - val_accuracy: 0.7604\n",
            "Epoch 205/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4346 - accuracy: 0.8038 - val_loss: 0.5312 - val_accuracy: 0.7604\n",
            "Epoch 206/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4346 - accuracy: 0.8038 - val_loss: 0.5312 - val_accuracy: 0.7604\n",
            "Epoch 207/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4342 - accuracy: 0.8038 - val_loss: 0.5311 - val_accuracy: 0.7604\n",
            "Epoch 208/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4338 - accuracy: 0.8021 - val_loss: 0.5311 - val_accuracy: 0.7552\n",
            "Epoch 209/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4336 - accuracy: 0.8021 - val_loss: 0.5310 - val_accuracy: 0.7552\n",
            "Epoch 210/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4331 - accuracy: 0.8038 - val_loss: 0.5309 - val_accuracy: 0.7604\n",
            "Epoch 211/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4329 - accuracy: 0.8021 - val_loss: 0.5307 - val_accuracy: 0.7604\n",
            "Epoch 212/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4326 - accuracy: 0.8021 - val_loss: 0.5305 - val_accuracy: 0.7604\n",
            "Epoch 213/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4323 - accuracy: 0.8021 - val_loss: 0.5304 - val_accuracy: 0.7604\n",
            "Epoch 214/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4324 - accuracy: 0.8021 - val_loss: 0.5303 - val_accuracy: 0.7604\n",
            "Epoch 215/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4316 - accuracy: 0.8021 - val_loss: 0.5302 - val_accuracy: 0.7604\n",
            "Epoch 216/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4313 - accuracy: 0.8021 - val_loss: 0.5303 - val_accuracy: 0.7604\n",
            "Epoch 217/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4310 - accuracy: 0.8038 - val_loss: 0.5305 - val_accuracy: 0.7604\n",
            "Epoch 218/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4308 - accuracy: 0.8056 - val_loss: 0.5308 - val_accuracy: 0.7552\n",
            "Epoch 219/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4306 - accuracy: 0.8021 - val_loss: 0.5307 - val_accuracy: 0.7552\n",
            "Epoch 220/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4301 - accuracy: 0.8038 - val_loss: 0.5309 - val_accuracy: 0.7552\n",
            "Epoch 221/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4297 - accuracy: 0.8038 - val_loss: 0.5306 - val_accuracy: 0.7552\n",
            "Epoch 222/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4297 - accuracy: 0.8021 - val_loss: 0.5305 - val_accuracy: 0.7552\n",
            "Epoch 223/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4293 - accuracy: 0.8056 - val_loss: 0.5308 - val_accuracy: 0.7552\n",
            "Epoch 224/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4292 - accuracy: 0.8021 - val_loss: 0.5307 - val_accuracy: 0.7552\n",
            "Epoch 225/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4291 - accuracy: 0.8056 - val_loss: 0.5302 - val_accuracy: 0.7552\n",
            "Epoch 226/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4285 - accuracy: 0.8038 - val_loss: 0.5303 - val_accuracy: 0.7552\n",
            "Epoch 227/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4284 - accuracy: 0.8038 - val_loss: 0.5305 - val_accuracy: 0.7552\n",
            "Epoch 228/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4280 - accuracy: 0.8056 - val_loss: 0.5309 - val_accuracy: 0.7552\n",
            "Epoch 229/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4278 - accuracy: 0.8038 - val_loss: 0.5311 - val_accuracy: 0.7552\n",
            "Epoch 230/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4276 - accuracy: 0.8038 - val_loss: 0.5306 - val_accuracy: 0.7552\n",
            "Epoch 231/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4276 - accuracy: 0.8038 - val_loss: 0.5307 - val_accuracy: 0.7552\n",
            "Epoch 232/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4270 - accuracy: 0.8038 - val_loss: 0.5306 - val_accuracy: 0.7552\n",
            "Epoch 233/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4268 - accuracy: 0.8021 - val_loss: 0.5309 - val_accuracy: 0.7552\n",
            "Epoch 234/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4264 - accuracy: 0.8056 - val_loss: 0.5309 - val_accuracy: 0.7552\n",
            "Epoch 235/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4263 - accuracy: 0.8038 - val_loss: 0.5308 - val_accuracy: 0.7552\n",
            "Epoch 236/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4259 - accuracy: 0.8038 - val_loss: 0.5311 - val_accuracy: 0.7552\n",
            "Epoch 237/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4257 - accuracy: 0.8056 - val_loss: 0.5312 - val_accuracy: 0.7552\n",
            "Epoch 238/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4254 - accuracy: 0.8056 - val_loss: 0.5310 - val_accuracy: 0.7552\n",
            "Epoch 239/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4253 - accuracy: 0.8056 - val_loss: 0.5310 - val_accuracy: 0.7552\n",
            "Epoch 240/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4252 - accuracy: 0.8038 - val_loss: 0.5312 - val_accuracy: 0.7604\n",
            "Epoch 241/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4249 - accuracy: 0.8038 - val_loss: 0.5311 - val_accuracy: 0.7656\n",
            "Epoch 242/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4244 - accuracy: 0.8056 - val_loss: 0.5313 - val_accuracy: 0.7656\n",
            "Epoch 243/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4242 - accuracy: 0.8056 - val_loss: 0.5313 - val_accuracy: 0.7656\n",
            "Epoch 244/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4240 - accuracy: 0.8073 - val_loss: 0.5310 - val_accuracy: 0.7656\n",
            "Epoch 245/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4238 - accuracy: 0.8056 - val_loss: 0.5312 - val_accuracy: 0.7656\n",
            "Epoch 246/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4237 - accuracy: 0.8003 - val_loss: 0.5315 - val_accuracy: 0.7656\n",
            "Epoch 247/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4236 - accuracy: 0.8021 - val_loss: 0.5316 - val_accuracy: 0.7656\n",
            "Epoch 248/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4232 - accuracy: 0.8056 - val_loss: 0.5312 - val_accuracy: 0.7708\n",
            "Epoch 249/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4232 - accuracy: 0.8038 - val_loss: 0.5312 - val_accuracy: 0.7708\n",
            "Epoch 250/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4229 - accuracy: 0.8056 - val_loss: 0.5313 - val_accuracy: 0.7708\n",
            "Epoch 251/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4226 - accuracy: 0.8021 - val_loss: 0.5317 - val_accuracy: 0.7708\n",
            "Epoch 252/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4224 - accuracy: 0.8021 - val_loss: 0.5320 - val_accuracy: 0.7708\n",
            "Epoch 253/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4221 - accuracy: 0.8038 - val_loss: 0.5317 - val_accuracy: 0.7708\n",
            "Epoch 254/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4218 - accuracy: 0.8021 - val_loss: 0.5320 - val_accuracy: 0.7656\n",
            "Epoch 255/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4218 - accuracy: 0.8056 - val_loss: 0.5318 - val_accuracy: 0.7656\n",
            "Epoch 256/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4217 - accuracy: 0.8038 - val_loss: 0.5319 - val_accuracy: 0.7656\n",
            "Epoch 257/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4210 - accuracy: 0.8073 - val_loss: 0.5316 - val_accuracy: 0.7656\n",
            "Epoch 258/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4213 - accuracy: 0.8038 - val_loss: 0.5318 - val_accuracy: 0.7656\n",
            "Epoch 259/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4210 - accuracy: 0.8021 - val_loss: 0.5321 - val_accuracy: 0.7656\n",
            "Epoch 260/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4207 - accuracy: 0.8038 - val_loss: 0.5324 - val_accuracy: 0.7656\n",
            "Epoch 261/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4203 - accuracy: 0.8056 - val_loss: 0.5328 - val_accuracy: 0.7656\n",
            "Epoch 262/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4201 - accuracy: 0.8056 - val_loss: 0.5325 - val_accuracy: 0.7656\n",
            "Epoch 263/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4200 - accuracy: 0.8038 - val_loss: 0.5321 - val_accuracy: 0.7656\n",
            "Epoch 264/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4197 - accuracy: 0.8021 - val_loss: 0.5322 - val_accuracy: 0.7656\n",
            "Epoch 265/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4194 - accuracy: 0.8038 - val_loss: 0.5320 - val_accuracy: 0.7656\n",
            "Epoch 266/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4195 - accuracy: 0.8038 - val_loss: 0.5318 - val_accuracy: 0.7604\n",
            "Epoch 267/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4194 - accuracy: 0.8038 - val_loss: 0.5325 - val_accuracy: 0.7656\n",
            "Epoch 268/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4190 - accuracy: 0.8021 - val_loss: 0.5324 - val_accuracy: 0.7656\n",
            "Epoch 269/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4189 - accuracy: 0.8038 - val_loss: 0.5322 - val_accuracy: 0.7604\n",
            "Epoch 270/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4187 - accuracy: 0.8021 - val_loss: 0.5325 - val_accuracy: 0.7656\n",
            "Epoch 271/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4185 - accuracy: 0.8056 - val_loss: 0.5324 - val_accuracy: 0.7604\n",
            "Epoch 272/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4184 - accuracy: 0.8003 - val_loss: 0.5321 - val_accuracy: 0.7552\n",
            "Epoch 273/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4181 - accuracy: 0.8056 - val_loss: 0.5328 - val_accuracy: 0.7708\n",
            "Epoch 274/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4177 - accuracy: 0.8056 - val_loss: 0.5324 - val_accuracy: 0.7656\n",
            "Epoch 275/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4177 - accuracy: 0.8038 - val_loss: 0.5319 - val_accuracy: 0.7604\n",
            "Epoch 276/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4174 - accuracy: 0.8038 - val_loss: 0.5323 - val_accuracy: 0.7604\n",
            "Epoch 277/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4174 - accuracy: 0.8021 - val_loss: 0.5323 - val_accuracy: 0.7604\n",
            "Epoch 278/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4172 - accuracy: 0.8003 - val_loss: 0.5321 - val_accuracy: 0.7604\n",
            "Epoch 279/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4170 - accuracy: 0.8038 - val_loss: 0.5318 - val_accuracy: 0.7604\n",
            "Epoch 280/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4168 - accuracy: 0.8021 - val_loss: 0.5314 - val_accuracy: 0.7604\n",
            "Epoch 281/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4165 - accuracy: 0.7969 - val_loss: 0.5318 - val_accuracy: 0.7604\n",
            "Epoch 282/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4166 - accuracy: 0.8021 - val_loss: 0.5325 - val_accuracy: 0.7656\n",
            "Epoch 283/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4161 - accuracy: 0.8038 - val_loss: 0.5320 - val_accuracy: 0.7604\n",
            "Epoch 284/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4161 - accuracy: 0.8021 - val_loss: 0.5325 - val_accuracy: 0.7656\n",
            "Epoch 285/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4158 - accuracy: 0.8003 - val_loss: 0.5325 - val_accuracy: 0.7656\n",
            "Epoch 286/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4159 - accuracy: 0.8003 - val_loss: 0.5319 - val_accuracy: 0.7604\n",
            "Epoch 287/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4156 - accuracy: 0.8038 - val_loss: 0.5318 - val_accuracy: 0.7604\n",
            "Epoch 288/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4154 - accuracy: 0.8021 - val_loss: 0.5320 - val_accuracy: 0.7656\n",
            "Epoch 289/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4152 - accuracy: 0.8021 - val_loss: 0.5327 - val_accuracy: 0.7656\n",
            "Epoch 290/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4151 - accuracy: 0.8021 - val_loss: 0.5326 - val_accuracy: 0.7656\n",
            "Epoch 291/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4149 - accuracy: 0.8038 - val_loss: 0.5325 - val_accuracy: 0.7656\n",
            "Epoch 292/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4149 - accuracy: 0.8073 - val_loss: 0.5322 - val_accuracy: 0.7656\n",
            "Epoch 293/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4148 - accuracy: 0.8073 - val_loss: 0.5322 - val_accuracy: 0.7656\n",
            "Epoch 294/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4146 - accuracy: 0.8038 - val_loss: 0.5322 - val_accuracy: 0.7656\n",
            "Epoch 295/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4142 - accuracy: 0.8038 - val_loss: 0.5327 - val_accuracy: 0.7604\n",
            "Epoch 296/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4145 - accuracy: 0.8003 - val_loss: 0.5322 - val_accuracy: 0.7656\n",
            "Epoch 297/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4139 - accuracy: 0.8056 - val_loss: 0.5321 - val_accuracy: 0.7656\n",
            "Epoch 298/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4140 - accuracy: 0.8073 - val_loss: 0.5321 - val_accuracy: 0.7604\n",
            "Epoch 299/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4138 - accuracy: 0.8073 - val_loss: 0.5327 - val_accuracy: 0.7604\n",
            "Epoch 300/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4134 - accuracy: 0.8073 - val_loss: 0.5337 - val_accuracy: 0.7552\n",
            "Epoch 301/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4134 - accuracy: 0.8073 - val_loss: 0.5332 - val_accuracy: 0.7552\n",
            "Epoch 302/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4131 - accuracy: 0.8073 - val_loss: 0.5327 - val_accuracy: 0.7604\n",
            "Epoch 303/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4129 - accuracy: 0.8090 - val_loss: 0.5332 - val_accuracy: 0.7552\n",
            "Epoch 304/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4131 - accuracy: 0.8073 - val_loss: 0.5334 - val_accuracy: 0.7552\n",
            "Epoch 305/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4126 - accuracy: 0.8056 - val_loss: 0.5335 - val_accuracy: 0.7552\n",
            "Epoch 306/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4126 - accuracy: 0.8125 - val_loss: 0.5336 - val_accuracy: 0.7552\n",
            "Epoch 307/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4122 - accuracy: 0.8073 - val_loss: 0.5334 - val_accuracy: 0.7552\n",
            "Epoch 308/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4122 - accuracy: 0.8056 - val_loss: 0.5334 - val_accuracy: 0.7552\n",
            "Epoch 309/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4122 - accuracy: 0.8090 - val_loss: 0.5335 - val_accuracy: 0.7552\n",
            "Epoch 310/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4123 - accuracy: 0.8056 - val_loss: 0.5339 - val_accuracy: 0.7500\n",
            "Epoch 311/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4119 - accuracy: 0.8056 - val_loss: 0.5334 - val_accuracy: 0.7552\n",
            "Epoch 312/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4116 - accuracy: 0.8056 - val_loss: 0.5338 - val_accuracy: 0.7500\n",
            "Epoch 313/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4116 - accuracy: 0.8056 - val_loss: 0.5342 - val_accuracy: 0.7500\n",
            "Epoch 314/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4116 - accuracy: 0.8090 - val_loss: 0.5346 - val_accuracy: 0.7500\n",
            "Epoch 315/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4111 - accuracy: 0.8073 - val_loss: 0.5349 - val_accuracy: 0.7500\n",
            "Epoch 316/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4113 - accuracy: 0.8021 - val_loss: 0.5354 - val_accuracy: 0.7500\n",
            "Epoch 317/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4109 - accuracy: 0.8073 - val_loss: 0.5341 - val_accuracy: 0.7500\n",
            "Epoch 318/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4109 - accuracy: 0.8073 - val_loss: 0.5352 - val_accuracy: 0.7500\n",
            "Epoch 319/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4107 - accuracy: 0.8038 - val_loss: 0.5355 - val_accuracy: 0.7500\n",
            "Epoch 320/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8090 - val_loss: 0.5352 - val_accuracy: 0.7500\n",
            "Epoch 321/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8090 - val_loss: 0.5350 - val_accuracy: 0.7500\n",
            "Epoch 322/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8073 - val_loss: 0.5356 - val_accuracy: 0.7500\n",
            "Epoch 323/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4099 - accuracy: 0.8090 - val_loss: 0.5351 - val_accuracy: 0.7500\n",
            "Epoch 324/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4098 - accuracy: 0.8073 - val_loss: 0.5348 - val_accuracy: 0.7448\n",
            "Epoch 325/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4098 - accuracy: 0.8090 - val_loss: 0.5350 - val_accuracy: 0.7448\n",
            "Epoch 326/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4099 - accuracy: 0.8108 - val_loss: 0.5349 - val_accuracy: 0.7448\n",
            "Epoch 327/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4095 - accuracy: 0.8073 - val_loss: 0.5357 - val_accuracy: 0.7448\n",
            "Epoch 328/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4097 - accuracy: 0.8108 - val_loss: 0.5360 - val_accuracy: 0.7448\n",
            "Epoch 329/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4092 - accuracy: 0.8090 - val_loss: 0.5357 - val_accuracy: 0.7448\n",
            "Epoch 330/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4091 - accuracy: 0.8125 - val_loss: 0.5363 - val_accuracy: 0.7500\n",
            "Epoch 331/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4090 - accuracy: 0.8108 - val_loss: 0.5359 - val_accuracy: 0.7448\n",
            "Epoch 332/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4086 - accuracy: 0.8073 - val_loss: 0.5363 - val_accuracy: 0.7448\n",
            "Epoch 333/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4086 - accuracy: 0.8090 - val_loss: 0.5358 - val_accuracy: 0.7448\n",
            "Epoch 334/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4085 - accuracy: 0.8108 - val_loss: 0.5369 - val_accuracy: 0.7552\n",
            "Epoch 335/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4084 - accuracy: 0.8073 - val_loss: 0.5362 - val_accuracy: 0.7448\n",
            "Epoch 336/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4078 - accuracy: 0.8090 - val_loss: 0.5365 - val_accuracy: 0.7448\n",
            "Epoch 337/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4080 - accuracy: 0.8056 - val_loss: 0.5360 - val_accuracy: 0.7448\n",
            "Epoch 338/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4078 - accuracy: 0.8142 - val_loss: 0.5361 - val_accuracy: 0.7448\n",
            "Epoch 339/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4074 - accuracy: 0.8125 - val_loss: 0.5365 - val_accuracy: 0.7448\n",
            "Epoch 340/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4076 - accuracy: 0.8090 - val_loss: 0.5366 - val_accuracy: 0.7500\n",
            "Epoch 341/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4072 - accuracy: 0.8125 - val_loss: 0.5361 - val_accuracy: 0.7448\n",
            "Epoch 342/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4072 - accuracy: 0.8090 - val_loss: 0.5359 - val_accuracy: 0.7448\n",
            "Epoch 343/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4075 - accuracy: 0.8108 - val_loss: 0.5355 - val_accuracy: 0.7448\n",
            "Epoch 344/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4069 - accuracy: 0.8142 - val_loss: 0.5363 - val_accuracy: 0.7448\n",
            "Epoch 345/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4069 - accuracy: 0.8108 - val_loss: 0.5354 - val_accuracy: 0.7448\n",
            "Epoch 346/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4065 - accuracy: 0.8125 - val_loss: 0.5358 - val_accuracy: 0.7448\n",
            "Epoch 347/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4066 - accuracy: 0.8125 - val_loss: 0.5363 - val_accuracy: 0.7448\n",
            "Epoch 348/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4070 - accuracy: 0.8090 - val_loss: 0.5362 - val_accuracy: 0.7448\n",
            "Epoch 349/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4060 - accuracy: 0.8108 - val_loss: 0.5363 - val_accuracy: 0.7448\n",
            "Epoch 350/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4063 - accuracy: 0.8108 - val_loss: 0.5362 - val_accuracy: 0.7448\n",
            "Epoch 351/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4061 - accuracy: 0.8090 - val_loss: 0.5364 - val_accuracy: 0.7448\n",
            "Epoch 352/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4059 - accuracy: 0.8125 - val_loss: 0.5362 - val_accuracy: 0.7448\n",
            "Epoch 353/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4057 - accuracy: 0.8090 - val_loss: 0.5358 - val_accuracy: 0.7448\n",
            "Epoch 354/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4057 - accuracy: 0.8125 - val_loss: 0.5362 - val_accuracy: 0.7448\n",
            "Epoch 355/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4055 - accuracy: 0.8108 - val_loss: 0.5368 - val_accuracy: 0.7448\n",
            "Epoch 356/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4054 - accuracy: 0.8090 - val_loss: 0.5362 - val_accuracy: 0.7448\n",
            "Epoch 357/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4050 - accuracy: 0.8142 - val_loss: 0.5374 - val_accuracy: 0.7448\n",
            "Epoch 358/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4050 - accuracy: 0.8142 - val_loss: 0.5372 - val_accuracy: 0.7448\n",
            "Epoch 359/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4047 - accuracy: 0.8090 - val_loss: 0.5377 - val_accuracy: 0.7448\n",
            "Epoch 360/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4050 - accuracy: 0.8108 - val_loss: 0.5373 - val_accuracy: 0.7448\n",
            "Epoch 361/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4047 - accuracy: 0.8125 - val_loss: 0.5366 - val_accuracy: 0.7448\n",
            "Epoch 362/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4043 - accuracy: 0.8108 - val_loss: 0.5378 - val_accuracy: 0.7448\n",
            "Epoch 363/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4042 - accuracy: 0.8160 - val_loss: 0.5379 - val_accuracy: 0.7448\n",
            "Epoch 364/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4048 - accuracy: 0.8125 - val_loss: 0.5379 - val_accuracy: 0.7448\n",
            "Epoch 365/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4043 - accuracy: 0.8108 - val_loss: 0.5385 - val_accuracy: 0.7500\n",
            "Epoch 366/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4041 - accuracy: 0.8125 - val_loss: 0.5383 - val_accuracy: 0.7448\n",
            "Epoch 367/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4043 - accuracy: 0.8108 - val_loss: 0.5387 - val_accuracy: 0.7500\n",
            "Epoch 368/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4037 - accuracy: 0.8125 - val_loss: 0.5390 - val_accuracy: 0.7500\n",
            "Epoch 369/800\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4039 - accuracy: 0.8142 - val_loss: 0.5398 - val_accuracy: 0.7500\n",
            "Epoch 370/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4041 - accuracy: 0.8125 - val_loss: 0.5401 - val_accuracy: 0.7500\n",
            "Epoch 371/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4036 - accuracy: 0.8160 - val_loss: 0.5399 - val_accuracy: 0.7500\n",
            "Epoch 372/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4032 - accuracy: 0.8125 - val_loss: 0.5400 - val_accuracy: 0.7500\n",
            "Epoch 373/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4031 - accuracy: 0.8142 - val_loss: 0.5412 - val_accuracy: 0.7500\n",
            "Epoch 374/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4030 - accuracy: 0.8125 - val_loss: 0.5403 - val_accuracy: 0.7500\n",
            "Epoch 375/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4032 - accuracy: 0.8160 - val_loss: 0.5407 - val_accuracy: 0.7500\n",
            "Epoch 376/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4028 - accuracy: 0.8125 - val_loss: 0.5414 - val_accuracy: 0.7500\n",
            "Epoch 377/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4027 - accuracy: 0.8125 - val_loss: 0.5406 - val_accuracy: 0.7448\n",
            "Epoch 378/800\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4026 - accuracy: 0.8125 - val_loss: 0.5408 - val_accuracy: 0.7448\n",
            "Epoch 379/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4022 - accuracy: 0.8194 - val_loss: 0.5401 - val_accuracy: 0.7448\n",
            "Epoch 380/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4022 - accuracy: 0.8125 - val_loss: 0.5405 - val_accuracy: 0.7448\n",
            "Epoch 381/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4023 - accuracy: 0.8125 - val_loss: 0.5409 - val_accuracy: 0.7448\n",
            "Epoch 382/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4025 - accuracy: 0.8160 - val_loss: 0.5405 - val_accuracy: 0.7448\n",
            "Epoch 383/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4018 - accuracy: 0.8177 - val_loss: 0.5403 - val_accuracy: 0.7500\n",
            "Epoch 384/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4018 - accuracy: 0.8142 - val_loss: 0.5408 - val_accuracy: 0.7500\n",
            "Epoch 385/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4015 - accuracy: 0.8160 - val_loss: 0.5414 - val_accuracy: 0.7448\n",
            "Epoch 386/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4016 - accuracy: 0.8125 - val_loss: 0.5422 - val_accuracy: 0.7448\n",
            "Epoch 387/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4013 - accuracy: 0.8177 - val_loss: 0.5417 - val_accuracy: 0.7448\n",
            "Epoch 388/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4012 - accuracy: 0.8177 - val_loss: 0.5419 - val_accuracy: 0.7448\n",
            "Epoch 389/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4013 - accuracy: 0.8160 - val_loss: 0.5421 - val_accuracy: 0.7448\n",
            "Epoch 390/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4015 - accuracy: 0.8160 - val_loss: 0.5423 - val_accuracy: 0.7448\n",
            "Epoch 391/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4008 - accuracy: 0.8194 - val_loss: 0.5419 - val_accuracy: 0.7500\n",
            "Epoch 392/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4008 - accuracy: 0.8177 - val_loss: 0.5421 - val_accuracy: 0.7448\n",
            "Epoch 393/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4006 - accuracy: 0.8177 - val_loss: 0.5423 - val_accuracy: 0.7500\n",
            "Epoch 394/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4005 - accuracy: 0.8142 - val_loss: 0.5422 - val_accuracy: 0.7500\n",
            "Epoch 395/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4004 - accuracy: 0.8160 - val_loss: 0.5427 - val_accuracy: 0.7448\n",
            "Epoch 396/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4004 - accuracy: 0.8177 - val_loss: 0.5432 - val_accuracy: 0.7396\n",
            "Epoch 397/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3999 - accuracy: 0.8194 - val_loss: 0.5433 - val_accuracy: 0.7396\n",
            "Epoch 398/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3999 - accuracy: 0.8194 - val_loss: 0.5435 - val_accuracy: 0.7500\n",
            "Epoch 399/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3996 - accuracy: 0.8177 - val_loss: 0.5435 - val_accuracy: 0.7500\n",
            "Epoch 400/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3997 - accuracy: 0.8177 - val_loss: 0.5429 - val_accuracy: 0.7500\n",
            "Epoch 401/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4000 - accuracy: 0.8177 - val_loss: 0.5440 - val_accuracy: 0.7552\n",
            "Epoch 402/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3993 - accuracy: 0.8194 - val_loss: 0.5435 - val_accuracy: 0.7500\n",
            "Epoch 403/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3997 - accuracy: 0.8194 - val_loss: 0.5434 - val_accuracy: 0.7500\n",
            "Epoch 404/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3994 - accuracy: 0.8194 - val_loss: 0.5433 - val_accuracy: 0.7500\n",
            "Epoch 405/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3991 - accuracy: 0.8177 - val_loss: 0.5438 - val_accuracy: 0.7604\n",
            "Epoch 406/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3991 - accuracy: 0.8177 - val_loss: 0.5442 - val_accuracy: 0.7656\n",
            "Epoch 407/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3991 - accuracy: 0.8194 - val_loss: 0.5445 - val_accuracy: 0.7656\n",
            "Epoch 408/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3988 - accuracy: 0.8177 - val_loss: 0.5449 - val_accuracy: 0.7656\n",
            "Epoch 409/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3987 - accuracy: 0.8194 - val_loss: 0.5451 - val_accuracy: 0.7656\n",
            "Epoch 410/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3988 - accuracy: 0.8194 - val_loss: 0.5447 - val_accuracy: 0.7656\n",
            "Epoch 411/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3987 - accuracy: 0.8229 - val_loss: 0.5441 - val_accuracy: 0.7656\n",
            "Epoch 412/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3988 - accuracy: 0.8212 - val_loss: 0.5436 - val_accuracy: 0.7656\n",
            "Epoch 413/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3981 - accuracy: 0.8177 - val_loss: 0.5442 - val_accuracy: 0.7656\n",
            "Epoch 414/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3978 - accuracy: 0.8160 - val_loss: 0.5450 - val_accuracy: 0.7656\n",
            "Epoch 415/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3978 - accuracy: 0.8194 - val_loss: 0.5453 - val_accuracy: 0.7656\n",
            "Epoch 416/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3980 - accuracy: 0.8177 - val_loss: 0.5455 - val_accuracy: 0.7656\n",
            "Epoch 417/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3979 - accuracy: 0.8194 - val_loss: 0.5454 - val_accuracy: 0.7656\n",
            "Epoch 418/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3973 - accuracy: 0.8177 - val_loss: 0.5454 - val_accuracy: 0.7656\n",
            "Epoch 419/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3975 - accuracy: 0.8194 - val_loss: 0.5457 - val_accuracy: 0.7656\n",
            "Epoch 420/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3971 - accuracy: 0.8194 - val_loss: 0.5466 - val_accuracy: 0.7656\n",
            "Epoch 421/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3973 - accuracy: 0.8247 - val_loss: 0.5460 - val_accuracy: 0.7656\n",
            "Epoch 422/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3973 - accuracy: 0.8212 - val_loss: 0.5456 - val_accuracy: 0.7656\n",
            "Epoch 423/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3971 - accuracy: 0.8194 - val_loss: 0.5462 - val_accuracy: 0.7656\n",
            "Epoch 424/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3969 - accuracy: 0.8229 - val_loss: 0.5458 - val_accuracy: 0.7656\n",
            "Epoch 425/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3968 - accuracy: 0.8194 - val_loss: 0.5459 - val_accuracy: 0.7656\n",
            "Epoch 426/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3964 - accuracy: 0.8212 - val_loss: 0.5458 - val_accuracy: 0.7656\n",
            "Epoch 427/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3962 - accuracy: 0.8194 - val_loss: 0.5461 - val_accuracy: 0.7656\n",
            "Epoch 428/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3965 - accuracy: 0.8194 - val_loss: 0.5466 - val_accuracy: 0.7656\n",
            "Epoch 429/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3962 - accuracy: 0.8194 - val_loss: 0.5472 - val_accuracy: 0.7656\n",
            "Epoch 430/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3961 - accuracy: 0.8212 - val_loss: 0.5470 - val_accuracy: 0.7656\n",
            "Epoch 431/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3960 - accuracy: 0.8194 - val_loss: 0.5475 - val_accuracy: 0.7656\n",
            "Epoch 432/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3961 - accuracy: 0.8194 - val_loss: 0.5473 - val_accuracy: 0.7656\n",
            "Epoch 433/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3958 - accuracy: 0.8194 - val_loss: 0.5480 - val_accuracy: 0.7656\n",
            "Epoch 434/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3955 - accuracy: 0.8177 - val_loss: 0.5486 - val_accuracy: 0.7656\n",
            "Epoch 435/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3958 - accuracy: 0.8212 - val_loss: 0.5485 - val_accuracy: 0.7656\n",
            "Epoch 436/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3956 - accuracy: 0.8194 - val_loss: 0.5486 - val_accuracy: 0.7656\n",
            "Epoch 437/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3951 - accuracy: 0.8229 - val_loss: 0.5482 - val_accuracy: 0.7656\n",
            "Epoch 438/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3953 - accuracy: 0.8212 - val_loss: 0.5487 - val_accuracy: 0.7656\n",
            "Epoch 439/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3951 - accuracy: 0.8212 - val_loss: 0.5491 - val_accuracy: 0.7656\n",
            "Epoch 440/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3953 - accuracy: 0.8281 - val_loss: 0.5486 - val_accuracy: 0.7656\n",
            "Epoch 441/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3950 - accuracy: 0.8247 - val_loss: 0.5489 - val_accuracy: 0.7656\n",
            "Epoch 442/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3949 - accuracy: 0.8247 - val_loss: 0.5500 - val_accuracy: 0.7656\n",
            "Epoch 443/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3952 - accuracy: 0.8229 - val_loss: 0.5490 - val_accuracy: 0.7656\n",
            "Epoch 444/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3950 - accuracy: 0.8212 - val_loss: 0.5497 - val_accuracy: 0.7656\n",
            "Epoch 445/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3950 - accuracy: 0.8229 - val_loss: 0.5499 - val_accuracy: 0.7656\n",
            "Epoch 446/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3945 - accuracy: 0.8229 - val_loss: 0.5500 - val_accuracy: 0.7656\n",
            "Epoch 447/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3944 - accuracy: 0.8264 - val_loss: 0.5503 - val_accuracy: 0.7656\n",
            "Epoch 448/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3944 - accuracy: 0.8264 - val_loss: 0.5504 - val_accuracy: 0.7656\n",
            "Epoch 449/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3945 - accuracy: 0.8264 - val_loss: 0.5507 - val_accuracy: 0.7656\n",
            "Epoch 450/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3941 - accuracy: 0.8229 - val_loss: 0.5503 - val_accuracy: 0.7656\n",
            "Epoch 451/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3941 - accuracy: 0.8264 - val_loss: 0.5505 - val_accuracy: 0.7656\n",
            "Epoch 452/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3939 - accuracy: 0.8264 - val_loss: 0.5505 - val_accuracy: 0.7656\n",
            "Epoch 453/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3938 - accuracy: 0.8247 - val_loss: 0.5507 - val_accuracy: 0.7656\n",
            "Epoch 454/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3940 - accuracy: 0.8281 - val_loss: 0.5506 - val_accuracy: 0.7656\n",
            "Epoch 455/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3939 - accuracy: 0.8281 - val_loss: 0.5503 - val_accuracy: 0.7656\n",
            "Epoch 456/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3936 - accuracy: 0.8264 - val_loss: 0.5524 - val_accuracy: 0.7656\n",
            "Epoch 457/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3938 - accuracy: 0.8281 - val_loss: 0.5512 - val_accuracy: 0.7656\n",
            "Epoch 458/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3936 - accuracy: 0.8281 - val_loss: 0.5517 - val_accuracy: 0.7656\n",
            "Epoch 459/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3936 - accuracy: 0.8247 - val_loss: 0.5510 - val_accuracy: 0.7656\n",
            "Epoch 460/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3935 - accuracy: 0.8247 - val_loss: 0.5516 - val_accuracy: 0.7656\n",
            "Epoch 461/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3929 - accuracy: 0.8281 - val_loss: 0.5507 - val_accuracy: 0.7604\n",
            "Epoch 462/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3931 - accuracy: 0.8247 - val_loss: 0.5512 - val_accuracy: 0.7656\n",
            "Epoch 463/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3928 - accuracy: 0.8264 - val_loss: 0.5508 - val_accuracy: 0.7604\n",
            "Epoch 464/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3931 - accuracy: 0.8264 - val_loss: 0.5516 - val_accuracy: 0.7656\n",
            "Epoch 465/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3931 - accuracy: 0.8299 - val_loss: 0.5504 - val_accuracy: 0.7604\n",
            "Epoch 466/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3931 - accuracy: 0.8264 - val_loss: 0.5506 - val_accuracy: 0.7604\n",
            "Epoch 467/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3928 - accuracy: 0.8281 - val_loss: 0.5512 - val_accuracy: 0.7604\n",
            "Epoch 468/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3930 - accuracy: 0.8247 - val_loss: 0.5515 - val_accuracy: 0.7604\n",
            "Epoch 469/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3923 - accuracy: 0.8247 - val_loss: 0.5522 - val_accuracy: 0.7656\n",
            "Epoch 470/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3924 - accuracy: 0.8247 - val_loss: 0.5527 - val_accuracy: 0.7656\n",
            "Epoch 471/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3924 - accuracy: 0.8299 - val_loss: 0.5517 - val_accuracy: 0.7604\n",
            "Epoch 472/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3926 - accuracy: 0.8247 - val_loss: 0.5527 - val_accuracy: 0.7656\n",
            "Epoch 473/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3922 - accuracy: 0.8247 - val_loss: 0.5540 - val_accuracy: 0.7656\n",
            "Epoch 474/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3920 - accuracy: 0.8264 - val_loss: 0.5540 - val_accuracy: 0.7656\n",
            "Epoch 475/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3924 - accuracy: 0.8316 - val_loss: 0.5533 - val_accuracy: 0.7656\n",
            "Epoch 476/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3921 - accuracy: 0.8264 - val_loss: 0.5534 - val_accuracy: 0.7656\n",
            "Epoch 477/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3921 - accuracy: 0.8281 - val_loss: 0.5528 - val_accuracy: 0.7604\n",
            "Epoch 478/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3918 - accuracy: 0.8299 - val_loss: 0.5525 - val_accuracy: 0.7604\n",
            "Epoch 479/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3914 - accuracy: 0.8264 - val_loss: 0.5525 - val_accuracy: 0.7604\n",
            "Epoch 480/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3915 - accuracy: 0.8264 - val_loss: 0.5535 - val_accuracy: 0.7656\n",
            "Epoch 481/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3917 - accuracy: 0.8316 - val_loss: 0.5528 - val_accuracy: 0.7604\n",
            "Epoch 482/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3916 - accuracy: 0.8316 - val_loss: 0.5526 - val_accuracy: 0.7604\n",
            "Epoch 483/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3916 - accuracy: 0.8264 - val_loss: 0.5528 - val_accuracy: 0.7604\n",
            "Epoch 484/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3912 - accuracy: 0.8264 - val_loss: 0.5532 - val_accuracy: 0.7604\n",
            "Epoch 485/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3913 - accuracy: 0.8264 - val_loss: 0.5532 - val_accuracy: 0.7604\n",
            "Epoch 486/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3912 - accuracy: 0.8247 - val_loss: 0.5544 - val_accuracy: 0.7656\n",
            "Epoch 487/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3908 - accuracy: 0.8299 - val_loss: 0.5545 - val_accuracy: 0.7656\n",
            "Epoch 488/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3908 - accuracy: 0.8299 - val_loss: 0.5543 - val_accuracy: 0.7656\n",
            "Epoch 489/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3909 - accuracy: 0.8316 - val_loss: 0.5533 - val_accuracy: 0.7604\n",
            "Epoch 490/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3912 - accuracy: 0.8316 - val_loss: 0.5533 - val_accuracy: 0.7604\n",
            "Epoch 491/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3907 - accuracy: 0.8281 - val_loss: 0.5538 - val_accuracy: 0.7604\n",
            "Epoch 492/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3908 - accuracy: 0.8264 - val_loss: 0.5547 - val_accuracy: 0.7656\n",
            "Epoch 493/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3908 - accuracy: 0.8281 - val_loss: 0.5548 - val_accuracy: 0.7656\n",
            "Epoch 494/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3904 - accuracy: 0.8264 - val_loss: 0.5560 - val_accuracy: 0.7656\n",
            "Epoch 495/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3906 - accuracy: 0.8333 - val_loss: 0.5546 - val_accuracy: 0.7656\n",
            "Epoch 496/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3903 - accuracy: 0.8299 - val_loss: 0.5545 - val_accuracy: 0.7656\n",
            "Epoch 497/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3902 - accuracy: 0.8281 - val_loss: 0.5555 - val_accuracy: 0.7656\n",
            "Epoch 498/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3902 - accuracy: 0.8281 - val_loss: 0.5553 - val_accuracy: 0.7656\n",
            "Epoch 499/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3902 - accuracy: 0.8281 - val_loss: 0.5552 - val_accuracy: 0.7656\n",
            "Epoch 500/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3903 - accuracy: 0.8299 - val_loss: 0.5556 - val_accuracy: 0.7656\n",
            "Epoch 501/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3904 - accuracy: 0.8247 - val_loss: 0.5559 - val_accuracy: 0.7656\n",
            "Epoch 502/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3902 - accuracy: 0.8299 - val_loss: 0.5559 - val_accuracy: 0.7656\n",
            "Epoch 503/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3895 - accuracy: 0.8299 - val_loss: 0.5556 - val_accuracy: 0.7656\n",
            "Epoch 504/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3900 - accuracy: 0.8299 - val_loss: 0.5555 - val_accuracy: 0.7656\n",
            "Epoch 505/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3895 - accuracy: 0.8281 - val_loss: 0.5560 - val_accuracy: 0.7656\n",
            "Epoch 506/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3899 - accuracy: 0.8281 - val_loss: 0.5561 - val_accuracy: 0.7656\n",
            "Epoch 507/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3896 - accuracy: 0.8316 - val_loss: 0.5559 - val_accuracy: 0.7656\n",
            "Epoch 508/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3898 - accuracy: 0.8299 - val_loss: 0.5561 - val_accuracy: 0.7656\n",
            "Epoch 509/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3894 - accuracy: 0.8299 - val_loss: 0.5556 - val_accuracy: 0.7656\n",
            "Epoch 510/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3894 - accuracy: 0.8281 - val_loss: 0.5556 - val_accuracy: 0.7656\n",
            "Epoch 511/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3896 - accuracy: 0.8333 - val_loss: 0.5556 - val_accuracy: 0.7656\n",
            "Epoch 512/800\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3893 - accuracy: 0.8264 - val_loss: 0.5557 - val_accuracy: 0.7656\n",
            "Epoch 513/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3891 - accuracy: 0.8299 - val_loss: 0.5567 - val_accuracy: 0.7656\n",
            "Epoch 514/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3892 - accuracy: 0.8281 - val_loss: 0.5565 - val_accuracy: 0.7656\n",
            "Epoch 515/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3894 - accuracy: 0.8281 - val_loss: 0.5565 - val_accuracy: 0.7656\n",
            "Epoch 516/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3889 - accuracy: 0.8299 - val_loss: 0.5570 - val_accuracy: 0.7656\n",
            "Epoch 517/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3888 - accuracy: 0.8264 - val_loss: 0.5580 - val_accuracy: 0.7656\n",
            "Epoch 518/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3889 - accuracy: 0.8316 - val_loss: 0.5578 - val_accuracy: 0.7656\n",
            "Epoch 519/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3891 - accuracy: 0.8299 - val_loss: 0.5566 - val_accuracy: 0.7656\n",
            "Epoch 520/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3888 - accuracy: 0.8299 - val_loss: 0.5573 - val_accuracy: 0.7656\n",
            "Epoch 521/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3886 - accuracy: 0.8299 - val_loss: 0.5575 - val_accuracy: 0.7656\n",
            "Epoch 522/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3885 - accuracy: 0.8299 - val_loss: 0.5576 - val_accuracy: 0.7656\n",
            "Epoch 523/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3886 - accuracy: 0.8316 - val_loss: 0.5571 - val_accuracy: 0.7656\n",
            "Epoch 524/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3883 - accuracy: 0.8264 - val_loss: 0.5572 - val_accuracy: 0.7656\n",
            "Epoch 525/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3885 - accuracy: 0.8299 - val_loss: 0.5579 - val_accuracy: 0.7656\n",
            "Epoch 526/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3885 - accuracy: 0.8281 - val_loss: 0.5577 - val_accuracy: 0.7656\n",
            "Epoch 527/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3879 - accuracy: 0.8281 - val_loss: 0.5597 - val_accuracy: 0.7656\n",
            "Epoch 528/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3885 - accuracy: 0.8316 - val_loss: 0.5591 - val_accuracy: 0.7656\n",
            "Epoch 529/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3881 - accuracy: 0.8299 - val_loss: 0.5591 - val_accuracy: 0.7656\n",
            "Epoch 530/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3880 - accuracy: 0.8299 - val_loss: 0.5586 - val_accuracy: 0.7656\n",
            "Epoch 531/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3882 - accuracy: 0.8316 - val_loss: 0.5578 - val_accuracy: 0.7656\n",
            "Epoch 532/800\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3878 - accuracy: 0.8299 - val_loss: 0.5580 - val_accuracy: 0.7656\n",
            "Epoch 533/800\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3880 - accuracy: 0.8281 - val_loss: 0.5588 - val_accuracy: 0.7656\n",
            "Epoch 534/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3873 - accuracy: 0.8333 - val_loss: 0.5576 - val_accuracy: 0.7656\n",
            "Epoch 535/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3875 - accuracy: 0.8299 - val_loss: 0.5582 - val_accuracy: 0.7656\n",
            "Epoch 536/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3873 - accuracy: 0.8316 - val_loss: 0.5587 - val_accuracy: 0.7656\n",
            "Epoch 537/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3879 - accuracy: 0.8333 - val_loss: 0.5586 - val_accuracy: 0.7656\n",
            "Epoch 538/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3875 - accuracy: 0.8281 - val_loss: 0.5588 - val_accuracy: 0.7656\n",
            "Epoch 539/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3876 - accuracy: 0.8281 - val_loss: 0.5586 - val_accuracy: 0.7656\n",
            "Epoch 540/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3874 - accuracy: 0.8299 - val_loss: 0.5582 - val_accuracy: 0.7656\n",
            "Epoch 541/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3871 - accuracy: 0.8281 - val_loss: 0.5591 - val_accuracy: 0.7656\n",
            "Epoch 542/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3870 - accuracy: 0.8316 - val_loss: 0.5583 - val_accuracy: 0.7656\n",
            "Epoch 543/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3871 - accuracy: 0.8299 - val_loss: 0.5589 - val_accuracy: 0.7656\n",
            "Epoch 544/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3871 - accuracy: 0.8316 - val_loss: 0.5594 - val_accuracy: 0.7656\n",
            "Epoch 545/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3871 - accuracy: 0.8299 - val_loss: 0.5586 - val_accuracy: 0.7656\n",
            "Epoch 546/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3871 - accuracy: 0.8299 - val_loss: 0.5593 - val_accuracy: 0.7656\n",
            "Epoch 547/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3869 - accuracy: 0.8316 - val_loss: 0.5599 - val_accuracy: 0.7604\n",
            "Epoch 548/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3869 - accuracy: 0.8316 - val_loss: 0.5606 - val_accuracy: 0.7604\n",
            "Epoch 549/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3869 - accuracy: 0.8299 - val_loss: 0.5602 - val_accuracy: 0.7604\n",
            "Epoch 550/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3863 - accuracy: 0.8333 - val_loss: 0.5598 - val_accuracy: 0.7604\n",
            "Epoch 551/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3872 - accuracy: 0.8351 - val_loss: 0.5599 - val_accuracy: 0.7656\n",
            "Epoch 552/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3865 - accuracy: 0.8281 - val_loss: 0.5607 - val_accuracy: 0.7604\n",
            "Epoch 553/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3865 - accuracy: 0.8316 - val_loss: 0.5605 - val_accuracy: 0.7604\n",
            "Epoch 554/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3863 - accuracy: 0.8299 - val_loss: 0.5609 - val_accuracy: 0.7604\n",
            "Epoch 555/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3862 - accuracy: 0.8316 - val_loss: 0.5617 - val_accuracy: 0.7604\n",
            "Epoch 556/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3860 - accuracy: 0.8333 - val_loss: 0.5621 - val_accuracy: 0.7604\n",
            "Epoch 557/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3864 - accuracy: 0.8281 - val_loss: 0.5618 - val_accuracy: 0.7604\n",
            "Epoch 558/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3857 - accuracy: 0.8316 - val_loss: 0.5618 - val_accuracy: 0.7604\n",
            "Epoch 559/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3863 - accuracy: 0.8299 - val_loss: 0.5615 - val_accuracy: 0.7604\n",
            "Epoch 560/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3858 - accuracy: 0.8316 - val_loss: 0.5606 - val_accuracy: 0.7604\n",
            "Epoch 561/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3856 - accuracy: 0.8333 - val_loss: 0.5608 - val_accuracy: 0.7604\n",
            "Epoch 562/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3857 - accuracy: 0.8351 - val_loss: 0.5602 - val_accuracy: 0.7656\n",
            "Epoch 563/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3859 - accuracy: 0.8316 - val_loss: 0.5603 - val_accuracy: 0.7656\n",
            "Epoch 564/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3855 - accuracy: 0.8299 - val_loss: 0.5603 - val_accuracy: 0.7656\n",
            "Epoch 565/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3859 - accuracy: 0.8316 - val_loss: 0.5604 - val_accuracy: 0.7656\n",
            "Epoch 566/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3853 - accuracy: 0.8316 - val_loss: 0.5616 - val_accuracy: 0.7604\n",
            "Epoch 567/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3852 - accuracy: 0.8299 - val_loss: 0.5622 - val_accuracy: 0.7604\n",
            "Epoch 568/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3852 - accuracy: 0.8316 - val_loss: 0.5620 - val_accuracy: 0.7604\n",
            "Epoch 569/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3856 - accuracy: 0.8299 - val_loss: 0.5613 - val_accuracy: 0.7604\n",
            "Epoch 570/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3851 - accuracy: 0.8316 - val_loss: 0.5622 - val_accuracy: 0.7604\n",
            "Epoch 571/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3852 - accuracy: 0.8316 - val_loss: 0.5613 - val_accuracy: 0.7604\n",
            "Epoch 572/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3852 - accuracy: 0.8299 - val_loss: 0.5614 - val_accuracy: 0.7656\n",
            "Epoch 573/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3850 - accuracy: 0.8316 - val_loss: 0.5617 - val_accuracy: 0.7656\n",
            "Epoch 574/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3846 - accuracy: 0.8333 - val_loss: 0.5628 - val_accuracy: 0.7604\n",
            "Epoch 575/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3852 - accuracy: 0.8333 - val_loss: 0.5621 - val_accuracy: 0.7604\n",
            "Epoch 576/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3852 - accuracy: 0.8299 - val_loss: 0.5621 - val_accuracy: 0.7604\n",
            "Epoch 577/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3847 - accuracy: 0.8299 - val_loss: 0.5630 - val_accuracy: 0.7604\n",
            "Epoch 578/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3847 - accuracy: 0.8316 - val_loss: 0.5624 - val_accuracy: 0.7604\n",
            "Epoch 579/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3852 - accuracy: 0.8316 - val_loss: 0.5627 - val_accuracy: 0.7604\n",
            "Epoch 580/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3844 - accuracy: 0.8351 - val_loss: 0.5615 - val_accuracy: 0.7708\n",
            "Epoch 581/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3849 - accuracy: 0.8299 - val_loss: 0.5626 - val_accuracy: 0.7604\n",
            "Epoch 582/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3844 - accuracy: 0.8316 - val_loss: 0.5622 - val_accuracy: 0.7656\n",
            "Epoch 583/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3844 - accuracy: 0.8299 - val_loss: 0.5629 - val_accuracy: 0.7604\n",
            "Epoch 584/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3843 - accuracy: 0.8316 - val_loss: 0.5640 - val_accuracy: 0.7604\n",
            "Epoch 585/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3843 - accuracy: 0.8281 - val_loss: 0.5626 - val_accuracy: 0.7656\n",
            "Epoch 586/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3842 - accuracy: 0.8316 - val_loss: 0.5637 - val_accuracy: 0.7604\n",
            "Epoch 587/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3842 - accuracy: 0.8333 - val_loss: 0.5630 - val_accuracy: 0.7656\n",
            "Epoch 588/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3847 - accuracy: 0.8351 - val_loss: 0.5622 - val_accuracy: 0.7708\n",
            "Epoch 589/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3841 - accuracy: 0.8316 - val_loss: 0.5636 - val_accuracy: 0.7604\n",
            "Epoch 590/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3838 - accuracy: 0.8333 - val_loss: 0.5630 - val_accuracy: 0.7656\n",
            "Epoch 591/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3841 - accuracy: 0.8316 - val_loss: 0.5637 - val_accuracy: 0.7604\n",
            "Epoch 592/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3835 - accuracy: 0.8299 - val_loss: 0.5642 - val_accuracy: 0.7604\n",
            "Epoch 593/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3841 - accuracy: 0.8316 - val_loss: 0.5639 - val_accuracy: 0.7604\n",
            "Epoch 594/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3835 - accuracy: 0.8316 - val_loss: 0.5634 - val_accuracy: 0.7604\n",
            "Epoch 595/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3833 - accuracy: 0.8316 - val_loss: 0.5650 - val_accuracy: 0.7604\n",
            "Epoch 596/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3834 - accuracy: 0.8316 - val_loss: 0.5656 - val_accuracy: 0.7604\n",
            "Epoch 597/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3835 - accuracy: 0.8351 - val_loss: 0.5648 - val_accuracy: 0.7604\n",
            "Epoch 598/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3833 - accuracy: 0.8333 - val_loss: 0.5649 - val_accuracy: 0.7604\n",
            "Epoch 599/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3838 - accuracy: 0.8299 - val_loss: 0.5651 - val_accuracy: 0.7604\n",
            "Epoch 600/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3835 - accuracy: 0.8316 - val_loss: 0.5649 - val_accuracy: 0.7604\n",
            "Epoch 601/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3832 - accuracy: 0.8333 - val_loss: 0.5646 - val_accuracy: 0.7604\n",
            "Epoch 602/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3828 - accuracy: 0.8316 - val_loss: 0.5652 - val_accuracy: 0.7604\n",
            "Epoch 603/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3836 - accuracy: 0.8333 - val_loss: 0.5646 - val_accuracy: 0.7604\n",
            "Epoch 604/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3830 - accuracy: 0.8299 - val_loss: 0.5650 - val_accuracy: 0.7604\n",
            "Epoch 605/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3828 - accuracy: 0.8281 - val_loss: 0.5646 - val_accuracy: 0.7604\n",
            "Epoch 606/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3829 - accuracy: 0.8299 - val_loss: 0.5651 - val_accuracy: 0.7604\n",
            "Epoch 607/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3830 - accuracy: 0.8333 - val_loss: 0.5661 - val_accuracy: 0.7604\n",
            "Epoch 608/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3828 - accuracy: 0.8333 - val_loss: 0.5662 - val_accuracy: 0.7604\n",
            "Epoch 609/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3828 - accuracy: 0.8299 - val_loss: 0.5659 - val_accuracy: 0.7604\n",
            "Epoch 610/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3824 - accuracy: 0.8299 - val_loss: 0.5646 - val_accuracy: 0.7604\n",
            "Epoch 611/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3829 - accuracy: 0.8299 - val_loss: 0.5651 - val_accuracy: 0.7604\n",
            "Epoch 612/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3825 - accuracy: 0.8333 - val_loss: 0.5665 - val_accuracy: 0.7604\n",
            "Epoch 613/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3823 - accuracy: 0.8281 - val_loss: 0.5664 - val_accuracy: 0.7604\n",
            "Epoch 614/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3821 - accuracy: 0.8299 - val_loss: 0.5655 - val_accuracy: 0.7604\n",
            "Epoch 615/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3819 - accuracy: 0.8333 - val_loss: 0.5657 - val_accuracy: 0.7604\n",
            "Epoch 616/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3822 - accuracy: 0.8351 - val_loss: 0.5666 - val_accuracy: 0.7604\n",
            "Epoch 617/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3819 - accuracy: 0.8351 - val_loss: 0.5679 - val_accuracy: 0.7604\n",
            "Epoch 618/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3823 - accuracy: 0.8316 - val_loss: 0.5670 - val_accuracy: 0.7604\n",
            "Epoch 619/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3818 - accuracy: 0.8281 - val_loss: 0.5657 - val_accuracy: 0.7604\n",
            "Epoch 620/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3819 - accuracy: 0.8316 - val_loss: 0.5655 - val_accuracy: 0.7604\n",
            "Epoch 621/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3817 - accuracy: 0.8316 - val_loss: 0.5667 - val_accuracy: 0.7604\n",
            "Epoch 622/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3821 - accuracy: 0.8333 - val_loss: 0.5675 - val_accuracy: 0.7604\n",
            "Epoch 623/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3821 - accuracy: 0.8281 - val_loss: 0.5664 - val_accuracy: 0.7604\n",
            "Epoch 624/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3816 - accuracy: 0.8281 - val_loss: 0.5665 - val_accuracy: 0.7604\n",
            "Epoch 625/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3817 - accuracy: 0.8403 - val_loss: 0.5664 - val_accuracy: 0.7604\n",
            "Epoch 626/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3812 - accuracy: 0.8351 - val_loss: 0.5682 - val_accuracy: 0.7604\n",
            "Epoch 627/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3817 - accuracy: 0.8316 - val_loss: 0.5676 - val_accuracy: 0.7604\n",
            "Epoch 628/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3815 - accuracy: 0.8351 - val_loss: 0.5677 - val_accuracy: 0.7604\n",
            "Epoch 629/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3813 - accuracy: 0.8316 - val_loss: 0.5673 - val_accuracy: 0.7604\n",
            "Epoch 630/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3810 - accuracy: 0.8316 - val_loss: 0.5678 - val_accuracy: 0.7604\n",
            "Epoch 631/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3813 - accuracy: 0.8316 - val_loss: 0.5688 - val_accuracy: 0.7604\n",
            "Epoch 632/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3813 - accuracy: 0.8316 - val_loss: 0.5680 - val_accuracy: 0.7604\n",
            "Epoch 633/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3810 - accuracy: 0.8333 - val_loss: 0.5676 - val_accuracy: 0.7604\n",
            "Epoch 634/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3810 - accuracy: 0.8333 - val_loss: 0.5678 - val_accuracy: 0.7604\n",
            "Epoch 635/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3813 - accuracy: 0.8281 - val_loss: 0.5683 - val_accuracy: 0.7604\n",
            "Epoch 636/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3810 - accuracy: 0.8316 - val_loss: 0.5686 - val_accuracy: 0.7604\n",
            "Epoch 637/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3809 - accuracy: 0.8333 - val_loss: 0.5691 - val_accuracy: 0.7604\n",
            "Epoch 638/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3805 - accuracy: 0.8316 - val_loss: 0.5682 - val_accuracy: 0.7604\n",
            "Epoch 639/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3808 - accuracy: 0.8333 - val_loss: 0.5682 - val_accuracy: 0.7604\n",
            "Epoch 640/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3806 - accuracy: 0.8299 - val_loss: 0.5684 - val_accuracy: 0.7604\n",
            "Epoch 641/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3808 - accuracy: 0.8333 - val_loss: 0.5666 - val_accuracy: 0.7708\n",
            "Epoch 642/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3805 - accuracy: 0.8333 - val_loss: 0.5685 - val_accuracy: 0.7656\n",
            "Epoch 643/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3807 - accuracy: 0.8333 - val_loss: 0.5683 - val_accuracy: 0.7656\n",
            "Epoch 644/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3802 - accuracy: 0.8316 - val_loss: 0.5701 - val_accuracy: 0.7604\n",
            "Epoch 645/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3803 - accuracy: 0.8281 - val_loss: 0.5693 - val_accuracy: 0.7656\n",
            "Epoch 646/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3803 - accuracy: 0.8316 - val_loss: 0.5688 - val_accuracy: 0.7656\n",
            "Epoch 647/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3804 - accuracy: 0.8299 - val_loss: 0.5684 - val_accuracy: 0.7656\n",
            "Epoch 648/800\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3803 - accuracy: 0.8316 - val_loss: 0.5690 - val_accuracy: 0.7656\n",
            "Epoch 649/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3803 - accuracy: 0.8299 - val_loss: 0.5685 - val_accuracy: 0.7656\n",
            "Epoch 650/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3799 - accuracy: 0.8299 - val_loss: 0.5684 - val_accuracy: 0.7656\n",
            "Epoch 651/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3798 - accuracy: 0.8333 - val_loss: 0.5695 - val_accuracy: 0.7656\n",
            "Epoch 652/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3799 - accuracy: 0.8316 - val_loss: 0.5689 - val_accuracy: 0.7656\n",
            "Epoch 653/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3802 - accuracy: 0.8333 - val_loss: 0.5686 - val_accuracy: 0.7656\n",
            "Epoch 654/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3797 - accuracy: 0.8351 - val_loss: 0.5695 - val_accuracy: 0.7656\n",
            "Epoch 655/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3795 - accuracy: 0.8299 - val_loss: 0.5686 - val_accuracy: 0.7656\n",
            "Epoch 656/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3796 - accuracy: 0.8281 - val_loss: 0.5687 - val_accuracy: 0.7656\n",
            "Epoch 657/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3795 - accuracy: 0.8351 - val_loss: 0.5685 - val_accuracy: 0.7656\n",
            "Epoch 658/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3794 - accuracy: 0.8333 - val_loss: 0.5694 - val_accuracy: 0.7656\n",
            "Epoch 659/800\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3795 - accuracy: 0.8281 - val_loss: 0.5699 - val_accuracy: 0.7656\n",
            "Epoch 660/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3790 - accuracy: 0.8299 - val_loss: 0.5674 - val_accuracy: 0.7708\n",
            "Epoch 661/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3793 - accuracy: 0.8351 - val_loss: 0.5687 - val_accuracy: 0.7656\n",
            "Epoch 662/800\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3795 - accuracy: 0.8351 - val_loss: 0.5699 - val_accuracy: 0.7656\n",
            "Epoch 663/800\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3789 - accuracy: 0.8281 - val_loss: 0.5676 - val_accuracy: 0.7708\n",
            "Epoch 664/800\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3789 - accuracy: 0.8316 - val_loss: 0.5693 - val_accuracy: 0.7656\n",
            "Epoch 665/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3792 - accuracy: 0.8368 - val_loss: 0.5699 - val_accuracy: 0.7656\n",
            "Epoch 666/800\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3790 - accuracy: 0.8333 - val_loss: 0.5702 - val_accuracy: 0.7656\n",
            "Epoch 667/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3793 - accuracy: 0.8333 - val_loss: 0.5683 - val_accuracy: 0.7656\n",
            "Epoch 668/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3783 - accuracy: 0.8351 - val_loss: 0.5704 - val_accuracy: 0.7656\n",
            "Epoch 669/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3787 - accuracy: 0.8368 - val_loss: 0.5696 - val_accuracy: 0.7656\n",
            "Epoch 670/800\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3788 - accuracy: 0.8281 - val_loss: 0.5690 - val_accuracy: 0.7656\n",
            "Epoch 671/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3788 - accuracy: 0.8333 - val_loss: 0.5682 - val_accuracy: 0.7656\n",
            "Epoch 672/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3788 - accuracy: 0.8351 - val_loss: 0.5690 - val_accuracy: 0.7656\n",
            "Epoch 673/800\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3784 - accuracy: 0.8368 - val_loss: 0.5696 - val_accuracy: 0.7656\n",
            "Epoch 674/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3788 - accuracy: 0.8333 - val_loss: 0.5700 - val_accuracy: 0.7656\n",
            "Epoch 675/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3780 - accuracy: 0.8333 - val_loss: 0.5699 - val_accuracy: 0.7656\n",
            "Epoch 676/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3784 - accuracy: 0.8333 - val_loss: 0.5698 - val_accuracy: 0.7656\n",
            "Epoch 677/800\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3784 - accuracy: 0.8351 - val_loss: 0.5709 - val_accuracy: 0.7656\n",
            "Epoch 678/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3784 - accuracy: 0.8351 - val_loss: 0.5704 - val_accuracy: 0.7656\n",
            "Epoch 679/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3784 - accuracy: 0.8385 - val_loss: 0.5701 - val_accuracy: 0.7656\n",
            "Epoch 680/800\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3782 - accuracy: 0.8351 - val_loss: 0.5700 - val_accuracy: 0.7656\n",
            "Epoch 681/800\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3784 - accuracy: 0.8299 - val_loss: 0.5690 - val_accuracy: 0.7656\n",
            "Epoch 682/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3779 - accuracy: 0.8333 - val_loss: 0.5699 - val_accuracy: 0.7656\n",
            "Epoch 683/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3779 - accuracy: 0.8351 - val_loss: 0.5694 - val_accuracy: 0.7656\n",
            "Epoch 684/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3778 - accuracy: 0.8333 - val_loss: 0.5692 - val_accuracy: 0.7656\n",
            "Epoch 685/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3779 - accuracy: 0.8351 - val_loss: 0.5707 - val_accuracy: 0.7656\n",
            "Epoch 686/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3777 - accuracy: 0.8333 - val_loss: 0.5701 - val_accuracy: 0.7656\n",
            "Epoch 687/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3778 - accuracy: 0.8316 - val_loss: 0.5711 - val_accuracy: 0.7656\n",
            "Epoch 688/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3780 - accuracy: 0.8351 - val_loss: 0.5713 - val_accuracy: 0.7656\n",
            "Epoch 689/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3773 - accuracy: 0.8385 - val_loss: 0.5727 - val_accuracy: 0.7604\n",
            "Epoch 690/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3776 - accuracy: 0.8368 - val_loss: 0.5726 - val_accuracy: 0.7604\n",
            "Epoch 691/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3777 - accuracy: 0.8316 - val_loss: 0.5730 - val_accuracy: 0.7604\n",
            "Epoch 692/800\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3773 - accuracy: 0.8333 - val_loss: 0.5731 - val_accuracy: 0.7604\n",
            "Epoch 693/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3769 - accuracy: 0.8351 - val_loss: 0.5713 - val_accuracy: 0.7656\n",
            "Epoch 694/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3773 - accuracy: 0.8351 - val_loss: 0.5724 - val_accuracy: 0.7604\n",
            "Epoch 695/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3776 - accuracy: 0.8333 - val_loss: 0.5727 - val_accuracy: 0.7604\n",
            "Epoch 696/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3777 - accuracy: 0.8351 - val_loss: 0.5714 - val_accuracy: 0.7656\n",
            "Epoch 697/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3771 - accuracy: 0.8351 - val_loss: 0.5725 - val_accuracy: 0.7604\n",
            "Epoch 698/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3770 - accuracy: 0.8385 - val_loss: 0.5724 - val_accuracy: 0.7604\n",
            "Epoch 699/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3775 - accuracy: 0.8368 - val_loss: 0.5719 - val_accuracy: 0.7656\n",
            "Epoch 700/800\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3774 - accuracy: 0.8333 - val_loss: 0.5718 - val_accuracy: 0.7656\n",
            "Epoch 701/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3764 - accuracy: 0.8351 - val_loss: 0.5735 - val_accuracy: 0.7604\n",
            "Epoch 702/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3770 - accuracy: 0.8351 - val_loss: 0.5740 - val_accuracy: 0.7604\n",
            "Epoch 703/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3764 - accuracy: 0.8316 - val_loss: 0.5751 - val_accuracy: 0.7604\n",
            "Epoch 704/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3770 - accuracy: 0.8316 - val_loss: 0.5742 - val_accuracy: 0.7604\n",
            "Epoch 705/800\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3766 - accuracy: 0.8368 - val_loss: 0.5724 - val_accuracy: 0.7604\n",
            "Epoch 706/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3760 - accuracy: 0.8403 - val_loss: 0.5738 - val_accuracy: 0.7604\n",
            "Epoch 707/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3765 - accuracy: 0.8403 - val_loss: 0.5749 - val_accuracy: 0.7604\n",
            "Epoch 708/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3770 - accuracy: 0.8299 - val_loss: 0.5721 - val_accuracy: 0.7604\n",
            "Epoch 709/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3764 - accuracy: 0.8351 - val_loss: 0.5736 - val_accuracy: 0.7604\n",
            "Epoch 710/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3763 - accuracy: 0.8316 - val_loss: 0.5729 - val_accuracy: 0.7604\n",
            "Epoch 711/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3765 - accuracy: 0.8368 - val_loss: 0.5749 - val_accuracy: 0.7552\n",
            "Epoch 712/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3763 - accuracy: 0.8351 - val_loss: 0.5732 - val_accuracy: 0.7552\n",
            "Epoch 713/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3759 - accuracy: 0.8403 - val_loss: 0.5743 - val_accuracy: 0.7552\n",
            "Epoch 714/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3763 - accuracy: 0.8316 - val_loss: 0.5751 - val_accuracy: 0.7552\n",
            "Epoch 715/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3763 - accuracy: 0.8333 - val_loss: 0.5738 - val_accuracy: 0.7552\n",
            "Epoch 716/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3761 - accuracy: 0.8351 - val_loss: 0.5728 - val_accuracy: 0.7552\n",
            "Epoch 717/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3758 - accuracy: 0.8385 - val_loss: 0.5739 - val_accuracy: 0.7552\n",
            "Epoch 718/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3756 - accuracy: 0.8385 - val_loss: 0.5738 - val_accuracy: 0.7552\n",
            "Epoch 719/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3763 - accuracy: 0.8299 - val_loss: 0.5735 - val_accuracy: 0.7552\n",
            "Epoch 720/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3761 - accuracy: 0.8368 - val_loss: 0.5743 - val_accuracy: 0.7552\n",
            "Epoch 721/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3754 - accuracy: 0.8316 - val_loss: 0.5744 - val_accuracy: 0.7552\n",
            "Epoch 722/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3760 - accuracy: 0.8299 - val_loss: 0.5727 - val_accuracy: 0.7552\n",
            "Epoch 723/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3759 - accuracy: 0.8351 - val_loss: 0.5746 - val_accuracy: 0.7552\n",
            "Epoch 724/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3760 - accuracy: 0.8368 - val_loss: 0.5743 - val_accuracy: 0.7552\n",
            "Epoch 725/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3753 - accuracy: 0.8351 - val_loss: 0.5750 - val_accuracy: 0.7552\n",
            "Epoch 726/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3753 - accuracy: 0.8351 - val_loss: 0.5753 - val_accuracy: 0.7552\n",
            "Epoch 727/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3754 - accuracy: 0.8351 - val_loss: 0.5737 - val_accuracy: 0.7552\n",
            "Epoch 728/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3752 - accuracy: 0.8351 - val_loss: 0.5748 - val_accuracy: 0.7552\n",
            "Epoch 729/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3757 - accuracy: 0.8333 - val_loss: 0.5745 - val_accuracy: 0.7552\n",
            "Epoch 730/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3752 - accuracy: 0.8368 - val_loss: 0.5733 - val_accuracy: 0.7552\n",
            "Epoch 731/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3751 - accuracy: 0.8333 - val_loss: 0.5752 - val_accuracy: 0.7552\n",
            "Epoch 732/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3751 - accuracy: 0.8333 - val_loss: 0.5756 - val_accuracy: 0.7552\n",
            "Epoch 733/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3751 - accuracy: 0.8333 - val_loss: 0.5765 - val_accuracy: 0.7552\n",
            "Epoch 734/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3750 - accuracy: 0.8351 - val_loss: 0.5772 - val_accuracy: 0.7552\n",
            "Epoch 735/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3751 - accuracy: 0.8333 - val_loss: 0.5767 - val_accuracy: 0.7552\n",
            "Epoch 736/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3746 - accuracy: 0.8333 - val_loss: 0.5749 - val_accuracy: 0.7552\n",
            "Epoch 737/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3746 - accuracy: 0.8351 - val_loss: 0.5751 - val_accuracy: 0.7552\n",
            "Epoch 738/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3744 - accuracy: 0.8368 - val_loss: 0.5747 - val_accuracy: 0.7552\n",
            "Epoch 739/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3742 - accuracy: 0.8351 - val_loss: 0.5765 - val_accuracy: 0.7552\n",
            "Epoch 740/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3741 - accuracy: 0.8299 - val_loss: 0.5772 - val_accuracy: 0.7552\n",
            "Epoch 741/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3751 - accuracy: 0.8385 - val_loss: 0.5769 - val_accuracy: 0.7552\n",
            "Epoch 742/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3752 - accuracy: 0.8368 - val_loss: 0.5767 - val_accuracy: 0.7552\n",
            "Epoch 743/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3743 - accuracy: 0.8385 - val_loss: 0.5757 - val_accuracy: 0.7552\n",
            "Epoch 744/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3739 - accuracy: 0.8333 - val_loss: 0.5781 - val_accuracy: 0.7552\n",
            "Epoch 745/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3746 - accuracy: 0.8316 - val_loss: 0.5763 - val_accuracy: 0.7552\n",
            "Epoch 746/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3740 - accuracy: 0.8351 - val_loss: 0.5767 - val_accuracy: 0.7552\n",
            "Epoch 747/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3738 - accuracy: 0.8333 - val_loss: 0.5759 - val_accuracy: 0.7552\n",
            "Epoch 748/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3737 - accuracy: 0.8333 - val_loss: 0.5768 - val_accuracy: 0.7552\n",
            "Epoch 749/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3743 - accuracy: 0.8281 - val_loss: 0.5768 - val_accuracy: 0.7552\n",
            "Epoch 750/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3739 - accuracy: 0.8368 - val_loss: 0.5766 - val_accuracy: 0.7552\n",
            "Epoch 751/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3736 - accuracy: 0.8385 - val_loss: 0.5762 - val_accuracy: 0.7552\n",
            "Epoch 752/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3741 - accuracy: 0.8351 - val_loss: 0.5769 - val_accuracy: 0.7552\n",
            "Epoch 753/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3738 - accuracy: 0.8333 - val_loss: 0.5788 - val_accuracy: 0.7552\n",
            "Epoch 754/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3733 - accuracy: 0.8333 - val_loss: 0.5788 - val_accuracy: 0.7552\n",
            "Epoch 755/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3740 - accuracy: 0.8351 - val_loss: 0.5797 - val_accuracy: 0.7552\n",
            "Epoch 756/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3736 - accuracy: 0.8333 - val_loss: 0.5810 - val_accuracy: 0.7552\n",
            "Epoch 757/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3733 - accuracy: 0.8316 - val_loss: 0.5788 - val_accuracy: 0.7552\n",
            "Epoch 758/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3729 - accuracy: 0.8333 - val_loss: 0.5769 - val_accuracy: 0.7552\n",
            "Epoch 759/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3732 - accuracy: 0.8316 - val_loss: 0.5769 - val_accuracy: 0.7552\n",
            "Epoch 760/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3729 - accuracy: 0.8316 - val_loss: 0.5780 - val_accuracy: 0.7552\n",
            "Epoch 761/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3729 - accuracy: 0.8403 - val_loss: 0.5765 - val_accuracy: 0.7552\n",
            "Epoch 762/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3728 - accuracy: 0.8368 - val_loss: 0.5775 - val_accuracy: 0.7552\n",
            "Epoch 763/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3728 - accuracy: 0.8351 - val_loss: 0.5781 - val_accuracy: 0.7552\n",
            "Epoch 764/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3729 - accuracy: 0.8368 - val_loss: 0.5777 - val_accuracy: 0.7552\n",
            "Epoch 765/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3724 - accuracy: 0.8299 - val_loss: 0.5796 - val_accuracy: 0.7552\n",
            "Epoch 766/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3731 - accuracy: 0.8351 - val_loss: 0.5784 - val_accuracy: 0.7552\n",
            "Epoch 767/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3728 - accuracy: 0.8333 - val_loss: 0.5783 - val_accuracy: 0.7552\n",
            "Epoch 768/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3727 - accuracy: 0.8351 - val_loss: 0.5793 - val_accuracy: 0.7552\n",
            "Epoch 769/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3728 - accuracy: 0.8368 - val_loss: 0.5780 - val_accuracy: 0.7552\n",
            "Epoch 770/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3723 - accuracy: 0.8333 - val_loss: 0.5787 - val_accuracy: 0.7552\n",
            "Epoch 771/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3726 - accuracy: 0.8299 - val_loss: 0.5776 - val_accuracy: 0.7552\n",
            "Epoch 772/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3726 - accuracy: 0.8299 - val_loss: 0.5784 - val_accuracy: 0.7552\n",
            "Epoch 773/800\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3722 - accuracy: 0.8299 - val_loss: 0.5795 - val_accuracy: 0.7552\n",
            "Epoch 774/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3724 - accuracy: 0.8351 - val_loss: 0.5783 - val_accuracy: 0.7552\n",
            "Epoch 775/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3721 - accuracy: 0.8351 - val_loss: 0.5790 - val_accuracy: 0.7552\n",
            "Epoch 776/800\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3722 - accuracy: 0.8333 - val_loss: 0.5786 - val_accuracy: 0.7552\n",
            "Epoch 777/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3720 - accuracy: 0.8368 - val_loss: 0.5791 - val_accuracy: 0.7552\n",
            "Epoch 778/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3716 - accuracy: 0.8368 - val_loss: 0.5783 - val_accuracy: 0.7552\n",
            "Epoch 779/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3715 - accuracy: 0.8299 - val_loss: 0.5796 - val_accuracy: 0.7552\n",
            "Epoch 780/800\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3713 - accuracy: 0.8316 - val_loss: 0.5784 - val_accuracy: 0.7552\n",
            "Epoch 781/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3713 - accuracy: 0.8316 - val_loss: 0.5783 - val_accuracy: 0.7552\n",
            "Epoch 782/800\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3716 - accuracy: 0.8351 - val_loss: 0.5780 - val_accuracy: 0.7552\n",
            "Epoch 783/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3718 - accuracy: 0.8385 - val_loss: 0.5796 - val_accuracy: 0.7552\n",
            "Epoch 784/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3712 - accuracy: 0.8316 - val_loss: 0.5798 - val_accuracy: 0.7552\n",
            "Epoch 785/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3719 - accuracy: 0.8299 - val_loss: 0.5785 - val_accuracy: 0.7500\n",
            "Epoch 786/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3714 - accuracy: 0.8333 - val_loss: 0.5781 - val_accuracy: 0.7552\n",
            "Epoch 787/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3712 - accuracy: 0.8333 - val_loss: 0.5794 - val_accuracy: 0.7552\n",
            "Epoch 788/800\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3713 - accuracy: 0.8316 - val_loss: 0.5797 - val_accuracy: 0.7552\n",
            "Epoch 789/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3715 - accuracy: 0.8403 - val_loss: 0.5806 - val_accuracy: 0.7552\n",
            "Epoch 790/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3711 - accuracy: 0.8316 - val_loss: 0.5820 - val_accuracy: 0.7552\n",
            "Epoch 791/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3715 - accuracy: 0.8316 - val_loss: 0.5828 - val_accuracy: 0.7552\n",
            "Epoch 792/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3712 - accuracy: 0.8299 - val_loss: 0.5803 - val_accuracy: 0.7604\n",
            "Epoch 793/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3704 - accuracy: 0.8351 - val_loss: 0.5825 - val_accuracy: 0.7552\n",
            "Epoch 794/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3708 - accuracy: 0.8333 - val_loss: 0.5824 - val_accuracy: 0.7552\n",
            "Epoch 795/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3715 - accuracy: 0.8368 - val_loss: 0.5811 - val_accuracy: 0.7552\n",
            "Epoch 796/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3704 - accuracy: 0.8316 - val_loss: 0.5825 - val_accuracy: 0.7604\n",
            "Epoch 797/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3708 - accuracy: 0.8299 - val_loss: 0.5836 - val_accuracy: 0.7552\n",
            "Epoch 798/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3704 - accuracy: 0.8316 - val_loss: 0.5840 - val_accuracy: 0.7604\n",
            "Epoch 799/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3709 - accuracy: 0.8368 - val_loss: 0.5862 - val_accuracy: 0.7552\n",
            "Epoch 800/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3706 - accuracy: 0.8385 - val_loss: 0.5846 - val_accuracy: 0.7604\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analysis:"
      ],
      "metadata": {
        "id": "1zi-4jwUCk7j"
      },
      "id": "1zi-4jwUCk7j"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Additional Layer (same number of node for the additional layer), Same Number of Epochs"
      ],
      "metadata": {
        "id": "IpMXQLXaBRqN"
      },
      "id": "IpMXQLXaBRqN"
    },
    {
      "cell_type": "code",
      "source": [
        "#Model with two hidden layers each having 6 nodes\n",
        "model_3= Sequential ([\n",
        "    #Layer 1\n",
        "    Dense(6, input_shape=(8,),activation=\"relu\"),\n",
        "\n",
        "    #Layer 2\n",
        "    Dense(8,activation=\"relu\"),\n",
        "\n",
        "    #Layer 3\n",
        "    #For this part of the activity, I wanted to see if adding another layer\n",
        "    #and having a different number of node would affect the accuracy or\n",
        "    #would it remain stagnant.\n",
        "    Dense(8,activation=\"relu\"),\n",
        "\n",
        "    #Output/Final Layer\n",
        "    Dense(1,activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "model_3.compile(SGD(lr = .001), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "run_hist_4 = model_3.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=800)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pxOQiXcBXQM",
        "outputId": "3e0ae21a-79af-4d41-f8c0-7daa304f1af0"
      },
      "id": "4pxOQiXcBXQM",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/800\n",
            "18/18 [==============================] - 1s 21ms/step - loss: 0.7004 - accuracy: 0.5799 - val_loss: 0.7045 - val_accuracy: 0.5521\n",
            "Epoch 2/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6924 - accuracy: 0.6146 - val_loss: 0.6981 - val_accuracy: 0.6094\n",
            "Epoch 3/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6856 - accuracy: 0.6389 - val_loss: 0.6926 - val_accuracy: 0.6198\n",
            "Epoch 4/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.6799 - accuracy: 0.6476 - val_loss: 0.6876 - val_accuracy: 0.6354\n",
            "Epoch 5/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6748 - accuracy: 0.6493 - val_loss: 0.6832 - val_accuracy: 0.6354\n",
            "Epoch 6/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6703 - accuracy: 0.6545 - val_loss: 0.6791 - val_accuracy: 0.6354\n",
            "Epoch 7/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6663 - accuracy: 0.6580 - val_loss: 0.6753 - val_accuracy: 0.6406\n",
            "Epoch 8/800\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.6626 - accuracy: 0.6580 - val_loss: 0.6716 - val_accuracy: 0.6406\n",
            "Epoch 9/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.6590 - accuracy: 0.6562 - val_loss: 0.6683 - val_accuracy: 0.6406\n",
            "Epoch 10/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.6557 - accuracy: 0.6562 - val_loss: 0.6649 - val_accuracy: 0.6406\n",
            "Epoch 11/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6526 - accuracy: 0.6562 - val_loss: 0.6617 - val_accuracy: 0.6406\n",
            "Epoch 12/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6496 - accuracy: 0.6562 - val_loss: 0.6585 - val_accuracy: 0.6406\n",
            "Epoch 13/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.6467 - accuracy: 0.6562 - val_loss: 0.6554 - val_accuracy: 0.6406\n",
            "Epoch 14/800\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.6438 - accuracy: 0.6562 - val_loss: 0.6525 - val_accuracy: 0.6406\n",
            "Epoch 15/800\n",
            "18/18 [==============================] - 0s 20ms/step - loss: 0.6410 - accuracy: 0.6562 - val_loss: 0.6496 - val_accuracy: 0.6406\n",
            "Epoch 16/800\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.6382 - accuracy: 0.6562 - val_loss: 0.6466 - val_accuracy: 0.6406\n",
            "Epoch 17/800\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.6353 - accuracy: 0.6562 - val_loss: 0.6438 - val_accuracy: 0.6406\n",
            "Epoch 18/800\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.6326 - accuracy: 0.6562 - val_loss: 0.6409 - val_accuracy: 0.6406\n",
            "Epoch 19/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6299 - accuracy: 0.6562 - val_loss: 0.6381 - val_accuracy: 0.6406\n",
            "Epoch 20/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6271 - accuracy: 0.6562 - val_loss: 0.6352 - val_accuracy: 0.6406\n",
            "Epoch 21/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.6244 - accuracy: 0.6562 - val_loss: 0.6323 - val_accuracy: 0.6406\n",
            "Epoch 22/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.6217 - accuracy: 0.6562 - val_loss: 0.6294 - val_accuracy: 0.6354\n",
            "Epoch 23/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6190 - accuracy: 0.6562 - val_loss: 0.6265 - val_accuracy: 0.6354\n",
            "Epoch 24/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6161 - accuracy: 0.6562 - val_loss: 0.6235 - val_accuracy: 0.6458\n",
            "Epoch 25/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6133 - accuracy: 0.6562 - val_loss: 0.6204 - val_accuracy: 0.6458\n",
            "Epoch 26/800\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.6103 - accuracy: 0.6580 - val_loss: 0.6173 - val_accuracy: 0.6458\n",
            "Epoch 27/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6074 - accuracy: 0.6580 - val_loss: 0.6142 - val_accuracy: 0.6458\n",
            "Epoch 28/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6045 - accuracy: 0.6649 - val_loss: 0.6111 - val_accuracy: 0.6458\n",
            "Epoch 29/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6014 - accuracy: 0.6684 - val_loss: 0.6080 - val_accuracy: 0.6510\n",
            "Epoch 30/800\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.5984 - accuracy: 0.6684 - val_loss: 0.6048 - val_accuracy: 0.6562\n",
            "Epoch 31/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5952 - accuracy: 0.6719 - val_loss: 0.6016 - val_accuracy: 0.6615\n",
            "Epoch 32/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5919 - accuracy: 0.6753 - val_loss: 0.5983 - val_accuracy: 0.6615\n",
            "Epoch 33/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5888 - accuracy: 0.6736 - val_loss: 0.5950 - val_accuracy: 0.6667\n",
            "Epoch 34/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5854 - accuracy: 0.6753 - val_loss: 0.5916 - val_accuracy: 0.6667\n",
            "Epoch 35/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5820 - accuracy: 0.6719 - val_loss: 0.5882 - val_accuracy: 0.6667\n",
            "Epoch 36/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5786 - accuracy: 0.6788 - val_loss: 0.5849 - val_accuracy: 0.6667\n",
            "Epoch 37/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5751 - accuracy: 0.6823 - val_loss: 0.5814 - val_accuracy: 0.6823\n",
            "Epoch 38/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5717 - accuracy: 0.6823 - val_loss: 0.5780 - val_accuracy: 0.6823\n",
            "Epoch 39/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5682 - accuracy: 0.6892 - val_loss: 0.5745 - val_accuracy: 0.6875\n",
            "Epoch 40/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5647 - accuracy: 0.6910 - val_loss: 0.5709 - val_accuracy: 0.6875\n",
            "Epoch 41/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5612 - accuracy: 0.7014 - val_loss: 0.5674 - val_accuracy: 0.6979\n",
            "Epoch 42/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5578 - accuracy: 0.6997 - val_loss: 0.5641 - val_accuracy: 0.7031\n",
            "Epoch 43/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5543 - accuracy: 0.7031 - val_loss: 0.5608 - val_accuracy: 0.7083\n",
            "Epoch 44/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5510 - accuracy: 0.7031 - val_loss: 0.5575 - val_accuracy: 0.7135\n",
            "Epoch 45/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5477 - accuracy: 0.7014 - val_loss: 0.5543 - val_accuracy: 0.7188\n",
            "Epoch 46/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5444 - accuracy: 0.7066 - val_loss: 0.5511 - val_accuracy: 0.7135\n",
            "Epoch 47/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5414 - accuracy: 0.7049 - val_loss: 0.5483 - val_accuracy: 0.7135\n",
            "Epoch 48/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5383 - accuracy: 0.7083 - val_loss: 0.5455 - val_accuracy: 0.7188\n",
            "Epoch 49/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5353 - accuracy: 0.7083 - val_loss: 0.5428 - val_accuracy: 0.7188\n",
            "Epoch 50/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5324 - accuracy: 0.7031 - val_loss: 0.5403 - val_accuracy: 0.7135\n",
            "Epoch 51/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5296 - accuracy: 0.6962 - val_loss: 0.5382 - val_accuracy: 0.7135\n",
            "Epoch 52/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5270 - accuracy: 0.7031 - val_loss: 0.5359 - val_accuracy: 0.7135\n",
            "Epoch 53/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5244 - accuracy: 0.6997 - val_loss: 0.5340 - val_accuracy: 0.7188\n",
            "Epoch 54/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5220 - accuracy: 0.7049 - val_loss: 0.5320 - val_accuracy: 0.7188\n",
            "Epoch 55/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5199 - accuracy: 0.7049 - val_loss: 0.5302 - val_accuracy: 0.7188\n",
            "Epoch 56/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5174 - accuracy: 0.6997 - val_loss: 0.5284 - val_accuracy: 0.7188\n",
            "Epoch 57/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5152 - accuracy: 0.6979 - val_loss: 0.5265 - val_accuracy: 0.7240\n",
            "Epoch 58/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5133 - accuracy: 0.7066 - val_loss: 0.5247 - val_accuracy: 0.7344\n",
            "Epoch 59/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5112 - accuracy: 0.7066 - val_loss: 0.5231 - val_accuracy: 0.7344\n",
            "Epoch 60/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5092 - accuracy: 0.7101 - val_loss: 0.5220 - val_accuracy: 0.7396\n",
            "Epoch 61/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.5075 - accuracy: 0.7101 - val_loss: 0.5206 - val_accuracy: 0.7448\n",
            "Epoch 62/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5056 - accuracy: 0.7135 - val_loss: 0.5196 - val_accuracy: 0.7396\n",
            "Epoch 63/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5037 - accuracy: 0.7153 - val_loss: 0.5189 - val_accuracy: 0.7448\n",
            "Epoch 64/800\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.5023 - accuracy: 0.7170 - val_loss: 0.5179 - val_accuracy: 0.7500\n",
            "Epoch 65/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5006 - accuracy: 0.7188 - val_loss: 0.5172 - val_accuracy: 0.7500\n",
            "Epoch 66/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4992 - accuracy: 0.7240 - val_loss: 0.5162 - val_accuracy: 0.7500\n",
            "Epoch 67/800\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4978 - accuracy: 0.7188 - val_loss: 0.5154 - val_accuracy: 0.7604\n",
            "Epoch 68/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4962 - accuracy: 0.7188 - val_loss: 0.5146 - val_accuracy: 0.7552\n",
            "Epoch 69/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4948 - accuracy: 0.7309 - val_loss: 0.5142 - val_accuracy: 0.7552\n",
            "Epoch 70/800\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4934 - accuracy: 0.7326 - val_loss: 0.5133 - val_accuracy: 0.7552\n",
            "Epoch 71/800\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4919 - accuracy: 0.7361 - val_loss: 0.5126 - val_accuracy: 0.7552\n",
            "Epoch 72/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4907 - accuracy: 0.7326 - val_loss: 0.5119 - val_accuracy: 0.7500\n",
            "Epoch 73/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4894 - accuracy: 0.7344 - val_loss: 0.5113 - val_accuracy: 0.7500\n",
            "Epoch 74/800\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4883 - accuracy: 0.7465 - val_loss: 0.5110 - val_accuracy: 0.7552\n",
            "Epoch 75/800\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4873 - accuracy: 0.7448 - val_loss: 0.5106 - val_accuracy: 0.7604\n",
            "Epoch 76/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4857 - accuracy: 0.7517 - val_loss: 0.5096 - val_accuracy: 0.7708\n",
            "Epoch 77/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4846 - accuracy: 0.7465 - val_loss: 0.5095 - val_accuracy: 0.7656\n",
            "Epoch 78/800\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4835 - accuracy: 0.7517 - val_loss: 0.5090 - val_accuracy: 0.7760\n",
            "Epoch 79/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4824 - accuracy: 0.7517 - val_loss: 0.5090 - val_accuracy: 0.7760\n",
            "Epoch 80/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4812 - accuracy: 0.7517 - val_loss: 0.5087 - val_accuracy: 0.7760\n",
            "Epoch 81/800\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4801 - accuracy: 0.7535 - val_loss: 0.5087 - val_accuracy: 0.7760\n",
            "Epoch 82/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4791 - accuracy: 0.7587 - val_loss: 0.5081 - val_accuracy: 0.7760\n",
            "Epoch 83/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4783 - accuracy: 0.7604 - val_loss: 0.5075 - val_accuracy: 0.7656\n",
            "Epoch 84/800\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4772 - accuracy: 0.7587 - val_loss: 0.5073 - val_accuracy: 0.7708\n",
            "Epoch 85/800\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4765 - accuracy: 0.7674 - val_loss: 0.5072 - val_accuracy: 0.7708\n",
            "Epoch 86/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4755 - accuracy: 0.7639 - val_loss: 0.5070 - val_accuracy: 0.7708\n",
            "Epoch 87/800\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4747 - accuracy: 0.7691 - val_loss: 0.5073 - val_accuracy: 0.7708\n",
            "Epoch 88/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4743 - accuracy: 0.7691 - val_loss: 0.5073 - val_accuracy: 0.7708\n",
            "Epoch 89/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4731 - accuracy: 0.7726 - val_loss: 0.5075 - val_accuracy: 0.7760\n",
            "Epoch 90/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4724 - accuracy: 0.7743 - val_loss: 0.5071 - val_accuracy: 0.7760\n",
            "Epoch 91/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4716 - accuracy: 0.7795 - val_loss: 0.5070 - val_accuracy: 0.7656\n",
            "Epoch 92/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4709 - accuracy: 0.7760 - val_loss: 0.5071 - val_accuracy: 0.7656\n",
            "Epoch 93/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4703 - accuracy: 0.7760 - val_loss: 0.5073 - val_accuracy: 0.7656\n",
            "Epoch 94/800\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4695 - accuracy: 0.7812 - val_loss: 0.5073 - val_accuracy: 0.7656\n",
            "Epoch 95/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4686 - accuracy: 0.7847 - val_loss: 0.5073 - val_accuracy: 0.7656\n",
            "Epoch 96/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4679 - accuracy: 0.7847 - val_loss: 0.5071 - val_accuracy: 0.7604\n",
            "Epoch 97/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7830 - val_loss: 0.5071 - val_accuracy: 0.7604\n",
            "Epoch 98/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4667 - accuracy: 0.7847 - val_loss: 0.5074 - val_accuracy: 0.7604\n",
            "Epoch 99/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4662 - accuracy: 0.7847 - val_loss: 0.5073 - val_accuracy: 0.7604\n",
            "Epoch 100/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4654 - accuracy: 0.7865 - val_loss: 0.5077 - val_accuracy: 0.7604\n",
            "Epoch 101/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4649 - accuracy: 0.7882 - val_loss: 0.5080 - val_accuracy: 0.7604\n",
            "Epoch 102/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4641 - accuracy: 0.7812 - val_loss: 0.5080 - val_accuracy: 0.7552\n",
            "Epoch 103/800\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4636 - accuracy: 0.7812 - val_loss: 0.5084 - val_accuracy: 0.7500\n",
            "Epoch 104/800\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4628 - accuracy: 0.7865 - val_loss: 0.5082 - val_accuracy: 0.7552\n",
            "Epoch 105/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4623 - accuracy: 0.7865 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
            "Epoch 106/800\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4618 - accuracy: 0.7865 - val_loss: 0.5080 - val_accuracy: 0.7448\n",
            "Epoch 107/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4612 - accuracy: 0.7899 - val_loss: 0.5079 - val_accuracy: 0.7448\n",
            "Epoch 108/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4606 - accuracy: 0.7882 - val_loss: 0.5082 - val_accuracy: 0.7448\n",
            "Epoch 109/800\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4598 - accuracy: 0.7917 - val_loss: 0.5077 - val_accuracy: 0.7448\n",
            "Epoch 110/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4594 - accuracy: 0.7917 - val_loss: 0.5083 - val_accuracy: 0.7448\n",
            "Epoch 111/800\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.4589 - accuracy: 0.7969 - val_loss: 0.5080 - val_accuracy: 0.7448\n",
            "Epoch 112/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4583 - accuracy: 0.7934 - val_loss: 0.5084 - val_accuracy: 0.7448\n",
            "Epoch 113/800\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4577 - accuracy: 0.7934 - val_loss: 0.5087 - val_accuracy: 0.7448\n",
            "Epoch 114/800\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4571 - accuracy: 0.7969 - val_loss: 0.5084 - val_accuracy: 0.7500\n",
            "Epoch 115/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4567 - accuracy: 0.7951 - val_loss: 0.5085 - val_accuracy: 0.7500\n",
            "Epoch 116/800\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.4563 - accuracy: 0.7951 - val_loss: 0.5085 - val_accuracy: 0.7500\n",
            "Epoch 117/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4557 - accuracy: 0.8003 - val_loss: 0.5084 - val_accuracy: 0.7500\n",
            "Epoch 118/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4553 - accuracy: 0.7951 - val_loss: 0.5086 - val_accuracy: 0.7500\n",
            "Epoch 119/800\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4546 - accuracy: 0.7986 - val_loss: 0.5084 - val_accuracy: 0.7500\n",
            "Epoch 120/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4543 - accuracy: 0.7986 - val_loss: 0.5084 - val_accuracy: 0.7500\n",
            "Epoch 121/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4540 - accuracy: 0.7986 - val_loss: 0.5082 - val_accuracy: 0.7552\n",
            "Epoch 122/800\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.4536 - accuracy: 0.7934 - val_loss: 0.5087 - val_accuracy: 0.7552\n",
            "Epoch 123/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4533 - accuracy: 0.7969 - val_loss: 0.5092 - val_accuracy: 0.7552\n",
            "Epoch 124/800\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4528 - accuracy: 0.7969 - val_loss: 0.5094 - val_accuracy: 0.7552\n",
            "Epoch 125/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4524 - accuracy: 0.7934 - val_loss: 0.5101 - val_accuracy: 0.7552\n",
            "Epoch 126/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4519 - accuracy: 0.7986 - val_loss: 0.5095 - val_accuracy: 0.7552\n",
            "Epoch 127/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4518 - accuracy: 0.7951 - val_loss: 0.5096 - val_accuracy: 0.7552\n",
            "Epoch 128/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4514 - accuracy: 0.7969 - val_loss: 0.5098 - val_accuracy: 0.7552\n",
            "Epoch 129/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4512 - accuracy: 0.7951 - val_loss: 0.5100 - val_accuracy: 0.7552\n",
            "Epoch 130/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4506 - accuracy: 0.7934 - val_loss: 0.5101 - val_accuracy: 0.7552\n",
            "Epoch 131/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4501 - accuracy: 0.7969 - val_loss: 0.5102 - val_accuracy: 0.7552\n",
            "Epoch 132/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4500 - accuracy: 0.7986 - val_loss: 0.5105 - val_accuracy: 0.7552\n",
            "Epoch 133/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4499 - accuracy: 0.7969 - val_loss: 0.5106 - val_accuracy: 0.7552\n",
            "Epoch 134/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4493 - accuracy: 0.7934 - val_loss: 0.5108 - val_accuracy: 0.7552\n",
            "Epoch 135/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4493 - accuracy: 0.7986 - val_loss: 0.5111 - val_accuracy: 0.7552\n",
            "Epoch 136/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4487 - accuracy: 0.7986 - val_loss: 0.5111 - val_accuracy: 0.7552\n",
            "Epoch 137/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4483 - accuracy: 0.7969 - val_loss: 0.5107 - val_accuracy: 0.7604\n",
            "Epoch 138/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4482 - accuracy: 0.7951 - val_loss: 0.5106 - val_accuracy: 0.7604\n",
            "Epoch 139/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4478 - accuracy: 0.7969 - val_loss: 0.5108 - val_accuracy: 0.7604\n",
            "Epoch 140/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4474 - accuracy: 0.7986 - val_loss: 0.5109 - val_accuracy: 0.7604\n",
            "Epoch 141/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4475 - accuracy: 0.7951 - val_loss: 0.5110 - val_accuracy: 0.7604\n",
            "Epoch 142/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4472 - accuracy: 0.7951 - val_loss: 0.5109 - val_accuracy: 0.7604\n",
            "Epoch 143/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4468 - accuracy: 0.7969 - val_loss: 0.5112 - val_accuracy: 0.7604\n",
            "Epoch 144/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4461 - accuracy: 0.7969 - val_loss: 0.5113 - val_accuracy: 0.7604\n",
            "Epoch 145/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4465 - accuracy: 0.7969 - val_loss: 0.5110 - val_accuracy: 0.7552\n",
            "Epoch 146/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4466 - accuracy: 0.7986 - val_loss: 0.5113 - val_accuracy: 0.7552\n",
            "Epoch 147/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4457 - accuracy: 0.8003 - val_loss: 0.5110 - val_accuracy: 0.7552\n",
            "Epoch 148/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4452 - accuracy: 0.7951 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
            "Epoch 149/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4451 - accuracy: 0.7969 - val_loss: 0.5111 - val_accuracy: 0.7604\n",
            "Epoch 150/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4448 - accuracy: 0.8021 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
            "Epoch 151/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4446 - accuracy: 0.7986 - val_loss: 0.5114 - val_accuracy: 0.7604\n",
            "Epoch 152/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4441 - accuracy: 0.7986 - val_loss: 0.5116 - val_accuracy: 0.7604\n",
            "Epoch 153/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4440 - accuracy: 0.7969 - val_loss: 0.5115 - val_accuracy: 0.7604\n",
            "Epoch 154/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4439 - accuracy: 0.7934 - val_loss: 0.5122 - val_accuracy: 0.7552\n",
            "Epoch 155/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4435 - accuracy: 0.7969 - val_loss: 0.5123 - val_accuracy: 0.7552\n",
            "Epoch 156/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4433 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7552\n",
            "Epoch 157/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4431 - accuracy: 0.7986 - val_loss: 0.5124 - val_accuracy: 0.7552\n",
            "Epoch 158/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4430 - accuracy: 0.7969 - val_loss: 0.5125 - val_accuracy: 0.7552\n",
            "Epoch 159/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4426 - accuracy: 0.8003 - val_loss: 0.5129 - val_accuracy: 0.7552\n",
            "Epoch 160/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4426 - accuracy: 0.7969 - val_loss: 0.5125 - val_accuracy: 0.7552\n",
            "Epoch 161/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4422 - accuracy: 0.7934 - val_loss: 0.5130 - val_accuracy: 0.7552\n",
            "Epoch 162/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4421 - accuracy: 0.7969 - val_loss: 0.5128 - val_accuracy: 0.7552\n",
            "Epoch 163/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4420 - accuracy: 0.7969 - val_loss: 0.5136 - val_accuracy: 0.7604\n",
            "Epoch 164/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4418 - accuracy: 0.7986 - val_loss: 0.5133 - val_accuracy: 0.7604\n",
            "Epoch 165/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4418 - accuracy: 0.7986 - val_loss: 0.5131 - val_accuracy: 0.7604\n",
            "Epoch 166/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.7951 - val_loss: 0.5133 - val_accuracy: 0.7604\n",
            "Epoch 167/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4414 - accuracy: 0.7951 - val_loss: 0.5136 - val_accuracy: 0.7604\n",
            "Epoch 168/800\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4411 - accuracy: 0.8003 - val_loss: 0.5133 - val_accuracy: 0.7604\n",
            "Epoch 169/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4410 - accuracy: 0.7969 - val_loss: 0.5137 - val_accuracy: 0.7604\n",
            "Epoch 170/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4408 - accuracy: 0.7969 - val_loss: 0.5135 - val_accuracy: 0.7604\n",
            "Epoch 171/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4405 - accuracy: 0.8003 - val_loss: 0.5132 - val_accuracy: 0.7604\n",
            "Epoch 172/800\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4405 - accuracy: 0.7969 - val_loss: 0.5131 - val_accuracy: 0.7604\n",
            "Epoch 173/800\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4409 - accuracy: 0.7986 - val_loss: 0.5134 - val_accuracy: 0.7604\n",
            "Epoch 174/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4403 - accuracy: 0.7969 - val_loss: 0.5139 - val_accuracy: 0.7604\n",
            "Epoch 175/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4401 - accuracy: 0.7969 - val_loss: 0.5138 - val_accuracy: 0.7604\n",
            "Epoch 176/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4398 - accuracy: 0.8003 - val_loss: 0.5139 - val_accuracy: 0.7604\n",
            "Epoch 177/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4396 - accuracy: 0.7969 - val_loss: 0.5138 - val_accuracy: 0.7604\n",
            "Epoch 178/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4394 - accuracy: 0.7951 - val_loss: 0.5138 - val_accuracy: 0.7604\n",
            "Epoch 179/800\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4394 - accuracy: 0.7986 - val_loss: 0.5134 - val_accuracy: 0.7604\n",
            "Epoch 180/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4393 - accuracy: 0.7969 - val_loss: 0.5137 - val_accuracy: 0.7604\n",
            "Epoch 181/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4395 - accuracy: 0.7951 - val_loss: 0.5143 - val_accuracy: 0.7656\n",
            "Epoch 182/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4390 - accuracy: 0.7986 - val_loss: 0.5140 - val_accuracy: 0.7604\n",
            "Epoch 183/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4389 - accuracy: 0.7986 - val_loss: 0.5141 - val_accuracy: 0.7656\n",
            "Epoch 184/800\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4387 - accuracy: 0.8003 - val_loss: 0.5140 - val_accuracy: 0.7656\n",
            "Epoch 185/800\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4384 - accuracy: 0.8003 - val_loss: 0.5142 - val_accuracy: 0.7656\n",
            "Epoch 186/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4381 - accuracy: 0.7969 - val_loss: 0.5141 - val_accuracy: 0.7656\n",
            "Epoch 187/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4383 - accuracy: 0.7986 - val_loss: 0.5141 - val_accuracy: 0.7656\n",
            "Epoch 188/800\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4378 - accuracy: 0.8003 - val_loss: 0.5142 - val_accuracy: 0.7656\n",
            "Epoch 189/800\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4379 - accuracy: 0.7969 - val_loss: 0.5138 - val_accuracy: 0.7708\n",
            "Epoch 190/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4378 - accuracy: 0.8021 - val_loss: 0.5143 - val_accuracy: 0.7708\n",
            "Epoch 191/800\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4376 - accuracy: 0.8003 - val_loss: 0.5144 - val_accuracy: 0.7656\n",
            "Epoch 192/800\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.4373 - accuracy: 0.8021 - val_loss: 0.5142 - val_accuracy: 0.7708\n",
            "Epoch 193/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4371 - accuracy: 0.7986 - val_loss: 0.5136 - val_accuracy: 0.7708\n",
            "Epoch 194/800\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4371 - accuracy: 0.8038 - val_loss: 0.5141 - val_accuracy: 0.7708\n",
            "Epoch 195/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4367 - accuracy: 0.8021 - val_loss: 0.5140 - val_accuracy: 0.7708\n",
            "Epoch 196/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4366 - accuracy: 0.7986 - val_loss: 0.5134 - val_accuracy: 0.7708\n",
            "Epoch 197/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4369 - accuracy: 0.8038 - val_loss: 0.5129 - val_accuracy: 0.7656\n",
            "Epoch 198/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4366 - accuracy: 0.7986 - val_loss: 0.5128 - val_accuracy: 0.7656\n",
            "Epoch 199/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4365 - accuracy: 0.8003 - val_loss: 0.5130 - val_accuracy: 0.7656\n",
            "Epoch 200/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4365 - accuracy: 0.8021 - val_loss: 0.5133 - val_accuracy: 0.7656\n",
            "Epoch 201/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4364 - accuracy: 0.8038 - val_loss: 0.5136 - val_accuracy: 0.7708\n",
            "Epoch 202/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4358 - accuracy: 0.8038 - val_loss: 0.5137 - val_accuracy: 0.7656\n",
            "Epoch 203/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4360 - accuracy: 0.8038 - val_loss: 0.5135 - val_accuracy: 0.7656\n",
            "Epoch 204/800\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4362 - accuracy: 0.8073 - val_loss: 0.5140 - val_accuracy: 0.7656\n",
            "Epoch 205/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4357 - accuracy: 0.8056 - val_loss: 0.5140 - val_accuracy: 0.7656\n",
            "Epoch 206/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4357 - accuracy: 0.8038 - val_loss: 0.5139 - val_accuracy: 0.7656\n",
            "Epoch 207/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4355 - accuracy: 0.8073 - val_loss: 0.5140 - val_accuracy: 0.7656\n",
            "Epoch 208/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4359 - accuracy: 0.8056 - val_loss: 0.5134 - val_accuracy: 0.7656\n",
            "Epoch 209/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4352 - accuracy: 0.8090 - val_loss: 0.5135 - val_accuracy: 0.7656\n",
            "Epoch 210/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4351 - accuracy: 0.8108 - val_loss: 0.5134 - val_accuracy: 0.7656\n",
            "Epoch 211/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4348 - accuracy: 0.8056 - val_loss: 0.5133 - val_accuracy: 0.7656\n",
            "Epoch 212/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4346 - accuracy: 0.8038 - val_loss: 0.5136 - val_accuracy: 0.7656\n",
            "Epoch 213/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4346 - accuracy: 0.8056 - val_loss: 0.5135 - val_accuracy: 0.7656\n",
            "Epoch 214/800\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4344 - accuracy: 0.8056 - val_loss: 0.5135 - val_accuracy: 0.7656\n",
            "Epoch 215/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4343 - accuracy: 0.8056 - val_loss: 0.5133 - val_accuracy: 0.7656\n",
            "Epoch 216/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4342 - accuracy: 0.8056 - val_loss: 0.5132 - val_accuracy: 0.7656\n",
            "Epoch 217/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4342 - accuracy: 0.8056 - val_loss: 0.5131 - val_accuracy: 0.7656\n",
            "Epoch 218/800\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4338 - accuracy: 0.8073 - val_loss: 0.5135 - val_accuracy: 0.7604\n",
            "Epoch 219/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4338 - accuracy: 0.8073 - val_loss: 0.5132 - val_accuracy: 0.7656\n",
            "Epoch 220/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4339 - accuracy: 0.8090 - val_loss: 0.5135 - val_accuracy: 0.7604\n",
            "Epoch 221/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4336 - accuracy: 0.8073 - val_loss: 0.5129 - val_accuracy: 0.7656\n",
            "Epoch 222/800\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4333 - accuracy: 0.8090 - val_loss: 0.5133 - val_accuracy: 0.7604\n",
            "Epoch 223/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4339 - accuracy: 0.8073 - val_loss: 0.5133 - val_accuracy: 0.7604\n",
            "Epoch 224/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4333 - accuracy: 0.8108 - val_loss: 0.5128 - val_accuracy: 0.7656\n",
            "Epoch 225/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4331 - accuracy: 0.8090 - val_loss: 0.5131 - val_accuracy: 0.7604\n",
            "Epoch 226/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4329 - accuracy: 0.8090 - val_loss: 0.5132 - val_accuracy: 0.7604\n",
            "Epoch 227/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4329 - accuracy: 0.8108 - val_loss: 0.5124 - val_accuracy: 0.7656\n",
            "Epoch 228/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4326 - accuracy: 0.8108 - val_loss: 0.5127 - val_accuracy: 0.7656\n",
            "Epoch 229/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4331 - accuracy: 0.8108 - val_loss: 0.5129 - val_accuracy: 0.7656\n",
            "Epoch 230/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4323 - accuracy: 0.8090 - val_loss: 0.5125 - val_accuracy: 0.7656\n",
            "Epoch 231/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4323 - accuracy: 0.8108 - val_loss: 0.5127 - val_accuracy: 0.7656\n",
            "Epoch 232/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4324 - accuracy: 0.8125 - val_loss: 0.5129 - val_accuracy: 0.7656\n",
            "Epoch 233/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4323 - accuracy: 0.8056 - val_loss: 0.5128 - val_accuracy: 0.7656\n",
            "Epoch 234/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4323 - accuracy: 0.8108 - val_loss: 0.5127 - val_accuracy: 0.7656\n",
            "Epoch 235/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4319 - accuracy: 0.8090 - val_loss: 0.5123 - val_accuracy: 0.7656\n",
            "Epoch 236/800\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4321 - accuracy: 0.8125 - val_loss: 0.5126 - val_accuracy: 0.7656\n",
            "Epoch 237/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4319 - accuracy: 0.8142 - val_loss: 0.5128 - val_accuracy: 0.7656\n",
            "Epoch 238/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4321 - accuracy: 0.8108 - val_loss: 0.5124 - val_accuracy: 0.7656\n",
            "Epoch 239/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4316 - accuracy: 0.8125 - val_loss: 0.5125 - val_accuracy: 0.7656\n",
            "Epoch 240/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4313 - accuracy: 0.8108 - val_loss: 0.5133 - val_accuracy: 0.7656\n",
            "Epoch 241/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4314 - accuracy: 0.8142 - val_loss: 0.5134 - val_accuracy: 0.7656\n",
            "Epoch 242/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4311 - accuracy: 0.8125 - val_loss: 0.5123 - val_accuracy: 0.7656\n",
            "Epoch 243/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4313 - accuracy: 0.8142 - val_loss: 0.5127 - val_accuracy: 0.7604\n",
            "Epoch 244/800\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4313 - accuracy: 0.8125 - val_loss: 0.5124 - val_accuracy: 0.7656\n",
            "Epoch 245/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4311 - accuracy: 0.8125 - val_loss: 0.5126 - val_accuracy: 0.7604\n",
            "Epoch 246/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4307 - accuracy: 0.8142 - val_loss: 0.5123 - val_accuracy: 0.7656\n",
            "Epoch 247/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4306 - accuracy: 0.8142 - val_loss: 0.5126 - val_accuracy: 0.7604\n",
            "Epoch 248/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4309 - accuracy: 0.8125 - val_loss: 0.5128 - val_accuracy: 0.7604\n",
            "Epoch 249/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4308 - accuracy: 0.8108 - val_loss: 0.5125 - val_accuracy: 0.7604\n",
            "Epoch 250/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4307 - accuracy: 0.8108 - val_loss: 0.5119 - val_accuracy: 0.7656\n",
            "Epoch 251/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4306 - accuracy: 0.8090 - val_loss: 0.5122 - val_accuracy: 0.7656\n",
            "Epoch 252/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4302 - accuracy: 0.8125 - val_loss: 0.5121 - val_accuracy: 0.7656\n",
            "Epoch 253/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4304 - accuracy: 0.8142 - val_loss: 0.5125 - val_accuracy: 0.7604\n",
            "Epoch 254/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4300 - accuracy: 0.8160 - val_loss: 0.5118 - val_accuracy: 0.7656\n",
            "Epoch 255/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4303 - accuracy: 0.8142 - val_loss: 0.5127 - val_accuracy: 0.7604\n",
            "Epoch 256/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4299 - accuracy: 0.8108 - val_loss: 0.5121 - val_accuracy: 0.7656\n",
            "Epoch 257/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4303 - accuracy: 0.8125 - val_loss: 0.5125 - val_accuracy: 0.7604\n",
            "Epoch 258/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4297 - accuracy: 0.8125 - val_loss: 0.5120 - val_accuracy: 0.7656\n",
            "Epoch 259/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4299 - accuracy: 0.8125 - val_loss: 0.5122 - val_accuracy: 0.7604\n",
            "Epoch 260/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4298 - accuracy: 0.8125 - val_loss: 0.5119 - val_accuracy: 0.7656\n",
            "Epoch 261/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4299 - accuracy: 0.8108 - val_loss: 0.5118 - val_accuracy: 0.7656\n",
            "Epoch 262/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4300 - accuracy: 0.8090 - val_loss: 0.5129 - val_accuracy: 0.7656\n",
            "Epoch 263/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4300 - accuracy: 0.8125 - val_loss: 0.5128 - val_accuracy: 0.7656\n",
            "Epoch 264/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4294 - accuracy: 0.8090 - val_loss: 0.5124 - val_accuracy: 0.7604\n",
            "Epoch 265/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4292 - accuracy: 0.8125 - val_loss: 0.5122 - val_accuracy: 0.7604\n",
            "Epoch 266/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.8090 - val_loss: 0.5119 - val_accuracy: 0.7604\n",
            "Epoch 267/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4292 - accuracy: 0.8108 - val_loss: 0.5118 - val_accuracy: 0.7604\n",
            "Epoch 268/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4288 - accuracy: 0.8125 - val_loss: 0.5119 - val_accuracy: 0.7604\n",
            "Epoch 269/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4297 - accuracy: 0.8090 - val_loss: 0.5113 - val_accuracy: 0.7656\n",
            "Epoch 270/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4290 - accuracy: 0.8160 - val_loss: 0.5116 - val_accuracy: 0.7656\n",
            "Epoch 271/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4289 - accuracy: 0.8125 - val_loss: 0.5124 - val_accuracy: 0.7656\n",
            "Epoch 272/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4286 - accuracy: 0.8125 - val_loss: 0.5124 - val_accuracy: 0.7656\n",
            "Epoch 273/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4288 - accuracy: 0.8142 - val_loss: 0.5118 - val_accuracy: 0.7604\n",
            "Epoch 274/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4286 - accuracy: 0.8090 - val_loss: 0.5116 - val_accuracy: 0.7656\n",
            "Epoch 275/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4285 - accuracy: 0.8125 - val_loss: 0.5117 - val_accuracy: 0.7604\n",
            "Epoch 276/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4285 - accuracy: 0.8108 - val_loss: 0.5119 - val_accuracy: 0.7604\n",
            "Epoch 277/800\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4283 - accuracy: 0.8108 - val_loss: 0.5117 - val_accuracy: 0.7604\n",
            "Epoch 278/800\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4285 - accuracy: 0.8125 - val_loss: 0.5114 - val_accuracy: 0.7656\n",
            "Epoch 279/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.8108 - val_loss: 0.5111 - val_accuracy: 0.7656\n",
            "Epoch 280/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.8090 - val_loss: 0.5103 - val_accuracy: 0.7656\n",
            "Epoch 281/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4283 - accuracy: 0.8125 - val_loss: 0.5110 - val_accuracy: 0.7656\n",
            "Epoch 282/800\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4279 - accuracy: 0.8160 - val_loss: 0.5116 - val_accuracy: 0.7656\n",
            "Epoch 283/800\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.4275 - accuracy: 0.8142 - val_loss: 0.5114 - val_accuracy: 0.7656\n",
            "Epoch 284/800\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.4279 - accuracy: 0.8125 - val_loss: 0.5116 - val_accuracy: 0.7656\n",
            "Epoch 285/800\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.4280 - accuracy: 0.8108 - val_loss: 0.5117 - val_accuracy: 0.7656\n",
            "Epoch 286/800\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4276 - accuracy: 0.8090 - val_loss: 0.5122 - val_accuracy: 0.7656\n",
            "Epoch 287/800\n",
            "18/18 [==============================] - 0s 19ms/step - loss: 0.4273 - accuracy: 0.8125 - val_loss: 0.5125 - val_accuracy: 0.7656\n",
            "Epoch 288/800\n",
            "18/18 [==============================] - 0s 20ms/step - loss: 0.4272 - accuracy: 0.8142 - val_loss: 0.5127 - val_accuracy: 0.7656\n",
            "Epoch 289/800\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.4272 - accuracy: 0.8142 - val_loss: 0.5129 - val_accuracy: 0.7656\n",
            "Epoch 290/800\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4276 - accuracy: 0.8108 - val_loss: 0.5124 - val_accuracy: 0.7656\n",
            "Epoch 291/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4269 - accuracy: 0.8108 - val_loss: 0.5127 - val_accuracy: 0.7656\n",
            "Epoch 292/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4269 - accuracy: 0.8125 - val_loss: 0.5118 - val_accuracy: 0.7604\n",
            "Epoch 293/800\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4269 - accuracy: 0.8125 - val_loss: 0.5118 - val_accuracy: 0.7656\n",
            "Epoch 294/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4266 - accuracy: 0.8108 - val_loss: 0.5122 - val_accuracy: 0.7656\n",
            "Epoch 295/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4267 - accuracy: 0.8125 - val_loss: 0.5117 - val_accuracy: 0.7656\n",
            "Epoch 296/800\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4267 - accuracy: 0.8108 - val_loss: 0.5114 - val_accuracy: 0.7656\n",
            "Epoch 297/800\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4265 - accuracy: 0.8125 - val_loss: 0.5116 - val_accuracy: 0.7656\n",
            "Epoch 298/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4265 - accuracy: 0.8142 - val_loss: 0.5121 - val_accuracy: 0.7656\n",
            "Epoch 299/800\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4264 - accuracy: 0.8125 - val_loss: 0.5122 - val_accuracy: 0.7656\n",
            "Epoch 300/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4261 - accuracy: 0.8142 - val_loss: 0.5128 - val_accuracy: 0.7656\n",
            "Epoch 301/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4264 - accuracy: 0.8108 - val_loss: 0.5125 - val_accuracy: 0.7656\n",
            "Epoch 302/800\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4262 - accuracy: 0.8125 - val_loss: 0.5123 - val_accuracy: 0.7656\n",
            "Epoch 303/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4259 - accuracy: 0.8125 - val_loss: 0.5129 - val_accuracy: 0.7656\n",
            "Epoch 304/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4260 - accuracy: 0.8108 - val_loss: 0.5119 - val_accuracy: 0.7708\n",
            "Epoch 305/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4258 - accuracy: 0.8108 - val_loss: 0.5122 - val_accuracy: 0.7656\n",
            "Epoch 306/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4258 - accuracy: 0.8073 - val_loss: 0.5112 - val_accuracy: 0.7656\n",
            "Epoch 307/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4262 - accuracy: 0.8108 - val_loss: 0.5119 - val_accuracy: 0.7708\n",
            "Epoch 308/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4257 - accuracy: 0.8108 - val_loss: 0.5124 - val_accuracy: 0.7656\n",
            "Epoch 309/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4259 - accuracy: 0.8108 - val_loss: 0.5128 - val_accuracy: 0.7656\n",
            "Epoch 310/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4254 - accuracy: 0.8108 - val_loss: 0.5127 - val_accuracy: 0.7656\n",
            "Epoch 311/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4261 - accuracy: 0.8090 - val_loss: 0.5122 - val_accuracy: 0.7656\n",
            "Epoch 312/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4254 - accuracy: 0.8090 - val_loss: 0.5122 - val_accuracy: 0.7656\n",
            "Epoch 313/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4250 - accuracy: 0.8125 - val_loss: 0.5129 - val_accuracy: 0.7656\n",
            "Epoch 314/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4253 - accuracy: 0.8125 - val_loss: 0.5125 - val_accuracy: 0.7656\n",
            "Epoch 315/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4250 - accuracy: 0.8108 - val_loss: 0.5125 - val_accuracy: 0.7656\n",
            "Epoch 316/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4251 - accuracy: 0.8108 - val_loss: 0.5129 - val_accuracy: 0.7656\n",
            "Epoch 317/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4247 - accuracy: 0.8142 - val_loss: 0.5126 - val_accuracy: 0.7656\n",
            "Epoch 318/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4246 - accuracy: 0.8108 - val_loss: 0.5118 - val_accuracy: 0.7708\n",
            "Epoch 319/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4248 - accuracy: 0.8125 - val_loss: 0.5114 - val_accuracy: 0.7656\n",
            "Epoch 320/800\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4245 - accuracy: 0.8090 - val_loss: 0.5125 - val_accuracy: 0.7656\n",
            "Epoch 321/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4241 - accuracy: 0.8142 - val_loss: 0.5129 - val_accuracy: 0.7708\n",
            "Epoch 322/800\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4242 - accuracy: 0.8108 - val_loss: 0.5123 - val_accuracy: 0.7656\n",
            "Epoch 323/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4243 - accuracy: 0.8108 - val_loss: 0.5123 - val_accuracy: 0.7656\n",
            "Epoch 324/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4242 - accuracy: 0.8142 - val_loss: 0.5125 - val_accuracy: 0.7656\n",
            "Epoch 325/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4240 - accuracy: 0.8108 - val_loss: 0.5125 - val_accuracy: 0.7656\n",
            "Epoch 326/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4235 - accuracy: 0.8125 - val_loss: 0.5125 - val_accuracy: 0.7656\n",
            "Epoch 327/800\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4237 - accuracy: 0.8108 - val_loss: 0.5122 - val_accuracy: 0.7656\n",
            "Epoch 328/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4238 - accuracy: 0.8108 - val_loss: 0.5111 - val_accuracy: 0.7656\n",
            "Epoch 329/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4238 - accuracy: 0.8090 - val_loss: 0.5119 - val_accuracy: 0.7708\n",
            "Epoch 330/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4235 - accuracy: 0.8108 - val_loss: 0.5117 - val_accuracy: 0.7708\n",
            "Epoch 331/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4236 - accuracy: 0.8142 - val_loss: 0.5117 - val_accuracy: 0.7708\n",
            "Epoch 332/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4235 - accuracy: 0.8090 - val_loss: 0.5125 - val_accuracy: 0.7708\n",
            "Epoch 333/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4235 - accuracy: 0.8090 - val_loss: 0.5127 - val_accuracy: 0.7656\n",
            "Epoch 334/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4235 - accuracy: 0.8125 - val_loss: 0.5125 - val_accuracy: 0.7708\n",
            "Epoch 335/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4232 - accuracy: 0.8108 - val_loss: 0.5115 - val_accuracy: 0.7708\n",
            "Epoch 336/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4230 - accuracy: 0.8073 - val_loss: 0.5124 - val_accuracy: 0.7708\n",
            "Epoch 337/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4231 - accuracy: 0.8090 - val_loss: 0.5130 - val_accuracy: 0.7656\n",
            "Epoch 338/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4227 - accuracy: 0.8108 - val_loss: 0.5119 - val_accuracy: 0.7708\n",
            "Epoch 339/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4227 - accuracy: 0.8142 - val_loss: 0.5120 - val_accuracy: 0.7760\n",
            "Epoch 340/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4226 - accuracy: 0.8125 - val_loss: 0.5119 - val_accuracy: 0.7760\n",
            "Epoch 341/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4228 - accuracy: 0.8142 - val_loss: 0.5113 - val_accuracy: 0.7656\n",
            "Epoch 342/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4224 - accuracy: 0.8108 - val_loss: 0.5120 - val_accuracy: 0.7708\n",
            "Epoch 343/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4224 - accuracy: 0.8125 - val_loss: 0.5111 - val_accuracy: 0.7656\n",
            "Epoch 344/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4224 - accuracy: 0.8160 - val_loss: 0.5113 - val_accuracy: 0.7708\n",
            "Epoch 345/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4222 - accuracy: 0.8125 - val_loss: 0.5119 - val_accuracy: 0.7760\n",
            "Epoch 346/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4223 - accuracy: 0.8125 - val_loss: 0.5114 - val_accuracy: 0.7708\n",
            "Epoch 347/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4222 - accuracy: 0.8108 - val_loss: 0.5123 - val_accuracy: 0.7656\n",
            "Epoch 348/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4219 - accuracy: 0.8142 - val_loss: 0.5131 - val_accuracy: 0.7656\n",
            "Epoch 349/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4221 - accuracy: 0.8125 - val_loss: 0.5118 - val_accuracy: 0.7760\n",
            "Epoch 350/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4219 - accuracy: 0.8108 - val_loss: 0.5126 - val_accuracy: 0.7656\n",
            "Epoch 351/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4220 - accuracy: 0.8090 - val_loss: 0.5129 - val_accuracy: 0.7656\n",
            "Epoch 352/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4219 - accuracy: 0.8090 - val_loss: 0.5118 - val_accuracy: 0.7708\n",
            "Epoch 353/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4217 - accuracy: 0.8108 - val_loss: 0.5126 - val_accuracy: 0.7656\n",
            "Epoch 354/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4216 - accuracy: 0.8142 - val_loss: 0.5129 - val_accuracy: 0.7656\n",
            "Epoch 355/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4212 - accuracy: 0.8108 - val_loss: 0.5127 - val_accuracy: 0.7656\n",
            "Epoch 356/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4215 - accuracy: 0.8090 - val_loss: 0.5119 - val_accuracy: 0.7708\n",
            "Epoch 357/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4211 - accuracy: 0.8108 - val_loss: 0.5120 - val_accuracy: 0.7708\n",
            "Epoch 358/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4215 - accuracy: 0.8177 - val_loss: 0.5122 - val_accuracy: 0.7708\n",
            "Epoch 359/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4210 - accuracy: 0.8160 - val_loss: 0.5136 - val_accuracy: 0.7656\n",
            "Epoch 360/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4213 - accuracy: 0.8142 - val_loss: 0.5137 - val_accuracy: 0.7656\n",
            "Epoch 361/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4212 - accuracy: 0.8125 - val_loss: 0.5130 - val_accuracy: 0.7656\n",
            "Epoch 362/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4209 - accuracy: 0.8125 - val_loss: 0.5120 - val_accuracy: 0.7708\n",
            "Epoch 363/800\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4212 - accuracy: 0.8125 - val_loss: 0.5119 - val_accuracy: 0.7708\n",
            "Epoch 364/800\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4208 - accuracy: 0.8160 - val_loss: 0.5116 - val_accuracy: 0.7708\n",
            "Epoch 365/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4209 - accuracy: 0.8125 - val_loss: 0.5126 - val_accuracy: 0.7656\n",
            "Epoch 366/800\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4208 - accuracy: 0.8108 - val_loss: 0.5127 - val_accuracy: 0.7656\n",
            "Epoch 367/800\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4205 - accuracy: 0.8142 - val_loss: 0.5126 - val_accuracy: 0.7656\n",
            "Epoch 368/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4208 - accuracy: 0.8142 - val_loss: 0.5122 - val_accuracy: 0.7708\n",
            "Epoch 369/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4204 - accuracy: 0.8160 - val_loss: 0.5126 - val_accuracy: 0.7708\n",
            "Epoch 370/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4205 - accuracy: 0.8125 - val_loss: 0.5119 - val_accuracy: 0.7708\n",
            "Epoch 371/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4201 - accuracy: 0.8142 - val_loss: 0.5122 - val_accuracy: 0.7708\n",
            "Epoch 372/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4202 - accuracy: 0.8142 - val_loss: 0.5132 - val_accuracy: 0.7656\n",
            "Epoch 373/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4202 - accuracy: 0.8160 - val_loss: 0.5120 - val_accuracy: 0.7708\n",
            "Epoch 374/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4204 - accuracy: 0.8125 - val_loss: 0.5126 - val_accuracy: 0.7708\n",
            "Epoch 375/800\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4198 - accuracy: 0.8125 - val_loss: 0.5119 - val_accuracy: 0.7708\n",
            "Epoch 376/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4199 - accuracy: 0.8090 - val_loss: 0.5124 - val_accuracy: 0.7708\n",
            "Epoch 377/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4196 - accuracy: 0.8160 - val_loss: 0.5121 - val_accuracy: 0.7708\n",
            "Epoch 378/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4202 - accuracy: 0.8142 - val_loss: 0.5129 - val_accuracy: 0.7656\n",
            "Epoch 379/800\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4194 - accuracy: 0.8177 - val_loss: 0.5120 - val_accuracy: 0.7708\n",
            "Epoch 380/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4195 - accuracy: 0.8125 - val_loss: 0.5122 - val_accuracy: 0.7708\n",
            "Epoch 381/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4198 - accuracy: 0.8125 - val_loss: 0.5121 - val_accuracy: 0.7708\n",
            "Epoch 382/800\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4196 - accuracy: 0.8142 - val_loss: 0.5128 - val_accuracy: 0.7656\n",
            "Epoch 383/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4192 - accuracy: 0.8142 - val_loss: 0.5120 - val_accuracy: 0.7656\n",
            "Epoch 384/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4195 - accuracy: 0.8142 - val_loss: 0.5117 - val_accuracy: 0.7708\n",
            "Epoch 385/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4192 - accuracy: 0.8142 - val_loss: 0.5117 - val_accuracy: 0.7708\n",
            "Epoch 386/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4194 - accuracy: 0.8177 - val_loss: 0.5123 - val_accuracy: 0.7760\n",
            "Epoch 387/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4191 - accuracy: 0.8142 - val_loss: 0.5124 - val_accuracy: 0.7708\n",
            "Epoch 388/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4190 - accuracy: 0.8125 - val_loss: 0.5116 - val_accuracy: 0.7708\n",
            "Epoch 389/800\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4196 - accuracy: 0.8142 - val_loss: 0.5117 - val_accuracy: 0.7708\n",
            "Epoch 390/800\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4188 - accuracy: 0.8142 - val_loss: 0.5122 - val_accuracy: 0.7708\n",
            "Epoch 391/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4188 - accuracy: 0.8160 - val_loss: 0.5121 - val_accuracy: 0.7656\n",
            "Epoch 392/800\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4188 - accuracy: 0.8160 - val_loss: 0.5127 - val_accuracy: 0.7656\n",
            "Epoch 393/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4188 - accuracy: 0.8142 - val_loss: 0.5133 - val_accuracy: 0.7656\n",
            "Epoch 394/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4190 - accuracy: 0.8142 - val_loss: 0.5128 - val_accuracy: 0.7656\n",
            "Epoch 395/800\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4187 - accuracy: 0.8142 - val_loss: 0.5126 - val_accuracy: 0.7656\n",
            "Epoch 396/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4187 - accuracy: 0.8160 - val_loss: 0.5140 - val_accuracy: 0.7656\n",
            "Epoch 397/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4186 - accuracy: 0.8160 - val_loss: 0.5130 - val_accuracy: 0.7656\n",
            "Epoch 398/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4186 - accuracy: 0.8142 - val_loss: 0.5124 - val_accuracy: 0.7708\n",
            "Epoch 399/800\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4190 - accuracy: 0.8142 - val_loss: 0.5123 - val_accuracy: 0.7708\n",
            "Epoch 400/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4181 - accuracy: 0.8177 - val_loss: 0.5132 - val_accuracy: 0.7656\n",
            "Epoch 401/800\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.4183 - accuracy: 0.8160 - val_loss: 0.5128 - val_accuracy: 0.7656\n",
            "Epoch 402/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4183 - accuracy: 0.8142 - val_loss: 0.5138 - val_accuracy: 0.7656\n",
            "Epoch 403/800\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.4181 - accuracy: 0.8125 - val_loss: 0.5127 - val_accuracy: 0.7656\n",
            "Epoch 404/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4183 - accuracy: 0.8142 - val_loss: 0.5124 - val_accuracy: 0.7708\n",
            "Epoch 405/800\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4180 - accuracy: 0.8160 - val_loss: 0.5120 - val_accuracy: 0.7656\n",
            "Epoch 406/800\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.4181 - accuracy: 0.8160 - val_loss: 0.5115 - val_accuracy: 0.7708\n",
            "Epoch 407/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4177 - accuracy: 0.8125 - val_loss: 0.5125 - val_accuracy: 0.7656\n",
            "Epoch 408/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4178 - accuracy: 0.8142 - val_loss: 0.5119 - val_accuracy: 0.7656\n",
            "Epoch 409/800\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4180 - accuracy: 0.8160 - val_loss: 0.5121 - val_accuracy: 0.7656\n",
            "Epoch 410/800\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.4179 - accuracy: 0.8142 - val_loss: 0.5128 - val_accuracy: 0.7656\n",
            "Epoch 411/800\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.4177 - accuracy: 0.8142 - val_loss: 0.5121 - val_accuracy: 0.7656\n",
            "Epoch 412/800\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4175 - accuracy: 0.8142 - val_loss: 0.5119 - val_accuracy: 0.7656\n",
            "Epoch 413/800\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4172 - accuracy: 0.8177 - val_loss: 0.5122 - val_accuracy: 0.7656\n",
            "Epoch 414/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4174 - accuracy: 0.8142 - val_loss: 0.5124 - val_accuracy: 0.7656\n",
            "Epoch 415/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4177 - accuracy: 0.8142 - val_loss: 0.5123 - val_accuracy: 0.7656\n",
            "Epoch 416/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4173 - accuracy: 0.8194 - val_loss: 0.5123 - val_accuracy: 0.7656\n",
            "Epoch 417/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4170 - accuracy: 0.8142 - val_loss: 0.5126 - val_accuracy: 0.7656\n",
            "Epoch 418/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4177 - accuracy: 0.8125 - val_loss: 0.5125 - val_accuracy: 0.7656\n",
            "Epoch 419/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4170 - accuracy: 0.8142 - val_loss: 0.5123 - val_accuracy: 0.7656\n",
            "Epoch 420/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4168 - accuracy: 0.8177 - val_loss: 0.5131 - val_accuracy: 0.7656\n",
            "Epoch 421/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4169 - accuracy: 0.8160 - val_loss: 0.5121 - val_accuracy: 0.7656\n",
            "Epoch 422/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4170 - accuracy: 0.8142 - val_loss: 0.5133 - val_accuracy: 0.7656\n",
            "Epoch 423/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4174 - accuracy: 0.8142 - val_loss: 0.5128 - val_accuracy: 0.7656\n",
            "Epoch 424/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4169 - accuracy: 0.8177 - val_loss: 0.5128 - val_accuracy: 0.7656\n",
            "Epoch 425/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4166 - accuracy: 0.8160 - val_loss: 0.5131 - val_accuracy: 0.7656\n",
            "Epoch 426/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4160 - accuracy: 0.8177 - val_loss: 0.5133 - val_accuracy: 0.7604\n",
            "Epoch 427/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4169 - accuracy: 0.8160 - val_loss: 0.5133 - val_accuracy: 0.7656\n",
            "Epoch 428/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4164 - accuracy: 0.8160 - val_loss: 0.5120 - val_accuracy: 0.7708\n",
            "Epoch 429/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4163 - accuracy: 0.8177 - val_loss: 0.5127 - val_accuracy: 0.7656\n",
            "Epoch 430/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4161 - accuracy: 0.8177 - val_loss: 0.5128 - val_accuracy: 0.7656\n",
            "Epoch 431/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4162 - accuracy: 0.8177 - val_loss: 0.5120 - val_accuracy: 0.7708\n",
            "Epoch 432/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4159 - accuracy: 0.8194 - val_loss: 0.5121 - val_accuracy: 0.7708\n",
            "Epoch 433/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4157 - accuracy: 0.8177 - val_loss: 0.5119 - val_accuracy: 0.7708\n",
            "Epoch 434/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4160 - accuracy: 0.8177 - val_loss: 0.5122 - val_accuracy: 0.7656\n",
            "Epoch 435/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4157 - accuracy: 0.8194 - val_loss: 0.5128 - val_accuracy: 0.7656\n",
            "Epoch 436/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4154 - accuracy: 0.8142 - val_loss: 0.5118 - val_accuracy: 0.7708\n",
            "Epoch 437/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4159 - accuracy: 0.8194 - val_loss: 0.5122 - val_accuracy: 0.7656\n",
            "Epoch 438/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4153 - accuracy: 0.8194 - val_loss: 0.5124 - val_accuracy: 0.7656\n",
            "Epoch 439/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4153 - accuracy: 0.8160 - val_loss: 0.5136 - val_accuracy: 0.7656\n",
            "Epoch 440/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4154 - accuracy: 0.8194 - val_loss: 0.5129 - val_accuracy: 0.7656\n",
            "Epoch 441/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4152 - accuracy: 0.8160 - val_loss: 0.5136 - val_accuracy: 0.7604\n",
            "Epoch 442/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4156 - accuracy: 0.8177 - val_loss: 0.5126 - val_accuracy: 0.7604\n",
            "Epoch 443/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4151 - accuracy: 0.8177 - val_loss: 0.5131 - val_accuracy: 0.7604\n",
            "Epoch 444/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4149 - accuracy: 0.8212 - val_loss: 0.5124 - val_accuracy: 0.7604\n",
            "Epoch 445/800\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4152 - accuracy: 0.8177 - val_loss: 0.5113 - val_accuracy: 0.7656\n",
            "Epoch 446/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4152 - accuracy: 0.8194 - val_loss: 0.5122 - val_accuracy: 0.7604\n",
            "Epoch 447/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4148 - accuracy: 0.8177 - val_loss: 0.5119 - val_accuracy: 0.7604\n",
            "Epoch 448/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4150 - accuracy: 0.8177 - val_loss: 0.5116 - val_accuracy: 0.7656\n",
            "Epoch 449/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4149 - accuracy: 0.8177 - val_loss: 0.5117 - val_accuracy: 0.7604\n",
            "Epoch 450/800\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4149 - accuracy: 0.8229 - val_loss: 0.5116 - val_accuracy: 0.7604\n",
            "Epoch 451/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4147 - accuracy: 0.8160 - val_loss: 0.5126 - val_accuracy: 0.7604\n",
            "Epoch 452/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4146 - accuracy: 0.8194 - val_loss: 0.5122 - val_accuracy: 0.7604\n",
            "Epoch 453/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4142 - accuracy: 0.8194 - val_loss: 0.5124 - val_accuracy: 0.7604\n",
            "Epoch 454/800\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4144 - accuracy: 0.8194 - val_loss: 0.5127 - val_accuracy: 0.7552\n",
            "Epoch 455/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4145 - accuracy: 0.8212 - val_loss: 0.5126 - val_accuracy: 0.7500\n",
            "Epoch 456/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4141 - accuracy: 0.8194 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
            "Epoch 457/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4144 - accuracy: 0.8212 - val_loss: 0.5126 - val_accuracy: 0.7552\n",
            "Epoch 458/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4139 - accuracy: 0.8160 - val_loss: 0.5118 - val_accuracy: 0.7604\n",
            "Epoch 459/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4141 - accuracy: 0.8194 - val_loss: 0.5114 - val_accuracy: 0.7500\n",
            "Epoch 460/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4139 - accuracy: 0.8194 - val_loss: 0.5122 - val_accuracy: 0.7552\n",
            "Epoch 461/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4139 - accuracy: 0.8194 - val_loss: 0.5119 - val_accuracy: 0.7552\n",
            "Epoch 462/800\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4140 - accuracy: 0.8142 - val_loss: 0.5111 - val_accuracy: 0.7604\n",
            "Epoch 463/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4138 - accuracy: 0.8194 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
            "Epoch 464/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4137 - accuracy: 0.8177 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
            "Epoch 465/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4136 - accuracy: 0.8177 - val_loss: 0.5126 - val_accuracy: 0.7552\n",
            "Epoch 466/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4135 - accuracy: 0.8194 - val_loss: 0.5120 - val_accuracy: 0.7552\n",
            "Epoch 467/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4136 - accuracy: 0.8160 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
            "Epoch 468/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4136 - accuracy: 0.8125 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
            "Epoch 469/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4134 - accuracy: 0.8194 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
            "Epoch 470/800\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4133 - accuracy: 0.8177 - val_loss: 0.5119 - val_accuracy: 0.7500\n",
            "Epoch 471/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4133 - accuracy: 0.8142 - val_loss: 0.5118 - val_accuracy: 0.7552\n",
            "Epoch 472/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4136 - accuracy: 0.8177 - val_loss: 0.5112 - val_accuracy: 0.7552\n",
            "Epoch 473/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4132 - accuracy: 0.8142 - val_loss: 0.5115 - val_accuracy: 0.7500\n",
            "Epoch 474/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4128 - accuracy: 0.8194 - val_loss: 0.5112 - val_accuracy: 0.7500\n",
            "Epoch 475/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4133 - accuracy: 0.8160 - val_loss: 0.5118 - val_accuracy: 0.7552\n",
            "Epoch 476/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4128 - accuracy: 0.8177 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
            "Epoch 477/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4130 - accuracy: 0.8142 - val_loss: 0.5116 - val_accuracy: 0.7500\n",
            "Epoch 478/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4127 - accuracy: 0.8177 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
            "Epoch 479/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4128 - accuracy: 0.8160 - val_loss: 0.5114 - val_accuracy: 0.7500\n",
            "Epoch 480/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4131 - accuracy: 0.8177 - val_loss: 0.5111 - val_accuracy: 0.7500\n",
            "Epoch 481/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4132 - accuracy: 0.8160 - val_loss: 0.5104 - val_accuracy: 0.7552\n",
            "Epoch 482/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4124 - accuracy: 0.8194 - val_loss: 0.5115 - val_accuracy: 0.7500\n",
            "Epoch 483/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4126 - accuracy: 0.8160 - val_loss: 0.5122 - val_accuracy: 0.7500\n",
            "Epoch 484/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4126 - accuracy: 0.8160 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
            "Epoch 485/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4127 - accuracy: 0.8177 - val_loss: 0.5107 - val_accuracy: 0.7552\n",
            "Epoch 486/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4125 - accuracy: 0.8177 - val_loss: 0.5113 - val_accuracy: 0.7500\n",
            "Epoch 487/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4123 - accuracy: 0.8194 - val_loss: 0.5103 - val_accuracy: 0.7552\n",
            "Epoch 488/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4122 - accuracy: 0.8160 - val_loss: 0.5120 - val_accuracy: 0.7500\n",
            "Epoch 489/800\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4128 - accuracy: 0.8142 - val_loss: 0.5119 - val_accuracy: 0.7500\n",
            "Epoch 490/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4120 - accuracy: 0.8160 - val_loss: 0.5109 - val_accuracy: 0.7500\n",
            "Epoch 491/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4123 - accuracy: 0.8177 - val_loss: 0.5123 - val_accuracy: 0.7552\n",
            "Epoch 492/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4119 - accuracy: 0.8160 - val_loss: 0.5126 - val_accuracy: 0.7552\n",
            "Epoch 493/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4119 - accuracy: 0.8177 - val_loss: 0.5112 - val_accuracy: 0.7500\n",
            "Epoch 494/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4121 - accuracy: 0.8160 - val_loss: 0.5113 - val_accuracy: 0.7448\n",
            "Epoch 495/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4117 - accuracy: 0.8194 - val_loss: 0.5110 - val_accuracy: 0.7500\n",
            "Epoch 496/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4116 - accuracy: 0.8142 - val_loss: 0.5106 - val_accuracy: 0.7500\n",
            "Epoch 497/800\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4116 - accuracy: 0.8125 - val_loss: 0.5103 - val_accuracy: 0.7500\n",
            "Epoch 498/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4117 - accuracy: 0.8177 - val_loss: 0.5109 - val_accuracy: 0.7448\n",
            "Epoch 499/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4115 - accuracy: 0.8194 - val_loss: 0.5102 - val_accuracy: 0.7448\n",
            "Epoch 500/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4117 - accuracy: 0.8160 - val_loss: 0.5121 - val_accuracy: 0.7448\n",
            "Epoch 501/800\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4114 - accuracy: 0.8177 - val_loss: 0.5107 - val_accuracy: 0.7448\n",
            "Epoch 502/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4121 - accuracy: 0.8142 - val_loss: 0.5113 - val_accuracy: 0.7448\n",
            "Epoch 503/800\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4111 - accuracy: 0.8194 - val_loss: 0.5106 - val_accuracy: 0.7448\n",
            "Epoch 504/800\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4114 - accuracy: 0.8160 - val_loss: 0.5101 - val_accuracy: 0.7448\n",
            "Epoch 505/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4115 - accuracy: 0.8142 - val_loss: 0.5105 - val_accuracy: 0.7500\n",
            "Epoch 506/800\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4115 - accuracy: 0.8177 - val_loss: 0.5111 - val_accuracy: 0.7500\n",
            "Epoch 507/800\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4113 - accuracy: 0.8142 - val_loss: 0.5112 - val_accuracy: 0.7500\n",
            "Epoch 508/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4111 - accuracy: 0.8194 - val_loss: 0.5107 - val_accuracy: 0.7448\n",
            "Epoch 509/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4113 - accuracy: 0.8177 - val_loss: 0.5106 - val_accuracy: 0.7448\n",
            "Epoch 510/800\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4114 - accuracy: 0.8160 - val_loss: 0.5112 - val_accuracy: 0.7448\n",
            "Epoch 511/800\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4112 - accuracy: 0.8160 - val_loss: 0.5107 - val_accuracy: 0.7448\n",
            "Epoch 512/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8177 - val_loss: 0.5124 - val_accuracy: 0.7552\n",
            "Epoch 513/800\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4111 - accuracy: 0.8194 - val_loss: 0.5114 - val_accuracy: 0.7448\n",
            "Epoch 514/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4112 - accuracy: 0.8212 - val_loss: 0.5111 - val_accuracy: 0.7448\n",
            "Epoch 515/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4113 - accuracy: 0.8194 - val_loss: 0.5117 - val_accuracy: 0.7448\n",
            "Epoch 516/800\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.4119 - accuracy: 0.8160 - val_loss: 0.5126 - val_accuracy: 0.7552\n",
            "Epoch 517/800\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4108 - accuracy: 0.8125 - val_loss: 0.5120 - val_accuracy: 0.7500\n",
            "Epoch 518/800\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.4108 - accuracy: 0.8177 - val_loss: 0.5110 - val_accuracy: 0.7448\n",
            "Epoch 519/800\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.4108 - accuracy: 0.8125 - val_loss: 0.5119 - val_accuracy: 0.7448\n",
            "Epoch 520/800\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.4108 - accuracy: 0.8160 - val_loss: 0.5116 - val_accuracy: 0.7448\n",
            "Epoch 521/800\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.4102 - accuracy: 0.8177 - val_loss: 0.5101 - val_accuracy: 0.7500\n",
            "Epoch 522/800\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.4107 - accuracy: 0.8142 - val_loss: 0.5118 - val_accuracy: 0.7448\n",
            "Epoch 523/800\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4107 - accuracy: 0.8194 - val_loss: 0.5123 - val_accuracy: 0.7448\n",
            "Epoch 524/800\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.4103 - accuracy: 0.8194 - val_loss: 0.5115 - val_accuracy: 0.7448\n",
            "Epoch 525/800\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4104 - accuracy: 0.8194 - val_loss: 0.5121 - val_accuracy: 0.7500\n",
            "Epoch 526/800\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.4103 - accuracy: 0.8142 - val_loss: 0.5117 - val_accuracy: 0.7500\n",
            "Epoch 527/800\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.4105 - accuracy: 0.8194 - val_loss: 0.5111 - val_accuracy: 0.7448\n",
            "Epoch 528/800\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.4100 - accuracy: 0.8229 - val_loss: 0.5110 - val_accuracy: 0.7448\n",
            "Epoch 529/800\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.4101 - accuracy: 0.8160 - val_loss: 0.5113 - val_accuracy: 0.7448\n",
            "Epoch 530/800\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4101 - accuracy: 0.8194 - val_loss: 0.5113 - val_accuracy: 0.7448\n",
            "Epoch 531/800\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4100 - accuracy: 0.8194 - val_loss: 0.5114 - val_accuracy: 0.7448\n",
            "Epoch 532/800\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4096 - accuracy: 0.8125 - val_loss: 0.5132 - val_accuracy: 0.7552\n",
            "Epoch 533/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4102 - accuracy: 0.8142 - val_loss: 0.5127 - val_accuracy: 0.7552\n",
            "Epoch 534/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8177 - val_loss: 0.5117 - val_accuracy: 0.7448\n",
            "Epoch 535/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4102 - accuracy: 0.8194 - val_loss: 0.5114 - val_accuracy: 0.7448\n",
            "Epoch 536/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4095 - accuracy: 0.8194 - val_loss: 0.5110 - val_accuracy: 0.7448\n",
            "Epoch 537/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4097 - accuracy: 0.8194 - val_loss: 0.5119 - val_accuracy: 0.7552\n",
            "Epoch 538/800\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4095 - accuracy: 0.8229 - val_loss: 0.5121 - val_accuracy: 0.7500\n",
            "Epoch 539/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4096 - accuracy: 0.8229 - val_loss: 0.5114 - val_accuracy: 0.7448\n",
            "Epoch 540/800\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4096 - accuracy: 0.8212 - val_loss: 0.5113 - val_accuracy: 0.7448\n",
            "Epoch 541/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4091 - accuracy: 0.8194 - val_loss: 0.5128 - val_accuracy: 0.7604\n",
            "Epoch 542/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4096 - accuracy: 0.8194 - val_loss: 0.5112 - val_accuracy: 0.7500\n",
            "Epoch 543/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4094 - accuracy: 0.8229 - val_loss: 0.5110 - val_accuracy: 0.7448\n",
            "Epoch 544/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4095 - accuracy: 0.8212 - val_loss: 0.5109 - val_accuracy: 0.7448\n",
            "Epoch 545/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4092 - accuracy: 0.8194 - val_loss: 0.5120 - val_accuracy: 0.7552\n",
            "Epoch 546/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4097 - accuracy: 0.8194 - val_loss: 0.5115 - val_accuracy: 0.7500\n",
            "Epoch 547/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4089 - accuracy: 0.8194 - val_loss: 0.5120 - val_accuracy: 0.7448\n",
            "Epoch 548/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4091 - accuracy: 0.8194 - val_loss: 0.5126 - val_accuracy: 0.7552\n",
            "Epoch 549/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4095 - accuracy: 0.8229 - val_loss: 0.5118 - val_accuracy: 0.7448\n",
            "Epoch 550/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4092 - accuracy: 0.8194 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
            "Epoch 551/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4087 - accuracy: 0.8177 - val_loss: 0.5121 - val_accuracy: 0.7500\n",
            "Epoch 552/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4090 - accuracy: 0.8212 - val_loss: 0.5120 - val_accuracy: 0.7500\n",
            "Epoch 553/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4093 - accuracy: 0.8229 - val_loss: 0.5124 - val_accuracy: 0.7604\n",
            "Epoch 554/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4091 - accuracy: 0.8177 - val_loss: 0.5122 - val_accuracy: 0.7604\n",
            "Epoch 555/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4089 - accuracy: 0.8229 - val_loss: 0.5112 - val_accuracy: 0.7448\n",
            "Epoch 556/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4087 - accuracy: 0.8194 - val_loss: 0.5110 - val_accuracy: 0.7448\n",
            "Epoch 557/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4089 - accuracy: 0.8229 - val_loss: 0.5111 - val_accuracy: 0.7448\n",
            "Epoch 558/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4086 - accuracy: 0.8212 - val_loss: 0.5126 - val_accuracy: 0.7604\n",
            "Epoch 559/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4085 - accuracy: 0.8247 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
            "Epoch 560/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4088 - accuracy: 0.8194 - val_loss: 0.5119 - val_accuracy: 0.7552\n",
            "Epoch 561/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4083 - accuracy: 0.8247 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
            "Epoch 562/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4085 - accuracy: 0.8247 - val_loss: 0.5114 - val_accuracy: 0.7448\n",
            "Epoch 563/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4083 - accuracy: 0.8194 - val_loss: 0.5101 - val_accuracy: 0.7500\n",
            "Epoch 564/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4083 - accuracy: 0.8212 - val_loss: 0.5120 - val_accuracy: 0.7500\n",
            "Epoch 565/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4082 - accuracy: 0.8212 - val_loss: 0.5124 - val_accuracy: 0.7552\n",
            "Epoch 566/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4083 - accuracy: 0.8247 - val_loss: 0.5130 - val_accuracy: 0.7552\n",
            "Epoch 567/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4078 - accuracy: 0.8229 - val_loss: 0.5110 - val_accuracy: 0.7500\n",
            "Epoch 568/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4083 - accuracy: 0.8160 - val_loss: 0.5130 - val_accuracy: 0.7604\n",
            "Epoch 569/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4082 - accuracy: 0.8264 - val_loss: 0.5125 - val_accuracy: 0.7552\n",
            "Epoch 570/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4085 - accuracy: 0.8194 - val_loss: 0.5127 - val_accuracy: 0.7552\n",
            "Epoch 571/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4080 - accuracy: 0.8264 - val_loss: 0.5114 - val_accuracy: 0.7500\n",
            "Epoch 572/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4076 - accuracy: 0.8212 - val_loss: 0.5122 - val_accuracy: 0.7500\n",
            "Epoch 573/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4076 - accuracy: 0.8229 - val_loss: 0.5120 - val_accuracy: 0.7500\n",
            "Epoch 574/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4078 - accuracy: 0.8194 - val_loss: 0.5119 - val_accuracy: 0.7500\n",
            "Epoch 575/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4078 - accuracy: 0.8212 - val_loss: 0.5117 - val_accuracy: 0.7500\n",
            "Epoch 576/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4082 - accuracy: 0.8229 - val_loss: 0.5121 - val_accuracy: 0.7500\n",
            "Epoch 577/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4078 - accuracy: 0.8194 - val_loss: 0.5123 - val_accuracy: 0.7500\n",
            "Epoch 578/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4073 - accuracy: 0.8212 - val_loss: 0.5121 - val_accuracy: 0.7500\n",
            "Epoch 579/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4073 - accuracy: 0.8229 - val_loss: 0.5128 - val_accuracy: 0.7604\n",
            "Epoch 580/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4077 - accuracy: 0.8229 - val_loss: 0.5118 - val_accuracy: 0.7500\n",
            "Epoch 581/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4074 - accuracy: 0.8247 - val_loss: 0.5123 - val_accuracy: 0.7552\n",
            "Epoch 582/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4074 - accuracy: 0.8177 - val_loss: 0.5127 - val_accuracy: 0.7604\n",
            "Epoch 583/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4075 - accuracy: 0.8247 - val_loss: 0.5122 - val_accuracy: 0.7552\n",
            "Epoch 584/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4075 - accuracy: 0.8229 - val_loss: 0.5115 - val_accuracy: 0.7500\n",
            "Epoch 585/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4072 - accuracy: 0.8194 - val_loss: 0.5116 - val_accuracy: 0.7500\n",
            "Epoch 586/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4073 - accuracy: 0.8194 - val_loss: 0.5114 - val_accuracy: 0.7500\n",
            "Epoch 587/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4072 - accuracy: 0.8247 - val_loss: 0.5109 - val_accuracy: 0.7500\n",
            "Epoch 588/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4073 - accuracy: 0.8194 - val_loss: 0.5128 - val_accuracy: 0.7552\n",
            "Epoch 589/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4067 - accuracy: 0.8247 - val_loss: 0.5120 - val_accuracy: 0.7500\n",
            "Epoch 590/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4069 - accuracy: 0.8194 - val_loss: 0.5136 - val_accuracy: 0.7552\n",
            "Epoch 591/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4069 - accuracy: 0.8229 - val_loss: 0.5143 - val_accuracy: 0.7552\n",
            "Epoch 592/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4073 - accuracy: 0.8212 - val_loss: 0.5135 - val_accuracy: 0.7552\n",
            "Epoch 593/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4066 - accuracy: 0.8177 - val_loss: 0.5135 - val_accuracy: 0.7552\n",
            "Epoch 594/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4076 - accuracy: 0.8212 - val_loss: 0.5115 - val_accuracy: 0.7500\n",
            "Epoch 595/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4071 - accuracy: 0.8229 - val_loss: 0.5128 - val_accuracy: 0.7448\n",
            "Epoch 596/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4065 - accuracy: 0.8212 - val_loss: 0.5122 - val_accuracy: 0.7500\n",
            "Epoch 597/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4063 - accuracy: 0.8212 - val_loss: 0.5137 - val_accuracy: 0.7552\n",
            "Epoch 598/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4063 - accuracy: 0.8212 - val_loss: 0.5126 - val_accuracy: 0.7500\n",
            "Epoch 599/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4066 - accuracy: 0.8229 - val_loss: 0.5127 - val_accuracy: 0.7500\n",
            "Epoch 600/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4064 - accuracy: 0.8194 - val_loss: 0.5120 - val_accuracy: 0.7500\n",
            "Epoch 601/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4064 - accuracy: 0.8247 - val_loss: 0.5127 - val_accuracy: 0.7500\n",
            "Epoch 602/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4067 - accuracy: 0.8247 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
            "Epoch 603/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4064 - accuracy: 0.8194 - val_loss: 0.5128 - val_accuracy: 0.7500\n",
            "Epoch 604/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4068 - accuracy: 0.8194 - val_loss: 0.5129 - val_accuracy: 0.7500\n",
            "Epoch 605/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4063 - accuracy: 0.8177 - val_loss: 0.5133 - val_accuracy: 0.7552\n",
            "Epoch 606/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4063 - accuracy: 0.8194 - val_loss: 0.5135 - val_accuracy: 0.7552\n",
            "Epoch 607/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4064 - accuracy: 0.8247 - val_loss: 0.5134 - val_accuracy: 0.7552\n",
            "Epoch 608/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4064 - accuracy: 0.8177 - val_loss: 0.5134 - val_accuracy: 0.7552\n",
            "Epoch 609/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4057 - accuracy: 0.8229 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
            "Epoch 610/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4066 - accuracy: 0.8160 - val_loss: 0.5138 - val_accuracy: 0.7552\n",
            "Epoch 611/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4066 - accuracy: 0.8160 - val_loss: 0.5132 - val_accuracy: 0.7552\n",
            "Epoch 612/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4065 - accuracy: 0.8316 - val_loss: 0.5121 - val_accuracy: 0.7500\n",
            "Epoch 613/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4059 - accuracy: 0.8229 - val_loss: 0.5123 - val_accuracy: 0.7500\n",
            "Epoch 614/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4060 - accuracy: 0.8229 - val_loss: 0.5119 - val_accuracy: 0.7500\n",
            "Epoch 615/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4057 - accuracy: 0.8247 - val_loss: 0.5127 - val_accuracy: 0.7500\n",
            "Epoch 616/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4060 - accuracy: 0.8194 - val_loss: 0.5136 - val_accuracy: 0.7604\n",
            "Epoch 617/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4060 - accuracy: 0.8247 - val_loss: 0.5127 - val_accuracy: 0.7500\n",
            "Epoch 618/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4059 - accuracy: 0.8229 - val_loss: 0.5136 - val_accuracy: 0.7604\n",
            "Epoch 619/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4055 - accuracy: 0.8264 - val_loss: 0.5124 - val_accuracy: 0.7552\n",
            "Epoch 620/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4053 - accuracy: 0.8229 - val_loss: 0.5137 - val_accuracy: 0.7604\n",
            "Epoch 621/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4060 - accuracy: 0.8229 - val_loss: 0.5119 - val_accuracy: 0.7500\n",
            "Epoch 622/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4055 - accuracy: 0.8316 - val_loss: 0.5116 - val_accuracy: 0.7500\n",
            "Epoch 623/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4054 - accuracy: 0.8194 - val_loss: 0.5139 - val_accuracy: 0.7604\n",
            "Epoch 624/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4055 - accuracy: 0.8299 - val_loss: 0.5145 - val_accuracy: 0.7604\n",
            "Epoch 625/800\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4055 - accuracy: 0.8264 - val_loss: 0.5139 - val_accuracy: 0.7604\n",
            "Epoch 626/800\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4057 - accuracy: 0.8229 - val_loss: 0.5133 - val_accuracy: 0.7552\n",
            "Epoch 627/800\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4059 - accuracy: 0.8264 - val_loss: 0.5119 - val_accuracy: 0.7552\n",
            "Epoch 628/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4054 - accuracy: 0.8281 - val_loss: 0.5123 - val_accuracy: 0.7552\n",
            "Epoch 629/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4052 - accuracy: 0.8160 - val_loss: 0.5140 - val_accuracy: 0.7604\n",
            "Epoch 630/800\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4056 - accuracy: 0.8281 - val_loss: 0.5127 - val_accuracy: 0.7552\n",
            "Epoch 631/800\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4048 - accuracy: 0.8281 - val_loss: 0.5122 - val_accuracy: 0.7552\n",
            "Epoch 632/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4048 - accuracy: 0.8281 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
            "Epoch 633/800\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4052 - accuracy: 0.8264 - val_loss: 0.5129 - val_accuracy: 0.7552\n",
            "Epoch 634/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4049 - accuracy: 0.8299 - val_loss: 0.5133 - val_accuracy: 0.7552\n",
            "Epoch 635/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4051 - accuracy: 0.8247 - val_loss: 0.5129 - val_accuracy: 0.7552\n",
            "Epoch 636/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4049 - accuracy: 0.8333 - val_loss: 0.5121 - val_accuracy: 0.7500\n",
            "Epoch 637/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4051 - accuracy: 0.8316 - val_loss: 0.5120 - val_accuracy: 0.7604\n",
            "Epoch 638/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4051 - accuracy: 0.8247 - val_loss: 0.5141 - val_accuracy: 0.7604\n",
            "Epoch 639/800\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4048 - accuracy: 0.8316 - val_loss: 0.5131 - val_accuracy: 0.7552\n",
            "Epoch 640/800\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4052 - accuracy: 0.8281 - val_loss: 0.5130 - val_accuracy: 0.7552\n",
            "Epoch 641/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4050 - accuracy: 0.8299 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
            "Epoch 642/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4047 - accuracy: 0.8316 - val_loss: 0.5120 - val_accuracy: 0.7604\n",
            "Epoch 643/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4042 - accuracy: 0.8264 - val_loss: 0.5143 - val_accuracy: 0.7604\n",
            "Epoch 644/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4047 - accuracy: 0.8316 - val_loss: 0.5128 - val_accuracy: 0.7552\n",
            "Epoch 645/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4045 - accuracy: 0.8299 - val_loss: 0.5120 - val_accuracy: 0.7604\n",
            "Epoch 646/800\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4045 - accuracy: 0.8229 - val_loss: 0.5128 - val_accuracy: 0.7552\n",
            "Epoch 647/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4045 - accuracy: 0.8351 - val_loss: 0.5128 - val_accuracy: 0.7552\n",
            "Epoch 648/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4037 - accuracy: 0.8316 - val_loss: 0.5112 - val_accuracy: 0.7604\n",
            "Epoch 649/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4046 - accuracy: 0.8142 - val_loss: 0.5141 - val_accuracy: 0.7604\n",
            "Epoch 650/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4048 - accuracy: 0.8264 - val_loss: 0.5149 - val_accuracy: 0.7604\n",
            "Epoch 651/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4046 - accuracy: 0.8281 - val_loss: 0.5125 - val_accuracy: 0.7604\n",
            "Epoch 652/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4041 - accuracy: 0.8281 - val_loss: 0.5117 - val_accuracy: 0.7656\n",
            "Epoch 653/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4043 - accuracy: 0.8264 - val_loss: 0.5131 - val_accuracy: 0.7552\n",
            "Epoch 654/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4039 - accuracy: 0.8299 - val_loss: 0.5144 - val_accuracy: 0.7604\n",
            "Epoch 655/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4047 - accuracy: 0.8299 - val_loss: 0.5126 - val_accuracy: 0.7552\n",
            "Epoch 656/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4042 - accuracy: 0.8333 - val_loss: 0.5122 - val_accuracy: 0.7552\n",
            "Epoch 657/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4041 - accuracy: 0.8316 - val_loss: 0.5152 - val_accuracy: 0.7604\n",
            "Epoch 658/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4042 - accuracy: 0.8247 - val_loss: 0.5162 - val_accuracy: 0.7604\n",
            "Epoch 659/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4043 - accuracy: 0.8281 - val_loss: 0.5140 - val_accuracy: 0.7552\n",
            "Epoch 660/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4043 - accuracy: 0.8264 - val_loss: 0.5146 - val_accuracy: 0.7604\n",
            "Epoch 661/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4039 - accuracy: 0.8299 - val_loss: 0.5133 - val_accuracy: 0.7552\n",
            "Epoch 662/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4040 - accuracy: 0.8281 - val_loss: 0.5128 - val_accuracy: 0.7552\n",
            "Epoch 663/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4035 - accuracy: 0.8299 - val_loss: 0.5137 - val_accuracy: 0.7552\n",
            "Epoch 664/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4042 - accuracy: 0.8333 - val_loss: 0.5142 - val_accuracy: 0.7552\n",
            "Epoch 665/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4039 - accuracy: 0.8299 - val_loss: 0.5137 - val_accuracy: 0.7552\n",
            "Epoch 666/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4035 - accuracy: 0.8316 - val_loss: 0.5140 - val_accuracy: 0.7552\n",
            "Epoch 667/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4036 - accuracy: 0.8316 - val_loss: 0.5149 - val_accuracy: 0.7604\n",
            "Epoch 668/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4034 - accuracy: 0.8316 - val_loss: 0.5141 - val_accuracy: 0.7552\n",
            "Epoch 669/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4035 - accuracy: 0.8229 - val_loss: 0.5150 - val_accuracy: 0.7604\n",
            "Epoch 670/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4039 - accuracy: 0.8299 - val_loss: 0.5148 - val_accuracy: 0.7604\n",
            "Epoch 671/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4037 - accuracy: 0.8247 - val_loss: 0.5133 - val_accuracy: 0.7604\n",
            "Epoch 672/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4030 - accuracy: 0.8299 - val_loss: 0.5119 - val_accuracy: 0.7656\n",
            "Epoch 673/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4036 - accuracy: 0.8333 - val_loss: 0.5127 - val_accuracy: 0.7604\n",
            "Epoch 674/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4029 - accuracy: 0.8212 - val_loss: 0.5144 - val_accuracy: 0.7552\n",
            "Epoch 675/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4041 - accuracy: 0.8299 - val_loss: 0.5145 - val_accuracy: 0.7604\n",
            "Epoch 676/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4032 - accuracy: 0.8351 - val_loss: 0.5144 - val_accuracy: 0.7552\n",
            "Epoch 677/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4031 - accuracy: 0.8299 - val_loss: 0.5131 - val_accuracy: 0.7604\n",
            "Epoch 678/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4035 - accuracy: 0.8333 - val_loss: 0.5131 - val_accuracy: 0.7604\n",
            "Epoch 679/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4029 - accuracy: 0.8333 - val_loss: 0.5126 - val_accuracy: 0.7604\n",
            "Epoch 680/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4032 - accuracy: 0.8351 - val_loss: 0.5127 - val_accuracy: 0.7604\n",
            "Epoch 681/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4029 - accuracy: 0.8333 - val_loss: 0.5130 - val_accuracy: 0.7604\n",
            "Epoch 682/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4033 - accuracy: 0.8299 - val_loss: 0.5143 - val_accuracy: 0.7604\n",
            "Epoch 683/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4040 - accuracy: 0.8316 - val_loss: 0.5137 - val_accuracy: 0.7552\n",
            "Epoch 684/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4032 - accuracy: 0.8281 - val_loss: 0.5140 - val_accuracy: 0.7552\n",
            "Epoch 685/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4025 - accuracy: 0.8281 - val_loss: 0.5161 - val_accuracy: 0.7604\n",
            "Epoch 686/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4029 - accuracy: 0.8281 - val_loss: 0.5154 - val_accuracy: 0.7604\n",
            "Epoch 687/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4029 - accuracy: 0.8281 - val_loss: 0.5134 - val_accuracy: 0.7552\n",
            "Epoch 688/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4028 - accuracy: 0.8281 - val_loss: 0.5125 - val_accuracy: 0.7656\n",
            "Epoch 689/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4028 - accuracy: 0.8299 - val_loss: 0.5125 - val_accuracy: 0.7656\n",
            "Epoch 690/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4033 - accuracy: 0.8299 - val_loss: 0.5125 - val_accuracy: 0.7656\n",
            "Epoch 691/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4031 - accuracy: 0.8264 - val_loss: 0.5123 - val_accuracy: 0.7656\n",
            "Epoch 692/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4029 - accuracy: 0.8316 - val_loss: 0.5128 - val_accuracy: 0.7604\n",
            "Epoch 693/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4030 - accuracy: 0.8316 - val_loss: 0.5130 - val_accuracy: 0.7604\n",
            "Epoch 694/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4022 - accuracy: 0.8264 - val_loss: 0.5143 - val_accuracy: 0.7552\n",
            "Epoch 695/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4026 - accuracy: 0.8264 - val_loss: 0.5141 - val_accuracy: 0.7552\n",
            "Epoch 696/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4021 - accuracy: 0.8316 - val_loss: 0.5144 - val_accuracy: 0.7552\n",
            "Epoch 697/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4028 - accuracy: 0.8264 - val_loss: 0.5141 - val_accuracy: 0.7552\n",
            "Epoch 698/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4025 - accuracy: 0.8299 - val_loss: 0.5138 - val_accuracy: 0.7604\n",
            "Epoch 699/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4023 - accuracy: 0.8281 - val_loss: 0.5137 - val_accuracy: 0.7604\n",
            "Epoch 700/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4019 - accuracy: 0.8281 - val_loss: 0.5139 - val_accuracy: 0.7552\n",
            "Epoch 701/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4023 - accuracy: 0.8316 - val_loss: 0.5150 - val_accuracy: 0.7604\n",
            "Epoch 702/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4025 - accuracy: 0.8247 - val_loss: 0.5127 - val_accuracy: 0.7604\n",
            "Epoch 703/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4017 - accuracy: 0.8316 - val_loss: 0.5116 - val_accuracy: 0.7760\n",
            "Epoch 704/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4023 - accuracy: 0.8316 - val_loss: 0.5124 - val_accuracy: 0.7708\n",
            "Epoch 705/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4019 - accuracy: 0.8299 - val_loss: 0.5134 - val_accuracy: 0.7604\n",
            "Epoch 706/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4019 - accuracy: 0.8299 - val_loss: 0.5132 - val_accuracy: 0.7604\n",
            "Epoch 707/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4017 - accuracy: 0.8212 - val_loss: 0.5149 - val_accuracy: 0.7552\n",
            "Epoch 708/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4025 - accuracy: 0.8316 - val_loss: 0.5126 - val_accuracy: 0.7604\n",
            "Epoch 709/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4021 - accuracy: 0.8299 - val_loss: 0.5145 - val_accuracy: 0.7552\n",
            "Epoch 710/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4017 - accuracy: 0.8333 - val_loss: 0.5155 - val_accuracy: 0.7604\n",
            "Epoch 711/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4019 - accuracy: 0.8247 - val_loss: 0.5134 - val_accuracy: 0.7604\n",
            "Epoch 712/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4014 - accuracy: 0.8281 - val_loss: 0.5136 - val_accuracy: 0.7604\n",
            "Epoch 713/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4020 - accuracy: 0.8247 - val_loss: 0.5136 - val_accuracy: 0.7604\n",
            "Epoch 714/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4015 - accuracy: 0.8281 - val_loss: 0.5143 - val_accuracy: 0.7552\n",
            "Epoch 715/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4014 - accuracy: 0.8281 - val_loss: 0.5128 - val_accuracy: 0.7708\n",
            "Epoch 716/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4014 - accuracy: 0.8247 - val_loss: 0.5138 - val_accuracy: 0.7604\n",
            "Epoch 717/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4019 - accuracy: 0.8316 - val_loss: 0.5138 - val_accuracy: 0.7604\n",
            "Epoch 718/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4014 - accuracy: 0.8281 - val_loss: 0.5134 - val_accuracy: 0.7604\n",
            "Epoch 719/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4013 - accuracy: 0.8299 - val_loss: 0.5127 - val_accuracy: 0.7708\n",
            "Epoch 720/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4016 - accuracy: 0.8316 - val_loss: 0.5137 - val_accuracy: 0.7604\n",
            "Epoch 721/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4015 - accuracy: 0.8316 - val_loss: 0.5130 - val_accuracy: 0.7656\n",
            "Epoch 722/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4013 - accuracy: 0.8247 - val_loss: 0.5148 - val_accuracy: 0.7552\n",
            "Epoch 723/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4009 - accuracy: 0.8281 - val_loss: 0.5127 - val_accuracy: 0.7708\n",
            "Epoch 724/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4016 - accuracy: 0.8247 - val_loss: 0.5145 - val_accuracy: 0.7656\n",
            "Epoch 725/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4009 - accuracy: 0.8299 - val_loss: 0.5141 - val_accuracy: 0.7604\n",
            "Epoch 726/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4011 - accuracy: 0.8264 - val_loss: 0.5145 - val_accuracy: 0.7656\n",
            "Epoch 727/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4016 - accuracy: 0.8281 - val_loss: 0.5137 - val_accuracy: 0.7656\n",
            "Epoch 728/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4013 - accuracy: 0.8281 - val_loss: 0.5131 - val_accuracy: 0.7708\n",
            "Epoch 729/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4011 - accuracy: 0.8316 - val_loss: 0.5137 - val_accuracy: 0.7656\n",
            "Epoch 730/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4008 - accuracy: 0.8299 - val_loss: 0.5138 - val_accuracy: 0.7656\n",
            "Epoch 731/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4013 - accuracy: 0.8264 - val_loss: 0.5140 - val_accuracy: 0.7656\n",
            "Epoch 732/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4009 - accuracy: 0.8299 - val_loss: 0.5133 - val_accuracy: 0.7656\n",
            "Epoch 733/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4009 - accuracy: 0.8316 - val_loss: 0.5140 - val_accuracy: 0.7656\n",
            "Epoch 734/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4009 - accuracy: 0.8281 - val_loss: 0.5136 - val_accuracy: 0.7656\n",
            "Epoch 735/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4009 - accuracy: 0.8281 - val_loss: 0.5146 - val_accuracy: 0.7604\n",
            "Epoch 736/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3999 - accuracy: 0.8212 - val_loss: 0.5172 - val_accuracy: 0.7604\n",
            "Epoch 737/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4008 - accuracy: 0.8316 - val_loss: 0.5138 - val_accuracy: 0.7656\n",
            "Epoch 738/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4000 - accuracy: 0.8299 - val_loss: 0.5139 - val_accuracy: 0.7656\n",
            "Epoch 739/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4001 - accuracy: 0.8316 - val_loss: 0.5134 - val_accuracy: 0.7656\n",
            "Epoch 740/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4006 - accuracy: 0.8281 - val_loss: 0.5142 - val_accuracy: 0.7656\n",
            "Epoch 741/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4000 - accuracy: 0.8247 - val_loss: 0.5143 - val_accuracy: 0.7656\n",
            "Epoch 742/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3998 - accuracy: 0.8281 - val_loss: 0.5124 - val_accuracy: 0.7708\n",
            "Epoch 743/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4002 - accuracy: 0.8264 - val_loss: 0.5134 - val_accuracy: 0.7656\n",
            "Epoch 744/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4000 - accuracy: 0.8316 - val_loss: 0.5141 - val_accuracy: 0.7656\n",
            "Epoch 745/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4003 - accuracy: 0.8299 - val_loss: 0.5131 - val_accuracy: 0.7656\n",
            "Epoch 746/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4005 - accuracy: 0.8281 - val_loss: 0.5140 - val_accuracy: 0.7656\n",
            "Epoch 747/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3998 - accuracy: 0.8299 - val_loss: 0.5140 - val_accuracy: 0.7656\n",
            "Epoch 748/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3997 - accuracy: 0.8264 - val_loss: 0.5143 - val_accuracy: 0.7656\n",
            "Epoch 749/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3997 - accuracy: 0.8299 - val_loss: 0.5160 - val_accuracy: 0.7656\n",
            "Epoch 750/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3995 - accuracy: 0.8299 - val_loss: 0.5134 - val_accuracy: 0.7656\n",
            "Epoch 751/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4004 - accuracy: 0.8316 - val_loss: 0.5136 - val_accuracy: 0.7656\n",
            "Epoch 752/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3998 - accuracy: 0.8281 - val_loss: 0.5132 - val_accuracy: 0.7656\n",
            "Epoch 753/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3996 - accuracy: 0.8299 - val_loss: 0.5132 - val_accuracy: 0.7656\n",
            "Epoch 754/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4001 - accuracy: 0.8247 - val_loss: 0.5139 - val_accuracy: 0.7708\n",
            "Epoch 755/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3995 - accuracy: 0.8299 - val_loss: 0.5137 - val_accuracy: 0.7708\n",
            "Epoch 756/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3999 - accuracy: 0.8299 - val_loss: 0.5116 - val_accuracy: 0.7760\n",
            "Epoch 757/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3999 - accuracy: 0.8281 - val_loss: 0.5132 - val_accuracy: 0.7708\n",
            "Epoch 758/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3995 - accuracy: 0.8281 - val_loss: 0.5129 - val_accuracy: 0.7708\n",
            "Epoch 759/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3997 - accuracy: 0.8316 - val_loss: 0.5130 - val_accuracy: 0.7708\n",
            "Epoch 760/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3995 - accuracy: 0.8333 - val_loss: 0.5129 - val_accuracy: 0.7760\n",
            "Epoch 761/800\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3997 - accuracy: 0.8316 - val_loss: 0.5121 - val_accuracy: 0.7708\n",
            "Epoch 762/800\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3987 - accuracy: 0.8299 - val_loss: 0.5138 - val_accuracy: 0.7708\n",
            "Epoch 763/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3995 - accuracy: 0.8281 - val_loss: 0.5129 - val_accuracy: 0.7708\n",
            "Epoch 764/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3992 - accuracy: 0.8299 - val_loss: 0.5147 - val_accuracy: 0.7708\n",
            "Epoch 765/800\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3998 - accuracy: 0.8281 - val_loss: 0.5142 - val_accuracy: 0.7708\n",
            "Epoch 766/800\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3989 - accuracy: 0.8281 - val_loss: 0.5124 - val_accuracy: 0.7760\n",
            "Epoch 767/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3989 - accuracy: 0.8316 - val_loss: 0.5131 - val_accuracy: 0.7708\n",
            "Epoch 768/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3996 - accuracy: 0.8281 - val_loss: 0.5136 - val_accuracy: 0.7708\n",
            "Epoch 769/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3995 - accuracy: 0.8281 - val_loss: 0.5128 - val_accuracy: 0.7708\n",
            "Epoch 770/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3995 - accuracy: 0.8316 - val_loss: 0.5121 - val_accuracy: 0.7760\n",
            "Epoch 771/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3987 - accuracy: 0.8281 - val_loss: 0.5134 - val_accuracy: 0.7656\n",
            "Epoch 772/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3991 - accuracy: 0.8229 - val_loss: 0.5148 - val_accuracy: 0.7708\n",
            "Epoch 773/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3989 - accuracy: 0.8299 - val_loss: 0.5125 - val_accuracy: 0.7760\n",
            "Epoch 774/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3986 - accuracy: 0.8316 - val_loss: 0.5118 - val_accuracy: 0.7760\n",
            "Epoch 775/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3982 - accuracy: 0.8212 - val_loss: 0.5138 - val_accuracy: 0.7656\n",
            "Epoch 776/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3985 - accuracy: 0.8264 - val_loss: 0.5121 - val_accuracy: 0.7760\n",
            "Epoch 777/800\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3982 - accuracy: 0.8316 - val_loss: 0.5130 - val_accuracy: 0.7708\n",
            "Epoch 778/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3986 - accuracy: 0.8299 - val_loss: 0.5126 - val_accuracy: 0.7760\n",
            "Epoch 779/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3983 - accuracy: 0.8229 - val_loss: 0.5129 - val_accuracy: 0.7708\n",
            "Epoch 780/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3982 - accuracy: 0.8281 - val_loss: 0.5118 - val_accuracy: 0.7760\n",
            "Epoch 781/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3984 - accuracy: 0.8281 - val_loss: 0.5126 - val_accuracy: 0.7708\n",
            "Epoch 782/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3979 - accuracy: 0.8264 - val_loss: 0.5132 - val_accuracy: 0.7656\n",
            "Epoch 783/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3978 - accuracy: 0.8264 - val_loss: 0.5148 - val_accuracy: 0.7708\n",
            "Epoch 784/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3980 - accuracy: 0.8229 - val_loss: 0.5121 - val_accuracy: 0.7760\n",
            "Epoch 785/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3984 - accuracy: 0.8247 - val_loss: 0.5140 - val_accuracy: 0.7656\n",
            "Epoch 786/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3980 - accuracy: 0.8281 - val_loss: 0.5118 - val_accuracy: 0.7760\n",
            "Epoch 787/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3976 - accuracy: 0.8281 - val_loss: 0.5120 - val_accuracy: 0.7760\n",
            "Epoch 788/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3977 - accuracy: 0.8299 - val_loss: 0.5135 - val_accuracy: 0.7656\n",
            "Epoch 789/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3977 - accuracy: 0.8229 - val_loss: 0.5127 - val_accuracy: 0.7708\n",
            "Epoch 790/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3975 - accuracy: 0.8247 - val_loss: 0.5134 - val_accuracy: 0.7708\n",
            "Epoch 791/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3985 - accuracy: 0.8264 - val_loss: 0.5117 - val_accuracy: 0.7760\n",
            "Epoch 792/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3982 - accuracy: 0.8247 - val_loss: 0.5130 - val_accuracy: 0.7708\n",
            "Epoch 793/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3973 - accuracy: 0.8281 - val_loss: 0.5135 - val_accuracy: 0.7656\n",
            "Epoch 794/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3978 - accuracy: 0.8264 - val_loss: 0.5133 - val_accuracy: 0.7708\n",
            "Epoch 795/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3979 - accuracy: 0.8351 - val_loss: 0.5132 - val_accuracy: 0.7708\n",
            "Epoch 796/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3980 - accuracy: 0.8264 - val_loss: 0.5130 - val_accuracy: 0.7708\n",
            "Epoch 797/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3972 - accuracy: 0.8194 - val_loss: 0.5142 - val_accuracy: 0.7708\n",
            "Epoch 798/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3975 - accuracy: 0.8212 - val_loss: 0.5121 - val_accuracy: 0.7760\n",
            "Epoch 799/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3977 - accuracy: 0.8264 - val_loss: 0.5132 - val_accuracy: 0.7708\n",
            "Epoch 800/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3974 - accuracy: 0.8299 - val_loss: 0.5121 - val_accuracy: 0.7760\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analysis:"
      ],
      "metadata": {
        "id": "Xb6IDlMBChQU"
      },
      "id": "Xb6IDlMBChQU"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Different Epochs"
      ],
      "metadata": {
        "id": "gxmEgBUDCb2c"
      },
      "id": "gxmEgBUDCb2c"
    },
    {
      "cell_type": "code",
      "source": [
        "#Model with two hidden layers each having 6 nodes\n",
        "model_4 = Sequential([\n",
        "    #Layer 1\n",
        "    Dense(4, input_shape=(8,),activation=\"relu\"),\n",
        "\n",
        "    #Layer 2\n",
        "    Dense(10,activation=\"relu\"),\n",
        "\n",
        "    #Output/Final Layer\n",
        "    Dense(1,activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "model_4.compile(SGD(lr = .5), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "run_hist_5 = model_4.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glqkvbzoCGcM",
        "outputId": "f6a223bf-bc82-4edf-d957-c2b698b99b84"
      },
      "id": "glqkvbzoCGcM",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "18/18 [==============================] - 1s 13ms/step - loss: 0.8195 - accuracy: 0.3472 - val_loss: 0.8341 - val_accuracy: 0.3490\n",
            "Epoch 2/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7797 - accuracy: 0.3802 - val_loss: 0.7962 - val_accuracy: 0.3802\n",
            "Epoch 3/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7506 - accuracy: 0.4149 - val_loss: 0.7681 - val_accuracy: 0.3490\n",
            "Epoch 4/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7288 - accuracy: 0.4531 - val_loss: 0.7466 - val_accuracy: 0.4010\n",
            "Epoch 5/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7121 - accuracy: 0.4878 - val_loss: 0.7301 - val_accuracy: 0.4115\n",
            "Epoch 6/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6992 - accuracy: 0.5382 - val_loss: 0.7173 - val_accuracy: 0.4375\n",
            "Epoch 7/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6890 - accuracy: 0.5573 - val_loss: 0.7071 - val_accuracy: 0.5052\n",
            "Epoch 8/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6807 - accuracy: 0.5938 - val_loss: 0.6991 - val_accuracy: 0.5156\n",
            "Epoch 9/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6740 - accuracy: 0.6128 - val_loss: 0.6926 - val_accuracy: 0.5365\n",
            "Epoch 10/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6687 - accuracy: 0.6267 - val_loss: 0.6874 - val_accuracy: 0.5625\n",
            "Epoch 11/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6641 - accuracy: 0.6233 - val_loss: 0.6832 - val_accuracy: 0.5990\n",
            "Epoch 12/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6604 - accuracy: 0.6337 - val_loss: 0.6798 - val_accuracy: 0.6146\n",
            "Epoch 13/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6573 - accuracy: 0.6476 - val_loss: 0.6770 - val_accuracy: 0.6354\n",
            "Epoch 14/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6546 - accuracy: 0.6476 - val_loss: 0.6746 - val_accuracy: 0.6510\n",
            "Epoch 15/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6524 - accuracy: 0.6441 - val_loss: 0.6727 - val_accuracy: 0.6562\n",
            "Epoch 16/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6503 - accuracy: 0.6510 - val_loss: 0.6709 - val_accuracy: 0.6510\n",
            "Epoch 17/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6485 - accuracy: 0.6597 - val_loss: 0.6694 - val_accuracy: 0.6562\n",
            "Epoch 18/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6468 - accuracy: 0.6597 - val_loss: 0.6681 - val_accuracy: 0.6562\n",
            "Epoch 19/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6453 - accuracy: 0.6615 - val_loss: 0.6668 - val_accuracy: 0.6562\n",
            "Epoch 20/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6438 - accuracy: 0.6632 - val_loss: 0.6657 - val_accuracy: 0.6562\n",
            "Epoch 21/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6425 - accuracy: 0.6649 - val_loss: 0.6647 - val_accuracy: 0.6562\n",
            "Epoch 22/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6412 - accuracy: 0.6649 - val_loss: 0.6638 - val_accuracy: 0.6510\n",
            "Epoch 23/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6400 - accuracy: 0.6632 - val_loss: 0.6629 - val_accuracy: 0.6510\n",
            "Epoch 24/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6389 - accuracy: 0.6632 - val_loss: 0.6621 - val_accuracy: 0.6510\n",
            "Epoch 25/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6377 - accuracy: 0.6615 - val_loss: 0.6613 - val_accuracy: 0.6510\n",
            "Epoch 26/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6367 - accuracy: 0.6632 - val_loss: 0.6605 - val_accuracy: 0.6510\n",
            "Epoch 27/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6355 - accuracy: 0.6649 - val_loss: 0.6598 - val_accuracy: 0.6510\n",
            "Epoch 28/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6344 - accuracy: 0.6649 - val_loss: 0.6591 - val_accuracy: 0.6510\n",
            "Epoch 29/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6334 - accuracy: 0.6649 - val_loss: 0.6584 - val_accuracy: 0.6510\n",
            "Epoch 30/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6323 - accuracy: 0.6649 - val_loss: 0.6577 - val_accuracy: 0.6458\n",
            "Epoch 31/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6313 - accuracy: 0.6649 - val_loss: 0.6571 - val_accuracy: 0.6458\n",
            "Epoch 32/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6304 - accuracy: 0.6632 - val_loss: 0.6564 - val_accuracy: 0.6458\n",
            "Epoch 33/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6292 - accuracy: 0.6649 - val_loss: 0.6557 - val_accuracy: 0.6458\n",
            "Epoch 34/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6282 - accuracy: 0.6649 - val_loss: 0.6550 - val_accuracy: 0.6458\n",
            "Epoch 35/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6271 - accuracy: 0.6632 - val_loss: 0.6543 - val_accuracy: 0.6458\n",
            "Epoch 36/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6260 - accuracy: 0.6649 - val_loss: 0.6536 - val_accuracy: 0.6458\n",
            "Epoch 37/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6250 - accuracy: 0.6649 - val_loss: 0.6528 - val_accuracy: 0.6458\n",
            "Epoch 38/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6237 - accuracy: 0.6667 - val_loss: 0.6520 - val_accuracy: 0.6458\n",
            "Epoch 39/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6225 - accuracy: 0.6667 - val_loss: 0.6512 - val_accuracy: 0.6458\n",
            "Epoch 40/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6212 - accuracy: 0.6667 - val_loss: 0.6503 - val_accuracy: 0.6458\n",
            "Epoch 41/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6198 - accuracy: 0.6667 - val_loss: 0.6494 - val_accuracy: 0.6458\n",
            "Epoch 42/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6184 - accuracy: 0.6667 - val_loss: 0.6484 - val_accuracy: 0.6458\n",
            "Epoch 43/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6170 - accuracy: 0.6667 - val_loss: 0.6474 - val_accuracy: 0.6458\n",
            "Epoch 44/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6155 - accuracy: 0.6649 - val_loss: 0.6462 - val_accuracy: 0.6458\n",
            "Epoch 45/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6139 - accuracy: 0.6649 - val_loss: 0.6450 - val_accuracy: 0.6510\n",
            "Epoch 46/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6125 - accuracy: 0.6667 - val_loss: 0.6436 - val_accuracy: 0.6510\n",
            "Epoch 47/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6108 - accuracy: 0.6667 - val_loss: 0.6422 - val_accuracy: 0.6510\n",
            "Epoch 48/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6092 - accuracy: 0.6684 - val_loss: 0.6407 - val_accuracy: 0.6510\n",
            "Epoch 49/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6074 - accuracy: 0.6667 - val_loss: 0.6393 - val_accuracy: 0.6510\n",
            "Epoch 50/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6056 - accuracy: 0.6667 - val_loss: 0.6377 - val_accuracy: 0.6510\n",
            "Epoch 51/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6037 - accuracy: 0.6684 - val_loss: 0.6362 - val_accuracy: 0.6510\n",
            "Epoch 52/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6017 - accuracy: 0.6684 - val_loss: 0.6345 - val_accuracy: 0.6458\n",
            "Epoch 53/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5997 - accuracy: 0.6701 - val_loss: 0.6329 - val_accuracy: 0.6406\n",
            "Epoch 54/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5976 - accuracy: 0.6719 - val_loss: 0.6312 - val_accuracy: 0.6406\n",
            "Epoch 55/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5955 - accuracy: 0.6736 - val_loss: 0.6295 - val_accuracy: 0.6406\n",
            "Epoch 56/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5933 - accuracy: 0.6736 - val_loss: 0.6277 - val_accuracy: 0.6406\n",
            "Epoch 57/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5911 - accuracy: 0.6771 - val_loss: 0.6259 - val_accuracy: 0.6406\n",
            "Epoch 58/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5888 - accuracy: 0.6736 - val_loss: 0.6241 - val_accuracy: 0.6406\n",
            "Epoch 59/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5864 - accuracy: 0.6788 - val_loss: 0.6221 - val_accuracy: 0.6406\n",
            "Epoch 60/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5840 - accuracy: 0.6806 - val_loss: 0.6201 - val_accuracy: 0.6406\n",
            "Epoch 61/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5815 - accuracy: 0.6806 - val_loss: 0.6180 - val_accuracy: 0.6406\n",
            "Epoch 62/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5790 - accuracy: 0.6823 - val_loss: 0.6160 - val_accuracy: 0.6406\n",
            "Epoch 63/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5765 - accuracy: 0.6840 - val_loss: 0.6139 - val_accuracy: 0.6458\n",
            "Epoch 64/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5740 - accuracy: 0.6840 - val_loss: 0.6118 - val_accuracy: 0.6354\n",
            "Epoch 65/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5716 - accuracy: 0.6875 - val_loss: 0.6097 - val_accuracy: 0.6354\n",
            "Epoch 66/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5690 - accuracy: 0.6875 - val_loss: 0.6075 - val_accuracy: 0.6354\n",
            "Epoch 67/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5665 - accuracy: 0.6823 - val_loss: 0.6054 - val_accuracy: 0.6354\n",
            "Epoch 68/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.5639 - accuracy: 0.6875 - val_loss: 0.6032 - val_accuracy: 0.6354\n",
            "Epoch 69/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.5613 - accuracy: 0.6892 - val_loss: 0.6010 - val_accuracy: 0.6354\n",
            "Epoch 70/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5586 - accuracy: 0.6858 - val_loss: 0.5987 - val_accuracy: 0.6302\n",
            "Epoch 71/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5559 - accuracy: 0.6892 - val_loss: 0.5965 - val_accuracy: 0.6302\n",
            "Epoch 72/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5533 - accuracy: 0.6875 - val_loss: 0.5943 - val_accuracy: 0.6354\n",
            "Epoch 73/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5507 - accuracy: 0.6858 - val_loss: 0.5922 - val_accuracy: 0.6354\n",
            "Epoch 74/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5481 - accuracy: 0.6910 - val_loss: 0.5900 - val_accuracy: 0.6302\n",
            "Epoch 75/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5454 - accuracy: 0.6892 - val_loss: 0.5879 - val_accuracy: 0.6302\n",
            "Epoch 76/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5429 - accuracy: 0.6927 - val_loss: 0.5858 - val_accuracy: 0.6302\n",
            "Epoch 77/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5405 - accuracy: 0.6910 - val_loss: 0.5838 - val_accuracy: 0.6354\n",
            "Epoch 78/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5381 - accuracy: 0.6910 - val_loss: 0.5818 - val_accuracy: 0.6354\n",
            "Epoch 79/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5356 - accuracy: 0.6910 - val_loss: 0.5798 - val_accuracy: 0.6354\n",
            "Epoch 80/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5333 - accuracy: 0.6892 - val_loss: 0.5777 - val_accuracy: 0.6354\n",
            "Epoch 81/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5310 - accuracy: 0.6892 - val_loss: 0.5757 - val_accuracy: 0.6354\n",
            "Epoch 82/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5287 - accuracy: 0.6944 - val_loss: 0.5737 - val_accuracy: 0.6458\n",
            "Epoch 83/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5266 - accuracy: 0.6927 - val_loss: 0.5717 - val_accuracy: 0.6562\n",
            "Epoch 84/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5244 - accuracy: 0.6927 - val_loss: 0.5698 - val_accuracy: 0.6562\n",
            "Epoch 85/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5224 - accuracy: 0.6979 - val_loss: 0.5680 - val_accuracy: 0.6667\n",
            "Epoch 86/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5205 - accuracy: 0.7014 - val_loss: 0.5663 - val_accuracy: 0.6667\n",
            "Epoch 87/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5187 - accuracy: 0.7014 - val_loss: 0.5647 - val_accuracy: 0.6667\n",
            "Epoch 88/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5169 - accuracy: 0.7066 - val_loss: 0.5630 - val_accuracy: 0.6667\n",
            "Epoch 89/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5152 - accuracy: 0.7066 - val_loss: 0.5615 - val_accuracy: 0.6667\n",
            "Epoch 90/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5134 - accuracy: 0.7066 - val_loss: 0.5601 - val_accuracy: 0.6719\n",
            "Epoch 91/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5120 - accuracy: 0.7101 - val_loss: 0.5589 - val_accuracy: 0.6771\n",
            "Epoch 92/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5105 - accuracy: 0.7101 - val_loss: 0.5577 - val_accuracy: 0.6875\n",
            "Epoch 93/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5090 - accuracy: 0.7118 - val_loss: 0.5565 - val_accuracy: 0.6927\n",
            "Epoch 94/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5076 - accuracy: 0.7118 - val_loss: 0.5554 - val_accuracy: 0.7031\n",
            "Epoch 95/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5062 - accuracy: 0.7118 - val_loss: 0.5543 - val_accuracy: 0.7031\n",
            "Epoch 96/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5048 - accuracy: 0.7170 - val_loss: 0.5533 - val_accuracy: 0.7031\n",
            "Epoch 97/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5037 - accuracy: 0.7153 - val_loss: 0.5524 - val_accuracy: 0.7031\n",
            "Epoch 98/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5023 - accuracy: 0.7153 - val_loss: 0.5515 - val_accuracy: 0.7031\n",
            "Epoch 99/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5011 - accuracy: 0.7240 - val_loss: 0.5507 - val_accuracy: 0.7031\n",
            "Epoch 100/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5000 - accuracy: 0.7205 - val_loss: 0.5500 - val_accuracy: 0.7083\n",
            "Epoch 101/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4990 - accuracy: 0.7222 - val_loss: 0.5493 - val_accuracy: 0.7135\n",
            "Epoch 102/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4980 - accuracy: 0.7240 - val_loss: 0.5487 - val_accuracy: 0.7188\n",
            "Epoch 103/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4969 - accuracy: 0.7292 - val_loss: 0.5481 - val_accuracy: 0.7188\n",
            "Epoch 104/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4960 - accuracy: 0.7292 - val_loss: 0.5476 - val_accuracy: 0.7188\n",
            "Epoch 105/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4950 - accuracy: 0.7326 - val_loss: 0.5471 - val_accuracy: 0.7188\n",
            "Epoch 106/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4941 - accuracy: 0.7274 - val_loss: 0.5466 - val_accuracy: 0.7292\n",
            "Epoch 107/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4932 - accuracy: 0.7240 - val_loss: 0.5462 - val_accuracy: 0.7292\n",
            "Epoch 108/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4923 - accuracy: 0.7257 - val_loss: 0.5458 - val_accuracy: 0.7344\n",
            "Epoch 109/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4915 - accuracy: 0.7222 - val_loss: 0.5454 - val_accuracy: 0.7344\n",
            "Epoch 110/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4906 - accuracy: 0.7222 - val_loss: 0.5450 - val_accuracy: 0.7292\n",
            "Epoch 111/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4899 - accuracy: 0.7240 - val_loss: 0.5446 - val_accuracy: 0.7292\n",
            "Epoch 112/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4890 - accuracy: 0.7240 - val_loss: 0.5442 - val_accuracy: 0.7396\n",
            "Epoch 113/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4883 - accuracy: 0.7222 - val_loss: 0.5440 - val_accuracy: 0.7448\n",
            "Epoch 114/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4876 - accuracy: 0.7205 - val_loss: 0.5437 - val_accuracy: 0.7448\n",
            "Epoch 115/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4870 - accuracy: 0.7170 - val_loss: 0.5435 - val_accuracy: 0.7396\n",
            "Epoch 116/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4863 - accuracy: 0.7188 - val_loss: 0.5432 - val_accuracy: 0.7396\n",
            "Epoch 117/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4858 - accuracy: 0.7188 - val_loss: 0.5431 - val_accuracy: 0.7396\n",
            "Epoch 118/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4852 - accuracy: 0.7205 - val_loss: 0.5429 - val_accuracy: 0.7448\n",
            "Epoch 119/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4846 - accuracy: 0.7188 - val_loss: 0.5427 - val_accuracy: 0.7448\n",
            "Epoch 120/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4840 - accuracy: 0.7205 - val_loss: 0.5426 - val_accuracy: 0.7396\n",
            "Epoch 121/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4835 - accuracy: 0.7222 - val_loss: 0.5424 - val_accuracy: 0.7396\n",
            "Epoch 122/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4829 - accuracy: 0.7274 - val_loss: 0.5422 - val_accuracy: 0.7344\n",
            "Epoch 123/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4823 - accuracy: 0.7309 - val_loss: 0.5421 - val_accuracy: 0.7344\n",
            "Epoch 124/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4819 - accuracy: 0.7361 - val_loss: 0.5420 - val_accuracy: 0.7552\n",
            "Epoch 125/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4813 - accuracy: 0.7569 - val_loss: 0.5419 - val_accuracy: 0.7552\n",
            "Epoch 126/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4808 - accuracy: 0.7587 - val_loss: 0.5418 - val_accuracy: 0.7500\n",
            "Epoch 127/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4802 - accuracy: 0.7569 - val_loss: 0.5417 - val_accuracy: 0.7500\n",
            "Epoch 128/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4797 - accuracy: 0.7569 - val_loss: 0.5416 - val_accuracy: 0.7500\n",
            "Epoch 129/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4791 - accuracy: 0.7569 - val_loss: 0.5415 - val_accuracy: 0.7500\n",
            "Epoch 130/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4785 - accuracy: 0.7517 - val_loss: 0.5414 - val_accuracy: 0.7500\n",
            "Epoch 131/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4781 - accuracy: 0.7569 - val_loss: 0.5413 - val_accuracy: 0.7500\n",
            "Epoch 132/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4777 - accuracy: 0.7552 - val_loss: 0.5412 - val_accuracy: 0.7500\n",
            "Epoch 133/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4772 - accuracy: 0.7535 - val_loss: 0.5412 - val_accuracy: 0.7500\n",
            "Epoch 134/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4768 - accuracy: 0.7535 - val_loss: 0.5411 - val_accuracy: 0.7500\n",
            "Epoch 135/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4764 - accuracy: 0.7569 - val_loss: 0.5411 - val_accuracy: 0.7500\n",
            "Epoch 136/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4761 - accuracy: 0.7587 - val_loss: 0.5412 - val_accuracy: 0.7500\n",
            "Epoch 137/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4757 - accuracy: 0.7535 - val_loss: 0.5412 - val_accuracy: 0.7448\n",
            "Epoch 138/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4753 - accuracy: 0.7569 - val_loss: 0.5414 - val_accuracy: 0.7396\n",
            "Epoch 139/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4749 - accuracy: 0.7552 - val_loss: 0.5415 - val_accuracy: 0.7396\n",
            "Epoch 140/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4745 - accuracy: 0.7587 - val_loss: 0.5415 - val_accuracy: 0.7396\n",
            "Epoch 141/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4743 - accuracy: 0.7535 - val_loss: 0.5416 - val_accuracy: 0.7396\n",
            "Epoch 142/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4738 - accuracy: 0.7569 - val_loss: 0.5418 - val_accuracy: 0.7344\n",
            "Epoch 143/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4736 - accuracy: 0.7552 - val_loss: 0.5418 - val_accuracy: 0.7344\n",
            "Epoch 144/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4733 - accuracy: 0.7587 - val_loss: 0.5419 - val_accuracy: 0.7396\n",
            "Epoch 145/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4730 - accuracy: 0.7587 - val_loss: 0.5420 - val_accuracy: 0.7396\n",
            "Epoch 146/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4727 - accuracy: 0.7587 - val_loss: 0.5421 - val_accuracy: 0.7396\n",
            "Epoch 147/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4723 - accuracy: 0.7604 - val_loss: 0.5421 - val_accuracy: 0.7344\n",
            "Epoch 148/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4722 - accuracy: 0.7569 - val_loss: 0.5423 - val_accuracy: 0.7344\n",
            "Epoch 149/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4718 - accuracy: 0.7587 - val_loss: 0.5424 - val_accuracy: 0.7344\n",
            "Epoch 150/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4715 - accuracy: 0.7587 - val_loss: 0.5425 - val_accuracy: 0.7344\n",
            "Epoch 151/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4713 - accuracy: 0.7552 - val_loss: 0.5426 - val_accuracy: 0.7344\n",
            "Epoch 152/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4712 - accuracy: 0.7569 - val_loss: 0.5427 - val_accuracy: 0.7344\n",
            "Epoch 153/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4709 - accuracy: 0.7569 - val_loss: 0.5427 - val_accuracy: 0.7344\n",
            "Epoch 154/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4706 - accuracy: 0.7552 - val_loss: 0.5428 - val_accuracy: 0.7344\n",
            "Epoch 155/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4703 - accuracy: 0.7587 - val_loss: 0.5429 - val_accuracy: 0.7344\n",
            "Epoch 156/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4701 - accuracy: 0.7604 - val_loss: 0.5429 - val_accuracy: 0.7344\n",
            "Epoch 157/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4699 - accuracy: 0.7622 - val_loss: 0.5430 - val_accuracy: 0.7344\n",
            "Epoch 158/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4697 - accuracy: 0.7622 - val_loss: 0.5431 - val_accuracy: 0.7344\n",
            "Epoch 159/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4695 - accuracy: 0.7622 - val_loss: 0.5431 - val_accuracy: 0.7344\n",
            "Epoch 160/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4694 - accuracy: 0.7604 - val_loss: 0.5432 - val_accuracy: 0.7344\n",
            "Epoch 161/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4692 - accuracy: 0.7604 - val_loss: 0.5432 - val_accuracy: 0.7344\n",
            "Epoch 162/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4689 - accuracy: 0.7639 - val_loss: 0.5433 - val_accuracy: 0.7344\n",
            "Epoch 163/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4688 - accuracy: 0.7622 - val_loss: 0.5435 - val_accuracy: 0.7344\n",
            "Epoch 164/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4685 - accuracy: 0.7639 - val_loss: 0.5436 - val_accuracy: 0.7344\n",
            "Epoch 165/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4683 - accuracy: 0.7639 - val_loss: 0.5437 - val_accuracy: 0.7344\n",
            "Epoch 166/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4682 - accuracy: 0.7639 - val_loss: 0.5437 - val_accuracy: 0.7344\n",
            "Epoch 167/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4679 - accuracy: 0.7604 - val_loss: 0.5438 - val_accuracy: 0.7344\n",
            "Epoch 168/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4678 - accuracy: 0.7622 - val_loss: 0.5439 - val_accuracy: 0.7344\n",
            "Epoch 169/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4676 - accuracy: 0.7604 - val_loss: 0.5440 - val_accuracy: 0.7344\n",
            "Epoch 170/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4673 - accuracy: 0.7604 - val_loss: 0.5441 - val_accuracy: 0.7344\n",
            "Epoch 171/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4671 - accuracy: 0.7587 - val_loss: 0.5441 - val_accuracy: 0.7344\n",
            "Epoch 172/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4670 - accuracy: 0.7604 - val_loss: 0.5443 - val_accuracy: 0.7344\n",
            "Epoch 173/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4670 - accuracy: 0.7604 - val_loss: 0.5443 - val_accuracy: 0.7292\n",
            "Epoch 174/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4666 - accuracy: 0.7587 - val_loss: 0.5444 - val_accuracy: 0.7292\n",
            "Epoch 175/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4664 - accuracy: 0.7604 - val_loss: 0.5444 - val_accuracy: 0.7292\n",
            "Epoch 176/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4663 - accuracy: 0.7604 - val_loss: 0.5445 - val_accuracy: 0.7344\n",
            "Epoch 177/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4662 - accuracy: 0.7604 - val_loss: 0.5446 - val_accuracy: 0.7344\n",
            "Epoch 178/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4659 - accuracy: 0.7639 - val_loss: 0.5446 - val_accuracy: 0.7344\n",
            "Epoch 179/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4658 - accuracy: 0.7656 - val_loss: 0.5447 - val_accuracy: 0.7344\n",
            "Epoch 180/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4657 - accuracy: 0.7639 - val_loss: 0.5448 - val_accuracy: 0.7344\n",
            "Epoch 181/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4655 - accuracy: 0.7656 - val_loss: 0.5449 - val_accuracy: 0.7344\n",
            "Epoch 182/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4653 - accuracy: 0.7639 - val_loss: 0.5449 - val_accuracy: 0.7396\n",
            "Epoch 183/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4651 - accuracy: 0.7639 - val_loss: 0.5451 - val_accuracy: 0.7396\n",
            "Epoch 184/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4652 - accuracy: 0.7639 - val_loss: 0.5452 - val_accuracy: 0.7396\n",
            "Epoch 185/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4649 - accuracy: 0.7639 - val_loss: 0.5454 - val_accuracy: 0.7396\n",
            "Epoch 186/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4647 - accuracy: 0.7674 - val_loss: 0.5454 - val_accuracy: 0.7396\n",
            "Epoch 187/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4647 - accuracy: 0.7656 - val_loss: 0.5455 - val_accuracy: 0.7396\n",
            "Epoch 188/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4645 - accuracy: 0.7674 - val_loss: 0.5457 - val_accuracy: 0.7396\n",
            "Epoch 189/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4642 - accuracy: 0.7674 - val_loss: 0.5457 - val_accuracy: 0.7396\n",
            "Epoch 190/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4641 - accuracy: 0.7656 - val_loss: 0.5458 - val_accuracy: 0.7396\n",
            "Epoch 191/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4642 - accuracy: 0.7639 - val_loss: 0.5460 - val_accuracy: 0.7396\n",
            "Epoch 192/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4640 - accuracy: 0.7674 - val_loss: 0.5461 - val_accuracy: 0.7396\n",
            "Epoch 193/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4641 - accuracy: 0.7656 - val_loss: 0.5462 - val_accuracy: 0.7396\n",
            "Epoch 194/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4638 - accuracy: 0.7674 - val_loss: 0.5463 - val_accuracy: 0.7396\n",
            "Epoch 195/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4636 - accuracy: 0.7674 - val_loss: 0.5465 - val_accuracy: 0.7396\n",
            "Epoch 196/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4635 - accuracy: 0.7656 - val_loss: 0.5465 - val_accuracy: 0.7396\n",
            "Epoch 197/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4635 - accuracy: 0.7674 - val_loss: 0.5467 - val_accuracy: 0.7396\n",
            "Epoch 198/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4632 - accuracy: 0.7656 - val_loss: 0.5467 - val_accuracy: 0.7396\n",
            "Epoch 199/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4632 - accuracy: 0.7656 - val_loss: 0.5467 - val_accuracy: 0.7396\n",
            "Epoch 200/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4632 - accuracy: 0.7656 - val_loss: 0.5468 - val_accuracy: 0.7396\n",
            "Epoch 201/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4630 - accuracy: 0.7691 - val_loss: 0.5470 - val_accuracy: 0.7396\n",
            "Epoch 202/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4628 - accuracy: 0.7691 - val_loss: 0.5470 - val_accuracy: 0.7396\n",
            "Epoch 203/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4629 - accuracy: 0.7656 - val_loss: 0.5471 - val_accuracy: 0.7396\n",
            "Epoch 204/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4627 - accuracy: 0.7691 - val_loss: 0.5472 - val_accuracy: 0.7344\n",
            "Epoch 205/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4625 - accuracy: 0.7691 - val_loss: 0.5472 - val_accuracy: 0.7344\n",
            "Epoch 206/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4625 - accuracy: 0.7674 - val_loss: 0.5473 - val_accuracy: 0.7344\n",
            "Epoch 207/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4624 - accuracy: 0.7674 - val_loss: 0.5473 - val_accuracy: 0.7344\n",
            "Epoch 208/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4622 - accuracy: 0.7691 - val_loss: 0.5474 - val_accuracy: 0.7344\n",
            "Epoch 209/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4621 - accuracy: 0.7656 - val_loss: 0.5475 - val_accuracy: 0.7344\n",
            "Epoch 210/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4622 - accuracy: 0.7656 - val_loss: 0.5476 - val_accuracy: 0.7344\n",
            "Epoch 211/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4619 - accuracy: 0.7708 - val_loss: 0.5475 - val_accuracy: 0.7344\n",
            "Epoch 212/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4619 - accuracy: 0.7708 - val_loss: 0.5476 - val_accuracy: 0.7344\n",
            "Epoch 213/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4619 - accuracy: 0.7674 - val_loss: 0.5476 - val_accuracy: 0.7344\n",
            "Epoch 214/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4618 - accuracy: 0.7708 - val_loss: 0.5476 - val_accuracy: 0.7344\n",
            "Epoch 215/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4617 - accuracy: 0.7674 - val_loss: 0.5477 - val_accuracy: 0.7344\n",
            "Epoch 216/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4615 - accuracy: 0.7691 - val_loss: 0.5477 - val_accuracy: 0.7344\n",
            "Epoch 217/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4614 - accuracy: 0.7708 - val_loss: 0.5477 - val_accuracy: 0.7344\n",
            "Epoch 218/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4612 - accuracy: 0.7708 - val_loss: 0.5478 - val_accuracy: 0.7344\n",
            "Epoch 219/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4614 - accuracy: 0.7708 - val_loss: 0.5477 - val_accuracy: 0.7344\n",
            "Epoch 220/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4612 - accuracy: 0.7691 - val_loss: 0.5478 - val_accuracy: 0.7344\n",
            "Epoch 221/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4612 - accuracy: 0.7708 - val_loss: 0.5478 - val_accuracy: 0.7344\n",
            "Epoch 222/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4610 - accuracy: 0.7708 - val_loss: 0.5479 - val_accuracy: 0.7344\n",
            "Epoch 223/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4611 - accuracy: 0.7726 - val_loss: 0.5479 - val_accuracy: 0.7344\n",
            "Epoch 224/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4608 - accuracy: 0.7726 - val_loss: 0.5479 - val_accuracy: 0.7344\n",
            "Epoch 225/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4608 - accuracy: 0.7726 - val_loss: 0.5479 - val_accuracy: 0.7344\n",
            "Epoch 226/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4608 - accuracy: 0.7691 - val_loss: 0.5480 - val_accuracy: 0.7344\n",
            "Epoch 227/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4606 - accuracy: 0.7726 - val_loss: 0.5480 - val_accuracy: 0.7344\n",
            "Epoch 228/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4606 - accuracy: 0.7726 - val_loss: 0.5480 - val_accuracy: 0.7344\n",
            "Epoch 229/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4605 - accuracy: 0.7726 - val_loss: 0.5481 - val_accuracy: 0.7344\n",
            "Epoch 230/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4604 - accuracy: 0.7708 - val_loss: 0.5481 - val_accuracy: 0.7344\n",
            "Epoch 231/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4603 - accuracy: 0.7708 - val_loss: 0.5480 - val_accuracy: 0.7292\n",
            "Epoch 232/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4604 - accuracy: 0.7708 - val_loss: 0.5480 - val_accuracy: 0.7344\n",
            "Epoch 233/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4600 - accuracy: 0.7726 - val_loss: 0.5481 - val_accuracy: 0.7292\n",
            "Epoch 234/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4601 - accuracy: 0.7726 - val_loss: 0.5480 - val_accuracy: 0.7292\n",
            "Epoch 235/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4600 - accuracy: 0.7708 - val_loss: 0.5479 - val_accuracy: 0.7292\n",
            "Epoch 236/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4600 - accuracy: 0.7726 - val_loss: 0.5479 - val_accuracy: 0.7292\n",
            "Epoch 237/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4600 - accuracy: 0.7726 - val_loss: 0.5480 - val_accuracy: 0.7292\n",
            "Epoch 238/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4599 - accuracy: 0.7708 - val_loss: 0.5480 - val_accuracy: 0.7292\n",
            "Epoch 239/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4597 - accuracy: 0.7708 - val_loss: 0.5478 - val_accuracy: 0.7292\n",
            "Epoch 240/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4597 - accuracy: 0.7726 - val_loss: 0.5478 - val_accuracy: 0.7292\n",
            "Epoch 241/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4596 - accuracy: 0.7726 - val_loss: 0.5478 - val_accuracy: 0.7292\n",
            "Epoch 242/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4595 - accuracy: 0.7691 - val_loss: 0.5478 - val_accuracy: 0.7292\n",
            "Epoch 243/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4594 - accuracy: 0.7708 - val_loss: 0.5478 - val_accuracy: 0.7292\n",
            "Epoch 244/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4594 - accuracy: 0.7708 - val_loss: 0.5478 - val_accuracy: 0.7292\n",
            "Epoch 245/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4593 - accuracy: 0.7743 - val_loss: 0.5479 - val_accuracy: 0.7292\n",
            "Epoch 246/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4592 - accuracy: 0.7691 - val_loss: 0.5479 - val_accuracy: 0.7292\n",
            "Epoch 247/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4591 - accuracy: 0.7691 - val_loss: 0.5478 - val_accuracy: 0.7292\n",
            "Epoch 248/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4592 - accuracy: 0.7691 - val_loss: 0.5477 - val_accuracy: 0.7292\n",
            "Epoch 249/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4592 - accuracy: 0.7691 - val_loss: 0.5478 - val_accuracy: 0.7292\n",
            "Epoch 250/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4589 - accuracy: 0.7708 - val_loss: 0.5479 - val_accuracy: 0.7292\n",
            "Epoch 251/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4588 - accuracy: 0.7674 - val_loss: 0.5477 - val_accuracy: 0.7292\n",
            "Epoch 252/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4588 - accuracy: 0.7674 - val_loss: 0.5477 - val_accuracy: 0.7292\n",
            "Epoch 253/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4588 - accuracy: 0.7691 - val_loss: 0.5476 - val_accuracy: 0.7292\n",
            "Epoch 254/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4586 - accuracy: 0.7708 - val_loss: 0.5476 - val_accuracy: 0.7292\n",
            "Epoch 255/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4584 - accuracy: 0.7708 - val_loss: 0.5476 - val_accuracy: 0.7292\n",
            "Epoch 256/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4584 - accuracy: 0.7708 - val_loss: 0.5476 - val_accuracy: 0.7292\n",
            "Epoch 257/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4584 - accuracy: 0.7726 - val_loss: 0.5475 - val_accuracy: 0.7292\n",
            "Epoch 258/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4584 - accuracy: 0.7726 - val_loss: 0.5476 - val_accuracy: 0.7292\n",
            "Epoch 259/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4583 - accuracy: 0.7708 - val_loss: 0.5475 - val_accuracy: 0.7292\n",
            "Epoch 260/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4582 - accuracy: 0.7691 - val_loss: 0.5474 - val_accuracy: 0.7292\n",
            "Epoch 261/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4580 - accuracy: 0.7726 - val_loss: 0.5473 - val_accuracy: 0.7292\n",
            "Epoch 262/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4579 - accuracy: 0.7708 - val_loss: 0.5473 - val_accuracy: 0.7292\n",
            "Epoch 263/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4579 - accuracy: 0.7708 - val_loss: 0.5473 - val_accuracy: 0.7292\n",
            "Epoch 264/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4578 - accuracy: 0.7691 - val_loss: 0.5473 - val_accuracy: 0.7292\n",
            "Epoch 265/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4577 - accuracy: 0.7691 - val_loss: 0.5472 - val_accuracy: 0.7292\n",
            "Epoch 266/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4577 - accuracy: 0.7691 - val_loss: 0.5472 - val_accuracy: 0.7292\n",
            "Epoch 267/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4577 - accuracy: 0.7691 - val_loss: 0.5471 - val_accuracy: 0.7292\n",
            "Epoch 268/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4575 - accuracy: 0.7708 - val_loss: 0.5472 - val_accuracy: 0.7292\n",
            "Epoch 269/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4573 - accuracy: 0.7691 - val_loss: 0.5471 - val_accuracy: 0.7292\n",
            "Epoch 270/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4573 - accuracy: 0.7726 - val_loss: 0.5471 - val_accuracy: 0.7292\n",
            "Epoch 271/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4572 - accuracy: 0.7726 - val_loss: 0.5471 - val_accuracy: 0.7292\n",
            "Epoch 272/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4572 - accuracy: 0.7674 - val_loss: 0.5470 - val_accuracy: 0.7292\n",
            "Epoch 273/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4571 - accuracy: 0.7691 - val_loss: 0.5470 - val_accuracy: 0.7292\n",
            "Epoch 274/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4571 - accuracy: 0.7708 - val_loss: 0.5470 - val_accuracy: 0.7292\n",
            "Epoch 275/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4569 - accuracy: 0.7708 - val_loss: 0.5470 - val_accuracy: 0.7292\n",
            "Epoch 276/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4571 - accuracy: 0.7674 - val_loss: 0.5472 - val_accuracy: 0.7292\n",
            "Epoch 277/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4569 - accuracy: 0.7691 - val_loss: 0.5470 - val_accuracy: 0.7292\n",
            "Epoch 278/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4568 - accuracy: 0.7674 - val_loss: 0.5470 - val_accuracy: 0.7292\n",
            "Epoch 279/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4566 - accuracy: 0.7674 - val_loss: 0.5470 - val_accuracy: 0.7292\n",
            "Epoch 280/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4565 - accuracy: 0.7656 - val_loss: 0.5469 - val_accuracy: 0.7292\n",
            "Epoch 281/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4565 - accuracy: 0.7691 - val_loss: 0.5469 - val_accuracy: 0.7292\n",
            "Epoch 282/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4564 - accuracy: 0.7691 - val_loss: 0.5468 - val_accuracy: 0.7292\n",
            "Epoch 283/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4564 - accuracy: 0.7691 - val_loss: 0.5467 - val_accuracy: 0.7292\n",
            "Epoch 284/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4563 - accuracy: 0.7691 - val_loss: 0.5467 - val_accuracy: 0.7292\n",
            "Epoch 285/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4564 - accuracy: 0.7656 - val_loss: 0.5467 - val_accuracy: 0.7292\n",
            "Epoch 286/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4561 - accuracy: 0.7691 - val_loss: 0.5466 - val_accuracy: 0.7292\n",
            "Epoch 287/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4561 - accuracy: 0.7674 - val_loss: 0.5466 - val_accuracy: 0.7292\n",
            "Epoch 288/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4560 - accuracy: 0.7691 - val_loss: 0.5466 - val_accuracy: 0.7292\n",
            "Epoch 289/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4560 - accuracy: 0.7691 - val_loss: 0.5466 - val_accuracy: 0.7292\n",
            "Epoch 290/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4560 - accuracy: 0.7691 - val_loss: 0.5466 - val_accuracy: 0.7240\n",
            "Epoch 291/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4558 - accuracy: 0.7691 - val_loss: 0.5465 - val_accuracy: 0.7292\n",
            "Epoch 292/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4557 - accuracy: 0.7726 - val_loss: 0.5466 - val_accuracy: 0.7240\n",
            "Epoch 293/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4558 - accuracy: 0.7708 - val_loss: 0.5465 - val_accuracy: 0.7240\n",
            "Epoch 294/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4556 - accuracy: 0.7691 - val_loss: 0.5465 - val_accuracy: 0.7240\n",
            "Epoch 295/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4556 - accuracy: 0.7691 - val_loss: 0.5465 - val_accuracy: 0.7240\n",
            "Epoch 296/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4556 - accuracy: 0.7674 - val_loss: 0.5465 - val_accuracy: 0.7240\n",
            "Epoch 297/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4555 - accuracy: 0.7674 - val_loss: 0.5464 - val_accuracy: 0.7240\n",
            "Epoch 298/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4555 - accuracy: 0.7656 - val_loss: 0.5463 - val_accuracy: 0.7240\n",
            "Epoch 299/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4554 - accuracy: 0.7656 - val_loss: 0.5463 - val_accuracy: 0.7240\n",
            "Epoch 300/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4552 - accuracy: 0.7674 - val_loss: 0.5462 - val_accuracy: 0.7240\n",
            "Epoch 301/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4552 - accuracy: 0.7656 - val_loss: 0.5463 - val_accuracy: 0.7240\n",
            "Epoch 302/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4552 - accuracy: 0.7674 - val_loss: 0.5463 - val_accuracy: 0.7240\n",
            "Epoch 303/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4552 - accuracy: 0.7674 - val_loss: 0.5462 - val_accuracy: 0.7240\n",
            "Epoch 304/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4551 - accuracy: 0.7691 - val_loss: 0.5462 - val_accuracy: 0.7240\n",
            "Epoch 305/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4550 - accuracy: 0.7674 - val_loss: 0.5462 - val_accuracy: 0.7240\n",
            "Epoch 306/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4549 - accuracy: 0.7639 - val_loss: 0.5462 - val_accuracy: 0.7240\n",
            "Epoch 307/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4548 - accuracy: 0.7639 - val_loss: 0.5461 - val_accuracy: 0.7240\n",
            "Epoch 308/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4548 - accuracy: 0.7656 - val_loss: 0.5462 - val_accuracy: 0.7240\n",
            "Epoch 309/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4550 - accuracy: 0.7656 - val_loss: 0.5461 - val_accuracy: 0.7240\n",
            "Epoch 310/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4547 - accuracy: 0.7656 - val_loss: 0.5462 - val_accuracy: 0.7240\n",
            "Epoch 311/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4547 - accuracy: 0.7656 - val_loss: 0.5462 - val_accuracy: 0.7240\n",
            "Epoch 312/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4546 - accuracy: 0.7639 - val_loss: 0.5462 - val_accuracy: 0.7240\n",
            "Epoch 313/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4547 - accuracy: 0.7656 - val_loss: 0.5461 - val_accuracy: 0.7240\n",
            "Epoch 314/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4546 - accuracy: 0.7639 - val_loss: 0.5461 - val_accuracy: 0.7240\n",
            "Epoch 315/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4545 - accuracy: 0.7639 - val_loss: 0.5461 - val_accuracy: 0.7240\n",
            "Epoch 316/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4545 - accuracy: 0.7639 - val_loss: 0.5461 - val_accuracy: 0.7240\n",
            "Epoch 317/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4545 - accuracy: 0.7639 - val_loss: 0.5460 - val_accuracy: 0.7240\n",
            "Epoch 318/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4543 - accuracy: 0.7639 - val_loss: 0.5460 - val_accuracy: 0.7240\n",
            "Epoch 319/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4543 - accuracy: 0.7639 - val_loss: 0.5460 - val_accuracy: 0.7240\n",
            "Epoch 320/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4543 - accuracy: 0.7639 - val_loss: 0.5459 - val_accuracy: 0.7240\n",
            "Epoch 321/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4543 - accuracy: 0.7639 - val_loss: 0.5459 - val_accuracy: 0.7240\n",
            "Epoch 322/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4542 - accuracy: 0.7639 - val_loss: 0.5459 - val_accuracy: 0.7240\n",
            "Epoch 323/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4542 - accuracy: 0.7639 - val_loss: 0.5459 - val_accuracy: 0.7240\n",
            "Epoch 324/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4541 - accuracy: 0.7639 - val_loss: 0.5458 - val_accuracy: 0.7240\n",
            "Epoch 325/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4541 - accuracy: 0.7639 - val_loss: 0.5458 - val_accuracy: 0.7292\n",
            "Epoch 326/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4539 - accuracy: 0.7639 - val_loss: 0.5458 - val_accuracy: 0.7292\n",
            "Epoch 327/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4539 - accuracy: 0.7639 - val_loss: 0.5457 - val_accuracy: 0.7292\n",
            "Epoch 328/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4539 - accuracy: 0.7639 - val_loss: 0.5457 - val_accuracy: 0.7292\n",
            "Epoch 329/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4539 - accuracy: 0.7656 - val_loss: 0.5457 - val_accuracy: 0.7292\n",
            "Epoch 330/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4539 - accuracy: 0.7639 - val_loss: 0.5457 - val_accuracy: 0.7292\n",
            "Epoch 331/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4536 - accuracy: 0.7622 - val_loss: 0.5457 - val_accuracy: 0.7292\n",
            "Epoch 332/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4537 - accuracy: 0.7622 - val_loss: 0.5457 - val_accuracy: 0.7292\n",
            "Epoch 333/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4536 - accuracy: 0.7639 - val_loss: 0.5457 - val_accuracy: 0.7292\n",
            "Epoch 334/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4535 - accuracy: 0.7639 - val_loss: 0.5457 - val_accuracy: 0.7292\n",
            "Epoch 335/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4536 - accuracy: 0.7622 - val_loss: 0.5457 - val_accuracy: 0.7292\n",
            "Epoch 336/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4534 - accuracy: 0.7639 - val_loss: 0.5456 - val_accuracy: 0.7292\n",
            "Epoch 337/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4535 - accuracy: 0.7639 - val_loss: 0.5456 - val_accuracy: 0.7292\n",
            "Epoch 338/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4535 - accuracy: 0.7604 - val_loss: 0.5456 - val_accuracy: 0.7292\n",
            "Epoch 339/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4534 - accuracy: 0.7622 - val_loss: 0.5455 - val_accuracy: 0.7292\n",
            "Epoch 340/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4532 - accuracy: 0.7622 - val_loss: 0.5455 - val_accuracy: 0.7292\n",
            "Epoch 341/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4534 - accuracy: 0.7622 - val_loss: 0.5454 - val_accuracy: 0.7292\n",
            "Epoch 342/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4533 - accuracy: 0.7639 - val_loss: 0.5454 - val_accuracy: 0.7292\n",
            "Epoch 343/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4531 - accuracy: 0.7639 - val_loss: 0.5454 - val_accuracy: 0.7292\n",
            "Epoch 344/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4530 - accuracy: 0.7639 - val_loss: 0.5454 - val_accuracy: 0.7292\n",
            "Epoch 345/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4531 - accuracy: 0.7622 - val_loss: 0.5453 - val_accuracy: 0.7292\n",
            "Epoch 346/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4530 - accuracy: 0.7656 - val_loss: 0.5454 - val_accuracy: 0.7292\n",
            "Epoch 347/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4530 - accuracy: 0.7656 - val_loss: 0.5454 - val_accuracy: 0.7292\n",
            "Epoch 348/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4529 - accuracy: 0.7656 - val_loss: 0.5454 - val_accuracy: 0.7292\n",
            "Epoch 349/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4529 - accuracy: 0.7622 - val_loss: 0.5454 - val_accuracy: 0.7292\n",
            "Epoch 350/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4530 - accuracy: 0.7639 - val_loss: 0.5453 - val_accuracy: 0.7292\n",
            "Epoch 351/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4528 - accuracy: 0.7656 - val_loss: 0.5453 - val_accuracy: 0.7292\n",
            "Epoch 352/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4527 - accuracy: 0.7656 - val_loss: 0.5453 - val_accuracy: 0.7292\n",
            "Epoch 353/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4528 - accuracy: 0.7639 - val_loss: 0.5453 - val_accuracy: 0.7292\n",
            "Epoch 354/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4527 - accuracy: 0.7639 - val_loss: 0.5453 - val_accuracy: 0.7292\n",
            "Epoch 355/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4526 - accuracy: 0.7656 - val_loss: 0.5453 - val_accuracy: 0.7292\n",
            "Epoch 356/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4526 - accuracy: 0.7656 - val_loss: 0.5453 - val_accuracy: 0.7292\n",
            "Epoch 357/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4526 - accuracy: 0.7656 - val_loss: 0.5453 - val_accuracy: 0.7292\n",
            "Epoch 358/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4526 - accuracy: 0.7656 - val_loss: 0.5453 - val_accuracy: 0.7292\n",
            "Epoch 359/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4524 - accuracy: 0.7656 - val_loss: 0.5453 - val_accuracy: 0.7292\n",
            "Epoch 360/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4525 - accuracy: 0.7639 - val_loss: 0.5452 - val_accuracy: 0.7292\n",
            "Epoch 361/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4523 - accuracy: 0.7639 - val_loss: 0.5453 - val_accuracy: 0.7292\n",
            "Epoch 362/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4525 - accuracy: 0.7622 - val_loss: 0.5453 - val_accuracy: 0.7292\n",
            "Epoch 363/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4524 - accuracy: 0.7656 - val_loss: 0.5453 - val_accuracy: 0.7292\n",
            "Epoch 364/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4522 - accuracy: 0.7639 - val_loss: 0.5453 - val_accuracy: 0.7292\n",
            "Epoch 365/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4522 - accuracy: 0.7656 - val_loss: 0.5453 - val_accuracy: 0.7292\n",
            "Epoch 366/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4521 - accuracy: 0.7639 - val_loss: 0.5453 - val_accuracy: 0.7292\n",
            "Epoch 367/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4522 - accuracy: 0.7639 - val_loss: 0.5453 - val_accuracy: 0.7292\n",
            "Epoch 368/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4521 - accuracy: 0.7639 - val_loss: 0.5453 - val_accuracy: 0.7292\n",
            "Epoch 369/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4521 - accuracy: 0.7622 - val_loss: 0.5453 - val_accuracy: 0.7292\n",
            "Epoch 370/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4521 - accuracy: 0.7622 - val_loss: 0.5453 - val_accuracy: 0.7292\n",
            "Epoch 371/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4519 - accuracy: 0.7639 - val_loss: 0.5453 - val_accuracy: 0.7292\n",
            "Epoch 372/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4519 - accuracy: 0.7639 - val_loss: 0.5454 - val_accuracy: 0.7292\n",
            "Epoch 373/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4517 - accuracy: 0.7639 - val_loss: 0.5454 - val_accuracy: 0.7292\n",
            "Epoch 374/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4519 - accuracy: 0.7639 - val_loss: 0.5454 - val_accuracy: 0.7292\n",
            "Epoch 375/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4518 - accuracy: 0.7656 - val_loss: 0.5454 - val_accuracy: 0.7292\n",
            "Epoch 376/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4516 - accuracy: 0.7639 - val_loss: 0.5454 - val_accuracy: 0.7292\n",
            "Epoch 377/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4517 - accuracy: 0.7639 - val_loss: 0.5455 - val_accuracy: 0.7292\n",
            "Epoch 378/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4516 - accuracy: 0.7656 - val_loss: 0.5455 - val_accuracy: 0.7292\n",
            "Epoch 379/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4515 - accuracy: 0.7674 - val_loss: 0.5454 - val_accuracy: 0.7292\n",
            "Epoch 380/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4515 - accuracy: 0.7639 - val_loss: 0.5453 - val_accuracy: 0.7292\n",
            "Epoch 381/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4514 - accuracy: 0.7639 - val_loss: 0.5453 - val_accuracy: 0.7292\n",
            "Epoch 382/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4515 - accuracy: 0.7656 - val_loss: 0.5453 - val_accuracy: 0.7292\n",
            "Epoch 383/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4514 - accuracy: 0.7639 - val_loss: 0.5453 - val_accuracy: 0.7292\n",
            "Epoch 384/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4514 - accuracy: 0.7656 - val_loss: 0.5453 - val_accuracy: 0.7292\n",
            "Epoch 385/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4515 - accuracy: 0.7674 - val_loss: 0.5452 - val_accuracy: 0.7292\n",
            "Epoch 386/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4514 - accuracy: 0.7656 - val_loss: 0.5453 - val_accuracy: 0.7292\n",
            "Epoch 387/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4512 - accuracy: 0.7639 - val_loss: 0.5453 - val_accuracy: 0.7292\n",
            "Epoch 388/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4512 - accuracy: 0.7639 - val_loss: 0.5453 - val_accuracy: 0.7292\n",
            "Epoch 389/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4511 - accuracy: 0.7639 - val_loss: 0.5453 - val_accuracy: 0.7292\n",
            "Epoch 390/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4511 - accuracy: 0.7639 - val_loss: 0.5454 - val_accuracy: 0.7292\n",
            "Epoch 391/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4512 - accuracy: 0.7639 - val_loss: 0.5453 - val_accuracy: 0.7292\n",
            "Epoch 392/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4510 - accuracy: 0.7656 - val_loss: 0.5454 - val_accuracy: 0.7292\n",
            "Epoch 393/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4511 - accuracy: 0.7639 - val_loss: 0.5454 - val_accuracy: 0.7292\n",
            "Epoch 394/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4509 - accuracy: 0.7639 - val_loss: 0.5454 - val_accuracy: 0.7292\n",
            "Epoch 395/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4509 - accuracy: 0.7656 - val_loss: 0.5454 - val_accuracy: 0.7292\n",
            "Epoch 396/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4508 - accuracy: 0.7656 - val_loss: 0.5453 - val_accuracy: 0.7292\n",
            "Epoch 397/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4509 - accuracy: 0.7656 - val_loss: 0.5454 - val_accuracy: 0.7292\n",
            "Epoch 398/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4507 - accuracy: 0.7674 - val_loss: 0.5453 - val_accuracy: 0.7292\n",
            "Epoch 399/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4507 - accuracy: 0.7656 - val_loss: 0.5454 - val_accuracy: 0.7292\n",
            "Epoch 400/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4508 - accuracy: 0.7656 - val_loss: 0.5455 - val_accuracy: 0.7292\n",
            "Epoch 401/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4505 - accuracy: 0.7656 - val_loss: 0.5455 - val_accuracy: 0.7292\n",
            "Epoch 402/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4505 - accuracy: 0.7656 - val_loss: 0.5456 - val_accuracy: 0.7292\n",
            "Epoch 403/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4504 - accuracy: 0.7674 - val_loss: 0.5456 - val_accuracy: 0.7292\n",
            "Epoch 404/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4505 - accuracy: 0.7656 - val_loss: 0.5456 - val_accuracy: 0.7292\n",
            "Epoch 405/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4505 - accuracy: 0.7674 - val_loss: 0.5456 - val_accuracy: 0.7292\n",
            "Epoch 406/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4503 - accuracy: 0.7674 - val_loss: 0.5456 - val_accuracy: 0.7292\n",
            "Epoch 407/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4502 - accuracy: 0.7691 - val_loss: 0.5457 - val_accuracy: 0.7292\n",
            "Epoch 408/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4503 - accuracy: 0.7691 - val_loss: 0.5457 - val_accuracy: 0.7292\n",
            "Epoch 409/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4501 - accuracy: 0.7674 - val_loss: 0.5458 - val_accuracy: 0.7292\n",
            "Epoch 410/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4501 - accuracy: 0.7691 - val_loss: 0.5458 - val_accuracy: 0.7292\n",
            "Epoch 411/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4501 - accuracy: 0.7691 - val_loss: 0.5459 - val_accuracy: 0.7292\n",
            "Epoch 412/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4500 - accuracy: 0.7726 - val_loss: 0.5459 - val_accuracy: 0.7292\n",
            "Epoch 413/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4499 - accuracy: 0.7691 - val_loss: 0.5460 - val_accuracy: 0.7292\n",
            "Epoch 414/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4500 - accuracy: 0.7674 - val_loss: 0.5460 - val_accuracy: 0.7292\n",
            "Epoch 415/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4499 - accuracy: 0.7691 - val_loss: 0.5461 - val_accuracy: 0.7292\n",
            "Epoch 416/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4497 - accuracy: 0.7691 - val_loss: 0.5461 - val_accuracy: 0.7292\n",
            "Epoch 417/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4497 - accuracy: 0.7708 - val_loss: 0.5461 - val_accuracy: 0.7292\n",
            "Epoch 418/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4498 - accuracy: 0.7691 - val_loss: 0.5461 - val_accuracy: 0.7292\n",
            "Epoch 419/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4495 - accuracy: 0.7743 - val_loss: 0.5460 - val_accuracy: 0.7292\n",
            "Epoch 420/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4496 - accuracy: 0.7726 - val_loss: 0.5461 - val_accuracy: 0.7292\n",
            "Epoch 421/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4495 - accuracy: 0.7708 - val_loss: 0.5460 - val_accuracy: 0.7240\n",
            "Epoch 422/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4494 - accuracy: 0.7726 - val_loss: 0.5461 - val_accuracy: 0.7240\n",
            "Epoch 423/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4493 - accuracy: 0.7726 - val_loss: 0.5461 - val_accuracy: 0.7240\n",
            "Epoch 424/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4494 - accuracy: 0.7726 - val_loss: 0.5461 - val_accuracy: 0.7240\n",
            "Epoch 425/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4492 - accuracy: 0.7691 - val_loss: 0.5460 - val_accuracy: 0.7240\n",
            "Epoch 426/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4492 - accuracy: 0.7708 - val_loss: 0.5460 - val_accuracy: 0.7240\n",
            "Epoch 427/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4492 - accuracy: 0.7708 - val_loss: 0.5461 - val_accuracy: 0.7240\n",
            "Epoch 428/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4491 - accuracy: 0.7708 - val_loss: 0.5461 - val_accuracy: 0.7240\n",
            "Epoch 429/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4490 - accuracy: 0.7708 - val_loss: 0.5461 - val_accuracy: 0.7240\n",
            "Epoch 430/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4489 - accuracy: 0.7726 - val_loss: 0.5460 - val_accuracy: 0.7240\n",
            "Epoch 431/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4489 - accuracy: 0.7708 - val_loss: 0.5460 - val_accuracy: 0.7240\n",
            "Epoch 432/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4489 - accuracy: 0.7708 - val_loss: 0.5460 - val_accuracy: 0.7240\n",
            "Epoch 433/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4488 - accuracy: 0.7708 - val_loss: 0.5459 - val_accuracy: 0.7240\n",
            "Epoch 434/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4487 - accuracy: 0.7708 - val_loss: 0.5459 - val_accuracy: 0.7188\n",
            "Epoch 435/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4485 - accuracy: 0.7743 - val_loss: 0.5459 - val_accuracy: 0.7240\n",
            "Epoch 436/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4485 - accuracy: 0.7726 - val_loss: 0.5459 - val_accuracy: 0.7240\n",
            "Epoch 437/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4483 - accuracy: 0.7726 - val_loss: 0.5459 - val_accuracy: 0.7240\n",
            "Epoch 438/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4483 - accuracy: 0.7743 - val_loss: 0.5458 - val_accuracy: 0.7240\n",
            "Epoch 439/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4483 - accuracy: 0.7743 - val_loss: 0.5458 - val_accuracy: 0.7240\n",
            "Epoch 440/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4482 - accuracy: 0.7743 - val_loss: 0.5457 - val_accuracy: 0.7240\n",
            "Epoch 441/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4480 - accuracy: 0.7726 - val_loss: 0.5458 - val_accuracy: 0.7240\n",
            "Epoch 442/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4480 - accuracy: 0.7743 - val_loss: 0.5458 - val_accuracy: 0.7240\n",
            "Epoch 443/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4480 - accuracy: 0.7760 - val_loss: 0.5458 - val_accuracy: 0.7292\n",
            "Epoch 444/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4478 - accuracy: 0.7726 - val_loss: 0.5457 - val_accuracy: 0.7292\n",
            "Epoch 445/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4480 - accuracy: 0.7726 - val_loss: 0.5457 - val_accuracy: 0.7292\n",
            "Epoch 446/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4477 - accuracy: 0.7726 - val_loss: 0.5457 - val_accuracy: 0.7292\n",
            "Epoch 447/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4478 - accuracy: 0.7743 - val_loss: 0.5457 - val_accuracy: 0.7292\n",
            "Epoch 448/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4477 - accuracy: 0.7726 - val_loss: 0.5457 - val_accuracy: 0.7240\n",
            "Epoch 449/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4475 - accuracy: 0.7726 - val_loss: 0.5457 - val_accuracy: 0.7240\n",
            "Epoch 450/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4476 - accuracy: 0.7743 - val_loss: 0.5457 - val_accuracy: 0.7240\n",
            "Epoch 451/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4474 - accuracy: 0.7743 - val_loss: 0.5458 - val_accuracy: 0.7240\n",
            "Epoch 452/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4474 - accuracy: 0.7760 - val_loss: 0.5458 - val_accuracy: 0.7240\n",
            "Epoch 453/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4474 - accuracy: 0.7760 - val_loss: 0.5458 - val_accuracy: 0.7240\n",
            "Epoch 454/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4473 - accuracy: 0.7778 - val_loss: 0.5458 - val_accuracy: 0.7240\n",
            "Epoch 455/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4473 - accuracy: 0.7795 - val_loss: 0.5458 - val_accuracy: 0.7240\n",
            "Epoch 456/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4473 - accuracy: 0.7743 - val_loss: 0.5457 - val_accuracy: 0.7240\n",
            "Epoch 457/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4471 - accuracy: 0.7778 - val_loss: 0.5457 - val_accuracy: 0.7240\n",
            "Epoch 458/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4470 - accuracy: 0.7760 - val_loss: 0.5457 - val_accuracy: 0.7240\n",
            "Epoch 459/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4470 - accuracy: 0.7778 - val_loss: 0.5457 - val_accuracy: 0.7240\n",
            "Epoch 460/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4469 - accuracy: 0.7795 - val_loss: 0.5457 - val_accuracy: 0.7240\n",
            "Epoch 461/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4468 - accuracy: 0.7778 - val_loss: 0.5457 - val_accuracy: 0.7240\n",
            "Epoch 462/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4468 - accuracy: 0.7812 - val_loss: 0.5458 - val_accuracy: 0.7240\n",
            "Epoch 463/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4468 - accuracy: 0.7778 - val_loss: 0.5457 - val_accuracy: 0.7240\n",
            "Epoch 464/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4467 - accuracy: 0.7743 - val_loss: 0.5458 - val_accuracy: 0.7240\n",
            "Epoch 465/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4466 - accuracy: 0.7795 - val_loss: 0.5458 - val_accuracy: 0.7240\n",
            "Epoch 466/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4465 - accuracy: 0.7795 - val_loss: 0.5459 - val_accuracy: 0.7344\n",
            "Epoch 467/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4465 - accuracy: 0.7795 - val_loss: 0.5459 - val_accuracy: 0.7344\n",
            "Epoch 468/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4464 - accuracy: 0.7795 - val_loss: 0.5460 - val_accuracy: 0.7344\n",
            "Epoch 469/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4462 - accuracy: 0.7812 - val_loss: 0.5459 - val_accuracy: 0.7344\n",
            "Epoch 470/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4462 - accuracy: 0.7795 - val_loss: 0.5459 - val_accuracy: 0.7344\n",
            "Epoch 471/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4463 - accuracy: 0.7812 - val_loss: 0.5458 - val_accuracy: 0.7344\n",
            "Epoch 472/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4461 - accuracy: 0.7812 - val_loss: 0.5459 - val_accuracy: 0.7344\n",
            "Epoch 473/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4459 - accuracy: 0.7795 - val_loss: 0.5461 - val_accuracy: 0.7344\n",
            "Epoch 474/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4461 - accuracy: 0.7812 - val_loss: 0.5461 - val_accuracy: 0.7344\n",
            "Epoch 475/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4458 - accuracy: 0.7812 - val_loss: 0.5461 - val_accuracy: 0.7344\n",
            "Epoch 476/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4458 - accuracy: 0.7795 - val_loss: 0.5462 - val_accuracy: 0.7344\n",
            "Epoch 477/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4457 - accuracy: 0.7812 - val_loss: 0.5461 - val_accuracy: 0.7344\n",
            "Epoch 478/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4456 - accuracy: 0.7812 - val_loss: 0.5462 - val_accuracy: 0.7344\n",
            "Epoch 479/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4456 - accuracy: 0.7795 - val_loss: 0.5462 - val_accuracy: 0.7292\n",
            "Epoch 480/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4455 - accuracy: 0.7795 - val_loss: 0.5463 - val_accuracy: 0.7292\n",
            "Epoch 481/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4454 - accuracy: 0.7795 - val_loss: 0.5463 - val_accuracy: 0.7292\n",
            "Epoch 482/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4454 - accuracy: 0.7812 - val_loss: 0.5464 - val_accuracy: 0.7292\n",
            "Epoch 483/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4454 - accuracy: 0.7795 - val_loss: 0.5464 - val_accuracy: 0.7292\n",
            "Epoch 484/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4452 - accuracy: 0.7830 - val_loss: 0.5464 - val_accuracy: 0.7292\n",
            "Epoch 485/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4453 - accuracy: 0.7795 - val_loss: 0.5465 - val_accuracy: 0.7240\n",
            "Epoch 486/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4451 - accuracy: 0.7830 - val_loss: 0.5466 - val_accuracy: 0.7240\n",
            "Epoch 487/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4449 - accuracy: 0.7830 - val_loss: 0.5466 - val_accuracy: 0.7240\n",
            "Epoch 488/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4449 - accuracy: 0.7830 - val_loss: 0.5467 - val_accuracy: 0.7240\n",
            "Epoch 489/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4448 - accuracy: 0.7812 - val_loss: 0.5467 - val_accuracy: 0.7240\n",
            "Epoch 490/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4448 - accuracy: 0.7812 - val_loss: 0.5467 - val_accuracy: 0.7240\n",
            "Epoch 491/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4448 - accuracy: 0.7847 - val_loss: 0.5467 - val_accuracy: 0.7240\n",
            "Epoch 492/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4446 - accuracy: 0.7847 - val_loss: 0.5467 - val_accuracy: 0.7240\n",
            "Epoch 493/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4446 - accuracy: 0.7812 - val_loss: 0.5468 - val_accuracy: 0.7240\n",
            "Epoch 494/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4445 - accuracy: 0.7847 - val_loss: 0.5468 - val_accuracy: 0.7240\n",
            "Epoch 495/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4445 - accuracy: 0.7812 - val_loss: 0.5469 - val_accuracy: 0.7240\n",
            "Epoch 496/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4444 - accuracy: 0.7830 - val_loss: 0.5469 - val_accuracy: 0.7240\n",
            "Epoch 497/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4443 - accuracy: 0.7847 - val_loss: 0.5469 - val_accuracy: 0.7240\n",
            "Epoch 498/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4442 - accuracy: 0.7865 - val_loss: 0.5468 - val_accuracy: 0.7240\n",
            "Epoch 499/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4441 - accuracy: 0.7847 - val_loss: 0.5469 - val_accuracy: 0.7240\n",
            "Epoch 500/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4441 - accuracy: 0.7865 - val_loss: 0.5468 - val_accuracy: 0.7240\n",
            "Epoch 501/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4439 - accuracy: 0.7847 - val_loss: 0.5468 - val_accuracy: 0.7240\n",
            "Epoch 502/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4438 - accuracy: 0.7847 - val_loss: 0.5468 - val_accuracy: 0.7240\n",
            "Epoch 503/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4438 - accuracy: 0.7865 - val_loss: 0.5469 - val_accuracy: 0.7240\n",
            "Epoch 504/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4437 - accuracy: 0.7847 - val_loss: 0.5469 - val_accuracy: 0.7240\n",
            "Epoch 505/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4439 - accuracy: 0.7830 - val_loss: 0.5470 - val_accuracy: 0.7240\n",
            "Epoch 506/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4436 - accuracy: 0.7865 - val_loss: 0.5470 - val_accuracy: 0.7240\n",
            "Epoch 507/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4436 - accuracy: 0.7865 - val_loss: 0.5470 - val_accuracy: 0.7240\n",
            "Epoch 508/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4436 - accuracy: 0.7812 - val_loss: 0.5471 - val_accuracy: 0.7240\n",
            "Epoch 509/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4435 - accuracy: 0.7847 - val_loss: 0.5471 - val_accuracy: 0.7240\n",
            "Epoch 510/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4434 - accuracy: 0.7865 - val_loss: 0.5471 - val_accuracy: 0.7240\n",
            "Epoch 511/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4434 - accuracy: 0.7865 - val_loss: 0.5470 - val_accuracy: 0.7240\n",
            "Epoch 512/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4432 - accuracy: 0.7847 - val_loss: 0.5470 - val_accuracy: 0.7240\n",
            "Epoch 513/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4432 - accuracy: 0.7865 - val_loss: 0.5470 - val_accuracy: 0.7240\n",
            "Epoch 514/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4432 - accuracy: 0.7812 - val_loss: 0.5471 - val_accuracy: 0.7240\n",
            "Epoch 515/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4431 - accuracy: 0.7847 - val_loss: 0.5470 - val_accuracy: 0.7240\n",
            "Epoch 516/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4432 - accuracy: 0.7830 - val_loss: 0.5471 - val_accuracy: 0.7240\n",
            "Epoch 517/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4430 - accuracy: 0.7847 - val_loss: 0.5471 - val_accuracy: 0.7240\n",
            "Epoch 518/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4429 - accuracy: 0.7865 - val_loss: 0.5471 - val_accuracy: 0.7240\n",
            "Epoch 519/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4430 - accuracy: 0.7847 - val_loss: 0.5471 - val_accuracy: 0.7240\n",
            "Epoch 520/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4428 - accuracy: 0.7882 - val_loss: 0.5472 - val_accuracy: 0.7240\n",
            "Epoch 521/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4426 - accuracy: 0.7847 - val_loss: 0.5472 - val_accuracy: 0.7240\n",
            "Epoch 522/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4427 - accuracy: 0.7830 - val_loss: 0.5471 - val_accuracy: 0.7240\n",
            "Epoch 523/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4426 - accuracy: 0.7830 - val_loss: 0.5471 - val_accuracy: 0.7240\n",
            "Epoch 524/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4426 - accuracy: 0.7830 - val_loss: 0.5471 - val_accuracy: 0.7240\n",
            "Epoch 525/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4424 - accuracy: 0.7830 - val_loss: 0.5471 - val_accuracy: 0.7240\n",
            "Epoch 526/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4425 - accuracy: 0.7830 - val_loss: 0.5472 - val_accuracy: 0.7240\n",
            "Epoch 527/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4424 - accuracy: 0.7830 - val_loss: 0.5472 - val_accuracy: 0.7240\n",
            "Epoch 528/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4424 - accuracy: 0.7830 - val_loss: 0.5473 - val_accuracy: 0.7240\n",
            "Epoch 529/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4423 - accuracy: 0.7830 - val_loss: 0.5473 - val_accuracy: 0.7240\n",
            "Epoch 530/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4423 - accuracy: 0.7830 - val_loss: 0.5473 - val_accuracy: 0.7240\n",
            "Epoch 531/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4423 - accuracy: 0.7830 - val_loss: 0.5472 - val_accuracy: 0.7240\n",
            "Epoch 532/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4422 - accuracy: 0.7812 - val_loss: 0.5473 - val_accuracy: 0.7240\n",
            "Epoch 533/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4421 - accuracy: 0.7847 - val_loss: 0.5473 - val_accuracy: 0.7240\n",
            "Epoch 534/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4423 - accuracy: 0.7865 - val_loss: 0.5474 - val_accuracy: 0.7240\n",
            "Epoch 535/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4420 - accuracy: 0.7847 - val_loss: 0.5474 - val_accuracy: 0.7240\n",
            "Epoch 536/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4420 - accuracy: 0.7865 - val_loss: 0.5474 - val_accuracy: 0.7240\n",
            "Epoch 537/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4420 - accuracy: 0.7847 - val_loss: 0.5474 - val_accuracy: 0.7240\n",
            "Epoch 538/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4418 - accuracy: 0.7865 - val_loss: 0.5476 - val_accuracy: 0.7240\n",
            "Epoch 539/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4420 - accuracy: 0.7865 - val_loss: 0.5475 - val_accuracy: 0.7240\n",
            "Epoch 540/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4418 - accuracy: 0.7847 - val_loss: 0.5475 - val_accuracy: 0.7240\n",
            "Epoch 541/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4417 - accuracy: 0.7865 - val_loss: 0.5475 - val_accuracy: 0.7240\n",
            "Epoch 542/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4416 - accuracy: 0.7865 - val_loss: 0.5475 - val_accuracy: 0.7240\n",
            "Epoch 543/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4416 - accuracy: 0.7865 - val_loss: 0.5476 - val_accuracy: 0.7240\n",
            "Epoch 544/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4415 - accuracy: 0.7865 - val_loss: 0.5476 - val_accuracy: 0.7240\n",
            "Epoch 545/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4415 - accuracy: 0.7882 - val_loss: 0.5477 - val_accuracy: 0.7240\n",
            "Epoch 546/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4413 - accuracy: 0.7865 - val_loss: 0.5477 - val_accuracy: 0.7240\n",
            "Epoch 547/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4413 - accuracy: 0.7865 - val_loss: 0.5477 - val_accuracy: 0.7240\n",
            "Epoch 548/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4412 - accuracy: 0.7865 - val_loss: 0.5477 - val_accuracy: 0.7240\n",
            "Epoch 549/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.7865 - val_loss: 0.5478 - val_accuracy: 0.7240\n",
            "Epoch 550/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4412 - accuracy: 0.7865 - val_loss: 0.5477 - val_accuracy: 0.7240\n",
            "Epoch 551/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4411 - accuracy: 0.7882 - val_loss: 0.5478 - val_accuracy: 0.7240\n",
            "Epoch 552/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4411 - accuracy: 0.7882 - val_loss: 0.5479 - val_accuracy: 0.7240\n",
            "Epoch 553/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4409 - accuracy: 0.7865 - val_loss: 0.5479 - val_accuracy: 0.7240\n",
            "Epoch 554/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4408 - accuracy: 0.7865 - val_loss: 0.5479 - val_accuracy: 0.7240\n",
            "Epoch 555/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4407 - accuracy: 0.7882 - val_loss: 0.5480 - val_accuracy: 0.7240\n",
            "Epoch 556/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4408 - accuracy: 0.7882 - val_loss: 0.5480 - val_accuracy: 0.7240\n",
            "Epoch 557/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4407 - accuracy: 0.7882 - val_loss: 0.5481 - val_accuracy: 0.7240\n",
            "Epoch 558/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4408 - accuracy: 0.7865 - val_loss: 0.5481 - val_accuracy: 0.7240\n",
            "Epoch 559/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.7865 - val_loss: 0.5481 - val_accuracy: 0.7240\n",
            "Epoch 560/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.7865 - val_loss: 0.5480 - val_accuracy: 0.7240\n",
            "Epoch 561/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4404 - accuracy: 0.7882 - val_loss: 0.5481 - val_accuracy: 0.7240\n",
            "Epoch 562/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4404 - accuracy: 0.7882 - val_loss: 0.5481 - val_accuracy: 0.7240\n",
            "Epoch 563/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.7865 - val_loss: 0.5481 - val_accuracy: 0.7240\n",
            "Epoch 564/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.7882 - val_loss: 0.5481 - val_accuracy: 0.7240\n",
            "Epoch 565/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4402 - accuracy: 0.7882 - val_loss: 0.5481 - val_accuracy: 0.7240\n",
            "Epoch 566/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4401 - accuracy: 0.7882 - val_loss: 0.5481 - val_accuracy: 0.7240\n",
            "Epoch 567/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4400 - accuracy: 0.7882 - val_loss: 0.5481 - val_accuracy: 0.7240\n",
            "Epoch 568/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4400 - accuracy: 0.7882 - val_loss: 0.5482 - val_accuracy: 0.7240\n",
            "Epoch 569/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4401 - accuracy: 0.7882 - val_loss: 0.5483 - val_accuracy: 0.7240\n",
            "Epoch 570/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4398 - accuracy: 0.7882 - val_loss: 0.5483 - val_accuracy: 0.7240\n",
            "Epoch 571/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4398 - accuracy: 0.7899 - val_loss: 0.5483 - val_accuracy: 0.7240\n",
            "Epoch 572/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4399 - accuracy: 0.7882 - val_loss: 0.5484 - val_accuracy: 0.7240\n",
            "Epoch 573/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4397 - accuracy: 0.7899 - val_loss: 0.5483 - val_accuracy: 0.7240\n",
            "Epoch 574/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4395 - accuracy: 0.7899 - val_loss: 0.5483 - val_accuracy: 0.7240\n",
            "Epoch 575/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4395 - accuracy: 0.7899 - val_loss: 0.5483 - val_accuracy: 0.7240\n",
            "Epoch 576/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4395 - accuracy: 0.7899 - val_loss: 0.5483 - val_accuracy: 0.7240\n",
            "Epoch 577/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4395 - accuracy: 0.7899 - val_loss: 0.5484 - val_accuracy: 0.7240\n",
            "Epoch 578/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4394 - accuracy: 0.7899 - val_loss: 0.5484 - val_accuracy: 0.7240\n",
            "Epoch 579/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4393 - accuracy: 0.7899 - val_loss: 0.5483 - val_accuracy: 0.7240\n",
            "Epoch 580/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4393 - accuracy: 0.7882 - val_loss: 0.5483 - val_accuracy: 0.7240\n",
            "Epoch 581/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4392 - accuracy: 0.7899 - val_loss: 0.5483 - val_accuracy: 0.7240\n",
            "Epoch 582/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4392 - accuracy: 0.7899 - val_loss: 0.5484 - val_accuracy: 0.7240\n",
            "Epoch 583/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4391 - accuracy: 0.7899 - val_loss: 0.5485 - val_accuracy: 0.7240\n",
            "Epoch 584/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4390 - accuracy: 0.7899 - val_loss: 0.5484 - val_accuracy: 0.7240\n",
            "Epoch 585/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4390 - accuracy: 0.7899 - val_loss: 0.5484 - val_accuracy: 0.7240\n",
            "Epoch 586/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4390 - accuracy: 0.7899 - val_loss: 0.5484 - val_accuracy: 0.7292\n",
            "Epoch 587/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4389 - accuracy: 0.7899 - val_loss: 0.5484 - val_accuracy: 0.7292\n",
            "Epoch 588/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4389 - accuracy: 0.7899 - val_loss: 0.5484 - val_accuracy: 0.7292\n",
            "Epoch 589/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4388 - accuracy: 0.7882 - val_loss: 0.5485 - val_accuracy: 0.7292\n",
            "Epoch 590/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4387 - accuracy: 0.7899 - val_loss: 0.5485 - val_accuracy: 0.7292\n",
            "Epoch 591/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4386 - accuracy: 0.7899 - val_loss: 0.5485 - val_accuracy: 0.7292\n",
            "Epoch 592/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4385 - accuracy: 0.7899 - val_loss: 0.5485 - val_accuracy: 0.7292\n",
            "Epoch 593/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4385 - accuracy: 0.7882 - val_loss: 0.5486 - val_accuracy: 0.7292\n",
            "Epoch 594/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4385 - accuracy: 0.7899 - val_loss: 0.5486 - val_accuracy: 0.7292\n",
            "Epoch 595/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4386 - accuracy: 0.7882 - val_loss: 0.5485 - val_accuracy: 0.7292\n",
            "Epoch 596/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4384 - accuracy: 0.7882 - val_loss: 0.5485 - val_accuracy: 0.7292\n",
            "Epoch 597/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4383 - accuracy: 0.7899 - val_loss: 0.5485 - val_accuracy: 0.7292\n",
            "Epoch 598/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4383 - accuracy: 0.7899 - val_loss: 0.5485 - val_accuracy: 0.7292\n",
            "Epoch 599/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4382 - accuracy: 0.7882 - val_loss: 0.5485 - val_accuracy: 0.7292\n",
            "Epoch 600/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4381 - accuracy: 0.7882 - val_loss: 0.5485 - val_accuracy: 0.7292\n",
            "Epoch 601/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4382 - accuracy: 0.7899 - val_loss: 0.5484 - val_accuracy: 0.7292\n",
            "Epoch 602/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4381 - accuracy: 0.7882 - val_loss: 0.5484 - val_accuracy: 0.7292\n",
            "Epoch 603/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4382 - accuracy: 0.7882 - val_loss: 0.5484 - val_accuracy: 0.7292\n",
            "Epoch 604/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4380 - accuracy: 0.7882 - val_loss: 0.5485 - val_accuracy: 0.7292\n",
            "Epoch 605/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4380 - accuracy: 0.7882 - val_loss: 0.5485 - val_accuracy: 0.7292\n",
            "Epoch 606/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4379 - accuracy: 0.7882 - val_loss: 0.5485 - val_accuracy: 0.7292\n",
            "Epoch 607/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4379 - accuracy: 0.7882 - val_loss: 0.5484 - val_accuracy: 0.7292\n",
            "Epoch 608/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4378 - accuracy: 0.7882 - val_loss: 0.5484 - val_accuracy: 0.7292\n",
            "Epoch 609/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4378 - accuracy: 0.7882 - val_loss: 0.5486 - val_accuracy: 0.7292\n",
            "Epoch 610/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4376 - accuracy: 0.7882 - val_loss: 0.5486 - val_accuracy: 0.7292\n",
            "Epoch 611/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4376 - accuracy: 0.7882 - val_loss: 0.5486 - val_accuracy: 0.7292\n",
            "Epoch 612/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4376 - accuracy: 0.7865 - val_loss: 0.5486 - val_accuracy: 0.7292\n",
            "Epoch 613/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4375 - accuracy: 0.7865 - val_loss: 0.5486 - val_accuracy: 0.7344\n",
            "Epoch 614/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4375 - accuracy: 0.7865 - val_loss: 0.5485 - val_accuracy: 0.7344\n",
            "Epoch 615/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4375 - accuracy: 0.7882 - val_loss: 0.5485 - val_accuracy: 0.7344\n",
            "Epoch 616/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4374 - accuracy: 0.7865 - val_loss: 0.5486 - val_accuracy: 0.7344\n",
            "Epoch 617/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4373 - accuracy: 0.7865 - val_loss: 0.5486 - val_accuracy: 0.7344\n",
            "Epoch 618/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4373 - accuracy: 0.7865 - val_loss: 0.5486 - val_accuracy: 0.7344\n",
            "Epoch 619/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4373 - accuracy: 0.7865 - val_loss: 0.5486 - val_accuracy: 0.7344\n",
            "Epoch 620/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4372 - accuracy: 0.7865 - val_loss: 0.5485 - val_accuracy: 0.7344\n",
            "Epoch 621/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4371 - accuracy: 0.7865 - val_loss: 0.5486 - val_accuracy: 0.7344\n",
            "Epoch 622/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4370 - accuracy: 0.7865 - val_loss: 0.5487 - val_accuracy: 0.7344\n",
            "Epoch 623/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4371 - accuracy: 0.7865 - val_loss: 0.5486 - val_accuracy: 0.7344\n",
            "Epoch 624/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4371 - accuracy: 0.7865 - val_loss: 0.5486 - val_accuracy: 0.7344\n",
            "Epoch 625/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4369 - accuracy: 0.7865 - val_loss: 0.5485 - val_accuracy: 0.7344\n",
            "Epoch 626/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4369 - accuracy: 0.7865 - val_loss: 0.5485 - val_accuracy: 0.7344\n",
            "Epoch 627/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4368 - accuracy: 0.7865 - val_loss: 0.5485 - val_accuracy: 0.7344\n",
            "Epoch 628/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4368 - accuracy: 0.7865 - val_loss: 0.5485 - val_accuracy: 0.7344\n",
            "Epoch 629/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4367 - accuracy: 0.7865 - val_loss: 0.5486 - val_accuracy: 0.7344\n",
            "Epoch 630/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4366 - accuracy: 0.7865 - val_loss: 0.5486 - val_accuracy: 0.7344\n",
            "Epoch 631/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4366 - accuracy: 0.7865 - val_loss: 0.5486 - val_accuracy: 0.7344\n",
            "Epoch 632/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4365 - accuracy: 0.7882 - val_loss: 0.5487 - val_accuracy: 0.7344\n",
            "Epoch 633/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4364 - accuracy: 0.7865 - val_loss: 0.5487 - val_accuracy: 0.7344\n",
            "Epoch 634/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4364 - accuracy: 0.7865 - val_loss: 0.5486 - val_accuracy: 0.7344\n",
            "Epoch 635/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4364 - accuracy: 0.7865 - val_loss: 0.5486 - val_accuracy: 0.7344\n",
            "Epoch 636/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4363 - accuracy: 0.7865 - val_loss: 0.5486 - val_accuracy: 0.7344\n",
            "Epoch 637/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4362 - accuracy: 0.7865 - val_loss: 0.5486 - val_accuracy: 0.7344\n",
            "Epoch 638/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4362 - accuracy: 0.7865 - val_loss: 0.5486 - val_accuracy: 0.7344\n",
            "Epoch 639/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4361 - accuracy: 0.7865 - val_loss: 0.5486 - val_accuracy: 0.7344\n",
            "Epoch 640/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4360 - accuracy: 0.7865 - val_loss: 0.5485 - val_accuracy: 0.7344\n",
            "Epoch 641/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4361 - accuracy: 0.7865 - val_loss: 0.5485 - val_accuracy: 0.7344\n",
            "Epoch 642/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4360 - accuracy: 0.7865 - val_loss: 0.5486 - val_accuracy: 0.7344\n",
            "Epoch 643/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4360 - accuracy: 0.7865 - val_loss: 0.5486 - val_accuracy: 0.7344\n",
            "Epoch 644/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4359 - accuracy: 0.7865 - val_loss: 0.5486 - val_accuracy: 0.7344\n",
            "Epoch 645/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4358 - accuracy: 0.7865 - val_loss: 0.5486 - val_accuracy: 0.7344\n",
            "Epoch 646/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4359 - accuracy: 0.7865 - val_loss: 0.5485 - val_accuracy: 0.7344\n",
            "Epoch 647/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4358 - accuracy: 0.7865 - val_loss: 0.5485 - val_accuracy: 0.7344\n",
            "Epoch 648/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4357 - accuracy: 0.7865 - val_loss: 0.5485 - val_accuracy: 0.7344\n",
            "Epoch 649/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4358 - accuracy: 0.7865 - val_loss: 0.5486 - val_accuracy: 0.7396\n",
            "Epoch 650/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4357 - accuracy: 0.7865 - val_loss: 0.5487 - val_accuracy: 0.7396\n",
            "Epoch 651/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4355 - accuracy: 0.7865 - val_loss: 0.5487 - val_accuracy: 0.7396\n",
            "Epoch 652/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4356 - accuracy: 0.7865 - val_loss: 0.5488 - val_accuracy: 0.7396\n",
            "Epoch 653/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4356 - accuracy: 0.7865 - val_loss: 0.5488 - val_accuracy: 0.7396\n",
            "Epoch 654/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4356 - accuracy: 0.7865 - val_loss: 0.5488 - val_accuracy: 0.7396\n",
            "Epoch 655/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4356 - accuracy: 0.7865 - val_loss: 0.5489 - val_accuracy: 0.7396\n",
            "Epoch 656/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4355 - accuracy: 0.7847 - val_loss: 0.5490 - val_accuracy: 0.7396\n",
            "Epoch 657/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4354 - accuracy: 0.7865 - val_loss: 0.5491 - val_accuracy: 0.7396\n",
            "Epoch 658/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4354 - accuracy: 0.7865 - val_loss: 0.5490 - val_accuracy: 0.7396\n",
            "Epoch 659/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4354 - accuracy: 0.7847 - val_loss: 0.5489 - val_accuracy: 0.7344\n",
            "Epoch 660/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4353 - accuracy: 0.7865 - val_loss: 0.5489 - val_accuracy: 0.7344\n",
            "Epoch 661/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4352 - accuracy: 0.7865 - val_loss: 0.5489 - val_accuracy: 0.7344\n",
            "Epoch 662/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4352 - accuracy: 0.7865 - val_loss: 0.5489 - val_accuracy: 0.7344\n",
            "Epoch 663/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4353 - accuracy: 0.7847 - val_loss: 0.5489 - val_accuracy: 0.7344\n",
            "Epoch 664/1000\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4352 - accuracy: 0.7847 - val_loss: 0.5489 - val_accuracy: 0.7344\n",
            "Epoch 665/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4352 - accuracy: 0.7847 - val_loss: 0.5489 - val_accuracy: 0.7344\n",
            "Epoch 666/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4351 - accuracy: 0.7847 - val_loss: 0.5490 - val_accuracy: 0.7344\n",
            "Epoch 667/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4352 - accuracy: 0.7865 - val_loss: 0.5490 - val_accuracy: 0.7344\n",
            "Epoch 668/1000\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4351 - accuracy: 0.7847 - val_loss: 0.5490 - val_accuracy: 0.7344\n",
            "Epoch 669/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4350 - accuracy: 0.7847 - val_loss: 0.5490 - val_accuracy: 0.7344\n",
            "Epoch 670/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4349 - accuracy: 0.7847 - val_loss: 0.5490 - val_accuracy: 0.7344\n",
            "Epoch 671/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4351 - accuracy: 0.7847 - val_loss: 0.5489 - val_accuracy: 0.7344\n",
            "Epoch 672/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4349 - accuracy: 0.7847 - val_loss: 0.5489 - val_accuracy: 0.7344\n",
            "Epoch 673/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4349 - accuracy: 0.7847 - val_loss: 0.5489 - val_accuracy: 0.7344\n",
            "Epoch 674/1000\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4349 - accuracy: 0.7847 - val_loss: 0.5489 - val_accuracy: 0.7344\n",
            "Epoch 675/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4348 - accuracy: 0.7847 - val_loss: 0.5490 - val_accuracy: 0.7292\n",
            "Epoch 676/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4348 - accuracy: 0.7865 - val_loss: 0.5491 - val_accuracy: 0.7292\n",
            "Epoch 677/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4347 - accuracy: 0.7847 - val_loss: 0.5491 - val_accuracy: 0.7292\n",
            "Epoch 678/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4347 - accuracy: 0.7847 - val_loss: 0.5491 - val_accuracy: 0.7292\n",
            "Epoch 679/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4345 - accuracy: 0.7847 - val_loss: 0.5492 - val_accuracy: 0.7292\n",
            "Epoch 680/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4346 - accuracy: 0.7847 - val_loss: 0.5491 - val_accuracy: 0.7292\n",
            "Epoch 681/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4347 - accuracy: 0.7847 - val_loss: 0.5491 - val_accuracy: 0.7292\n",
            "Epoch 682/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4345 - accuracy: 0.7847 - val_loss: 0.5492 - val_accuracy: 0.7292\n",
            "Epoch 683/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4346 - accuracy: 0.7847 - val_loss: 0.5492 - val_accuracy: 0.7292\n",
            "Epoch 684/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4345 - accuracy: 0.7847 - val_loss: 0.5491 - val_accuracy: 0.7292\n",
            "Epoch 685/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4343 - accuracy: 0.7847 - val_loss: 0.5492 - val_accuracy: 0.7292\n",
            "Epoch 686/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4343 - accuracy: 0.7847 - val_loss: 0.5492 - val_accuracy: 0.7292\n",
            "Epoch 687/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4343 - accuracy: 0.7847 - val_loss: 0.5491 - val_accuracy: 0.7292\n",
            "Epoch 688/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4342 - accuracy: 0.7847 - val_loss: 0.5492 - val_accuracy: 0.7292\n",
            "Epoch 689/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4342 - accuracy: 0.7847 - val_loss: 0.5492 - val_accuracy: 0.7292\n",
            "Epoch 690/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4341 - accuracy: 0.7847 - val_loss: 0.5492 - val_accuracy: 0.7292\n",
            "Epoch 691/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4342 - accuracy: 0.7847 - val_loss: 0.5493 - val_accuracy: 0.7292\n",
            "Epoch 692/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4341 - accuracy: 0.7847 - val_loss: 0.5494 - val_accuracy: 0.7292\n",
            "Epoch 693/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4341 - accuracy: 0.7847 - val_loss: 0.5493 - val_accuracy: 0.7292\n",
            "Epoch 694/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4340 - accuracy: 0.7847 - val_loss: 0.5493 - val_accuracy: 0.7292\n",
            "Epoch 695/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4341 - accuracy: 0.7847 - val_loss: 0.5493 - val_accuracy: 0.7292\n",
            "Epoch 696/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4339 - accuracy: 0.7865 - val_loss: 0.5493 - val_accuracy: 0.7292\n",
            "Epoch 697/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4338 - accuracy: 0.7847 - val_loss: 0.5492 - val_accuracy: 0.7292\n",
            "Epoch 698/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4339 - accuracy: 0.7865 - val_loss: 0.5492 - val_accuracy: 0.7292\n",
            "Epoch 699/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4340 - accuracy: 0.7847 - val_loss: 0.5492 - val_accuracy: 0.7292\n",
            "Epoch 700/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4338 - accuracy: 0.7847 - val_loss: 0.5493 - val_accuracy: 0.7292\n",
            "Epoch 701/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4338 - accuracy: 0.7847 - val_loss: 0.5493 - val_accuracy: 0.7292\n",
            "Epoch 702/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4338 - accuracy: 0.7865 - val_loss: 0.5492 - val_accuracy: 0.7292\n",
            "Epoch 703/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4337 - accuracy: 0.7847 - val_loss: 0.5492 - val_accuracy: 0.7292\n",
            "Epoch 704/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4338 - accuracy: 0.7847 - val_loss: 0.5492 - val_accuracy: 0.7292\n",
            "Epoch 705/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4336 - accuracy: 0.7865 - val_loss: 0.5493 - val_accuracy: 0.7292\n",
            "Epoch 706/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4337 - accuracy: 0.7865 - val_loss: 0.5492 - val_accuracy: 0.7292\n",
            "Epoch 707/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4338 - accuracy: 0.7847 - val_loss: 0.5492 - val_accuracy: 0.7292\n",
            "Epoch 708/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4338 - accuracy: 0.7865 - val_loss: 0.5492 - val_accuracy: 0.7292\n",
            "Epoch 709/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4335 - accuracy: 0.7847 - val_loss: 0.5492 - val_accuracy: 0.7292\n",
            "Epoch 710/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4336 - accuracy: 0.7847 - val_loss: 0.5493 - val_accuracy: 0.7292\n",
            "Epoch 711/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4335 - accuracy: 0.7847 - val_loss: 0.5493 - val_accuracy: 0.7292\n",
            "Epoch 712/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4335 - accuracy: 0.7865 - val_loss: 0.5493 - val_accuracy: 0.7292\n",
            "Epoch 713/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4334 - accuracy: 0.7865 - val_loss: 0.5494 - val_accuracy: 0.7292\n",
            "Epoch 714/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4334 - accuracy: 0.7865 - val_loss: 0.5493 - val_accuracy: 0.7292\n",
            "Epoch 715/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4336 - accuracy: 0.7865 - val_loss: 0.5493 - val_accuracy: 0.7292\n",
            "Epoch 716/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4333 - accuracy: 0.7847 - val_loss: 0.5493 - val_accuracy: 0.7292\n",
            "Epoch 717/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4333 - accuracy: 0.7865 - val_loss: 0.5494 - val_accuracy: 0.7292\n",
            "Epoch 718/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4333 - accuracy: 0.7865 - val_loss: 0.5494 - val_accuracy: 0.7292\n",
            "Epoch 719/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4334 - accuracy: 0.7865 - val_loss: 0.5493 - val_accuracy: 0.7292\n",
            "Epoch 720/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4333 - accuracy: 0.7847 - val_loss: 0.5494 - val_accuracy: 0.7292\n",
            "Epoch 721/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4333 - accuracy: 0.7882 - val_loss: 0.5494 - val_accuracy: 0.7292\n",
            "Epoch 722/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4333 - accuracy: 0.7882 - val_loss: 0.5493 - val_accuracy: 0.7292\n",
            "Epoch 723/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4334 - accuracy: 0.7865 - val_loss: 0.5494 - val_accuracy: 0.7292\n",
            "Epoch 724/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4332 - accuracy: 0.7865 - val_loss: 0.5494 - val_accuracy: 0.7292\n",
            "Epoch 725/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4331 - accuracy: 0.7847 - val_loss: 0.5494 - val_accuracy: 0.7292\n",
            "Epoch 726/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4332 - accuracy: 0.7847 - val_loss: 0.5494 - val_accuracy: 0.7292\n",
            "Epoch 727/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4331 - accuracy: 0.7865 - val_loss: 0.5495 - val_accuracy: 0.7292\n",
            "Epoch 728/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4330 - accuracy: 0.7882 - val_loss: 0.5495 - val_accuracy: 0.7292\n",
            "Epoch 729/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4331 - accuracy: 0.7865 - val_loss: 0.5496 - val_accuracy: 0.7292\n",
            "Epoch 730/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4332 - accuracy: 0.7865 - val_loss: 0.5496 - val_accuracy: 0.7292\n",
            "Epoch 731/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4331 - accuracy: 0.7865 - val_loss: 0.5495 - val_accuracy: 0.7292\n",
            "Epoch 732/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4329 - accuracy: 0.7865 - val_loss: 0.5495 - val_accuracy: 0.7292\n",
            "Epoch 733/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4329 - accuracy: 0.7882 - val_loss: 0.5494 - val_accuracy: 0.7292\n",
            "Epoch 734/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4329 - accuracy: 0.7882 - val_loss: 0.5494 - val_accuracy: 0.7292\n",
            "Epoch 735/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4328 - accuracy: 0.7882 - val_loss: 0.5494 - val_accuracy: 0.7292\n",
            "Epoch 736/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4328 - accuracy: 0.7882 - val_loss: 0.5494 - val_accuracy: 0.7292\n",
            "Epoch 737/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4326 - accuracy: 0.7882 - val_loss: 0.5494 - val_accuracy: 0.7240\n",
            "Epoch 738/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4327 - accuracy: 0.7882 - val_loss: 0.5493 - val_accuracy: 0.7240\n",
            "Epoch 739/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4326 - accuracy: 0.7882 - val_loss: 0.5493 - val_accuracy: 0.7240\n",
            "Epoch 740/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4326 - accuracy: 0.7882 - val_loss: 0.5493 - val_accuracy: 0.7240\n",
            "Epoch 741/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4325 - accuracy: 0.7882 - val_loss: 0.5492 - val_accuracy: 0.7240\n",
            "Epoch 742/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4326 - accuracy: 0.7882 - val_loss: 0.5493 - val_accuracy: 0.7240\n",
            "Epoch 743/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4324 - accuracy: 0.7882 - val_loss: 0.5493 - val_accuracy: 0.7240\n",
            "Epoch 744/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4324 - accuracy: 0.7865 - val_loss: 0.5493 - val_accuracy: 0.7240\n",
            "Epoch 745/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4324 - accuracy: 0.7882 - val_loss: 0.5492 - val_accuracy: 0.7240\n",
            "Epoch 746/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4323 - accuracy: 0.7882 - val_loss: 0.5492 - val_accuracy: 0.7240\n",
            "Epoch 747/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4321 - accuracy: 0.7882 - val_loss: 0.5491 - val_accuracy: 0.7240\n",
            "Epoch 748/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4321 - accuracy: 0.7882 - val_loss: 0.5490 - val_accuracy: 0.7240\n",
            "Epoch 749/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4321 - accuracy: 0.7882 - val_loss: 0.5489 - val_accuracy: 0.7240\n",
            "Epoch 750/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4321 - accuracy: 0.7865 - val_loss: 0.5490 - val_accuracy: 0.7240\n",
            "Epoch 751/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4320 - accuracy: 0.7882 - val_loss: 0.5490 - val_accuracy: 0.7240\n",
            "Epoch 752/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4319 - accuracy: 0.7865 - val_loss: 0.5490 - val_accuracy: 0.7240\n",
            "Epoch 753/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4320 - accuracy: 0.7882 - val_loss: 0.5490 - val_accuracy: 0.7240\n",
            "Epoch 754/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4320 - accuracy: 0.7865 - val_loss: 0.5490 - val_accuracy: 0.7240\n",
            "Epoch 755/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4318 - accuracy: 0.7865 - val_loss: 0.5489 - val_accuracy: 0.7240\n",
            "Epoch 756/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4319 - accuracy: 0.7882 - val_loss: 0.5488 - val_accuracy: 0.7240\n",
            "Epoch 757/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4318 - accuracy: 0.7882 - val_loss: 0.5488 - val_accuracy: 0.7240\n",
            "Epoch 758/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4316 - accuracy: 0.7882 - val_loss: 0.5488 - val_accuracy: 0.7240\n",
            "Epoch 759/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4318 - accuracy: 0.7882 - val_loss: 0.5488 - val_accuracy: 0.7240\n",
            "Epoch 760/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4317 - accuracy: 0.7882 - val_loss: 0.5488 - val_accuracy: 0.7240\n",
            "Epoch 761/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4316 - accuracy: 0.7882 - val_loss: 0.5488 - val_accuracy: 0.7240\n",
            "Epoch 762/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4316 - accuracy: 0.7865 - val_loss: 0.5488 - val_accuracy: 0.7240\n",
            "Epoch 763/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4317 - accuracy: 0.7865 - val_loss: 0.5488 - val_accuracy: 0.7240\n",
            "Epoch 764/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4316 - accuracy: 0.7882 - val_loss: 0.5488 - val_accuracy: 0.7240\n",
            "Epoch 765/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4316 - accuracy: 0.7865 - val_loss: 0.5489 - val_accuracy: 0.7240\n",
            "Epoch 766/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4314 - accuracy: 0.7882 - val_loss: 0.5488 - val_accuracy: 0.7240\n",
            "Epoch 767/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4314 - accuracy: 0.7882 - val_loss: 0.5487 - val_accuracy: 0.7240\n",
            "Epoch 768/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4315 - accuracy: 0.7882 - val_loss: 0.5487 - val_accuracy: 0.7240\n",
            "Epoch 769/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4315 - accuracy: 0.7882 - val_loss: 0.5486 - val_accuracy: 0.7240\n",
            "Epoch 770/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4314 - accuracy: 0.7865 - val_loss: 0.5486 - val_accuracy: 0.7240\n",
            "Epoch 771/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4314 - accuracy: 0.7882 - val_loss: 0.5486 - val_accuracy: 0.7240\n",
            "Epoch 772/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4314 - accuracy: 0.7865 - val_loss: 0.5486 - val_accuracy: 0.7240\n",
            "Epoch 773/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4314 - accuracy: 0.7865 - val_loss: 0.5486 - val_accuracy: 0.7240\n",
            "Epoch 774/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4314 - accuracy: 0.7882 - val_loss: 0.5485 - val_accuracy: 0.7240\n",
            "Epoch 775/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4314 - accuracy: 0.7882 - val_loss: 0.5484 - val_accuracy: 0.7240\n",
            "Epoch 776/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4312 - accuracy: 0.7865 - val_loss: 0.5484 - val_accuracy: 0.7240\n",
            "Epoch 777/1000\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 0.4310 - accuracy: 0.7865 - val_loss: 0.5483 - val_accuracy: 0.7240\n",
            "Epoch 778/1000\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.4310 - accuracy: 0.7865 - val_loss: 0.5483 - val_accuracy: 0.7240\n",
            "Epoch 779/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4309 - accuracy: 0.7865 - val_loss: 0.5482 - val_accuracy: 0.7240\n",
            "Epoch 780/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4310 - accuracy: 0.7865 - val_loss: 0.5481 - val_accuracy: 0.7240\n",
            "Epoch 781/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4309 - accuracy: 0.7865 - val_loss: 0.5481 - val_accuracy: 0.7240\n",
            "Epoch 782/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4308 - accuracy: 0.7865 - val_loss: 0.5481 - val_accuracy: 0.7240\n",
            "Epoch 783/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4308 - accuracy: 0.7865 - val_loss: 0.5480 - val_accuracy: 0.7240\n",
            "Epoch 784/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4306 - accuracy: 0.7865 - val_loss: 0.5480 - val_accuracy: 0.7240\n",
            "Epoch 785/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4306 - accuracy: 0.7865 - val_loss: 0.5479 - val_accuracy: 0.7240\n",
            "Epoch 786/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4306 - accuracy: 0.7865 - val_loss: 0.5479 - val_accuracy: 0.7240\n",
            "Epoch 787/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4306 - accuracy: 0.7865 - val_loss: 0.5478 - val_accuracy: 0.7240\n",
            "Epoch 788/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4306 - accuracy: 0.7865 - val_loss: 0.5477 - val_accuracy: 0.7240\n",
            "Epoch 789/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4305 - accuracy: 0.7865 - val_loss: 0.5476 - val_accuracy: 0.7240\n",
            "Epoch 790/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4304 - accuracy: 0.7865 - val_loss: 0.5476 - val_accuracy: 0.7240\n",
            "Epoch 791/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4306 - accuracy: 0.7865 - val_loss: 0.5474 - val_accuracy: 0.7240\n",
            "Epoch 792/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4303 - accuracy: 0.7865 - val_loss: 0.5474 - val_accuracy: 0.7240\n",
            "Epoch 793/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4302 - accuracy: 0.7847 - val_loss: 0.5473 - val_accuracy: 0.7240\n",
            "Epoch 794/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4302 - accuracy: 0.7865 - val_loss: 0.5473 - val_accuracy: 0.7240\n",
            "Epoch 795/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4303 - accuracy: 0.7865 - val_loss: 0.5473 - val_accuracy: 0.7240\n",
            "Epoch 796/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4300 - accuracy: 0.7865 - val_loss: 0.5472 - val_accuracy: 0.7240\n",
            "Epoch 797/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4303 - accuracy: 0.7847 - val_loss: 0.5472 - val_accuracy: 0.7240\n",
            "Epoch 798/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4301 - accuracy: 0.7865 - val_loss: 0.5472 - val_accuracy: 0.7240\n",
            "Epoch 799/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4301 - accuracy: 0.7865 - val_loss: 0.5471 - val_accuracy: 0.7240\n",
            "Epoch 800/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4300 - accuracy: 0.7865 - val_loss: 0.5470 - val_accuracy: 0.7240\n",
            "Epoch 801/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4301 - accuracy: 0.7865 - val_loss: 0.5470 - val_accuracy: 0.7240\n",
            "Epoch 802/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4299 - accuracy: 0.7865 - val_loss: 0.5470 - val_accuracy: 0.7240\n",
            "Epoch 803/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4298 - accuracy: 0.7865 - val_loss: 0.5469 - val_accuracy: 0.7240\n",
            "Epoch 804/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4298 - accuracy: 0.7865 - val_loss: 0.5469 - val_accuracy: 0.7240\n",
            "Epoch 805/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4299 - accuracy: 0.7847 - val_loss: 0.5468 - val_accuracy: 0.7240\n",
            "Epoch 806/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4297 - accuracy: 0.7865 - val_loss: 0.5467 - val_accuracy: 0.7240\n",
            "Epoch 807/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4297 - accuracy: 0.7865 - val_loss: 0.5467 - val_accuracy: 0.7240\n",
            "Epoch 808/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4297 - accuracy: 0.7865 - val_loss: 0.5466 - val_accuracy: 0.7240\n",
            "Epoch 809/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4295 - accuracy: 0.7865 - val_loss: 0.5466 - val_accuracy: 0.7240\n",
            "Epoch 810/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4295 - accuracy: 0.7865 - val_loss: 0.5466 - val_accuracy: 0.7292\n",
            "Epoch 811/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4296 - accuracy: 0.7847 - val_loss: 0.5465 - val_accuracy: 0.7292\n",
            "Epoch 812/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4295 - accuracy: 0.7865 - val_loss: 0.5465 - val_accuracy: 0.7292\n",
            "Epoch 813/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4295 - accuracy: 0.7847 - val_loss: 0.5465 - val_accuracy: 0.7292\n",
            "Epoch 814/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4295 - accuracy: 0.7865 - val_loss: 0.5465 - val_accuracy: 0.7292\n",
            "Epoch 815/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4294 - accuracy: 0.7865 - val_loss: 0.5466 - val_accuracy: 0.7292\n",
            "Epoch 816/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4293 - accuracy: 0.7847 - val_loss: 0.5466 - val_accuracy: 0.7292\n",
            "Epoch 817/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4293 - accuracy: 0.7865 - val_loss: 0.5466 - val_accuracy: 0.7292\n",
            "Epoch 818/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4295 - accuracy: 0.7865 - val_loss: 0.5466 - val_accuracy: 0.7292\n",
            "Epoch 819/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4293 - accuracy: 0.7865 - val_loss: 0.5465 - val_accuracy: 0.7292\n",
            "Epoch 820/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4293 - accuracy: 0.7865 - val_loss: 0.5466 - val_accuracy: 0.7292\n",
            "Epoch 821/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4293 - accuracy: 0.7865 - val_loss: 0.5465 - val_accuracy: 0.7292\n",
            "Epoch 822/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4294 - accuracy: 0.7847 - val_loss: 0.5464 - val_accuracy: 0.7292\n",
            "Epoch 823/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4292 - accuracy: 0.7882 - val_loss: 0.5463 - val_accuracy: 0.7292\n",
            "Epoch 824/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4295 - accuracy: 0.7882 - val_loss: 0.5464 - val_accuracy: 0.7292\n",
            "Epoch 825/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4290 - accuracy: 0.7830 - val_loss: 0.5464 - val_accuracy: 0.7292\n",
            "Epoch 826/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4291 - accuracy: 0.7830 - val_loss: 0.5464 - val_accuracy: 0.7292\n",
            "Epoch 827/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4292 - accuracy: 0.7865 - val_loss: 0.5463 - val_accuracy: 0.7344\n",
            "Epoch 828/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4291 - accuracy: 0.7865 - val_loss: 0.5462 - val_accuracy: 0.7344\n",
            "Epoch 829/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4292 - accuracy: 0.7830 - val_loss: 0.5463 - val_accuracy: 0.7344\n",
            "Epoch 830/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4290 - accuracy: 0.7865 - val_loss: 0.5462 - val_accuracy: 0.7344\n",
            "Epoch 831/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4290 - accuracy: 0.7847 - val_loss: 0.5462 - val_accuracy: 0.7344\n",
            "Epoch 832/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4291 - accuracy: 0.7830 - val_loss: 0.5462 - val_accuracy: 0.7344\n",
            "Epoch 833/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4290 - accuracy: 0.7847 - val_loss: 0.5462 - val_accuracy: 0.7344\n",
            "Epoch 834/1000\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4289 - accuracy: 0.7830 - val_loss: 0.5462 - val_accuracy: 0.7344\n",
            "Epoch 835/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4289 - accuracy: 0.7830 - val_loss: 0.5461 - val_accuracy: 0.7344\n",
            "Epoch 836/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4290 - accuracy: 0.7847 - val_loss: 0.5460 - val_accuracy: 0.7344\n",
            "Epoch 837/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4289 - accuracy: 0.7847 - val_loss: 0.5460 - val_accuracy: 0.7344\n",
            "Epoch 838/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4288 - accuracy: 0.7847 - val_loss: 0.5460 - val_accuracy: 0.7344\n",
            "Epoch 839/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4286 - accuracy: 0.7865 - val_loss: 0.5460 - val_accuracy: 0.7344\n",
            "Epoch 840/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4286 - accuracy: 0.7865 - val_loss: 0.5460 - val_accuracy: 0.7344\n",
            "Epoch 841/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4286 - accuracy: 0.7865 - val_loss: 0.5460 - val_accuracy: 0.7344\n",
            "Epoch 842/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4286 - accuracy: 0.7865 - val_loss: 0.5460 - val_accuracy: 0.7344\n",
            "Epoch 843/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4287 - accuracy: 0.7847 - val_loss: 0.5460 - val_accuracy: 0.7344\n",
            "Epoch 844/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4285 - accuracy: 0.7865 - val_loss: 0.5460 - val_accuracy: 0.7344\n",
            "Epoch 845/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4285 - accuracy: 0.7882 - val_loss: 0.5460 - val_accuracy: 0.7344\n",
            "Epoch 846/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4286 - accuracy: 0.7865 - val_loss: 0.5459 - val_accuracy: 0.7344\n",
            "Epoch 847/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4286 - accuracy: 0.7865 - val_loss: 0.5459 - val_accuracy: 0.7344\n",
            "Epoch 848/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4284 - accuracy: 0.7865 - val_loss: 0.5460 - val_accuracy: 0.7344\n",
            "Epoch 849/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4285 - accuracy: 0.7847 - val_loss: 0.5459 - val_accuracy: 0.7396\n",
            "Epoch 850/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4285 - accuracy: 0.7865 - val_loss: 0.5459 - val_accuracy: 0.7396\n",
            "Epoch 851/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4283 - accuracy: 0.7865 - val_loss: 0.5459 - val_accuracy: 0.7396\n",
            "Epoch 852/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4284 - accuracy: 0.7847 - val_loss: 0.5458 - val_accuracy: 0.7396\n",
            "Epoch 853/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4284 - accuracy: 0.7847 - val_loss: 0.5458 - val_accuracy: 0.7396\n",
            "Epoch 854/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4283 - accuracy: 0.7847 - val_loss: 0.5458 - val_accuracy: 0.7396\n",
            "Epoch 855/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4283 - accuracy: 0.7865 - val_loss: 0.5458 - val_accuracy: 0.7396\n",
            "Epoch 856/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4284 - accuracy: 0.7882 - val_loss: 0.5457 - val_accuracy: 0.7396\n",
            "Epoch 857/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4282 - accuracy: 0.7847 - val_loss: 0.5458 - val_accuracy: 0.7396\n",
            "Epoch 858/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4283 - accuracy: 0.7847 - val_loss: 0.5458 - val_accuracy: 0.7396\n",
            "Epoch 859/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4282 - accuracy: 0.7882 - val_loss: 0.5457 - val_accuracy: 0.7396\n",
            "Epoch 860/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4284 - accuracy: 0.7830 - val_loss: 0.5457 - val_accuracy: 0.7396\n",
            "Epoch 861/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4284 - accuracy: 0.7882 - val_loss: 0.5457 - val_accuracy: 0.7396\n",
            "Epoch 862/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4283 - accuracy: 0.7847 - val_loss: 0.5457 - val_accuracy: 0.7396\n",
            "Epoch 863/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4281 - accuracy: 0.7865 - val_loss: 0.5457 - val_accuracy: 0.7396\n",
            "Epoch 864/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4280 - accuracy: 0.7882 - val_loss: 0.5457 - val_accuracy: 0.7396\n",
            "Epoch 865/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4281 - accuracy: 0.7882 - val_loss: 0.5457 - val_accuracy: 0.7396\n",
            "Epoch 866/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4282 - accuracy: 0.7847 - val_loss: 0.5457 - val_accuracy: 0.7396\n",
            "Epoch 867/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4281 - accuracy: 0.7882 - val_loss: 0.5456 - val_accuracy: 0.7396\n",
            "Epoch 868/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.7882 - val_loss: 0.5455 - val_accuracy: 0.7396\n",
            "Epoch 869/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4280 - accuracy: 0.7865 - val_loss: 0.5456 - val_accuracy: 0.7396\n",
            "Epoch 870/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4278 - accuracy: 0.7865 - val_loss: 0.5455 - val_accuracy: 0.7396\n",
            "Epoch 871/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4280 - accuracy: 0.7847 - val_loss: 0.5456 - val_accuracy: 0.7396\n",
            "Epoch 872/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.7865 - val_loss: 0.5456 - val_accuracy: 0.7396\n",
            "Epoch 873/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4280 - accuracy: 0.7882 - val_loss: 0.5455 - val_accuracy: 0.7396\n",
            "Epoch 874/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.7865 - val_loss: 0.5455 - val_accuracy: 0.7396\n",
            "Epoch 875/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4280 - accuracy: 0.7882 - val_loss: 0.5455 - val_accuracy: 0.7396\n",
            "Epoch 876/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4279 - accuracy: 0.7847 - val_loss: 0.5454 - val_accuracy: 0.7396\n",
            "Epoch 877/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4277 - accuracy: 0.7899 - val_loss: 0.5454 - val_accuracy: 0.7396\n",
            "Epoch 878/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.7847 - val_loss: 0.5454 - val_accuracy: 0.7396\n",
            "Epoch 879/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4277 - accuracy: 0.7899 - val_loss: 0.5453 - val_accuracy: 0.7396\n",
            "Epoch 880/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4278 - accuracy: 0.7865 - val_loss: 0.5453 - val_accuracy: 0.7396\n",
            "Epoch 881/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4277 - accuracy: 0.7865 - val_loss: 0.5453 - val_accuracy: 0.7396\n",
            "Epoch 882/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4277 - accuracy: 0.7847 - val_loss: 0.5454 - val_accuracy: 0.7396\n",
            "Epoch 883/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.7865 - val_loss: 0.5454 - val_accuracy: 0.7396\n",
            "Epoch 884/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4275 - accuracy: 0.7865 - val_loss: 0.5454 - val_accuracy: 0.7396\n",
            "Epoch 885/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4277 - accuracy: 0.7882 - val_loss: 0.5454 - val_accuracy: 0.7396\n",
            "Epoch 886/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4275 - accuracy: 0.7865 - val_loss: 0.5454 - val_accuracy: 0.7396\n",
            "Epoch 887/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4276 - accuracy: 0.7865 - val_loss: 0.5454 - val_accuracy: 0.7396\n",
            "Epoch 888/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4278 - accuracy: 0.7865 - val_loss: 0.5454 - val_accuracy: 0.7396\n",
            "Epoch 889/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4275 - accuracy: 0.7865 - val_loss: 0.5454 - val_accuracy: 0.7396\n",
            "Epoch 890/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4275 - accuracy: 0.7865 - val_loss: 0.5454 - val_accuracy: 0.7396\n",
            "Epoch 891/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4275 - accuracy: 0.7882 - val_loss: 0.5455 - val_accuracy: 0.7396\n",
            "Epoch 892/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4276 - accuracy: 0.7865 - val_loss: 0.5456 - val_accuracy: 0.7396\n",
            "Epoch 893/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4276 - accuracy: 0.7865 - val_loss: 0.5455 - val_accuracy: 0.7396\n",
            "Epoch 894/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4275 - accuracy: 0.7865 - val_loss: 0.5455 - val_accuracy: 0.7396\n",
            "Epoch 895/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4273 - accuracy: 0.7882 - val_loss: 0.5453 - val_accuracy: 0.7396\n",
            "Epoch 896/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4274 - accuracy: 0.7865 - val_loss: 0.5454 - val_accuracy: 0.7396\n",
            "Epoch 897/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4275 - accuracy: 0.7882 - val_loss: 0.5453 - val_accuracy: 0.7396\n",
            "Epoch 898/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4273 - accuracy: 0.7865 - val_loss: 0.5453 - val_accuracy: 0.7396\n",
            "Epoch 899/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4273 - accuracy: 0.7882 - val_loss: 0.5453 - val_accuracy: 0.7396\n",
            "Epoch 900/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4273 - accuracy: 0.7865 - val_loss: 0.5454 - val_accuracy: 0.7396\n",
            "Epoch 901/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4273 - accuracy: 0.7865 - val_loss: 0.5454 - val_accuracy: 0.7396\n",
            "Epoch 902/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4275 - accuracy: 0.7865 - val_loss: 0.5454 - val_accuracy: 0.7396\n",
            "Epoch 903/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4273 - accuracy: 0.7865 - val_loss: 0.5454 - val_accuracy: 0.7396\n",
            "Epoch 904/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4271 - accuracy: 0.7865 - val_loss: 0.5453 - val_accuracy: 0.7396\n",
            "Epoch 905/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4271 - accuracy: 0.7899 - val_loss: 0.5453 - val_accuracy: 0.7396\n",
            "Epoch 906/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4271 - accuracy: 0.7882 - val_loss: 0.5454 - val_accuracy: 0.7396\n",
            "Epoch 907/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4271 - accuracy: 0.7882 - val_loss: 0.5453 - val_accuracy: 0.7396\n",
            "Epoch 908/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4271 - accuracy: 0.7882 - val_loss: 0.5453 - val_accuracy: 0.7396\n",
            "Epoch 909/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4271 - accuracy: 0.7865 - val_loss: 0.5452 - val_accuracy: 0.7396\n",
            "Epoch 910/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4271 - accuracy: 0.7882 - val_loss: 0.5452 - val_accuracy: 0.7448\n",
            "Epoch 911/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4269 - accuracy: 0.7899 - val_loss: 0.5452 - val_accuracy: 0.7448\n",
            "Epoch 912/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4270 - accuracy: 0.7899 - val_loss: 0.5452 - val_accuracy: 0.7396\n",
            "Epoch 913/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4271 - accuracy: 0.7899 - val_loss: 0.5453 - val_accuracy: 0.7396\n",
            "Epoch 914/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4269 - accuracy: 0.7899 - val_loss: 0.5452 - val_accuracy: 0.7396\n",
            "Epoch 915/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4269 - accuracy: 0.7899 - val_loss: 0.5452 - val_accuracy: 0.7396\n",
            "Epoch 916/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4269 - accuracy: 0.7899 - val_loss: 0.5453 - val_accuracy: 0.7396\n",
            "Epoch 917/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4270 - accuracy: 0.7865 - val_loss: 0.5452 - val_accuracy: 0.7396\n",
            "Epoch 918/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4271 - accuracy: 0.7899 - val_loss: 0.5452 - val_accuracy: 0.7396\n",
            "Epoch 919/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4269 - accuracy: 0.7899 - val_loss: 0.5452 - val_accuracy: 0.7396\n",
            "Epoch 920/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4268 - accuracy: 0.7899 - val_loss: 0.5452 - val_accuracy: 0.7396\n",
            "Epoch 921/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4269 - accuracy: 0.7899 - val_loss: 0.5451 - val_accuracy: 0.7396\n",
            "Epoch 922/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4267 - accuracy: 0.7917 - val_loss: 0.5451 - val_accuracy: 0.7396\n",
            "Epoch 923/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4271 - accuracy: 0.7899 - val_loss: 0.5450 - val_accuracy: 0.7396\n",
            "Epoch 924/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4268 - accuracy: 0.7899 - val_loss: 0.5450 - val_accuracy: 0.7396\n",
            "Epoch 925/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4268 - accuracy: 0.7899 - val_loss: 0.5450 - val_accuracy: 0.7396\n",
            "Epoch 926/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4267 - accuracy: 0.7899 - val_loss: 0.5450 - val_accuracy: 0.7396\n",
            "Epoch 927/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4267 - accuracy: 0.7899 - val_loss: 0.5450 - val_accuracy: 0.7396\n",
            "Epoch 928/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4268 - accuracy: 0.7899 - val_loss: 0.5450 - val_accuracy: 0.7396\n",
            "Epoch 929/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4266 - accuracy: 0.7899 - val_loss: 0.5450 - val_accuracy: 0.7396\n",
            "Epoch 930/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4265 - accuracy: 0.7899 - val_loss: 0.5450 - val_accuracy: 0.7396\n",
            "Epoch 931/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4267 - accuracy: 0.7899 - val_loss: 0.5450 - val_accuracy: 0.7396\n",
            "Epoch 932/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4267 - accuracy: 0.7899 - val_loss: 0.5450 - val_accuracy: 0.7396\n",
            "Epoch 933/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4265 - accuracy: 0.7899 - val_loss: 0.5451 - val_accuracy: 0.7396\n",
            "Epoch 934/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4266 - accuracy: 0.7899 - val_loss: 0.5452 - val_accuracy: 0.7396\n",
            "Epoch 935/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4266 - accuracy: 0.7899 - val_loss: 0.5451 - val_accuracy: 0.7396\n",
            "Epoch 936/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4265 - accuracy: 0.7899 - val_loss: 0.5451 - val_accuracy: 0.7396\n",
            "Epoch 937/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4264 - accuracy: 0.7899 - val_loss: 0.5451 - val_accuracy: 0.7396\n",
            "Epoch 938/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4264 - accuracy: 0.7899 - val_loss: 0.5450 - val_accuracy: 0.7396\n",
            "Epoch 939/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4264 - accuracy: 0.7899 - val_loss: 0.5449 - val_accuracy: 0.7396\n",
            "Epoch 940/1000\n",
            "18/18 [==============================] - 1s 44ms/step - loss: 0.4263 - accuracy: 0.7899 - val_loss: 0.5449 - val_accuracy: 0.7396\n",
            "Epoch 941/1000\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 0.4265 - accuracy: 0.7899 - val_loss: 0.5449 - val_accuracy: 0.7396\n",
            "Epoch 942/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4263 - accuracy: 0.7899 - val_loss: 0.5449 - val_accuracy: 0.7396\n",
            "Epoch 943/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4263 - accuracy: 0.7917 - val_loss: 0.5449 - val_accuracy: 0.7396\n",
            "Epoch 944/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4265 - accuracy: 0.7899 - val_loss: 0.5447 - val_accuracy: 0.7396\n",
            "Epoch 945/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4265 - accuracy: 0.7917 - val_loss: 0.5447 - val_accuracy: 0.7396\n",
            "Epoch 946/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4262 - accuracy: 0.7882 - val_loss: 0.5447 - val_accuracy: 0.7396\n",
            "Epoch 947/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4262 - accuracy: 0.7899 - val_loss: 0.5448 - val_accuracy: 0.7396\n",
            "Epoch 948/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4263 - accuracy: 0.7882 - val_loss: 0.5448 - val_accuracy: 0.7396\n",
            "Epoch 949/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4263 - accuracy: 0.7882 - val_loss: 0.5448 - val_accuracy: 0.7396\n",
            "Epoch 950/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4262 - accuracy: 0.7882 - val_loss: 0.5447 - val_accuracy: 0.7396\n",
            "Epoch 951/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4263 - accuracy: 0.7899 - val_loss: 0.5447 - val_accuracy: 0.7396\n",
            "Epoch 952/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4261 - accuracy: 0.7899 - val_loss: 0.5446 - val_accuracy: 0.7396\n",
            "Epoch 953/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4262 - accuracy: 0.7899 - val_loss: 0.5446 - val_accuracy: 0.7396\n",
            "Epoch 954/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4262 - accuracy: 0.7917 - val_loss: 0.5445 - val_accuracy: 0.7396\n",
            "Epoch 955/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4261 - accuracy: 0.7899 - val_loss: 0.5445 - val_accuracy: 0.7396\n",
            "Epoch 956/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4260 - accuracy: 0.7899 - val_loss: 0.5444 - val_accuracy: 0.7396\n",
            "Epoch 957/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4260 - accuracy: 0.7917 - val_loss: 0.5444 - val_accuracy: 0.7396\n",
            "Epoch 958/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4260 - accuracy: 0.7899 - val_loss: 0.5443 - val_accuracy: 0.7396\n",
            "Epoch 959/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4259 - accuracy: 0.7934 - val_loss: 0.5443 - val_accuracy: 0.7396\n",
            "Epoch 960/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4261 - accuracy: 0.7917 - val_loss: 0.5443 - val_accuracy: 0.7396\n",
            "Epoch 961/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4258 - accuracy: 0.7917 - val_loss: 0.5443 - val_accuracy: 0.7396\n",
            "Epoch 962/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4258 - accuracy: 0.7899 - val_loss: 0.5442 - val_accuracy: 0.7396\n",
            "Epoch 963/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4258 - accuracy: 0.7934 - val_loss: 0.5442 - val_accuracy: 0.7396\n",
            "Epoch 964/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4258 - accuracy: 0.7934 - val_loss: 0.5443 - val_accuracy: 0.7396\n",
            "Epoch 965/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4257 - accuracy: 0.7934 - val_loss: 0.5443 - val_accuracy: 0.7396\n",
            "Epoch 966/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4259 - accuracy: 0.7917 - val_loss: 0.5442 - val_accuracy: 0.7396\n",
            "Epoch 967/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4258 - accuracy: 0.7934 - val_loss: 0.5442 - val_accuracy: 0.7396\n",
            "Epoch 968/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4256 - accuracy: 0.7934 - val_loss: 0.5442 - val_accuracy: 0.7396\n",
            "Epoch 969/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4256 - accuracy: 0.7934 - val_loss: 0.5443 - val_accuracy: 0.7396\n",
            "Epoch 970/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4257 - accuracy: 0.7917 - val_loss: 0.5442 - val_accuracy: 0.7396\n",
            "Epoch 971/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4255 - accuracy: 0.7969 - val_loss: 0.5441 - val_accuracy: 0.7396\n",
            "Epoch 972/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4254 - accuracy: 0.7969 - val_loss: 0.5441 - val_accuracy: 0.7396\n",
            "Epoch 973/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4255 - accuracy: 0.7934 - val_loss: 0.5441 - val_accuracy: 0.7396\n",
            "Epoch 974/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4256 - accuracy: 0.7986 - val_loss: 0.5439 - val_accuracy: 0.7396\n",
            "Epoch 975/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4254 - accuracy: 0.7986 - val_loss: 0.5439 - val_accuracy: 0.7396\n",
            "Epoch 976/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4253 - accuracy: 0.7969 - val_loss: 0.5438 - val_accuracy: 0.7396\n",
            "Epoch 977/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4254 - accuracy: 0.7969 - val_loss: 0.5437 - val_accuracy: 0.7396\n",
            "Epoch 978/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4252 - accuracy: 0.7969 - val_loss: 0.5437 - val_accuracy: 0.7396\n",
            "Epoch 979/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4252 - accuracy: 0.7986 - val_loss: 0.5437 - val_accuracy: 0.7396\n",
            "Epoch 980/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4252 - accuracy: 0.7986 - val_loss: 0.5436 - val_accuracy: 0.7396\n",
            "Epoch 981/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4252 - accuracy: 0.7986 - val_loss: 0.5437 - val_accuracy: 0.7396\n",
            "Epoch 982/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4252 - accuracy: 0.7986 - val_loss: 0.5437 - val_accuracy: 0.7396\n",
            "Epoch 983/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4251 - accuracy: 0.7986 - val_loss: 0.5436 - val_accuracy: 0.7396\n",
            "Epoch 984/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4251 - accuracy: 0.7986 - val_loss: 0.5437 - val_accuracy: 0.7396\n",
            "Epoch 985/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4250 - accuracy: 0.7969 - val_loss: 0.5437 - val_accuracy: 0.7396\n",
            "Epoch 986/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4249 - accuracy: 0.7986 - val_loss: 0.5437 - val_accuracy: 0.7396\n",
            "Epoch 987/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4251 - accuracy: 0.7986 - val_loss: 0.5436 - val_accuracy: 0.7396\n",
            "Epoch 988/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4250 - accuracy: 0.7986 - val_loss: 0.5435 - val_accuracy: 0.7396\n",
            "Epoch 989/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4249 - accuracy: 0.7969 - val_loss: 0.5435 - val_accuracy: 0.7396\n",
            "Epoch 990/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4248 - accuracy: 0.7986 - val_loss: 0.5435 - val_accuracy: 0.7396\n",
            "Epoch 991/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4248 - accuracy: 0.7986 - val_loss: 0.5436 - val_accuracy: 0.7396\n",
            "Epoch 992/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4249 - accuracy: 0.7986 - val_loss: 0.5436 - val_accuracy: 0.7396\n",
            "Epoch 993/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4249 - accuracy: 0.7986 - val_loss: 0.5436 - val_accuracy: 0.7396\n",
            "Epoch 994/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4247 - accuracy: 0.7986 - val_loss: 0.5436 - val_accuracy: 0.7448\n",
            "Epoch 995/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4247 - accuracy: 0.7986 - val_loss: 0.5436 - val_accuracy: 0.7448\n",
            "Epoch 996/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4246 - accuracy: 0.7986 - val_loss: 0.5436 - val_accuracy: 0.7448\n",
            "Epoch 997/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4245 - accuracy: 0.7986 - val_loss: 0.5438 - val_accuracy: 0.7448\n",
            "Epoch 998/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4246 - accuracy: 0.7986 - val_loss: 0.5437 - val_accuracy: 0.7448\n",
            "Epoch 999/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4245 - accuracy: 0.7986 - val_loss: 0.5436 - val_accuracy: 0.7448\n",
            "Epoch 1000/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4246 - accuracy: 0.7986 - val_loss: 0.5436 - val_accuracy: 0.7448\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model with 10 nodes with 4 Layers\n",
        "model_5 = Sequential([\n",
        "    #Layer 1\n",
        "    Dense(8, input_shape=(8,),activation=\"relu\"),\n",
        "\n",
        "    #Layer 3\n",
        "    Dense(8,activation=\"relu\"),\n",
        "\n",
        "    #Layer 4\n",
        "    Dense(6,activation=\"relu\"),\n",
        "\n",
        "    #Output/Final Layer\n",
        "    Dense(1,activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "model_5.compile(SGD(lr = .5), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "run_hist_6 = model_5.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEbosfEzRGEZ",
        "outputId": "774e3f1a-f677-4ae7-bbcf-ff845ffe06d9"
      },
      "id": "QEbosfEzRGEZ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "18/18 [==============================] - 1s 13ms/step - loss: 0.6868 - accuracy: 0.6441 - val_loss: 0.6961 - val_accuracy: 0.6042\n",
            "Epoch 2/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6796 - accuracy: 0.6510 - val_loss: 0.6898 - val_accuracy: 0.6406\n",
            "Epoch 3/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6729 - accuracy: 0.6545 - val_loss: 0.6841 - val_accuracy: 0.6458\n",
            "Epoch 4/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6666 - accuracy: 0.6562 - val_loss: 0.6786 - val_accuracy: 0.6458\n",
            "Epoch 5/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6606 - accuracy: 0.6528 - val_loss: 0.6735 - val_accuracy: 0.6406\n",
            "Epoch 6/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6549 - accuracy: 0.6545 - val_loss: 0.6686 - val_accuracy: 0.6458\n",
            "Epoch 7/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6491 - accuracy: 0.6545 - val_loss: 0.6639 - val_accuracy: 0.6406\n",
            "Epoch 8/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6436 - accuracy: 0.6545 - val_loss: 0.6592 - val_accuracy: 0.6406\n",
            "Epoch 9/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6385 - accuracy: 0.6545 - val_loss: 0.6545 - val_accuracy: 0.6406\n",
            "Epoch 10/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6332 - accuracy: 0.6545 - val_loss: 0.6499 - val_accuracy: 0.6406\n",
            "Epoch 11/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6280 - accuracy: 0.6545 - val_loss: 0.6455 - val_accuracy: 0.6406\n",
            "Epoch 12/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6231 - accuracy: 0.6528 - val_loss: 0.6412 - val_accuracy: 0.6406\n",
            "Epoch 13/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6180 - accuracy: 0.6528 - val_loss: 0.6369 - val_accuracy: 0.6406\n",
            "Epoch 14/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6132 - accuracy: 0.6562 - val_loss: 0.6327 - val_accuracy: 0.6406\n",
            "Epoch 15/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6082 - accuracy: 0.6545 - val_loss: 0.6285 - val_accuracy: 0.6406\n",
            "Epoch 16/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6033 - accuracy: 0.6545 - val_loss: 0.6244 - val_accuracy: 0.6406\n",
            "Epoch 17/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5985 - accuracy: 0.6580 - val_loss: 0.6204 - val_accuracy: 0.6406\n",
            "Epoch 18/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5939 - accuracy: 0.6615 - val_loss: 0.6165 - val_accuracy: 0.6510\n",
            "Epoch 19/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5893 - accuracy: 0.6736 - val_loss: 0.6127 - val_accuracy: 0.6562\n",
            "Epoch 20/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5846 - accuracy: 0.6858 - val_loss: 0.6089 - val_accuracy: 0.6771\n",
            "Epoch 21/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5802 - accuracy: 0.6962 - val_loss: 0.6053 - val_accuracy: 0.6927\n",
            "Epoch 22/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5759 - accuracy: 0.7014 - val_loss: 0.6017 - val_accuracy: 0.7083\n",
            "Epoch 23/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5716 - accuracy: 0.7083 - val_loss: 0.5982 - val_accuracy: 0.7240\n",
            "Epoch 24/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5672 - accuracy: 0.7153 - val_loss: 0.5945 - val_accuracy: 0.7292\n",
            "Epoch 25/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5630 - accuracy: 0.7170 - val_loss: 0.5909 - val_accuracy: 0.7344\n",
            "Epoch 26/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5590 - accuracy: 0.7135 - val_loss: 0.5875 - val_accuracy: 0.7344\n",
            "Epoch 27/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5548 - accuracy: 0.7240 - val_loss: 0.5841 - val_accuracy: 0.7344\n",
            "Epoch 28/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5507 - accuracy: 0.7222 - val_loss: 0.5806 - val_accuracy: 0.7292\n",
            "Epoch 29/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5467 - accuracy: 0.7274 - val_loss: 0.5773 - val_accuracy: 0.7396\n",
            "Epoch 30/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5427 - accuracy: 0.7292 - val_loss: 0.5741 - val_accuracy: 0.7396\n",
            "Epoch 31/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5389 - accuracy: 0.7292 - val_loss: 0.5709 - val_accuracy: 0.7448\n",
            "Epoch 32/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5350 - accuracy: 0.7361 - val_loss: 0.5678 - val_accuracy: 0.7552\n",
            "Epoch 33/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5315 - accuracy: 0.7396 - val_loss: 0.5647 - val_accuracy: 0.7552\n",
            "Epoch 34/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5278 - accuracy: 0.7465 - val_loss: 0.5619 - val_accuracy: 0.7500\n",
            "Epoch 35/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5245 - accuracy: 0.7500 - val_loss: 0.5591 - val_accuracy: 0.7500\n",
            "Epoch 36/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5212 - accuracy: 0.7569 - val_loss: 0.5564 - val_accuracy: 0.7500\n",
            "Epoch 37/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5180 - accuracy: 0.7622 - val_loss: 0.5537 - val_accuracy: 0.7500\n",
            "Epoch 38/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5149 - accuracy: 0.7656 - val_loss: 0.5511 - val_accuracy: 0.7552\n",
            "Epoch 39/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5118 - accuracy: 0.7674 - val_loss: 0.5485 - val_accuracy: 0.7552\n",
            "Epoch 40/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5091 - accuracy: 0.7691 - val_loss: 0.5459 - val_accuracy: 0.7552\n",
            "Epoch 41/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5064 - accuracy: 0.7708 - val_loss: 0.5436 - val_accuracy: 0.7604\n",
            "Epoch 42/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5038 - accuracy: 0.7639 - val_loss: 0.5413 - val_accuracy: 0.7656\n",
            "Epoch 43/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5013 - accuracy: 0.7674 - val_loss: 0.5392 - val_accuracy: 0.7604\n",
            "Epoch 44/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4990 - accuracy: 0.7656 - val_loss: 0.5371 - val_accuracy: 0.7656\n",
            "Epoch 45/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4968 - accuracy: 0.7674 - val_loss: 0.5351 - val_accuracy: 0.7656\n",
            "Epoch 46/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4948 - accuracy: 0.7691 - val_loss: 0.5334 - val_accuracy: 0.7656\n",
            "Epoch 47/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4929 - accuracy: 0.7743 - val_loss: 0.5318 - val_accuracy: 0.7656\n",
            "Epoch 48/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4911 - accuracy: 0.7726 - val_loss: 0.5304 - val_accuracy: 0.7656\n",
            "Epoch 49/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4896 - accuracy: 0.7726 - val_loss: 0.5288 - val_accuracy: 0.7604\n",
            "Epoch 50/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4878 - accuracy: 0.7760 - val_loss: 0.5277 - val_accuracy: 0.7552\n",
            "Epoch 51/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4864 - accuracy: 0.7760 - val_loss: 0.5265 - val_accuracy: 0.7500\n",
            "Epoch 52/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4849 - accuracy: 0.7760 - val_loss: 0.5254 - val_accuracy: 0.7500\n",
            "Epoch 53/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4838 - accuracy: 0.7726 - val_loss: 0.5243 - val_accuracy: 0.7500\n",
            "Epoch 54/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4822 - accuracy: 0.7760 - val_loss: 0.5233 - val_accuracy: 0.7500\n",
            "Epoch 55/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4810 - accuracy: 0.7726 - val_loss: 0.5223 - val_accuracy: 0.7500\n",
            "Epoch 56/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4799 - accuracy: 0.7708 - val_loss: 0.5213 - val_accuracy: 0.7500\n",
            "Epoch 57/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4788 - accuracy: 0.7708 - val_loss: 0.5204 - val_accuracy: 0.7500\n",
            "Epoch 58/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4777 - accuracy: 0.7795 - val_loss: 0.5196 - val_accuracy: 0.7500\n",
            "Epoch 59/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4765 - accuracy: 0.7743 - val_loss: 0.5187 - val_accuracy: 0.7448\n",
            "Epoch 60/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4756 - accuracy: 0.7760 - val_loss: 0.5179 - val_accuracy: 0.7448\n",
            "Epoch 61/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4745 - accuracy: 0.7778 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
            "Epoch 62/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4736 - accuracy: 0.7795 - val_loss: 0.5163 - val_accuracy: 0.7500\n",
            "Epoch 63/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4727 - accuracy: 0.7760 - val_loss: 0.5157 - val_accuracy: 0.7500\n",
            "Epoch 64/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4718 - accuracy: 0.7760 - val_loss: 0.5150 - val_accuracy: 0.7500\n",
            "Epoch 65/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4710 - accuracy: 0.7778 - val_loss: 0.5144 - val_accuracy: 0.7552\n",
            "Epoch 66/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4702 - accuracy: 0.7795 - val_loss: 0.5139 - val_accuracy: 0.7500\n",
            "Epoch 67/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4695 - accuracy: 0.7795 - val_loss: 0.5134 - val_accuracy: 0.7448\n",
            "Epoch 68/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4690 - accuracy: 0.7778 - val_loss: 0.5130 - val_accuracy: 0.7500\n",
            "Epoch 69/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4683 - accuracy: 0.7795 - val_loss: 0.5127 - val_accuracy: 0.7500\n",
            "Epoch 70/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4676 - accuracy: 0.7795 - val_loss: 0.5123 - val_accuracy: 0.7500\n",
            "Epoch 71/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4671 - accuracy: 0.7778 - val_loss: 0.5120 - val_accuracy: 0.7552\n",
            "Epoch 72/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4666 - accuracy: 0.7778 - val_loss: 0.5115 - val_accuracy: 0.7500\n",
            "Epoch 73/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4657 - accuracy: 0.7812 - val_loss: 0.5113 - val_accuracy: 0.7448\n",
            "Epoch 74/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4651 - accuracy: 0.7812 - val_loss: 0.5110 - val_accuracy: 0.7500\n",
            "Epoch 75/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4646 - accuracy: 0.7812 - val_loss: 0.5108 - val_accuracy: 0.7500\n",
            "Epoch 76/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4640 - accuracy: 0.7830 - val_loss: 0.5106 - val_accuracy: 0.7448\n",
            "Epoch 77/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4635 - accuracy: 0.7812 - val_loss: 0.5101 - val_accuracy: 0.7448\n",
            "Epoch 78/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4631 - accuracy: 0.7830 - val_loss: 0.5099 - val_accuracy: 0.7448\n",
            "Epoch 79/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4626 - accuracy: 0.7812 - val_loss: 0.5096 - val_accuracy: 0.7448\n",
            "Epoch 80/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4621 - accuracy: 0.7830 - val_loss: 0.5094 - val_accuracy: 0.7448\n",
            "Epoch 81/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4616 - accuracy: 0.7812 - val_loss: 0.5092 - val_accuracy: 0.7448\n",
            "Epoch 82/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4610 - accuracy: 0.7795 - val_loss: 0.5089 - val_accuracy: 0.7448\n",
            "Epoch 83/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4605 - accuracy: 0.7812 - val_loss: 0.5087 - val_accuracy: 0.7396\n",
            "Epoch 84/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4600 - accuracy: 0.7830 - val_loss: 0.5085 - val_accuracy: 0.7448\n",
            "Epoch 85/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4598 - accuracy: 0.7812 - val_loss: 0.5085 - val_accuracy: 0.7552\n",
            "Epoch 86/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4595 - accuracy: 0.7812 - val_loss: 0.5083 - val_accuracy: 0.7604\n",
            "Epoch 87/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4589 - accuracy: 0.7812 - val_loss: 0.5082 - val_accuracy: 0.7604\n",
            "Epoch 88/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4586 - accuracy: 0.7778 - val_loss: 0.5079 - val_accuracy: 0.7448\n",
            "Epoch 89/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4580 - accuracy: 0.7812 - val_loss: 0.5078 - val_accuracy: 0.7552\n",
            "Epoch 90/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4578 - accuracy: 0.7830 - val_loss: 0.5076 - val_accuracy: 0.7552\n",
            "Epoch 91/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4575 - accuracy: 0.7812 - val_loss: 0.5076 - val_accuracy: 0.7552\n",
            "Epoch 92/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4571 - accuracy: 0.7830 - val_loss: 0.5077 - val_accuracy: 0.7604\n",
            "Epoch 93/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4567 - accuracy: 0.7830 - val_loss: 0.5076 - val_accuracy: 0.7604\n",
            "Epoch 94/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4562 - accuracy: 0.7812 - val_loss: 0.5076 - val_accuracy: 0.7656\n",
            "Epoch 95/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4560 - accuracy: 0.7812 - val_loss: 0.5074 - val_accuracy: 0.7656\n",
            "Epoch 96/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4558 - accuracy: 0.7830 - val_loss: 0.5074 - val_accuracy: 0.7604\n",
            "Epoch 97/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4555 - accuracy: 0.7795 - val_loss: 0.5075 - val_accuracy: 0.7656\n",
            "Epoch 98/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4550 - accuracy: 0.7812 - val_loss: 0.5074 - val_accuracy: 0.7656\n",
            "Epoch 99/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4547 - accuracy: 0.7830 - val_loss: 0.5073 - val_accuracy: 0.7604\n",
            "Epoch 100/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4544 - accuracy: 0.7830 - val_loss: 0.5071 - val_accuracy: 0.7552\n",
            "Epoch 101/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4541 - accuracy: 0.7830 - val_loss: 0.5069 - val_accuracy: 0.7552\n",
            "Epoch 102/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4539 - accuracy: 0.7830 - val_loss: 0.5069 - val_accuracy: 0.7552\n",
            "Epoch 103/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4536 - accuracy: 0.7830 - val_loss: 0.5067 - val_accuracy: 0.7552\n",
            "Epoch 104/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4533 - accuracy: 0.7795 - val_loss: 0.5068 - val_accuracy: 0.7552\n",
            "Epoch 105/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4530 - accuracy: 0.7830 - val_loss: 0.5066 - val_accuracy: 0.7552\n",
            "Epoch 106/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4528 - accuracy: 0.7830 - val_loss: 0.5067 - val_accuracy: 0.7604\n",
            "Epoch 107/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4529 - accuracy: 0.7830 - val_loss: 0.5066 - val_accuracy: 0.7604\n",
            "Epoch 108/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4523 - accuracy: 0.7830 - val_loss: 0.5063 - val_accuracy: 0.7552\n",
            "Epoch 109/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4519 - accuracy: 0.7830 - val_loss: 0.5061 - val_accuracy: 0.7552\n",
            "Epoch 110/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4517 - accuracy: 0.7882 - val_loss: 0.5061 - val_accuracy: 0.7552\n",
            "Epoch 111/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4514 - accuracy: 0.7830 - val_loss: 0.5062 - val_accuracy: 0.7604\n",
            "Epoch 112/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4512 - accuracy: 0.7830 - val_loss: 0.5061 - val_accuracy: 0.7604\n",
            "Epoch 113/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4509 - accuracy: 0.7882 - val_loss: 0.5059 - val_accuracy: 0.7604\n",
            "Epoch 114/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4507 - accuracy: 0.7865 - val_loss: 0.5057 - val_accuracy: 0.7604\n",
            "Epoch 115/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.7865 - val_loss: 0.5056 - val_accuracy: 0.7604\n",
            "Epoch 116/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4501 - accuracy: 0.7847 - val_loss: 0.5054 - val_accuracy: 0.7552\n",
            "Epoch 117/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4497 - accuracy: 0.7865 - val_loss: 0.5054 - val_accuracy: 0.7552\n",
            "Epoch 118/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4495 - accuracy: 0.7865 - val_loss: 0.5052 - val_accuracy: 0.7448\n",
            "Epoch 119/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4493 - accuracy: 0.7882 - val_loss: 0.5050 - val_accuracy: 0.7448\n",
            "Epoch 120/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4493 - accuracy: 0.7847 - val_loss: 0.5050 - val_accuracy: 0.7448\n",
            "Epoch 121/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4487 - accuracy: 0.7847 - val_loss: 0.5048 - val_accuracy: 0.7448\n",
            "Epoch 122/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4484 - accuracy: 0.7882 - val_loss: 0.5047 - val_accuracy: 0.7448\n",
            "Epoch 123/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4482 - accuracy: 0.7882 - val_loss: 0.5047 - val_accuracy: 0.7448\n",
            "Epoch 124/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4479 - accuracy: 0.7865 - val_loss: 0.5048 - val_accuracy: 0.7448\n",
            "Epoch 125/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4477 - accuracy: 0.7882 - val_loss: 0.5048 - val_accuracy: 0.7500\n",
            "Epoch 126/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4475 - accuracy: 0.7934 - val_loss: 0.5047 - val_accuracy: 0.7552\n",
            "Epoch 127/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4473 - accuracy: 0.7882 - val_loss: 0.5045 - val_accuracy: 0.7500\n",
            "Epoch 128/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4471 - accuracy: 0.7899 - val_loss: 0.5045 - val_accuracy: 0.7500\n",
            "Epoch 129/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4469 - accuracy: 0.7882 - val_loss: 0.5044 - val_accuracy: 0.7552\n",
            "Epoch 130/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4466 - accuracy: 0.7882 - val_loss: 0.5044 - val_accuracy: 0.7552\n",
            "Epoch 131/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4464 - accuracy: 0.7899 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
            "Epoch 132/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4462 - accuracy: 0.7899 - val_loss: 0.5044 - val_accuracy: 0.7500\n",
            "Epoch 133/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4462 - accuracy: 0.7865 - val_loss: 0.5045 - val_accuracy: 0.7500\n",
            "Epoch 134/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4458 - accuracy: 0.7917 - val_loss: 0.5043 - val_accuracy: 0.7500\n",
            "Epoch 135/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4455 - accuracy: 0.7882 - val_loss: 0.5044 - val_accuracy: 0.7500\n",
            "Epoch 136/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4451 - accuracy: 0.7899 - val_loss: 0.5043 - val_accuracy: 0.7500\n",
            "Epoch 137/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4450 - accuracy: 0.7899 - val_loss: 0.5043 - val_accuracy: 0.7500\n",
            "Epoch 138/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4447 - accuracy: 0.7917 - val_loss: 0.5043 - val_accuracy: 0.7500\n",
            "Epoch 139/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4446 - accuracy: 0.7899 - val_loss: 0.5043 - val_accuracy: 0.7552\n",
            "Epoch 140/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4445 - accuracy: 0.7934 - val_loss: 0.5042 - val_accuracy: 0.7552\n",
            "Epoch 141/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4441 - accuracy: 0.7917 - val_loss: 0.5042 - val_accuracy: 0.7552\n",
            "Epoch 142/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4440 - accuracy: 0.7882 - val_loss: 0.5044 - val_accuracy: 0.7552\n",
            "Epoch 143/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4440 - accuracy: 0.7917 - val_loss: 0.5044 - val_accuracy: 0.7552\n",
            "Epoch 144/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4436 - accuracy: 0.7934 - val_loss: 0.5044 - val_accuracy: 0.7552\n",
            "Epoch 145/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4435 - accuracy: 0.7951 - val_loss: 0.5043 - val_accuracy: 0.7552\n",
            "Epoch 146/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4432 - accuracy: 0.7951 - val_loss: 0.5043 - val_accuracy: 0.7552\n",
            "Epoch 147/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4431 - accuracy: 0.7951 - val_loss: 0.5042 - val_accuracy: 0.7552\n",
            "Epoch 148/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4428 - accuracy: 0.7969 - val_loss: 0.5040 - val_accuracy: 0.7500\n",
            "Epoch 149/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4426 - accuracy: 0.7917 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
            "Epoch 150/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4424 - accuracy: 0.7951 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
            "Epoch 151/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4422 - accuracy: 0.7934 - val_loss: 0.5043 - val_accuracy: 0.7552\n",
            "Epoch 152/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4420 - accuracy: 0.7969 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
            "Epoch 153/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4416 - accuracy: 0.7934 - val_loss: 0.5043 - val_accuracy: 0.7552\n",
            "Epoch 154/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4418 - accuracy: 0.7969 - val_loss: 0.5044 - val_accuracy: 0.7552\n",
            "Epoch 155/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.7969 - val_loss: 0.5045 - val_accuracy: 0.7500\n",
            "Epoch 156/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4414 - accuracy: 0.7951 - val_loss: 0.5044 - val_accuracy: 0.7500\n",
            "Epoch 157/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4411 - accuracy: 0.7986 - val_loss: 0.5042 - val_accuracy: 0.7500\n",
            "Epoch 158/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4409 - accuracy: 0.7969 - val_loss: 0.5042 - val_accuracy: 0.7500\n",
            "Epoch 159/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4407 - accuracy: 0.7969 - val_loss: 0.5040 - val_accuracy: 0.7500\n",
            "Epoch 160/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4404 - accuracy: 0.7917 - val_loss: 0.5041 - val_accuracy: 0.7500\n",
            "Epoch 161/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4402 - accuracy: 0.7917 - val_loss: 0.5042 - val_accuracy: 0.7500\n",
            "Epoch 162/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.7951 - val_loss: 0.5041 - val_accuracy: 0.7500\n",
            "Epoch 163/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4400 - accuracy: 0.7951 - val_loss: 0.5042 - val_accuracy: 0.7500\n",
            "Epoch 164/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4397 - accuracy: 0.7951 - val_loss: 0.5042 - val_accuracy: 0.7500\n",
            "Epoch 165/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4396 - accuracy: 0.7969 - val_loss: 0.5042 - val_accuracy: 0.7500\n",
            "Epoch 166/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4397 - accuracy: 0.7951 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
            "Epoch 167/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4395 - accuracy: 0.7934 - val_loss: 0.5042 - val_accuracy: 0.7552\n",
            "Epoch 168/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4394 - accuracy: 0.7986 - val_loss: 0.5042 - val_accuracy: 0.7552\n",
            "Epoch 169/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4391 - accuracy: 0.7986 - val_loss: 0.5042 - val_accuracy: 0.7552\n",
            "Epoch 170/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4391 - accuracy: 0.7986 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 171/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4388 - accuracy: 0.7986 - val_loss: 0.5039 - val_accuracy: 0.7552\n",
            "Epoch 172/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4388 - accuracy: 0.7951 - val_loss: 0.5038 - val_accuracy: 0.7552\n",
            "Epoch 173/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4385 - accuracy: 0.7969 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 174/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4384 - accuracy: 0.7969 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
            "Epoch 175/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4381 - accuracy: 0.7969 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
            "Epoch 176/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4382 - accuracy: 0.7951 - val_loss: 0.5042 - val_accuracy: 0.7552\n",
            "Epoch 177/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4376 - accuracy: 0.7986 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
            "Epoch 178/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4375 - accuracy: 0.8021 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
            "Epoch 179/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4372 - accuracy: 0.8038 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 180/500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4372 - accuracy: 0.7969 - val_loss: 0.5039 - val_accuracy: 0.7552\n",
            "Epoch 181/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4373 - accuracy: 0.8003 - val_loss: 0.5038 - val_accuracy: 0.7552\n",
            "Epoch 182/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4369 - accuracy: 0.8003 - val_loss: 0.5037 - val_accuracy: 0.7552\n",
            "Epoch 183/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4366 - accuracy: 0.7951 - val_loss: 0.5038 - val_accuracy: 0.7552\n",
            "Epoch 184/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4366 - accuracy: 0.7969 - val_loss: 0.5039 - val_accuracy: 0.7604\n",
            "Epoch 185/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4365 - accuracy: 0.7951 - val_loss: 0.5041 - val_accuracy: 0.7604\n",
            "Epoch 186/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4364 - accuracy: 0.8003 - val_loss: 0.5040 - val_accuracy: 0.7604\n",
            "Epoch 187/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4363 - accuracy: 0.7969 - val_loss: 0.5041 - val_accuracy: 0.7604\n",
            "Epoch 188/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4358 - accuracy: 0.8003 - val_loss: 0.5039 - val_accuracy: 0.7604\n",
            "Epoch 189/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4358 - accuracy: 0.7969 - val_loss: 0.5041 - val_accuracy: 0.7604\n",
            "Epoch 190/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4358 - accuracy: 0.7986 - val_loss: 0.5041 - val_accuracy: 0.7604\n",
            "Epoch 191/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4358 - accuracy: 0.7986 - val_loss: 0.5039 - val_accuracy: 0.7604\n",
            "Epoch 192/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4354 - accuracy: 0.7969 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
            "Epoch 193/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4353 - accuracy: 0.7934 - val_loss: 0.5038 - val_accuracy: 0.7604\n",
            "Epoch 194/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4351 - accuracy: 0.7986 - val_loss: 0.5038 - val_accuracy: 0.7604\n",
            "Epoch 195/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4349 - accuracy: 0.7969 - val_loss: 0.5039 - val_accuracy: 0.7604\n",
            "Epoch 196/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4348 - accuracy: 0.7917 - val_loss: 0.5040 - val_accuracy: 0.7604\n",
            "Epoch 197/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4348 - accuracy: 0.7951 - val_loss: 0.5041 - val_accuracy: 0.7604\n",
            "Epoch 198/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4346 - accuracy: 0.7951 - val_loss: 0.5044 - val_accuracy: 0.7604\n",
            "Epoch 199/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4345 - accuracy: 0.7934 - val_loss: 0.5043 - val_accuracy: 0.7604\n",
            "Epoch 200/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4346 - accuracy: 0.7951 - val_loss: 0.5041 - val_accuracy: 0.7604\n",
            "Epoch 201/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4342 - accuracy: 0.7917 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 202/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4341 - accuracy: 0.7951 - val_loss: 0.5038 - val_accuracy: 0.7552\n",
            "Epoch 203/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4339 - accuracy: 0.7969 - val_loss: 0.5037 - val_accuracy: 0.7552\n",
            "Epoch 204/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4336 - accuracy: 0.7951 - val_loss: 0.5039 - val_accuracy: 0.7552\n",
            "Epoch 205/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4335 - accuracy: 0.7934 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 206/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4334 - accuracy: 0.7917 - val_loss: 0.5040 - val_accuracy: 0.7552\n",
            "Epoch 207/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4331 - accuracy: 0.7934 - val_loss: 0.5037 - val_accuracy: 0.7552\n",
            "Epoch 208/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4330 - accuracy: 0.7934 - val_loss: 0.5037 - val_accuracy: 0.7552\n",
            "Epoch 209/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4327 - accuracy: 0.7934 - val_loss: 0.5037 - val_accuracy: 0.7552\n",
            "Epoch 210/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4325 - accuracy: 0.7899 - val_loss: 0.5035 - val_accuracy: 0.7552\n",
            "Epoch 211/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4325 - accuracy: 0.7934 - val_loss: 0.5035 - val_accuracy: 0.7552\n",
            "Epoch 212/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4324 - accuracy: 0.7934 - val_loss: 0.5036 - val_accuracy: 0.7552\n",
            "Epoch 213/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4323 - accuracy: 0.7934 - val_loss: 0.5033 - val_accuracy: 0.7552\n",
            "Epoch 214/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4322 - accuracy: 0.7882 - val_loss: 0.5032 - val_accuracy: 0.7552\n",
            "Epoch 215/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4318 - accuracy: 0.7899 - val_loss: 0.5033 - val_accuracy: 0.7552\n",
            "Epoch 216/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4318 - accuracy: 0.7899 - val_loss: 0.5029 - val_accuracy: 0.7552\n",
            "Epoch 217/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4317 - accuracy: 0.7917 - val_loss: 0.5029 - val_accuracy: 0.7552\n",
            "Epoch 218/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4314 - accuracy: 0.7917 - val_loss: 0.5028 - val_accuracy: 0.7552\n",
            "Epoch 219/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4312 - accuracy: 0.7899 - val_loss: 0.5029 - val_accuracy: 0.7552\n",
            "Epoch 220/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4310 - accuracy: 0.7917 - val_loss: 0.5032 - val_accuracy: 0.7552\n",
            "Epoch 221/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4308 - accuracy: 0.7899 - val_loss: 0.5031 - val_accuracy: 0.7552\n",
            "Epoch 222/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4307 - accuracy: 0.7917 - val_loss: 0.5029 - val_accuracy: 0.7552\n",
            "Epoch 223/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4309 - accuracy: 0.7917 - val_loss: 0.5027 - val_accuracy: 0.7552\n",
            "Epoch 224/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4305 - accuracy: 0.7882 - val_loss: 0.5027 - val_accuracy: 0.7552\n",
            "Epoch 225/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4303 - accuracy: 0.7934 - val_loss: 0.5029 - val_accuracy: 0.7552\n",
            "Epoch 226/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4304 - accuracy: 0.7882 - val_loss: 0.5028 - val_accuracy: 0.7552\n",
            "Epoch 227/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4301 - accuracy: 0.7882 - val_loss: 0.5026 - val_accuracy: 0.7552\n",
            "Epoch 228/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4302 - accuracy: 0.7917 - val_loss: 0.5028 - val_accuracy: 0.7552\n",
            "Epoch 229/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4299 - accuracy: 0.7899 - val_loss: 0.5028 - val_accuracy: 0.7552\n",
            "Epoch 230/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4299 - accuracy: 0.7882 - val_loss: 0.5027 - val_accuracy: 0.7552\n",
            "Epoch 231/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4295 - accuracy: 0.7917 - val_loss: 0.5027 - val_accuracy: 0.7552\n",
            "Epoch 232/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4294 - accuracy: 0.7934 - val_loss: 0.5026 - val_accuracy: 0.7552\n",
            "Epoch 233/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4297 - accuracy: 0.7917 - val_loss: 0.5028 - val_accuracy: 0.7552\n",
            "Epoch 234/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4293 - accuracy: 0.7882 - val_loss: 0.5027 - val_accuracy: 0.7552\n",
            "Epoch 235/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4292 - accuracy: 0.7899 - val_loss: 0.5024 - val_accuracy: 0.7552\n",
            "Epoch 236/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4291 - accuracy: 0.7934 - val_loss: 0.5022 - val_accuracy: 0.7552\n",
            "Epoch 237/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4290 - accuracy: 0.7917 - val_loss: 0.5023 - val_accuracy: 0.7552\n",
            "Epoch 238/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4287 - accuracy: 0.7917 - val_loss: 0.5023 - val_accuracy: 0.7552\n",
            "Epoch 239/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4285 - accuracy: 0.7899 - val_loss: 0.5024 - val_accuracy: 0.7552\n",
            "Epoch 240/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4280 - accuracy: 0.7917 - val_loss: 0.5022 - val_accuracy: 0.7552\n",
            "Epoch 241/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4280 - accuracy: 0.7899 - val_loss: 0.5022 - val_accuracy: 0.7552\n",
            "Epoch 242/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4278 - accuracy: 0.7917 - val_loss: 0.5021 - val_accuracy: 0.7552\n",
            "Epoch 243/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4279 - accuracy: 0.7899 - val_loss: 0.5020 - val_accuracy: 0.7552\n",
            "Epoch 244/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4275 - accuracy: 0.7917 - val_loss: 0.5019 - val_accuracy: 0.7552\n",
            "Epoch 245/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4274 - accuracy: 0.7899 - val_loss: 0.5020 - val_accuracy: 0.7552\n",
            "Epoch 246/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4273 - accuracy: 0.7899 - val_loss: 0.5017 - val_accuracy: 0.7552\n",
            "Epoch 247/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4272 - accuracy: 0.7899 - val_loss: 0.5019 - val_accuracy: 0.7552\n",
            "Epoch 248/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4271 - accuracy: 0.7917 - val_loss: 0.5021 - val_accuracy: 0.7552\n",
            "Epoch 249/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4272 - accuracy: 0.7899 - val_loss: 0.5020 - val_accuracy: 0.7552\n",
            "Epoch 250/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4268 - accuracy: 0.7917 - val_loss: 0.5020 - val_accuracy: 0.7552\n",
            "Epoch 251/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4269 - accuracy: 0.7917 - val_loss: 0.5017 - val_accuracy: 0.7552\n",
            "Epoch 252/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4265 - accuracy: 0.7882 - val_loss: 0.5020 - val_accuracy: 0.7552\n",
            "Epoch 253/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4262 - accuracy: 0.7882 - val_loss: 0.5022 - val_accuracy: 0.7552\n",
            "Epoch 254/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4266 - accuracy: 0.7917 - val_loss: 0.5019 - val_accuracy: 0.7552\n",
            "Epoch 255/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4259 - accuracy: 0.7899 - val_loss: 0.5018 - val_accuracy: 0.7552\n",
            "Epoch 256/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4260 - accuracy: 0.7934 - val_loss: 0.5017 - val_accuracy: 0.7552\n",
            "Epoch 257/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4261 - accuracy: 0.7899 - val_loss: 0.5018 - val_accuracy: 0.7552\n",
            "Epoch 258/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4256 - accuracy: 0.7917 - val_loss: 0.5018 - val_accuracy: 0.7552\n",
            "Epoch 259/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4258 - accuracy: 0.7934 - val_loss: 0.5017 - val_accuracy: 0.7552\n",
            "Epoch 260/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4253 - accuracy: 0.7882 - val_loss: 0.5018 - val_accuracy: 0.7552\n",
            "Epoch 261/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4256 - accuracy: 0.7934 - val_loss: 0.5017 - val_accuracy: 0.7552\n",
            "Epoch 262/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4252 - accuracy: 0.7917 - val_loss: 0.5018 - val_accuracy: 0.7552\n",
            "Epoch 263/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4254 - accuracy: 0.7917 - val_loss: 0.5019 - val_accuracy: 0.7552\n",
            "Epoch 264/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4251 - accuracy: 0.7917 - val_loss: 0.5020 - val_accuracy: 0.7552\n",
            "Epoch 265/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4245 - accuracy: 0.7934 - val_loss: 0.5018 - val_accuracy: 0.7552\n",
            "Epoch 266/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4247 - accuracy: 0.7899 - val_loss: 0.5017 - val_accuracy: 0.7552\n",
            "Epoch 267/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4247 - accuracy: 0.7917 - val_loss: 0.5016 - val_accuracy: 0.7552\n",
            "Epoch 268/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4242 - accuracy: 0.7934 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 269/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4242 - accuracy: 0.7934 - val_loss: 0.5016 - val_accuracy: 0.7552\n",
            "Epoch 270/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4242 - accuracy: 0.7917 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 271/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4238 - accuracy: 0.7917 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
            "Epoch 272/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4237 - accuracy: 0.7917 - val_loss: 0.5017 - val_accuracy: 0.7500\n",
            "Epoch 273/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4238 - accuracy: 0.7917 - val_loss: 0.5014 - val_accuracy: 0.7552\n",
            "Epoch 274/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4235 - accuracy: 0.7934 - val_loss: 0.5016 - val_accuracy: 0.7500\n",
            "Epoch 275/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4235 - accuracy: 0.7934 - val_loss: 0.5016 - val_accuracy: 0.7552\n",
            "Epoch 276/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4233 - accuracy: 0.7882 - val_loss: 0.5018 - val_accuracy: 0.7500\n",
            "Epoch 277/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4232 - accuracy: 0.7899 - val_loss: 0.5019 - val_accuracy: 0.7552\n",
            "Epoch 278/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4232 - accuracy: 0.7899 - val_loss: 0.5018 - val_accuracy: 0.7500\n",
            "Epoch 279/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4231 - accuracy: 0.7951 - val_loss: 0.5018 - val_accuracy: 0.7500\n",
            "Epoch 280/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4229 - accuracy: 0.7951 - val_loss: 0.5020 - val_accuracy: 0.7500\n",
            "Epoch 281/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4230 - accuracy: 0.7934 - val_loss: 0.5022 - val_accuracy: 0.7500\n",
            "Epoch 282/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4229 - accuracy: 0.7934 - val_loss: 0.5024 - val_accuracy: 0.7500\n",
            "Epoch 283/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4227 - accuracy: 0.7969 - val_loss: 0.5027 - val_accuracy: 0.7500\n",
            "Epoch 284/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4226 - accuracy: 0.7951 - val_loss: 0.5024 - val_accuracy: 0.7500\n",
            "Epoch 285/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4223 - accuracy: 0.7969 - val_loss: 0.5024 - val_accuracy: 0.7500\n",
            "Epoch 286/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4224 - accuracy: 0.7951 - val_loss: 0.5027 - val_accuracy: 0.7500\n",
            "Epoch 287/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4222 - accuracy: 0.7951 - val_loss: 0.5029 - val_accuracy: 0.7500\n",
            "Epoch 288/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4222 - accuracy: 0.7934 - val_loss: 0.5028 - val_accuracy: 0.7500\n",
            "Epoch 289/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4223 - accuracy: 0.8003 - val_loss: 0.5028 - val_accuracy: 0.7500\n",
            "Epoch 290/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4219 - accuracy: 0.8021 - val_loss: 0.5029 - val_accuracy: 0.7500\n",
            "Epoch 291/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4218 - accuracy: 0.7986 - val_loss: 0.5030 - val_accuracy: 0.7500\n",
            "Epoch 292/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4217 - accuracy: 0.7951 - val_loss: 0.5026 - val_accuracy: 0.7448\n",
            "Epoch 293/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4217 - accuracy: 0.7969 - val_loss: 0.5029 - val_accuracy: 0.7448\n",
            "Epoch 294/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4216 - accuracy: 0.7986 - val_loss: 0.5028 - val_accuracy: 0.7448\n",
            "Epoch 295/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4215 - accuracy: 0.8003 - val_loss: 0.5032 - val_accuracy: 0.7500\n",
            "Epoch 296/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4213 - accuracy: 0.7969 - val_loss: 0.5032 - val_accuracy: 0.7500\n",
            "Epoch 297/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4213 - accuracy: 0.7969 - val_loss: 0.5032 - val_accuracy: 0.7448\n",
            "Epoch 298/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4209 - accuracy: 0.7969 - val_loss: 0.5034 - val_accuracy: 0.7500\n",
            "Epoch 299/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4211 - accuracy: 0.7969 - val_loss: 0.5034 - val_accuracy: 0.7500\n",
            "Epoch 300/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4209 - accuracy: 0.8003 - val_loss: 0.5035 - val_accuracy: 0.7500\n",
            "Epoch 301/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4208 - accuracy: 0.8003 - val_loss: 0.5037 - val_accuracy: 0.7448\n",
            "Epoch 302/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4207 - accuracy: 0.8003 - val_loss: 0.5038 - val_accuracy: 0.7448\n",
            "Epoch 303/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4205 - accuracy: 0.7986 - val_loss: 0.5035 - val_accuracy: 0.7396\n",
            "Epoch 304/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4204 - accuracy: 0.7986 - val_loss: 0.5036 - val_accuracy: 0.7396\n",
            "Epoch 305/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4206 - accuracy: 0.7969 - val_loss: 0.5038 - val_accuracy: 0.7396\n",
            "Epoch 306/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4205 - accuracy: 0.7969 - val_loss: 0.5039 - val_accuracy: 0.7396\n",
            "Epoch 307/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4203 - accuracy: 0.8003 - val_loss: 0.5039 - val_accuracy: 0.7396\n",
            "Epoch 308/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4201 - accuracy: 0.7986 - val_loss: 0.5040 - val_accuracy: 0.7396\n",
            "Epoch 309/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4199 - accuracy: 0.7986 - val_loss: 0.5042 - val_accuracy: 0.7500\n",
            "Epoch 310/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4199 - accuracy: 0.7969 - val_loss: 0.5042 - val_accuracy: 0.7396\n",
            "Epoch 311/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4200 - accuracy: 0.7986 - val_loss: 0.5045 - val_accuracy: 0.7500\n",
            "Epoch 312/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4201 - accuracy: 0.7986 - val_loss: 0.5046 - val_accuracy: 0.7500\n",
            "Epoch 313/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4197 - accuracy: 0.7969 - val_loss: 0.5049 - val_accuracy: 0.7552\n",
            "Epoch 314/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4195 - accuracy: 0.7986 - val_loss: 0.5048 - val_accuracy: 0.7500\n",
            "Epoch 315/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4195 - accuracy: 0.7986 - val_loss: 0.5045 - val_accuracy: 0.7396\n",
            "Epoch 316/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4194 - accuracy: 0.8003 - val_loss: 0.5044 - val_accuracy: 0.7396\n",
            "Epoch 317/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4193 - accuracy: 0.7986 - val_loss: 0.5046 - val_accuracy: 0.7396\n",
            "Epoch 318/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4192 - accuracy: 0.7969 - val_loss: 0.5049 - val_accuracy: 0.7448\n",
            "Epoch 319/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4190 - accuracy: 0.7986 - val_loss: 0.5048 - val_accuracy: 0.7396\n",
            "Epoch 320/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4189 - accuracy: 0.7969 - val_loss: 0.5050 - val_accuracy: 0.7448\n",
            "Epoch 321/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4185 - accuracy: 0.7986 - val_loss: 0.5053 - val_accuracy: 0.7448\n",
            "Epoch 322/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4190 - accuracy: 0.7986 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
            "Epoch 323/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4184 - accuracy: 0.7951 - val_loss: 0.5058 - val_accuracy: 0.7500\n",
            "Epoch 324/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4183 - accuracy: 0.7934 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
            "Epoch 325/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4181 - accuracy: 0.7951 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
            "Epoch 326/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4179 - accuracy: 0.8003 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 327/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4183 - accuracy: 0.7969 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
            "Epoch 328/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4178 - accuracy: 0.7969 - val_loss: 0.5057 - val_accuracy: 0.7396\n",
            "Epoch 329/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4180 - accuracy: 0.7969 - val_loss: 0.5059 - val_accuracy: 0.7448\n",
            "Epoch 330/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4175 - accuracy: 0.7934 - val_loss: 0.5059 - val_accuracy: 0.7396\n",
            "Epoch 331/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4174 - accuracy: 0.7969 - val_loss: 0.5061 - val_accuracy: 0.7448\n",
            "Epoch 332/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4173 - accuracy: 0.7969 - val_loss: 0.5061 - val_accuracy: 0.7396\n",
            "Epoch 333/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4175 - accuracy: 0.7951 - val_loss: 0.5061 - val_accuracy: 0.7396\n",
            "Epoch 334/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4172 - accuracy: 0.7951 - val_loss: 0.5066 - val_accuracy: 0.7500\n",
            "Epoch 335/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4172 - accuracy: 0.7969 - val_loss: 0.5069 - val_accuracy: 0.7500\n",
            "Epoch 336/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4168 - accuracy: 0.7934 - val_loss: 0.5071 - val_accuracy: 0.7500\n",
            "Epoch 337/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4167 - accuracy: 0.7969 - val_loss: 0.5071 - val_accuracy: 0.7500\n",
            "Epoch 338/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4169 - accuracy: 0.7969 - val_loss: 0.5071 - val_accuracy: 0.7500\n",
            "Epoch 339/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4166 - accuracy: 0.7951 - val_loss: 0.5073 - val_accuracy: 0.7500\n",
            "Epoch 340/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4162 - accuracy: 0.7951 - val_loss: 0.5073 - val_accuracy: 0.7500\n",
            "Epoch 341/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4163 - accuracy: 0.7969 - val_loss: 0.5077 - val_accuracy: 0.7500\n",
            "Epoch 342/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4163 - accuracy: 0.7969 - val_loss: 0.5074 - val_accuracy: 0.7500\n",
            "Epoch 343/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4163 - accuracy: 0.7986 - val_loss: 0.5075 - val_accuracy: 0.7500\n",
            "Epoch 344/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4160 - accuracy: 0.7951 - val_loss: 0.5075 - val_accuracy: 0.7500\n",
            "Epoch 345/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4159 - accuracy: 0.7986 - val_loss: 0.5074 - val_accuracy: 0.7500\n",
            "Epoch 346/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4155 - accuracy: 0.7951 - val_loss: 0.5075 - val_accuracy: 0.7500\n",
            "Epoch 347/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4154 - accuracy: 0.7986 - val_loss: 0.5076 - val_accuracy: 0.7500\n",
            "Epoch 348/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4156 - accuracy: 0.7969 - val_loss: 0.5076 - val_accuracy: 0.7500\n",
            "Epoch 349/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4154 - accuracy: 0.7986 - val_loss: 0.5078 - val_accuracy: 0.7500\n",
            "Epoch 350/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4153 - accuracy: 0.7986 - val_loss: 0.5079 - val_accuracy: 0.7500\n",
            "Epoch 351/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4150 - accuracy: 0.7969 - val_loss: 0.5083 - val_accuracy: 0.7448\n",
            "Epoch 352/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4151 - accuracy: 0.8003 - val_loss: 0.5079 - val_accuracy: 0.7500\n",
            "Epoch 353/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4153 - accuracy: 0.7986 - val_loss: 0.5076 - val_accuracy: 0.7500\n",
            "Epoch 354/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4150 - accuracy: 0.7986 - val_loss: 0.5078 - val_accuracy: 0.7500\n",
            "Epoch 355/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4147 - accuracy: 0.7951 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
            "Epoch 356/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4146 - accuracy: 0.7986 - val_loss: 0.5083 - val_accuracy: 0.7448\n",
            "Epoch 357/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4145 - accuracy: 0.7986 - val_loss: 0.5082 - val_accuracy: 0.7448\n",
            "Epoch 358/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4142 - accuracy: 0.8021 - val_loss: 0.5086 - val_accuracy: 0.7448\n",
            "Epoch 359/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4143 - accuracy: 0.8003 - val_loss: 0.5081 - val_accuracy: 0.7448\n",
            "Epoch 360/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4140 - accuracy: 0.8038 - val_loss: 0.5085 - val_accuracy: 0.7448\n",
            "Epoch 361/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4140 - accuracy: 0.7986 - val_loss: 0.5085 - val_accuracy: 0.7448\n",
            "Epoch 362/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4141 - accuracy: 0.7986 - val_loss: 0.5085 - val_accuracy: 0.7448\n",
            "Epoch 363/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4141 - accuracy: 0.8003 - val_loss: 0.5087 - val_accuracy: 0.7448\n",
            "Epoch 364/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4138 - accuracy: 0.7969 - val_loss: 0.5086 - val_accuracy: 0.7448\n",
            "Epoch 365/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4139 - accuracy: 0.7986 - val_loss: 0.5084 - val_accuracy: 0.7448\n",
            "Epoch 366/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4134 - accuracy: 0.8021 - val_loss: 0.5087 - val_accuracy: 0.7448\n",
            "Epoch 367/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4134 - accuracy: 0.7986 - val_loss: 0.5085 - val_accuracy: 0.7448\n",
            "Epoch 368/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4137 - accuracy: 0.7986 - val_loss: 0.5085 - val_accuracy: 0.7448\n",
            "Epoch 369/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4131 - accuracy: 0.8003 - val_loss: 0.5086 - val_accuracy: 0.7448\n",
            "Epoch 370/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4130 - accuracy: 0.8021 - val_loss: 0.5085 - val_accuracy: 0.7448\n",
            "Epoch 371/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4129 - accuracy: 0.7986 - val_loss: 0.5085 - val_accuracy: 0.7500\n",
            "Epoch 372/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4130 - accuracy: 0.7986 - val_loss: 0.5088 - val_accuracy: 0.7448\n",
            "Epoch 373/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4130 - accuracy: 0.7969 - val_loss: 0.5090 - val_accuracy: 0.7448\n",
            "Epoch 374/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4130 - accuracy: 0.8021 - val_loss: 0.5086 - val_accuracy: 0.7448\n",
            "Epoch 375/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4127 - accuracy: 0.8003 - val_loss: 0.5088 - val_accuracy: 0.7448\n",
            "Epoch 376/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4125 - accuracy: 0.8003 - val_loss: 0.5087 - val_accuracy: 0.7448\n",
            "Epoch 377/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4125 - accuracy: 0.8021 - val_loss: 0.5088 - val_accuracy: 0.7448\n",
            "Epoch 378/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4126 - accuracy: 0.8021 - val_loss: 0.5093 - val_accuracy: 0.7448\n",
            "Epoch 379/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4124 - accuracy: 0.8038 - val_loss: 0.5093 - val_accuracy: 0.7448\n",
            "Epoch 380/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4121 - accuracy: 0.8003 - val_loss: 0.5092 - val_accuracy: 0.7448\n",
            "Epoch 381/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4124 - accuracy: 0.8003 - val_loss: 0.5091 - val_accuracy: 0.7448\n",
            "Epoch 382/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4120 - accuracy: 0.8003 - val_loss: 0.5088 - val_accuracy: 0.7448\n",
            "Epoch 383/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4118 - accuracy: 0.7986 - val_loss: 0.5091 - val_accuracy: 0.7448\n",
            "Epoch 384/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4117 - accuracy: 0.7986 - val_loss: 0.5094 - val_accuracy: 0.7448\n",
            "Epoch 385/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4119 - accuracy: 0.8003 - val_loss: 0.5090 - val_accuracy: 0.7448\n",
            "Epoch 386/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4114 - accuracy: 0.7969 - val_loss: 0.5093 - val_accuracy: 0.7448\n",
            "Epoch 387/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4118 - accuracy: 0.7986 - val_loss: 0.5091 - val_accuracy: 0.7448\n",
            "Epoch 388/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4116 - accuracy: 0.8003 - val_loss: 0.5091 - val_accuracy: 0.7448\n",
            "Epoch 389/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4114 - accuracy: 0.7969 - val_loss: 0.5094 - val_accuracy: 0.7448\n",
            "Epoch 390/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4113 - accuracy: 0.7986 - val_loss: 0.5089 - val_accuracy: 0.7448\n",
            "Epoch 391/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4111 - accuracy: 0.7986 - val_loss: 0.5091 - val_accuracy: 0.7448\n",
            "Epoch 392/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4111 - accuracy: 0.7969 - val_loss: 0.5088 - val_accuracy: 0.7448\n",
            "Epoch 393/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4111 - accuracy: 0.7969 - val_loss: 0.5093 - val_accuracy: 0.7448\n",
            "Epoch 394/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.7986 - val_loss: 0.5091 - val_accuracy: 0.7448\n",
            "Epoch 395/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8003 - val_loss: 0.5093 - val_accuracy: 0.7448\n",
            "Epoch 396/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.7969 - val_loss: 0.5094 - val_accuracy: 0.7448\n",
            "Epoch 397/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.7986 - val_loss: 0.5092 - val_accuracy: 0.7448\n",
            "Epoch 398/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8021 - val_loss: 0.5092 - val_accuracy: 0.7448\n",
            "Epoch 399/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4100 - accuracy: 0.7986 - val_loss: 0.5093 - val_accuracy: 0.7448\n",
            "Epoch 400/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4098 - accuracy: 0.8021 - val_loss: 0.5102 - val_accuracy: 0.7448\n",
            "Epoch 401/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4101 - accuracy: 0.7969 - val_loss: 0.5101 - val_accuracy: 0.7448\n",
            "Epoch 402/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4098 - accuracy: 0.8003 - val_loss: 0.5096 - val_accuracy: 0.7448\n",
            "Epoch 403/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4096 - accuracy: 0.8003 - val_loss: 0.5096 - val_accuracy: 0.7448\n",
            "Epoch 404/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4098 - accuracy: 0.7951 - val_loss: 0.5097 - val_accuracy: 0.7448\n",
            "Epoch 405/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4093 - accuracy: 0.7969 - val_loss: 0.5098 - val_accuracy: 0.7448\n",
            "Epoch 406/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4092 - accuracy: 0.7986 - val_loss: 0.5098 - val_accuracy: 0.7448\n",
            "Epoch 407/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4096 - accuracy: 0.7951 - val_loss: 0.5100 - val_accuracy: 0.7448\n",
            "Epoch 408/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4095 - accuracy: 0.7951 - val_loss: 0.5098 - val_accuracy: 0.7448\n",
            "Epoch 409/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4090 - accuracy: 0.7969 - val_loss: 0.5097 - val_accuracy: 0.7448\n",
            "Epoch 410/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4087 - accuracy: 0.7951 - val_loss: 0.5097 - val_accuracy: 0.7448\n",
            "Epoch 411/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4089 - accuracy: 0.7986 - val_loss: 0.5102 - val_accuracy: 0.7448\n",
            "Epoch 412/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4091 - accuracy: 0.7969 - val_loss: 0.5099 - val_accuracy: 0.7448\n",
            "Epoch 413/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4086 - accuracy: 0.7917 - val_loss: 0.5102 - val_accuracy: 0.7448\n",
            "Epoch 414/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4085 - accuracy: 0.7951 - val_loss: 0.5100 - val_accuracy: 0.7448\n",
            "Epoch 415/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4084 - accuracy: 0.7969 - val_loss: 0.5102 - val_accuracy: 0.7448\n",
            "Epoch 416/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4081 - accuracy: 0.8003 - val_loss: 0.5095 - val_accuracy: 0.7448\n",
            "Epoch 417/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4082 - accuracy: 0.7934 - val_loss: 0.5097 - val_accuracy: 0.7448\n",
            "Epoch 418/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4082 - accuracy: 0.7934 - val_loss: 0.5094 - val_accuracy: 0.7448\n",
            "Epoch 419/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4081 - accuracy: 0.7951 - val_loss: 0.5098 - val_accuracy: 0.7448\n",
            "Epoch 420/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4078 - accuracy: 0.7969 - val_loss: 0.5097 - val_accuracy: 0.7448\n",
            "Epoch 421/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4079 - accuracy: 0.7917 - val_loss: 0.5100 - val_accuracy: 0.7448\n",
            "Epoch 422/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4076 - accuracy: 0.7969 - val_loss: 0.5102 - val_accuracy: 0.7448\n",
            "Epoch 423/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4076 - accuracy: 0.7986 - val_loss: 0.5099 - val_accuracy: 0.7448\n",
            "Epoch 424/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4076 - accuracy: 0.7986 - val_loss: 0.5094 - val_accuracy: 0.7448\n",
            "Epoch 425/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4074 - accuracy: 0.8003 - val_loss: 0.5097 - val_accuracy: 0.7448\n",
            "Epoch 426/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4071 - accuracy: 0.7986 - val_loss: 0.5100 - val_accuracy: 0.7448\n",
            "Epoch 427/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4073 - accuracy: 0.7951 - val_loss: 0.5102 - val_accuracy: 0.7448\n",
            "Epoch 428/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4072 - accuracy: 0.7951 - val_loss: 0.5103 - val_accuracy: 0.7448\n",
            "Epoch 429/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4069 - accuracy: 0.8003 - val_loss: 0.5099 - val_accuracy: 0.7448\n",
            "Epoch 430/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4071 - accuracy: 0.8003 - val_loss: 0.5101 - val_accuracy: 0.7448\n",
            "Epoch 431/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4068 - accuracy: 0.7969 - val_loss: 0.5097 - val_accuracy: 0.7448\n",
            "Epoch 432/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4067 - accuracy: 0.8003 - val_loss: 0.5104 - val_accuracy: 0.7448\n",
            "Epoch 433/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4066 - accuracy: 0.8021 - val_loss: 0.5096 - val_accuracy: 0.7448\n",
            "Epoch 434/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4066 - accuracy: 0.7986 - val_loss: 0.5102 - val_accuracy: 0.7448\n",
            "Epoch 435/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4064 - accuracy: 0.7969 - val_loss: 0.5102 - val_accuracy: 0.7448\n",
            "Epoch 436/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4065 - accuracy: 0.7951 - val_loss: 0.5103 - val_accuracy: 0.7448\n",
            "Epoch 437/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4062 - accuracy: 0.7986 - val_loss: 0.5104 - val_accuracy: 0.7448\n",
            "Epoch 438/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4065 - accuracy: 0.7986 - val_loss: 0.5101 - val_accuracy: 0.7448\n",
            "Epoch 439/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4062 - accuracy: 0.7986 - val_loss: 0.5102 - val_accuracy: 0.7448\n",
            "Epoch 440/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4062 - accuracy: 0.7969 - val_loss: 0.5105 - val_accuracy: 0.7448\n",
            "Epoch 441/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4060 - accuracy: 0.7986 - val_loss: 0.5106 - val_accuracy: 0.7448\n",
            "Epoch 442/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4058 - accuracy: 0.7969 - val_loss: 0.5106 - val_accuracy: 0.7448\n",
            "Epoch 443/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4058 - accuracy: 0.7969 - val_loss: 0.5107 - val_accuracy: 0.7448\n",
            "Epoch 444/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4056 - accuracy: 0.8021 - val_loss: 0.5109 - val_accuracy: 0.7448\n",
            "Epoch 445/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4058 - accuracy: 0.7986 - val_loss: 0.5113 - val_accuracy: 0.7448\n",
            "Epoch 446/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4052 - accuracy: 0.7986 - val_loss: 0.5107 - val_accuracy: 0.7448\n",
            "Epoch 447/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4054 - accuracy: 0.7986 - val_loss: 0.5109 - val_accuracy: 0.7448\n",
            "Epoch 448/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4052 - accuracy: 0.8003 - val_loss: 0.5111 - val_accuracy: 0.7448\n",
            "Epoch 449/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4053 - accuracy: 0.8003 - val_loss: 0.5105 - val_accuracy: 0.7448\n",
            "Epoch 450/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4051 - accuracy: 0.8003 - val_loss: 0.5106 - val_accuracy: 0.7448\n",
            "Epoch 451/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4050 - accuracy: 0.8038 - val_loss: 0.5108 - val_accuracy: 0.7448\n",
            "Epoch 452/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4055 - accuracy: 0.8021 - val_loss: 0.5110 - val_accuracy: 0.7448\n",
            "Epoch 453/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4050 - accuracy: 0.8021 - val_loss: 0.5112 - val_accuracy: 0.7448\n",
            "Epoch 454/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4047 - accuracy: 0.8003 - val_loss: 0.5115 - val_accuracy: 0.7448\n",
            "Epoch 455/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4052 - accuracy: 0.7986 - val_loss: 0.5117 - val_accuracy: 0.7500\n",
            "Epoch 456/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4045 - accuracy: 0.8003 - val_loss: 0.5112 - val_accuracy: 0.7448\n",
            "Epoch 457/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4045 - accuracy: 0.8038 - val_loss: 0.5110 - val_accuracy: 0.7448\n",
            "Epoch 458/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4043 - accuracy: 0.8038 - val_loss: 0.5118 - val_accuracy: 0.7448\n",
            "Epoch 459/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4047 - accuracy: 0.8038 - val_loss: 0.5108 - val_accuracy: 0.7448\n",
            "Epoch 460/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4044 - accuracy: 0.8021 - val_loss: 0.5109 - val_accuracy: 0.7448\n",
            "Epoch 461/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4044 - accuracy: 0.8038 - val_loss: 0.5114 - val_accuracy: 0.7448\n",
            "Epoch 462/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4042 - accuracy: 0.8021 - val_loss: 0.5111 - val_accuracy: 0.7448\n",
            "Epoch 463/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4039 - accuracy: 0.8021 - val_loss: 0.5113 - val_accuracy: 0.7448\n",
            "Epoch 464/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4043 - accuracy: 0.8021 - val_loss: 0.5118 - val_accuracy: 0.7448\n",
            "Epoch 465/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4039 - accuracy: 0.8021 - val_loss: 0.5120 - val_accuracy: 0.7448\n",
            "Epoch 466/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4039 - accuracy: 0.8003 - val_loss: 0.5120 - val_accuracy: 0.7448\n",
            "Epoch 467/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4034 - accuracy: 0.8021 - val_loss: 0.5121 - val_accuracy: 0.7448\n",
            "Epoch 468/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4036 - accuracy: 0.8021 - val_loss: 0.5117 - val_accuracy: 0.7448\n",
            "Epoch 469/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4036 - accuracy: 0.8021 - val_loss: 0.5121 - val_accuracy: 0.7448\n",
            "Epoch 470/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4037 - accuracy: 0.8038 - val_loss: 0.5123 - val_accuracy: 0.7448\n",
            "Epoch 471/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4035 - accuracy: 0.8021 - val_loss: 0.5120 - val_accuracy: 0.7448\n",
            "Epoch 472/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4034 - accuracy: 0.8021 - val_loss: 0.5118 - val_accuracy: 0.7448\n",
            "Epoch 473/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4033 - accuracy: 0.8003 - val_loss: 0.5122 - val_accuracy: 0.7448\n",
            "Epoch 474/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4035 - accuracy: 0.8021 - val_loss: 0.5125 - val_accuracy: 0.7500\n",
            "Epoch 475/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4029 - accuracy: 0.8056 - val_loss: 0.5121 - val_accuracy: 0.7448\n",
            "Epoch 476/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4031 - accuracy: 0.8038 - val_loss: 0.5121 - val_accuracy: 0.7448\n",
            "Epoch 477/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4030 - accuracy: 0.8021 - val_loss: 0.5123 - val_accuracy: 0.7448\n",
            "Epoch 478/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4029 - accuracy: 0.8021 - val_loss: 0.5120 - val_accuracy: 0.7448\n",
            "Epoch 479/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4029 - accuracy: 0.8038 - val_loss: 0.5126 - val_accuracy: 0.7500\n",
            "Epoch 480/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4027 - accuracy: 0.8038 - val_loss: 0.5126 - val_accuracy: 0.7448\n",
            "Epoch 481/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4027 - accuracy: 0.8038 - val_loss: 0.5121 - val_accuracy: 0.7500\n",
            "Epoch 482/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4025 - accuracy: 0.8056 - val_loss: 0.5125 - val_accuracy: 0.7500\n",
            "Epoch 483/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4024 - accuracy: 0.8038 - val_loss: 0.5122 - val_accuracy: 0.7500\n",
            "Epoch 484/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4022 - accuracy: 0.8038 - val_loss: 0.5121 - val_accuracy: 0.7448\n",
            "Epoch 485/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4025 - accuracy: 0.8021 - val_loss: 0.5126 - val_accuracy: 0.7500\n",
            "Epoch 486/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4020 - accuracy: 0.8056 - val_loss: 0.5128 - val_accuracy: 0.7500\n",
            "Epoch 487/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4021 - accuracy: 0.8038 - val_loss: 0.5132 - val_accuracy: 0.7500\n",
            "Epoch 488/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4023 - accuracy: 0.8038 - val_loss: 0.5127 - val_accuracy: 0.7500\n",
            "Epoch 489/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4020 - accuracy: 0.8021 - val_loss: 0.5127 - val_accuracy: 0.7500\n",
            "Epoch 490/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4018 - accuracy: 0.8056 - val_loss: 0.5130 - val_accuracy: 0.7396\n",
            "Epoch 491/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4019 - accuracy: 0.8038 - val_loss: 0.5133 - val_accuracy: 0.7500\n",
            "Epoch 492/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4016 - accuracy: 0.8021 - val_loss: 0.5128 - val_accuracy: 0.7448\n",
            "Epoch 493/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4018 - accuracy: 0.8056 - val_loss: 0.5134 - val_accuracy: 0.7500\n",
            "Epoch 494/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4018 - accuracy: 0.8021 - val_loss: 0.5135 - val_accuracy: 0.7500\n",
            "Epoch 495/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4011 - accuracy: 0.8056 - val_loss: 0.5131 - val_accuracy: 0.7500\n",
            "Epoch 496/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4013 - accuracy: 0.8073 - val_loss: 0.5135 - val_accuracy: 0.7500\n",
            "Epoch 497/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4013 - accuracy: 0.8038 - val_loss: 0.5138 - val_accuracy: 0.7500\n",
            "Epoch 498/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4013 - accuracy: 0.8056 - val_loss: 0.5134 - val_accuracy: 0.7500\n",
            "Epoch 499/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4010 - accuracy: 0.8056 - val_loss: 0.5137 - val_accuracy: 0.7500\n",
            "Epoch 500/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4011 - accuracy: 0.8038 - val_loss: 0.5148 - val_accuracy: 0.7552\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_4.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist_4.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "wvJCdx8jWSsk",
        "outputId": "8a9e247f-83eb-49f8-b8b8-06a26c7a9489"
      },
      "id": "wvJCdx8jWSsk",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7dd34a189f60>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_6.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist_6.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "asR0SM4hWPTW",
        "outputId": "619d4460-0a8c-4a0e-d6e5-363f4721fd6c"
      },
      "id": "asR0SM4hWPTW",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7dd34a2d30a0>"
            ]
          },
          "metadata": {},
          "execution_count": 58
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "broad-appointment",
      "metadata": {
        "id": "broad-appointment"
      },
      "source": [
        "#With the Loan_data dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2=pd.read_csv('/content/drive/MyDrive/Data Science (3rd Year 1st Sem)/loan_data.csv')\n",
        "model_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "71jSVha-Aipx",
        "outputId": "d7ff8345-2586-401d-bd59-77095d508e0d"
      },
      "id": "71jSVha-Aipx",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      credit.policy             purpose  int.rate  installment  \\\n",
              "0                 1  debt_consolidation    0.1189       829.10   \n",
              "1                 1         credit_card    0.1071       228.22   \n",
              "2                 1  debt_consolidation    0.1357       366.86   \n",
              "3                 1  debt_consolidation    0.1008       162.34   \n",
              "4                 1         credit_card    0.1426       102.92   \n",
              "...             ...                 ...       ...          ...   \n",
              "9573              0           all_other    0.1461       344.76   \n",
              "9574              0           all_other    0.1253       257.70   \n",
              "9575              0  debt_consolidation    0.1071        97.81   \n",
              "9576              0    home_improvement    0.1600       351.58   \n",
              "9577              0  debt_consolidation    0.1392       853.43   \n",
              "\n",
              "      log.annual.inc    dti  fico  days.with.cr.line  revol.bal  revol.util  \\\n",
              "0          11.350407  19.48   737        5639.958333      28854        52.1   \n",
              "1          11.082143  14.29   707        2760.000000      33623        76.7   \n",
              "2          10.373491  11.63   682        4710.000000       3511        25.6   \n",
              "3          11.350407   8.10   712        2699.958333      33667        73.2   \n",
              "4          11.299732  14.97   667        4066.000000       4740        39.5   \n",
              "...              ...    ...   ...                ...        ...         ...   \n",
              "9573       12.180755  10.39   672       10474.000000     215372        82.1   \n",
              "9574       11.141862   0.21   722        4380.000000        184         1.1   \n",
              "9575       10.596635  13.09   687        3450.041667      10036        82.9   \n",
              "9576       10.819778  19.18   692        1800.000000          0         3.2   \n",
              "9577       11.264464  16.28   732        4740.000000      37879        57.0   \n",
              "\n",
              "      inq.last.6mths  delinq.2yrs  pub.rec  not.fully.paid  \n",
              "0                  0            0        0               0  \n",
              "1                  0            0        0               0  \n",
              "2                  1            0        0               0  \n",
              "3                  1            0        0               0  \n",
              "4                  0            1        0               0  \n",
              "...              ...          ...      ...             ...  \n",
              "9573               2            0        0               1  \n",
              "9574               5            0        0               1  \n",
              "9575               8            0        0               1  \n",
              "9576               5            0        0               1  \n",
              "9577               6            0        0               1  \n",
              "\n",
              "[9578 rows x 14 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-255d26a9-7328-40c1-afb7-888cff6b3902\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>credit.policy</th>\n",
              "      <th>purpose</th>\n",
              "      <th>int.rate</th>\n",
              "      <th>installment</th>\n",
              "      <th>log.annual.inc</th>\n",
              "      <th>dti</th>\n",
              "      <th>fico</th>\n",
              "      <th>days.with.cr.line</th>\n",
              "      <th>revol.bal</th>\n",
              "      <th>revol.util</th>\n",
              "      <th>inq.last.6mths</th>\n",
              "      <th>delinq.2yrs</th>\n",
              "      <th>pub.rec</th>\n",
              "      <th>not.fully.paid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>debt_consolidation</td>\n",
              "      <td>0.1189</td>\n",
              "      <td>829.10</td>\n",
              "      <td>11.350407</td>\n",
              "      <td>19.48</td>\n",
              "      <td>737</td>\n",
              "      <td>5639.958333</td>\n",
              "      <td>28854</td>\n",
              "      <td>52.1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>credit_card</td>\n",
              "      <td>0.1071</td>\n",
              "      <td>228.22</td>\n",
              "      <td>11.082143</td>\n",
              "      <td>14.29</td>\n",
              "      <td>707</td>\n",
              "      <td>2760.000000</td>\n",
              "      <td>33623</td>\n",
              "      <td>76.7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>debt_consolidation</td>\n",
              "      <td>0.1357</td>\n",
              "      <td>366.86</td>\n",
              "      <td>10.373491</td>\n",
              "      <td>11.63</td>\n",
              "      <td>682</td>\n",
              "      <td>4710.000000</td>\n",
              "      <td>3511</td>\n",
              "      <td>25.6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>debt_consolidation</td>\n",
              "      <td>0.1008</td>\n",
              "      <td>162.34</td>\n",
              "      <td>11.350407</td>\n",
              "      <td>8.10</td>\n",
              "      <td>712</td>\n",
              "      <td>2699.958333</td>\n",
              "      <td>33667</td>\n",
              "      <td>73.2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>credit_card</td>\n",
              "      <td>0.1426</td>\n",
              "      <td>102.92</td>\n",
              "      <td>11.299732</td>\n",
              "      <td>14.97</td>\n",
              "      <td>667</td>\n",
              "      <td>4066.000000</td>\n",
              "      <td>4740</td>\n",
              "      <td>39.5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9573</th>\n",
              "      <td>0</td>\n",
              "      <td>all_other</td>\n",
              "      <td>0.1461</td>\n",
              "      <td>344.76</td>\n",
              "      <td>12.180755</td>\n",
              "      <td>10.39</td>\n",
              "      <td>672</td>\n",
              "      <td>10474.000000</td>\n",
              "      <td>215372</td>\n",
              "      <td>82.1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9574</th>\n",
              "      <td>0</td>\n",
              "      <td>all_other</td>\n",
              "      <td>0.1253</td>\n",
              "      <td>257.70</td>\n",
              "      <td>11.141862</td>\n",
              "      <td>0.21</td>\n",
              "      <td>722</td>\n",
              "      <td>4380.000000</td>\n",
              "      <td>184</td>\n",
              "      <td>1.1</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9575</th>\n",
              "      <td>0</td>\n",
              "      <td>debt_consolidation</td>\n",
              "      <td>0.1071</td>\n",
              "      <td>97.81</td>\n",
              "      <td>10.596635</td>\n",
              "      <td>13.09</td>\n",
              "      <td>687</td>\n",
              "      <td>3450.041667</td>\n",
              "      <td>10036</td>\n",
              "      <td>82.9</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9576</th>\n",
              "      <td>0</td>\n",
              "      <td>home_improvement</td>\n",
              "      <td>0.1600</td>\n",
              "      <td>351.58</td>\n",
              "      <td>10.819778</td>\n",
              "      <td>19.18</td>\n",
              "      <td>692</td>\n",
              "      <td>1800.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>3.2</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9577</th>\n",
              "      <td>0</td>\n",
              "      <td>debt_consolidation</td>\n",
              "      <td>0.1392</td>\n",
              "      <td>853.43</td>\n",
              "      <td>11.264464</td>\n",
              "      <td>16.28</td>\n",
              "      <td>732</td>\n",
              "      <td>4740.000000</td>\n",
              "      <td>37879</td>\n",
              "      <td>57.0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9578 rows  14 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-255d26a9-7328-40c1-afb7-888cff6b3902')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-255d26a9-7328-40c1-afb7-888cff6b3902 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-255d26a9-7328-40c1-afb7-888cff6b3902');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2e61d2a3-cd70-4a89-9c2f-e1b31b78cd96\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2e61d2a3-cd70-4a89-9c2f-e1b31b78cd96')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2e61d2a3-cd70-4a89-9c2f-e1b31b78cd96 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.drop(columns=\"purpose\",axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "LiyaFiOuBAmK"
      },
      "id": "LiyaFiOuBAmK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "eswb_StzAyY6",
        "outputId": "49f2bf38-86d9-47da-fb7d-abb362c5ce8a"
      },
      "id": "eswb_StzAyY6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      credit.policy  int.rate  installment  log.annual.inc    dti  fico  \\\n",
              "0                 1    0.1189       829.10       11.350407  19.48   737   \n",
              "1                 1    0.1071       228.22       11.082143  14.29   707   \n",
              "2                 1    0.1357       366.86       10.373491  11.63   682   \n",
              "3                 1    0.1008       162.34       11.350407   8.10   712   \n",
              "4                 1    0.1426       102.92       11.299732  14.97   667   \n",
              "...             ...       ...          ...             ...    ...   ...   \n",
              "9573              0    0.1461       344.76       12.180755  10.39   672   \n",
              "9574              0    0.1253       257.70       11.141862   0.21   722   \n",
              "9575              0    0.1071        97.81       10.596635  13.09   687   \n",
              "9576              0    0.1600       351.58       10.819778  19.18   692   \n",
              "9577              0    0.1392       853.43       11.264464  16.28   732   \n",
              "\n",
              "      days.with.cr.line  revol.bal  revol.util  inq.last.6mths  delinq.2yrs  \\\n",
              "0           5639.958333      28854        52.1               0            0   \n",
              "1           2760.000000      33623        76.7               0            0   \n",
              "2           4710.000000       3511        25.6               1            0   \n",
              "3           2699.958333      33667        73.2               1            0   \n",
              "4           4066.000000       4740        39.5               0            1   \n",
              "...                 ...        ...         ...             ...          ...   \n",
              "9573       10474.000000     215372        82.1               2            0   \n",
              "9574        4380.000000        184         1.1               5            0   \n",
              "9575        3450.041667      10036        82.9               8            0   \n",
              "9576        1800.000000          0         3.2               5            0   \n",
              "9577        4740.000000      37879        57.0               6            0   \n",
              "\n",
              "      pub.rec  not.fully.paid  \n",
              "0           0               0  \n",
              "1           0               0  \n",
              "2           0               0  \n",
              "3           0               0  \n",
              "4           0               0  \n",
              "...       ...             ...  \n",
              "9573        0               1  \n",
              "9574        0               1  \n",
              "9575        0               1  \n",
              "9576        0               1  \n",
              "9577        0               1  \n",
              "\n",
              "[9578 rows x 13 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eeec8ed1-541b-4eb6-8e95-24df10762fe1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>credit.policy</th>\n",
              "      <th>int.rate</th>\n",
              "      <th>installment</th>\n",
              "      <th>log.annual.inc</th>\n",
              "      <th>dti</th>\n",
              "      <th>fico</th>\n",
              "      <th>days.with.cr.line</th>\n",
              "      <th>revol.bal</th>\n",
              "      <th>revol.util</th>\n",
              "      <th>inq.last.6mths</th>\n",
              "      <th>delinq.2yrs</th>\n",
              "      <th>pub.rec</th>\n",
              "      <th>not.fully.paid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.1189</td>\n",
              "      <td>829.10</td>\n",
              "      <td>11.350407</td>\n",
              "      <td>19.48</td>\n",
              "      <td>737</td>\n",
              "      <td>5639.958333</td>\n",
              "      <td>28854</td>\n",
              "      <td>52.1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.1071</td>\n",
              "      <td>228.22</td>\n",
              "      <td>11.082143</td>\n",
              "      <td>14.29</td>\n",
              "      <td>707</td>\n",
              "      <td>2760.000000</td>\n",
              "      <td>33623</td>\n",
              "      <td>76.7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0.1357</td>\n",
              "      <td>366.86</td>\n",
              "      <td>10.373491</td>\n",
              "      <td>11.63</td>\n",
              "      <td>682</td>\n",
              "      <td>4710.000000</td>\n",
              "      <td>3511</td>\n",
              "      <td>25.6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0.1008</td>\n",
              "      <td>162.34</td>\n",
              "      <td>11.350407</td>\n",
              "      <td>8.10</td>\n",
              "      <td>712</td>\n",
              "      <td>2699.958333</td>\n",
              "      <td>33667</td>\n",
              "      <td>73.2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0.1426</td>\n",
              "      <td>102.92</td>\n",
              "      <td>11.299732</td>\n",
              "      <td>14.97</td>\n",
              "      <td>667</td>\n",
              "      <td>4066.000000</td>\n",
              "      <td>4740</td>\n",
              "      <td>39.5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9573</th>\n",
              "      <td>0</td>\n",
              "      <td>0.1461</td>\n",
              "      <td>344.76</td>\n",
              "      <td>12.180755</td>\n",
              "      <td>10.39</td>\n",
              "      <td>672</td>\n",
              "      <td>10474.000000</td>\n",
              "      <td>215372</td>\n",
              "      <td>82.1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9574</th>\n",
              "      <td>0</td>\n",
              "      <td>0.1253</td>\n",
              "      <td>257.70</td>\n",
              "      <td>11.141862</td>\n",
              "      <td>0.21</td>\n",
              "      <td>722</td>\n",
              "      <td>4380.000000</td>\n",
              "      <td>184</td>\n",
              "      <td>1.1</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9575</th>\n",
              "      <td>0</td>\n",
              "      <td>0.1071</td>\n",
              "      <td>97.81</td>\n",
              "      <td>10.596635</td>\n",
              "      <td>13.09</td>\n",
              "      <td>687</td>\n",
              "      <td>3450.041667</td>\n",
              "      <td>10036</td>\n",
              "      <td>82.9</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9576</th>\n",
              "      <td>0</td>\n",
              "      <td>0.1600</td>\n",
              "      <td>351.58</td>\n",
              "      <td>10.819778</td>\n",
              "      <td>19.18</td>\n",
              "      <td>692</td>\n",
              "      <td>1800.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>3.2</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9577</th>\n",
              "      <td>0</td>\n",
              "      <td>0.1392</td>\n",
              "      <td>853.43</td>\n",
              "      <td>11.264464</td>\n",
              "      <td>16.28</td>\n",
              "      <td>732</td>\n",
              "      <td>4740.000000</td>\n",
              "      <td>37879</td>\n",
              "      <td>57.0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9578 rows  13 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eeec8ed1-541b-4eb6-8e95-24df10762fe1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-eeec8ed1-541b-4eb6-8e95-24df10762fe1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-eeec8ed1-541b-4eb6-8e95-24df10762fe1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b71bedc0-aec2-46c1-bc63-1200b5e107cc\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b71bedc0-aec2-46c1-bc63-1200b5e107cc')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b71bedc0-aec2-46c1-bc63-1200b5e107cc button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model with two hidden layers each having 6 nodes\n",
        "model_2 = Sequential ([\n",
        "    #Layer 1\n",
        "    Dense(6, input_shape=(8,),activation=\"relu\"),\n",
        "    #Layer 2\n",
        "    Dense(4,activation=\"relu\"),\n",
        "    #Output/Final Layer\n",
        "    Dense(1,activation=\"sigmoid\")\n",
        "])"
      ],
      "metadata": {
        "id": "aBt3eJQqBGpi"
      },
      "id": "aBt3eJQqBGpi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "run_hist_7 = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47eCtF3DCPs5",
        "outputId": "575d293e-2bfb-4e55-da22-944354e61b52"
      },
      "id": "47eCtF3DCPs5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3523 - accuracy: 0.8333 - val_loss: 0.6519 - val_accuracy: 0.7448\n",
            "Epoch 2/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3521 - accuracy: 0.8333 - val_loss: 0.6515 - val_accuracy: 0.7448\n",
            "Epoch 3/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3520 - accuracy: 0.8316 - val_loss: 0.6528 - val_accuracy: 0.7448\n",
            "Epoch 4/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3517 - accuracy: 0.8351 - val_loss: 0.6544 - val_accuracy: 0.7396\n",
            "Epoch 5/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3520 - accuracy: 0.8385 - val_loss: 0.6527 - val_accuracy: 0.7448\n",
            "Epoch 6/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3519 - accuracy: 0.8281 - val_loss: 0.6499 - val_accuracy: 0.7448\n",
            "Epoch 7/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3525 - accuracy: 0.8333 - val_loss: 0.6499 - val_accuracy: 0.7448\n",
            "Epoch 8/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3519 - accuracy: 0.8351 - val_loss: 0.6528 - val_accuracy: 0.7448\n",
            "Epoch 9/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3521 - accuracy: 0.8333 - val_loss: 0.6522 - val_accuracy: 0.7448\n",
            "Epoch 10/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3522 - accuracy: 0.8385 - val_loss: 0.6532 - val_accuracy: 0.7448\n",
            "Epoch 11/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3518 - accuracy: 0.8368 - val_loss: 0.6550 - val_accuracy: 0.7396\n",
            "Epoch 12/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3518 - accuracy: 0.8333 - val_loss: 0.6539 - val_accuracy: 0.7448\n",
            "Epoch 13/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3518 - accuracy: 0.8333 - val_loss: 0.6504 - val_accuracy: 0.7448\n",
            "Epoch 14/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3515 - accuracy: 0.8420 - val_loss: 0.6511 - val_accuracy: 0.7500\n",
            "Epoch 15/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3516 - accuracy: 0.8333 - val_loss: 0.6517 - val_accuracy: 0.7448\n",
            "Epoch 16/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3518 - accuracy: 0.8368 - val_loss: 0.6530 - val_accuracy: 0.7448\n",
            "Epoch 17/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3519 - accuracy: 0.8385 - val_loss: 0.6542 - val_accuracy: 0.7500\n",
            "Epoch 18/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3516 - accuracy: 0.8333 - val_loss: 0.6563 - val_accuracy: 0.7448\n",
            "Epoch 19/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3519 - accuracy: 0.8333 - val_loss: 0.6539 - val_accuracy: 0.7396\n",
            "Epoch 20/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3521 - accuracy: 0.8385 - val_loss: 0.6531 - val_accuracy: 0.7448\n",
            "Epoch 21/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3519 - accuracy: 0.8316 - val_loss: 0.6531 - val_accuracy: 0.7500\n",
            "Epoch 22/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3522 - accuracy: 0.8316 - val_loss: 0.6532 - val_accuracy: 0.7448\n",
            "Epoch 23/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3517 - accuracy: 0.8368 - val_loss: 0.6532 - val_accuracy: 0.7448\n",
            "Epoch 24/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3516 - accuracy: 0.8368 - val_loss: 0.6533 - val_accuracy: 0.7448\n",
            "Epoch 25/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3522 - accuracy: 0.8368 - val_loss: 0.6532 - val_accuracy: 0.7448\n",
            "Epoch 26/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3514 - accuracy: 0.8368 - val_loss: 0.6533 - val_accuracy: 0.7500\n",
            "Epoch 27/500\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 0.3518 - accuracy: 0.8333 - val_loss: 0.6534 - val_accuracy: 0.7448\n",
            "Epoch 28/500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3517 - accuracy: 0.8351 - val_loss: 0.6534 - val_accuracy: 0.7500\n",
            "Epoch 29/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3524 - accuracy: 0.8333 - val_loss: 0.6536 - val_accuracy: 0.7448\n",
            "Epoch 30/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3513 - accuracy: 0.8333 - val_loss: 0.6545 - val_accuracy: 0.7448\n",
            "Epoch 31/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3513 - accuracy: 0.8351 - val_loss: 0.6521 - val_accuracy: 0.7448\n",
            "Epoch 32/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3515 - accuracy: 0.8368 - val_loss: 0.6538 - val_accuracy: 0.7396\n",
            "Epoch 33/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3515 - accuracy: 0.8316 - val_loss: 0.6526 - val_accuracy: 0.7448\n",
            "Epoch 34/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3514 - accuracy: 0.8368 - val_loss: 0.6507 - val_accuracy: 0.7448\n",
            "Epoch 35/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3514 - accuracy: 0.8403 - val_loss: 0.6516 - val_accuracy: 0.7500\n",
            "Epoch 36/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3513 - accuracy: 0.8420 - val_loss: 0.6519 - val_accuracy: 0.7500\n",
            "Epoch 37/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3516 - accuracy: 0.8368 - val_loss: 0.6514 - val_accuracy: 0.7500\n",
            "Epoch 38/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3511 - accuracy: 0.8420 - val_loss: 0.6545 - val_accuracy: 0.7500\n",
            "Epoch 39/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3522 - accuracy: 0.8368 - val_loss: 0.6553 - val_accuracy: 0.7448\n",
            "Epoch 40/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3517 - accuracy: 0.8368 - val_loss: 0.6541 - val_accuracy: 0.7500\n",
            "Epoch 41/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3516 - accuracy: 0.8368 - val_loss: 0.6532 - val_accuracy: 0.7500\n",
            "Epoch 42/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3514 - accuracy: 0.8351 - val_loss: 0.6547 - val_accuracy: 0.7500\n",
            "Epoch 43/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3515 - accuracy: 0.8316 - val_loss: 0.6522 - val_accuracy: 0.7500\n",
            "Epoch 44/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3510 - accuracy: 0.8351 - val_loss: 0.6507 - val_accuracy: 0.7448\n",
            "Epoch 45/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3515 - accuracy: 0.8368 - val_loss: 0.6526 - val_accuracy: 0.7448\n",
            "Epoch 46/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3512 - accuracy: 0.8403 - val_loss: 0.6549 - val_accuracy: 0.7500\n",
            "Epoch 47/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3515 - accuracy: 0.8368 - val_loss: 0.6545 - val_accuracy: 0.7500\n",
            "Epoch 48/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3514 - accuracy: 0.8351 - val_loss: 0.6551 - val_accuracy: 0.7448\n",
            "Epoch 49/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3514 - accuracy: 0.8333 - val_loss: 0.6555 - val_accuracy: 0.7448\n",
            "Epoch 50/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3516 - accuracy: 0.8368 - val_loss: 0.6549 - val_accuracy: 0.7500\n",
            "Epoch 51/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3512 - accuracy: 0.8316 - val_loss: 0.6537 - val_accuracy: 0.7448\n",
            "Epoch 52/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3515 - accuracy: 0.8299 - val_loss: 0.6510 - val_accuracy: 0.7448\n",
            "Epoch 53/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3517 - accuracy: 0.8385 - val_loss: 0.6530 - val_accuracy: 0.7500\n",
            "Epoch 54/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3514 - accuracy: 0.8333 - val_loss: 0.6535 - val_accuracy: 0.7448\n",
            "Epoch 55/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3520 - accuracy: 0.8351 - val_loss: 0.6524 - val_accuracy: 0.7448\n",
            "Epoch 56/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3518 - accuracy: 0.8403 - val_loss: 0.6533 - val_accuracy: 0.7448\n",
            "Epoch 57/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3511 - accuracy: 0.8403 - val_loss: 0.6543 - val_accuracy: 0.7500\n",
            "Epoch 58/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3518 - accuracy: 0.8385 - val_loss: 0.6564 - val_accuracy: 0.7448\n",
            "Epoch 59/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3511 - accuracy: 0.8403 - val_loss: 0.6570 - val_accuracy: 0.7448\n",
            "Epoch 60/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3510 - accuracy: 0.8316 - val_loss: 0.6546 - val_accuracy: 0.7448\n",
            "Epoch 61/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3512 - accuracy: 0.8351 - val_loss: 0.6540 - val_accuracy: 0.7448\n",
            "Epoch 62/500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3511 - accuracy: 0.8316 - val_loss: 0.6532 - val_accuracy: 0.7448\n",
            "Epoch 63/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3513 - accuracy: 0.8455 - val_loss: 0.6554 - val_accuracy: 0.7448\n",
            "Epoch 64/500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3513 - accuracy: 0.8333 - val_loss: 0.6532 - val_accuracy: 0.7500\n",
            "Epoch 65/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3517 - accuracy: 0.8368 - val_loss: 0.6506 - val_accuracy: 0.7500\n",
            "Epoch 66/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3514 - accuracy: 0.8368 - val_loss: 0.6500 - val_accuracy: 0.7500\n",
            "Epoch 67/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3509 - accuracy: 0.8368 - val_loss: 0.6520 - val_accuracy: 0.7448\n",
            "Epoch 68/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3516 - accuracy: 0.8385 - val_loss: 0.6532 - val_accuracy: 0.7448\n",
            "Epoch 69/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3512 - accuracy: 0.8368 - val_loss: 0.6526 - val_accuracy: 0.7500\n",
            "Epoch 70/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3509 - accuracy: 0.8351 - val_loss: 0.6533 - val_accuracy: 0.7500\n",
            "Epoch 71/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3508 - accuracy: 0.8351 - val_loss: 0.6530 - val_accuracy: 0.7448\n",
            "Epoch 72/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3514 - accuracy: 0.8403 - val_loss: 0.6556 - val_accuracy: 0.7500\n",
            "Epoch 73/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3513 - accuracy: 0.8368 - val_loss: 0.6571 - val_accuracy: 0.7448\n",
            "Epoch 74/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3513 - accuracy: 0.8333 - val_loss: 0.6566 - val_accuracy: 0.7396\n",
            "Epoch 75/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3513 - accuracy: 0.8351 - val_loss: 0.6567 - val_accuracy: 0.7448\n",
            "Epoch 76/500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3514 - accuracy: 0.8316 - val_loss: 0.6567 - val_accuracy: 0.7448\n",
            "Epoch 77/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3512 - accuracy: 0.8299 - val_loss: 0.6543 - val_accuracy: 0.7500\n",
            "Epoch 78/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3511 - accuracy: 0.8333 - val_loss: 0.6545 - val_accuracy: 0.7448\n",
            "Epoch 79/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3508 - accuracy: 0.8403 - val_loss: 0.6570 - val_accuracy: 0.7448\n",
            "Epoch 80/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3510 - accuracy: 0.8385 - val_loss: 0.6564 - val_accuracy: 0.7396\n",
            "Epoch 81/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3513 - accuracy: 0.8333 - val_loss: 0.6563 - val_accuracy: 0.7396\n",
            "Epoch 82/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3508 - accuracy: 0.8403 - val_loss: 0.6562 - val_accuracy: 0.7396\n",
            "Epoch 83/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3508 - accuracy: 0.8368 - val_loss: 0.6558 - val_accuracy: 0.7448\n",
            "Epoch 84/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3509 - accuracy: 0.8403 - val_loss: 0.6569 - val_accuracy: 0.7448\n",
            "Epoch 85/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3513 - accuracy: 0.8368 - val_loss: 0.6561 - val_accuracy: 0.7396\n",
            "Epoch 86/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3509 - accuracy: 0.8385 - val_loss: 0.6557 - val_accuracy: 0.7396\n",
            "Epoch 87/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3512 - accuracy: 0.8385 - val_loss: 0.6554 - val_accuracy: 0.7500\n",
            "Epoch 88/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3514 - accuracy: 0.8351 - val_loss: 0.6565 - val_accuracy: 0.7448\n",
            "Epoch 89/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3512 - accuracy: 0.8420 - val_loss: 0.6573 - val_accuracy: 0.7448\n",
            "Epoch 90/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3511 - accuracy: 0.8351 - val_loss: 0.6568 - val_accuracy: 0.7448\n",
            "Epoch 91/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3514 - accuracy: 0.8368 - val_loss: 0.6573 - val_accuracy: 0.7448\n",
            "Epoch 92/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3513 - accuracy: 0.8385 - val_loss: 0.6561 - val_accuracy: 0.7448\n",
            "Epoch 93/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3510 - accuracy: 0.8368 - val_loss: 0.6549 - val_accuracy: 0.7500\n",
            "Epoch 94/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3515 - accuracy: 0.8368 - val_loss: 0.6550 - val_accuracy: 0.7500\n",
            "Epoch 95/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3511 - accuracy: 0.8385 - val_loss: 0.6545 - val_accuracy: 0.7500\n",
            "Epoch 96/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3512 - accuracy: 0.8316 - val_loss: 0.6536 - val_accuracy: 0.7500\n",
            "Epoch 97/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3508 - accuracy: 0.8368 - val_loss: 0.6533 - val_accuracy: 0.7500\n",
            "Epoch 98/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3510 - accuracy: 0.8403 - val_loss: 0.6540 - val_accuracy: 0.7500\n",
            "Epoch 99/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3509 - accuracy: 0.8351 - val_loss: 0.6543 - val_accuracy: 0.7500\n",
            "Epoch 100/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3507 - accuracy: 0.8333 - val_loss: 0.6571 - val_accuracy: 0.7448\n",
            "Epoch 101/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3514 - accuracy: 0.8316 - val_loss: 0.6556 - val_accuracy: 0.7500\n",
            "Epoch 102/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3509 - accuracy: 0.8420 - val_loss: 0.6583 - val_accuracy: 0.7448\n",
            "Epoch 103/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3519 - accuracy: 0.8403 - val_loss: 0.6584 - val_accuracy: 0.7448\n",
            "Epoch 104/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3510 - accuracy: 0.8316 - val_loss: 0.6563 - val_accuracy: 0.7500\n",
            "Epoch 105/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3514 - accuracy: 0.8333 - val_loss: 0.6584 - val_accuracy: 0.7448\n",
            "Epoch 106/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3508 - accuracy: 0.8368 - val_loss: 0.6567 - val_accuracy: 0.7500\n",
            "Epoch 107/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3506 - accuracy: 0.8403 - val_loss: 0.6582 - val_accuracy: 0.7448\n",
            "Epoch 108/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3508 - accuracy: 0.8333 - val_loss: 0.6594 - val_accuracy: 0.7448\n",
            "Epoch 109/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3512 - accuracy: 0.8299 - val_loss: 0.6567 - val_accuracy: 0.7448\n",
            "Epoch 110/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3511 - accuracy: 0.8351 - val_loss: 0.6558 - val_accuracy: 0.7500\n",
            "Epoch 111/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3508 - accuracy: 0.8368 - val_loss: 0.6564 - val_accuracy: 0.7500\n",
            "Epoch 112/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3505 - accuracy: 0.8368 - val_loss: 0.6553 - val_accuracy: 0.7500\n",
            "Epoch 113/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3512 - accuracy: 0.8385 - val_loss: 0.6560 - val_accuracy: 0.7448\n",
            "Epoch 114/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3514 - accuracy: 0.8333 - val_loss: 0.6553 - val_accuracy: 0.7500\n",
            "Epoch 115/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3507 - accuracy: 0.8368 - val_loss: 0.6567 - val_accuracy: 0.7448\n",
            "Epoch 116/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3506 - accuracy: 0.8368 - val_loss: 0.6562 - val_accuracy: 0.7500\n",
            "Epoch 117/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3507 - accuracy: 0.8351 - val_loss: 0.6567 - val_accuracy: 0.7500\n",
            "Epoch 118/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3508 - accuracy: 0.8351 - val_loss: 0.6567 - val_accuracy: 0.7500\n",
            "Epoch 119/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3509 - accuracy: 0.8351 - val_loss: 0.6572 - val_accuracy: 0.7500\n",
            "Epoch 120/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3513 - accuracy: 0.8368 - val_loss: 0.6572 - val_accuracy: 0.7448\n",
            "Epoch 121/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3508 - accuracy: 0.8385 - val_loss: 0.6583 - val_accuracy: 0.7448\n",
            "Epoch 122/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3511 - accuracy: 0.8299 - val_loss: 0.6569 - val_accuracy: 0.7500\n",
            "Epoch 123/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3502 - accuracy: 0.8333 - val_loss: 0.6585 - val_accuracy: 0.7448\n",
            "Epoch 124/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3509 - accuracy: 0.8385 - val_loss: 0.6574 - val_accuracy: 0.7448\n",
            "Epoch 125/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3508 - accuracy: 0.8368 - val_loss: 0.6573 - val_accuracy: 0.7500\n",
            "Epoch 126/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3507 - accuracy: 0.8351 - val_loss: 0.6572 - val_accuracy: 0.7500\n",
            "Epoch 127/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3509 - accuracy: 0.8299 - val_loss: 0.6558 - val_accuracy: 0.7552\n",
            "Epoch 128/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3507 - accuracy: 0.8316 - val_loss: 0.6570 - val_accuracy: 0.7500\n",
            "Epoch 129/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3507 - accuracy: 0.8368 - val_loss: 0.6575 - val_accuracy: 0.7448\n",
            "Epoch 130/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3510 - accuracy: 0.8368 - val_loss: 0.6556 - val_accuracy: 0.7552\n",
            "Epoch 131/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3511 - accuracy: 0.8316 - val_loss: 0.6547 - val_accuracy: 0.7500\n",
            "Epoch 132/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3502 - accuracy: 0.8403 - val_loss: 0.6596 - val_accuracy: 0.7448\n",
            "Epoch 133/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3505 - accuracy: 0.8333 - val_loss: 0.6582 - val_accuracy: 0.7500\n",
            "Epoch 134/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3504 - accuracy: 0.8316 - val_loss: 0.6556 - val_accuracy: 0.7552\n",
            "Epoch 135/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3509 - accuracy: 0.8385 - val_loss: 0.6560 - val_accuracy: 0.7552\n",
            "Epoch 136/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3504 - accuracy: 0.8368 - val_loss: 0.6575 - val_accuracy: 0.7552\n",
            "Epoch 137/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3505 - accuracy: 0.8351 - val_loss: 0.6585 - val_accuracy: 0.7448\n",
            "Epoch 138/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3506 - accuracy: 0.8316 - val_loss: 0.6549 - val_accuracy: 0.7500\n",
            "Epoch 139/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3512 - accuracy: 0.8368 - val_loss: 0.6566 - val_accuracy: 0.7500\n",
            "Epoch 140/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3513 - accuracy: 0.8333 - val_loss: 0.6552 - val_accuracy: 0.7500\n",
            "Epoch 141/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3511 - accuracy: 0.8333 - val_loss: 0.6540 - val_accuracy: 0.7500\n",
            "Epoch 142/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3506 - accuracy: 0.8385 - val_loss: 0.6577 - val_accuracy: 0.7552\n",
            "Epoch 143/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3506 - accuracy: 0.8385 - val_loss: 0.6565 - val_accuracy: 0.7552\n",
            "Epoch 144/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3506 - accuracy: 0.8333 - val_loss: 0.6597 - val_accuracy: 0.7448\n",
            "Epoch 145/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3508 - accuracy: 0.8316 - val_loss: 0.6594 - val_accuracy: 0.7448\n",
            "Epoch 146/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3510 - accuracy: 0.8351 - val_loss: 0.6561 - val_accuracy: 0.7552\n",
            "Epoch 147/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3504 - accuracy: 0.8351 - val_loss: 0.6567 - val_accuracy: 0.7552\n",
            "Epoch 148/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3505 - accuracy: 0.8316 - val_loss: 0.6571 - val_accuracy: 0.7552\n",
            "Epoch 149/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3508 - accuracy: 0.8368 - val_loss: 0.6583 - val_accuracy: 0.7500\n",
            "Epoch 150/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3512 - accuracy: 0.8368 - val_loss: 0.6585 - val_accuracy: 0.7500\n",
            "Epoch 151/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3509 - accuracy: 0.8316 - val_loss: 0.6575 - val_accuracy: 0.7552\n",
            "Epoch 152/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3506 - accuracy: 0.8299 - val_loss: 0.6556 - val_accuracy: 0.7552\n",
            "Epoch 153/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3508 - accuracy: 0.8351 - val_loss: 0.6567 - val_accuracy: 0.7500\n",
            "Epoch 154/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3507 - accuracy: 0.8368 - val_loss: 0.6555 - val_accuracy: 0.7552\n",
            "Epoch 155/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3504 - accuracy: 0.8333 - val_loss: 0.6585 - val_accuracy: 0.7552\n",
            "Epoch 156/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3507 - accuracy: 0.8385 - val_loss: 0.6587 - val_accuracy: 0.7552\n",
            "Epoch 157/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3505 - accuracy: 0.8385 - val_loss: 0.6599 - val_accuracy: 0.7448\n",
            "Epoch 158/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3502 - accuracy: 0.8351 - val_loss: 0.6599 - val_accuracy: 0.7448\n",
            "Epoch 159/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3514 - accuracy: 0.8316 - val_loss: 0.6578 - val_accuracy: 0.7500\n",
            "Epoch 160/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3509 - accuracy: 0.8351 - val_loss: 0.6568 - val_accuracy: 0.7552\n",
            "Epoch 161/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3506 - accuracy: 0.8351 - val_loss: 0.6586 - val_accuracy: 0.7500\n",
            "Epoch 162/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3505 - accuracy: 0.8333 - val_loss: 0.6587 - val_accuracy: 0.7500\n",
            "Epoch 163/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3509 - accuracy: 0.8385 - val_loss: 0.6576 - val_accuracy: 0.7500\n",
            "Epoch 164/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3505 - accuracy: 0.8333 - val_loss: 0.6548 - val_accuracy: 0.7500\n",
            "Epoch 165/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3505 - accuracy: 0.8368 - val_loss: 0.6542 - val_accuracy: 0.7552\n",
            "Epoch 166/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3508 - accuracy: 0.8351 - val_loss: 0.6578 - val_accuracy: 0.7552\n",
            "Epoch 167/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3501 - accuracy: 0.8333 - val_loss: 0.6566 - val_accuracy: 0.7552\n",
            "Epoch 168/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3506 - accuracy: 0.8333 - val_loss: 0.6583 - val_accuracy: 0.7552\n",
            "Epoch 169/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3507 - accuracy: 0.8351 - val_loss: 0.6562 - val_accuracy: 0.7500\n",
            "Epoch 170/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3504 - accuracy: 0.8385 - val_loss: 0.6561 - val_accuracy: 0.7552\n",
            "Epoch 171/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3505 - accuracy: 0.8385 - val_loss: 0.6569 - val_accuracy: 0.7552\n",
            "Epoch 172/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3504 - accuracy: 0.8351 - val_loss: 0.6560 - val_accuracy: 0.7552\n",
            "Epoch 173/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3510 - accuracy: 0.8368 - val_loss: 0.6577 - val_accuracy: 0.7552\n",
            "Epoch 174/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3510 - accuracy: 0.8368 - val_loss: 0.6591 - val_accuracy: 0.7552\n",
            "Epoch 175/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3508 - accuracy: 0.8333 - val_loss: 0.6594 - val_accuracy: 0.7500\n",
            "Epoch 176/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3501 - accuracy: 0.8351 - val_loss: 0.6589 - val_accuracy: 0.7552\n",
            "Epoch 177/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3504 - accuracy: 0.8351 - val_loss: 0.6587 - val_accuracy: 0.7552\n",
            "Epoch 178/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3505 - accuracy: 0.8264 - val_loss: 0.6576 - val_accuracy: 0.7500\n",
            "Epoch 179/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3508 - accuracy: 0.8403 - val_loss: 0.6569 - val_accuracy: 0.7552\n",
            "Epoch 180/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3508 - accuracy: 0.8351 - val_loss: 0.6578 - val_accuracy: 0.7552\n",
            "Epoch 181/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3506 - accuracy: 0.8316 - val_loss: 0.6559 - val_accuracy: 0.7552\n",
            "Epoch 182/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3506 - accuracy: 0.8316 - val_loss: 0.6565 - val_accuracy: 0.7552\n",
            "Epoch 183/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3505 - accuracy: 0.8316 - val_loss: 0.6555 - val_accuracy: 0.7552\n",
            "Epoch 184/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3504 - accuracy: 0.8299 - val_loss: 0.6551 - val_accuracy: 0.7552\n",
            "Epoch 185/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3502 - accuracy: 0.8351 - val_loss: 0.6546 - val_accuracy: 0.7500\n",
            "Epoch 186/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3509 - accuracy: 0.8368 - val_loss: 0.6571 - val_accuracy: 0.7552\n",
            "Epoch 187/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3505 - accuracy: 0.8333 - val_loss: 0.6576 - val_accuracy: 0.7552\n",
            "Epoch 188/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3507 - accuracy: 0.8368 - val_loss: 0.6593 - val_accuracy: 0.7500\n",
            "Epoch 189/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3509 - accuracy: 0.8351 - val_loss: 0.6620 - val_accuracy: 0.7448\n",
            "Epoch 190/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3508 - accuracy: 0.8333 - val_loss: 0.6608 - val_accuracy: 0.7500\n",
            "Epoch 191/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3502 - accuracy: 0.8385 - val_loss: 0.6612 - val_accuracy: 0.7500\n",
            "Epoch 192/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3505 - accuracy: 0.8316 - val_loss: 0.6576 - val_accuracy: 0.7552\n",
            "Epoch 193/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3500 - accuracy: 0.8351 - val_loss: 0.6588 - val_accuracy: 0.7500\n",
            "Epoch 194/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3502 - accuracy: 0.8316 - val_loss: 0.6591 - val_accuracy: 0.7500\n",
            "Epoch 195/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3504 - accuracy: 0.8351 - val_loss: 0.6603 - val_accuracy: 0.7500\n",
            "Epoch 196/500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3501 - accuracy: 0.8281 - val_loss: 0.6574 - val_accuracy: 0.7552\n",
            "Epoch 197/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3504 - accuracy: 0.8316 - val_loss: 0.6580 - val_accuracy: 0.7552\n",
            "Epoch 198/500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3503 - accuracy: 0.8368 - val_loss: 0.6585 - val_accuracy: 0.7552\n",
            "Epoch 199/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3507 - accuracy: 0.8316 - val_loss: 0.6600 - val_accuracy: 0.7500\n",
            "Epoch 200/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3501 - accuracy: 0.8351 - val_loss: 0.6573 - val_accuracy: 0.7552\n",
            "Epoch 201/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3499 - accuracy: 0.8351 - val_loss: 0.6555 - val_accuracy: 0.7552\n",
            "Epoch 202/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3504 - accuracy: 0.8368 - val_loss: 0.6586 - val_accuracy: 0.7500\n",
            "Epoch 203/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3507 - accuracy: 0.8351 - val_loss: 0.6580 - val_accuracy: 0.7552\n",
            "Epoch 204/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3501 - accuracy: 0.8333 - val_loss: 0.6578 - val_accuracy: 0.7552\n",
            "Epoch 205/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3502 - accuracy: 0.8351 - val_loss: 0.6564 - val_accuracy: 0.7552\n",
            "Epoch 206/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3502 - accuracy: 0.8351 - val_loss: 0.6551 - val_accuracy: 0.7604\n",
            "Epoch 207/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3498 - accuracy: 0.8351 - val_loss: 0.6580 - val_accuracy: 0.7552\n",
            "Epoch 208/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3500 - accuracy: 0.8351 - val_loss: 0.6590 - val_accuracy: 0.7552\n",
            "Epoch 209/500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3503 - accuracy: 0.8351 - val_loss: 0.6580 - val_accuracy: 0.7552\n",
            "Epoch 210/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3503 - accuracy: 0.8368 - val_loss: 0.6596 - val_accuracy: 0.7500\n",
            "Epoch 211/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3501 - accuracy: 0.8351 - val_loss: 0.6592 - val_accuracy: 0.7552\n",
            "Epoch 212/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3502 - accuracy: 0.8351 - val_loss: 0.6587 - val_accuracy: 0.7552\n",
            "Epoch 213/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3498 - accuracy: 0.8299 - val_loss: 0.6601 - val_accuracy: 0.7500\n",
            "Epoch 214/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3498 - accuracy: 0.8316 - val_loss: 0.6601 - val_accuracy: 0.7500\n",
            "Epoch 215/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3505 - accuracy: 0.8351 - val_loss: 0.6618 - val_accuracy: 0.7500\n",
            "Epoch 216/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3502 - accuracy: 0.8316 - val_loss: 0.6609 - val_accuracy: 0.7500\n",
            "Epoch 217/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3501 - accuracy: 0.8333 - val_loss: 0.6640 - val_accuracy: 0.7448\n",
            "Epoch 218/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3501 - accuracy: 0.8281 - val_loss: 0.6599 - val_accuracy: 0.7552\n",
            "Epoch 219/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3500 - accuracy: 0.8333 - val_loss: 0.6584 - val_accuracy: 0.7552\n",
            "Epoch 220/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3506 - accuracy: 0.8316 - val_loss: 0.6573 - val_accuracy: 0.7552\n",
            "Epoch 221/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3504 - accuracy: 0.8333 - val_loss: 0.6592 - val_accuracy: 0.7552\n",
            "Epoch 222/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3501 - accuracy: 0.8351 - val_loss: 0.6596 - val_accuracy: 0.7552\n",
            "Epoch 223/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3503 - accuracy: 0.8351 - val_loss: 0.6606 - val_accuracy: 0.7500\n",
            "Epoch 224/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3506 - accuracy: 0.8333 - val_loss: 0.6617 - val_accuracy: 0.7500\n",
            "Epoch 225/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3504 - accuracy: 0.8333 - val_loss: 0.6603 - val_accuracy: 0.7500\n",
            "Epoch 226/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3509 - accuracy: 0.8351 - val_loss: 0.6602 - val_accuracy: 0.7500\n",
            "Epoch 227/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3504 - accuracy: 0.8333 - val_loss: 0.6585 - val_accuracy: 0.7552\n",
            "Epoch 228/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3499 - accuracy: 0.8316 - val_loss: 0.6606 - val_accuracy: 0.7500\n",
            "Epoch 229/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3502 - accuracy: 0.8368 - val_loss: 0.6611 - val_accuracy: 0.7500\n",
            "Epoch 230/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3501 - accuracy: 0.8351 - val_loss: 0.6599 - val_accuracy: 0.7500\n",
            "Epoch 231/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3497 - accuracy: 0.8333 - val_loss: 0.6605 - val_accuracy: 0.7500\n",
            "Epoch 232/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3503 - accuracy: 0.8333 - val_loss: 0.6597 - val_accuracy: 0.7552\n",
            "Epoch 233/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3504 - accuracy: 0.8316 - val_loss: 0.6588 - val_accuracy: 0.7552\n",
            "Epoch 234/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3504 - accuracy: 0.8351 - val_loss: 0.6607 - val_accuracy: 0.7500\n",
            "Epoch 235/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3503 - accuracy: 0.8351 - val_loss: 0.6600 - val_accuracy: 0.7500\n",
            "Epoch 236/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3493 - accuracy: 0.8351 - val_loss: 0.6599 - val_accuracy: 0.7500\n",
            "Epoch 237/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3505 - accuracy: 0.8368 - val_loss: 0.6615 - val_accuracy: 0.7500\n",
            "Epoch 238/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3503 - accuracy: 0.8333 - val_loss: 0.6598 - val_accuracy: 0.7552\n",
            "Epoch 239/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3503 - accuracy: 0.8368 - val_loss: 0.6599 - val_accuracy: 0.7552\n",
            "Epoch 240/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3498 - accuracy: 0.8368 - val_loss: 0.6613 - val_accuracy: 0.7500\n",
            "Epoch 241/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3501 - accuracy: 0.8333 - val_loss: 0.6597 - val_accuracy: 0.7552\n",
            "Epoch 242/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3500 - accuracy: 0.8368 - val_loss: 0.6598 - val_accuracy: 0.7500\n",
            "Epoch 243/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3497 - accuracy: 0.8333 - val_loss: 0.6599 - val_accuracy: 0.7500\n",
            "Epoch 244/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3494 - accuracy: 0.8333 - val_loss: 0.6598 - val_accuracy: 0.7552\n",
            "Epoch 245/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3500 - accuracy: 0.8333 - val_loss: 0.6603 - val_accuracy: 0.7552\n",
            "Epoch 246/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3499 - accuracy: 0.8333 - val_loss: 0.6601 - val_accuracy: 0.7552\n",
            "Epoch 247/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3507 - accuracy: 0.8351 - val_loss: 0.6610 - val_accuracy: 0.7500\n",
            "Epoch 248/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3501 - accuracy: 0.8333 - val_loss: 0.6609 - val_accuracy: 0.7500\n",
            "Epoch 249/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3500 - accuracy: 0.8316 - val_loss: 0.6581 - val_accuracy: 0.7552\n",
            "Epoch 250/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3496 - accuracy: 0.8368 - val_loss: 0.6615 - val_accuracy: 0.7500\n",
            "Epoch 251/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3502 - accuracy: 0.8333 - val_loss: 0.6628 - val_accuracy: 0.7500\n",
            "Epoch 252/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3498 - accuracy: 0.8299 - val_loss: 0.6607 - val_accuracy: 0.7552\n",
            "Epoch 253/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3501 - accuracy: 0.8385 - val_loss: 0.6617 - val_accuracy: 0.7500\n",
            "Epoch 254/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3500 - accuracy: 0.8299 - val_loss: 0.6602 - val_accuracy: 0.7552\n",
            "Epoch 255/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3501 - accuracy: 0.8333 - val_loss: 0.6618 - val_accuracy: 0.7500\n",
            "Epoch 256/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3498 - accuracy: 0.8351 - val_loss: 0.6620 - val_accuracy: 0.7500\n",
            "Epoch 257/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3499 - accuracy: 0.8333 - val_loss: 0.6614 - val_accuracy: 0.7500\n",
            "Epoch 258/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3497 - accuracy: 0.8351 - val_loss: 0.6635 - val_accuracy: 0.7448\n",
            "Epoch 259/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3503 - accuracy: 0.8316 - val_loss: 0.6615 - val_accuracy: 0.7500\n",
            "Epoch 260/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3501 - accuracy: 0.8316 - val_loss: 0.6606 - val_accuracy: 0.7552\n",
            "Epoch 261/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3497 - accuracy: 0.8351 - val_loss: 0.6616 - val_accuracy: 0.7500\n",
            "Epoch 262/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3501 - accuracy: 0.8368 - val_loss: 0.6641 - val_accuracy: 0.7500\n",
            "Epoch 263/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3499 - accuracy: 0.8333 - val_loss: 0.6636 - val_accuracy: 0.7500\n",
            "Epoch 264/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3500 - accuracy: 0.8281 - val_loss: 0.6604 - val_accuracy: 0.7552\n",
            "Epoch 265/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3503 - accuracy: 0.8299 - val_loss: 0.6600 - val_accuracy: 0.7552\n",
            "Epoch 266/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3500 - accuracy: 0.8368 - val_loss: 0.6613 - val_accuracy: 0.7500\n",
            "Epoch 267/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3496 - accuracy: 0.8333 - val_loss: 0.6603 - val_accuracy: 0.7552\n",
            "Epoch 268/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3497 - accuracy: 0.8368 - val_loss: 0.6604 - val_accuracy: 0.7552\n",
            "Epoch 269/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3498 - accuracy: 0.8333 - val_loss: 0.6622 - val_accuracy: 0.7500\n",
            "Epoch 270/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3502 - accuracy: 0.8316 - val_loss: 0.6610 - val_accuracy: 0.7500\n",
            "Epoch 271/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3501 - accuracy: 0.8333 - val_loss: 0.6598 - val_accuracy: 0.7552\n",
            "Epoch 272/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3502 - accuracy: 0.8351 - val_loss: 0.6630 - val_accuracy: 0.7500\n",
            "Epoch 273/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3497 - accuracy: 0.8316 - val_loss: 0.6610 - val_accuracy: 0.7500\n",
            "Epoch 274/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3502 - accuracy: 0.8351 - val_loss: 0.6610 - val_accuracy: 0.7500\n",
            "Epoch 275/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3501 - accuracy: 0.8333 - val_loss: 0.6616 - val_accuracy: 0.7500\n",
            "Epoch 276/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3503 - accuracy: 0.8351 - val_loss: 0.6609 - val_accuracy: 0.7552\n",
            "Epoch 277/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3501 - accuracy: 0.8316 - val_loss: 0.6594 - val_accuracy: 0.7552\n",
            "Epoch 278/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3495 - accuracy: 0.8333 - val_loss: 0.6607 - val_accuracy: 0.7500\n",
            "Epoch 279/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3501 - accuracy: 0.8368 - val_loss: 0.6615 - val_accuracy: 0.7500\n",
            "Epoch 280/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3496 - accuracy: 0.8316 - val_loss: 0.6595 - val_accuracy: 0.7552\n",
            "Epoch 281/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3498 - accuracy: 0.8333 - val_loss: 0.6588 - val_accuracy: 0.7552\n",
            "Epoch 282/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3500 - accuracy: 0.8368 - val_loss: 0.6618 - val_accuracy: 0.7500\n",
            "Epoch 283/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3498 - accuracy: 0.8351 - val_loss: 0.6625 - val_accuracy: 0.7500\n",
            "Epoch 284/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3499 - accuracy: 0.8351 - val_loss: 0.6620 - val_accuracy: 0.7500\n",
            "Epoch 285/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3498 - accuracy: 0.8316 - val_loss: 0.6608 - val_accuracy: 0.7448\n",
            "Epoch 286/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3498 - accuracy: 0.8316 - val_loss: 0.6607 - val_accuracy: 0.7500\n",
            "Epoch 287/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3494 - accuracy: 0.8403 - val_loss: 0.6622 - val_accuracy: 0.7500\n",
            "Epoch 288/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3500 - accuracy: 0.8333 - val_loss: 0.6622 - val_accuracy: 0.7500\n",
            "Epoch 289/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3500 - accuracy: 0.8316 - val_loss: 0.6589 - val_accuracy: 0.7552\n",
            "Epoch 290/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3499 - accuracy: 0.8351 - val_loss: 0.6615 - val_accuracy: 0.7552\n",
            "Epoch 291/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3498 - accuracy: 0.8333 - val_loss: 0.6609 - val_accuracy: 0.7552\n",
            "Epoch 292/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3499 - accuracy: 0.8333 - val_loss: 0.6619 - val_accuracy: 0.7500\n",
            "Epoch 293/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3495 - accuracy: 0.8316 - val_loss: 0.6614 - val_accuracy: 0.7448\n",
            "Epoch 294/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3498 - accuracy: 0.8368 - val_loss: 0.6632 - val_accuracy: 0.7500\n",
            "Epoch 295/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3502 - accuracy: 0.8333 - val_loss: 0.6627 - val_accuracy: 0.7500\n",
            "Epoch 296/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3498 - accuracy: 0.8316 - val_loss: 0.6584 - val_accuracy: 0.7552\n",
            "Epoch 297/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3501 - accuracy: 0.8368 - val_loss: 0.6587 - val_accuracy: 0.7500\n",
            "Epoch 298/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3496 - accuracy: 0.8368 - val_loss: 0.6600 - val_accuracy: 0.7448\n",
            "Epoch 299/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3496 - accuracy: 0.8351 - val_loss: 0.6601 - val_accuracy: 0.7552\n",
            "Epoch 300/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3498 - accuracy: 0.8368 - val_loss: 0.6607 - val_accuracy: 0.7552\n",
            "Epoch 301/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3494 - accuracy: 0.8351 - val_loss: 0.6630 - val_accuracy: 0.7500\n",
            "Epoch 302/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3499 - accuracy: 0.8351 - val_loss: 0.6633 - val_accuracy: 0.7500\n",
            "Epoch 303/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3501 - accuracy: 0.8316 - val_loss: 0.6613 - val_accuracy: 0.7552\n",
            "Epoch 304/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3498 - accuracy: 0.8299 - val_loss: 0.6602 - val_accuracy: 0.7552\n",
            "Epoch 305/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3499 - accuracy: 0.8368 - val_loss: 0.6635 - val_accuracy: 0.7500\n",
            "Epoch 306/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3496 - accuracy: 0.8385 - val_loss: 0.6612 - val_accuracy: 0.7552\n",
            "Epoch 307/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3495 - accuracy: 0.8333 - val_loss: 0.6636 - val_accuracy: 0.7500\n",
            "Epoch 308/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3499 - accuracy: 0.8351 - val_loss: 0.6630 - val_accuracy: 0.7500\n",
            "Epoch 309/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3494 - accuracy: 0.8351 - val_loss: 0.6611 - val_accuracy: 0.7448\n",
            "Epoch 310/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3499 - accuracy: 0.8385 - val_loss: 0.6605 - val_accuracy: 0.7552\n",
            "Epoch 311/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3499 - accuracy: 0.8368 - val_loss: 0.6625 - val_accuracy: 0.7500\n",
            "Epoch 312/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3501 - accuracy: 0.8385 - val_loss: 0.6625 - val_accuracy: 0.7552\n",
            "Epoch 313/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3496 - accuracy: 0.8351 - val_loss: 0.6633 - val_accuracy: 0.7500\n",
            "Epoch 314/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3497 - accuracy: 0.8368 - val_loss: 0.6631 - val_accuracy: 0.7500\n",
            "Epoch 315/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3501 - accuracy: 0.8333 - val_loss: 0.6632 - val_accuracy: 0.7500\n",
            "Epoch 316/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3495 - accuracy: 0.8351 - val_loss: 0.6644 - val_accuracy: 0.7500\n",
            "Epoch 317/500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3500 - accuracy: 0.8351 - val_loss: 0.6653 - val_accuracy: 0.7500\n",
            "Epoch 318/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3493 - accuracy: 0.8368 - val_loss: 0.6640 - val_accuracy: 0.7448\n",
            "Epoch 319/500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3501 - accuracy: 0.8351 - val_loss: 0.6613 - val_accuracy: 0.7448\n",
            "Epoch 320/500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3502 - accuracy: 0.8333 - val_loss: 0.6613 - val_accuracy: 0.7448\n",
            "Epoch 321/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3491 - accuracy: 0.8333 - val_loss: 0.6619 - val_accuracy: 0.7552\n",
            "Epoch 322/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3496 - accuracy: 0.8351 - val_loss: 0.6637 - val_accuracy: 0.7500\n",
            "Epoch 323/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3496 - accuracy: 0.8368 - val_loss: 0.6625 - val_accuracy: 0.7552\n",
            "Epoch 324/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3500 - accuracy: 0.8316 - val_loss: 0.6632 - val_accuracy: 0.7500\n",
            "Epoch 325/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3496 - accuracy: 0.8351 - val_loss: 0.6631 - val_accuracy: 0.7500\n",
            "Epoch 326/500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3497 - accuracy: 0.8333 - val_loss: 0.6637 - val_accuracy: 0.7500\n",
            "Epoch 327/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3495 - accuracy: 0.8351 - val_loss: 0.6608 - val_accuracy: 0.7500\n",
            "Epoch 328/500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3493 - accuracy: 0.8351 - val_loss: 0.6612 - val_accuracy: 0.7500\n",
            "Epoch 329/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3496 - accuracy: 0.8368 - val_loss: 0.6624 - val_accuracy: 0.7500\n",
            "Epoch 330/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3496 - accuracy: 0.8368 - val_loss: 0.6644 - val_accuracy: 0.7500\n",
            "Epoch 331/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3493 - accuracy: 0.8351 - val_loss: 0.6645 - val_accuracy: 0.7500\n",
            "Epoch 332/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3497 - accuracy: 0.8333 - val_loss: 0.6637 - val_accuracy: 0.7500\n",
            "Epoch 333/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3495 - accuracy: 0.8351 - val_loss: 0.6639 - val_accuracy: 0.7500\n",
            "Epoch 334/500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3494 - accuracy: 0.8368 - val_loss: 0.6636 - val_accuracy: 0.7500\n",
            "Epoch 335/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3496 - accuracy: 0.8299 - val_loss: 0.6612 - val_accuracy: 0.7552\n",
            "Epoch 336/500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3499 - accuracy: 0.8316 - val_loss: 0.6628 - val_accuracy: 0.7500\n",
            "Epoch 337/500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3496 - accuracy: 0.8351 - val_loss: 0.6598 - val_accuracy: 0.7500\n",
            "Epoch 338/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3498 - accuracy: 0.8368 - val_loss: 0.6623 - val_accuracy: 0.7500\n",
            "Epoch 339/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3497 - accuracy: 0.8368 - val_loss: 0.6609 - val_accuracy: 0.7552\n",
            "Epoch 340/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3493 - accuracy: 0.8351 - val_loss: 0.6631 - val_accuracy: 0.7500\n",
            "Epoch 341/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3494 - accuracy: 0.8351 - val_loss: 0.6616 - val_accuracy: 0.7552\n",
            "Epoch 342/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3495 - accuracy: 0.8368 - val_loss: 0.6634 - val_accuracy: 0.7500\n",
            "Epoch 343/500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3495 - accuracy: 0.8368 - val_loss: 0.6636 - val_accuracy: 0.7500\n",
            "Epoch 344/500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3492 - accuracy: 0.8385 - val_loss: 0.6636 - val_accuracy: 0.7500\n",
            "Epoch 345/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3496 - accuracy: 0.8351 - val_loss: 0.6637 - val_accuracy: 0.7500\n",
            "Epoch 346/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3494 - accuracy: 0.8368 - val_loss: 0.6660 - val_accuracy: 0.7500\n",
            "Epoch 347/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3502 - accuracy: 0.8281 - val_loss: 0.6626 - val_accuracy: 0.7500\n",
            "Epoch 348/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3491 - accuracy: 0.8333 - val_loss: 0.6620 - val_accuracy: 0.7552\n",
            "Epoch 349/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3495 - accuracy: 0.8368 - val_loss: 0.6617 - val_accuracy: 0.7552\n",
            "Epoch 350/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3495 - accuracy: 0.8403 - val_loss: 0.6635 - val_accuracy: 0.7500\n",
            "Epoch 351/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3498 - accuracy: 0.8368 - val_loss: 0.6633 - val_accuracy: 0.7500\n",
            "Epoch 352/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3490 - accuracy: 0.8351 - val_loss: 0.6631 - val_accuracy: 0.7500\n",
            "Epoch 353/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3494 - accuracy: 0.8351 - val_loss: 0.6625 - val_accuracy: 0.7552\n",
            "Epoch 354/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3488 - accuracy: 0.8368 - val_loss: 0.6646 - val_accuracy: 0.7500\n",
            "Epoch 355/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3497 - accuracy: 0.8333 - val_loss: 0.6636 - val_accuracy: 0.7500\n",
            "Epoch 356/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3495 - accuracy: 0.8333 - val_loss: 0.6630 - val_accuracy: 0.7552\n",
            "Epoch 357/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3493 - accuracy: 0.8351 - val_loss: 0.6627 - val_accuracy: 0.7552\n",
            "Epoch 358/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3496 - accuracy: 0.8385 - val_loss: 0.6628 - val_accuracy: 0.7552\n",
            "Epoch 359/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3495 - accuracy: 0.8333 - val_loss: 0.6622 - val_accuracy: 0.7552\n",
            "Epoch 360/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3489 - accuracy: 0.8403 - val_loss: 0.6667 - val_accuracy: 0.7500\n",
            "Epoch 361/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3494 - accuracy: 0.8368 - val_loss: 0.6664 - val_accuracy: 0.7500\n",
            "Epoch 362/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3501 - accuracy: 0.8316 - val_loss: 0.6632 - val_accuracy: 0.7500\n",
            "Epoch 363/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3496 - accuracy: 0.8351 - val_loss: 0.6636 - val_accuracy: 0.7500\n",
            "Epoch 364/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3497 - accuracy: 0.8368 - val_loss: 0.6635 - val_accuracy: 0.7500\n",
            "Epoch 365/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3499 - accuracy: 0.8351 - val_loss: 0.6635 - val_accuracy: 0.7500\n",
            "Epoch 366/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3493 - accuracy: 0.8351 - val_loss: 0.6611 - val_accuracy: 0.7552\n",
            "Epoch 367/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3489 - accuracy: 0.8368 - val_loss: 0.6632 - val_accuracy: 0.7500\n",
            "Epoch 368/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3494 - accuracy: 0.8333 - val_loss: 0.6629 - val_accuracy: 0.7552\n",
            "Epoch 369/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3495 - accuracy: 0.8316 - val_loss: 0.6629 - val_accuracy: 0.7552\n",
            "Epoch 370/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3496 - accuracy: 0.8333 - val_loss: 0.6615 - val_accuracy: 0.7500\n",
            "Epoch 371/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3493 - accuracy: 0.8385 - val_loss: 0.6617 - val_accuracy: 0.7552\n",
            "Epoch 372/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3492 - accuracy: 0.8368 - val_loss: 0.6623 - val_accuracy: 0.7552\n",
            "Epoch 373/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3493 - accuracy: 0.8299 - val_loss: 0.6637 - val_accuracy: 0.7552\n",
            "Epoch 374/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3492 - accuracy: 0.8368 - val_loss: 0.6632 - val_accuracy: 0.7552\n",
            "Epoch 375/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3493 - accuracy: 0.8368 - val_loss: 0.6624 - val_accuracy: 0.7552\n",
            "Epoch 376/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3496 - accuracy: 0.8316 - val_loss: 0.6626 - val_accuracy: 0.7552\n",
            "Epoch 377/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3492 - accuracy: 0.8368 - val_loss: 0.6628 - val_accuracy: 0.7552\n",
            "Epoch 378/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3491 - accuracy: 0.8403 - val_loss: 0.6636 - val_accuracy: 0.7500\n",
            "Epoch 379/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3495 - accuracy: 0.8333 - val_loss: 0.6636 - val_accuracy: 0.7500\n",
            "Epoch 380/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3494 - accuracy: 0.8333 - val_loss: 0.6649 - val_accuracy: 0.7500\n",
            "Epoch 381/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3492 - accuracy: 0.8299 - val_loss: 0.6619 - val_accuracy: 0.7552\n",
            "Epoch 382/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3498 - accuracy: 0.8333 - val_loss: 0.6623 - val_accuracy: 0.7552\n",
            "Epoch 383/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3497 - accuracy: 0.8333 - val_loss: 0.6639 - val_accuracy: 0.7500\n",
            "Epoch 384/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3490 - accuracy: 0.8368 - val_loss: 0.6636 - val_accuracy: 0.7500\n",
            "Epoch 385/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3495 - accuracy: 0.8351 - val_loss: 0.6631 - val_accuracy: 0.7552\n",
            "Epoch 386/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3499 - accuracy: 0.8333 - val_loss: 0.6618 - val_accuracy: 0.7500\n",
            "Epoch 387/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3495 - accuracy: 0.8351 - val_loss: 0.6617 - val_accuracy: 0.7552\n",
            "Epoch 388/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3491 - accuracy: 0.8351 - val_loss: 0.6620 - val_accuracy: 0.7552\n",
            "Epoch 389/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3491 - accuracy: 0.8351 - val_loss: 0.6642 - val_accuracy: 0.7500\n",
            "Epoch 390/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3493 - accuracy: 0.8333 - val_loss: 0.6642 - val_accuracy: 0.7500\n",
            "Epoch 391/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3496 - accuracy: 0.8351 - val_loss: 0.6617 - val_accuracy: 0.7500\n",
            "Epoch 392/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3491 - accuracy: 0.8368 - val_loss: 0.6629 - val_accuracy: 0.7396\n",
            "Epoch 393/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3492 - accuracy: 0.8403 - val_loss: 0.6665 - val_accuracy: 0.7500\n",
            "Epoch 394/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3496 - accuracy: 0.8333 - val_loss: 0.6670 - val_accuracy: 0.7500\n",
            "Epoch 395/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3496 - accuracy: 0.8316 - val_loss: 0.6651 - val_accuracy: 0.7500\n",
            "Epoch 396/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3490 - accuracy: 0.8385 - val_loss: 0.6640 - val_accuracy: 0.7500\n",
            "Epoch 397/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3490 - accuracy: 0.8368 - val_loss: 0.6642 - val_accuracy: 0.7500\n",
            "Epoch 398/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3494 - accuracy: 0.8368 - val_loss: 0.6629 - val_accuracy: 0.7552\n",
            "Epoch 399/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3495 - accuracy: 0.8351 - val_loss: 0.6643 - val_accuracy: 0.7500\n",
            "Epoch 400/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3492 - accuracy: 0.8368 - val_loss: 0.6641 - val_accuracy: 0.7500\n",
            "Epoch 401/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3498 - accuracy: 0.8403 - val_loss: 0.6615 - val_accuracy: 0.7552\n",
            "Epoch 402/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3493 - accuracy: 0.8351 - val_loss: 0.6612 - val_accuracy: 0.7500\n",
            "Epoch 403/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3492 - accuracy: 0.8333 - val_loss: 0.6620 - val_accuracy: 0.7552\n",
            "Epoch 404/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3494 - accuracy: 0.8351 - val_loss: 0.6610 - val_accuracy: 0.7500\n",
            "Epoch 405/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3492 - accuracy: 0.8333 - val_loss: 0.6626 - val_accuracy: 0.7552\n",
            "Epoch 406/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3500 - accuracy: 0.8351 - val_loss: 0.6641 - val_accuracy: 0.7552\n",
            "Epoch 407/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3490 - accuracy: 0.8333 - val_loss: 0.6639 - val_accuracy: 0.7552\n",
            "Epoch 408/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3493 - accuracy: 0.8368 - val_loss: 0.6638 - val_accuracy: 0.7552\n",
            "Epoch 409/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3490 - accuracy: 0.8351 - val_loss: 0.6646 - val_accuracy: 0.7500\n",
            "Epoch 410/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3495 - accuracy: 0.8368 - val_loss: 0.6642 - val_accuracy: 0.7448\n",
            "Epoch 411/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3492 - accuracy: 0.8351 - val_loss: 0.6658 - val_accuracy: 0.7500\n",
            "Epoch 412/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3494 - accuracy: 0.8351 - val_loss: 0.6638 - val_accuracy: 0.7500\n",
            "Epoch 413/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3491 - accuracy: 0.8351 - val_loss: 0.6629 - val_accuracy: 0.7552\n",
            "Epoch 414/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3491 - accuracy: 0.8333 - val_loss: 0.6657 - val_accuracy: 0.7500\n",
            "Epoch 415/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3492 - accuracy: 0.8316 - val_loss: 0.6630 - val_accuracy: 0.7552\n",
            "Epoch 416/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3492 - accuracy: 0.8351 - val_loss: 0.6630 - val_accuracy: 0.7552\n",
            "Epoch 417/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3492 - accuracy: 0.8316 - val_loss: 0.6629 - val_accuracy: 0.7500\n",
            "Epoch 418/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3493 - accuracy: 0.8385 - val_loss: 0.6652 - val_accuracy: 0.7500\n",
            "Epoch 419/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3490 - accuracy: 0.8316 - val_loss: 0.6640 - val_accuracy: 0.7500\n",
            "Epoch 420/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3495 - accuracy: 0.8351 - val_loss: 0.6640 - val_accuracy: 0.7500\n",
            "Epoch 421/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3489 - accuracy: 0.8333 - val_loss: 0.6646 - val_accuracy: 0.7500\n",
            "Epoch 422/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3498 - accuracy: 0.8316 - val_loss: 0.6624 - val_accuracy: 0.7552\n",
            "Epoch 423/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3495 - accuracy: 0.8368 - val_loss: 0.6643 - val_accuracy: 0.7500\n",
            "Epoch 424/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3494 - accuracy: 0.8368 - val_loss: 0.6638 - val_accuracy: 0.7448\n",
            "Epoch 425/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3493 - accuracy: 0.8333 - val_loss: 0.6626 - val_accuracy: 0.7500\n",
            "Epoch 426/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3491 - accuracy: 0.8333 - val_loss: 0.6643 - val_accuracy: 0.7500\n",
            "Epoch 427/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3492 - accuracy: 0.8351 - val_loss: 0.6640 - val_accuracy: 0.7500\n",
            "Epoch 428/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3491 - accuracy: 0.8351 - val_loss: 0.6636 - val_accuracy: 0.7500\n",
            "Epoch 429/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3490 - accuracy: 0.8316 - val_loss: 0.6626 - val_accuracy: 0.7552\n",
            "Epoch 430/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3488 - accuracy: 0.8368 - val_loss: 0.6643 - val_accuracy: 0.7500\n",
            "Epoch 431/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3489 - accuracy: 0.8351 - val_loss: 0.6654 - val_accuracy: 0.7500\n",
            "Epoch 432/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3492 - accuracy: 0.8368 - val_loss: 0.6625 - val_accuracy: 0.7552\n",
            "Epoch 433/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3491 - accuracy: 0.8351 - val_loss: 0.6642 - val_accuracy: 0.7500\n",
            "Epoch 434/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3489 - accuracy: 0.8316 - val_loss: 0.6645 - val_accuracy: 0.7500\n",
            "Epoch 435/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3493 - accuracy: 0.8299 - val_loss: 0.6635 - val_accuracy: 0.7448\n",
            "Epoch 436/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3490 - accuracy: 0.8368 - val_loss: 0.6651 - val_accuracy: 0.7500\n",
            "Epoch 437/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3491 - accuracy: 0.8316 - val_loss: 0.6645 - val_accuracy: 0.7500\n",
            "Epoch 438/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3495 - accuracy: 0.8316 - val_loss: 0.6646 - val_accuracy: 0.7500\n",
            "Epoch 439/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3497 - accuracy: 0.8368 - val_loss: 0.6638 - val_accuracy: 0.7500\n",
            "Epoch 440/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3493 - accuracy: 0.8385 - val_loss: 0.6661 - val_accuracy: 0.7500\n",
            "Epoch 441/500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3492 - accuracy: 0.8351 - val_loss: 0.6667 - val_accuracy: 0.7448\n",
            "Epoch 442/500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3496 - accuracy: 0.8281 - val_loss: 0.6655 - val_accuracy: 0.7500\n",
            "Epoch 443/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3492 - accuracy: 0.8351 - val_loss: 0.6656 - val_accuracy: 0.7500\n",
            "Epoch 444/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3488 - accuracy: 0.8351 - val_loss: 0.6650 - val_accuracy: 0.7500\n",
            "Epoch 445/500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3488 - accuracy: 0.8316 - val_loss: 0.6664 - val_accuracy: 0.7500\n",
            "Epoch 446/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3490 - accuracy: 0.8351 - val_loss: 0.6664 - val_accuracy: 0.7500\n",
            "Epoch 447/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3491 - accuracy: 0.8333 - val_loss: 0.6639 - val_accuracy: 0.7500\n",
            "Epoch 448/500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3488 - accuracy: 0.8333 - val_loss: 0.6637 - val_accuracy: 0.7500\n",
            "Epoch 449/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3488 - accuracy: 0.8333 - val_loss: 0.6661 - val_accuracy: 0.7500\n",
            "Epoch 450/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3493 - accuracy: 0.8333 - val_loss: 0.6670 - val_accuracy: 0.7500\n",
            "Epoch 451/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3489 - accuracy: 0.8333 - val_loss: 0.6676 - val_accuracy: 0.7500\n",
            "Epoch 452/500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3496 - accuracy: 0.8316 - val_loss: 0.6664 - val_accuracy: 0.7500\n",
            "Epoch 453/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3491 - accuracy: 0.8299 - val_loss: 0.6655 - val_accuracy: 0.7500\n",
            "Epoch 454/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3490 - accuracy: 0.8385 - val_loss: 0.6660 - val_accuracy: 0.7500\n",
            "Epoch 455/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3492 - accuracy: 0.8299 - val_loss: 0.6635 - val_accuracy: 0.7448\n",
            "Epoch 456/500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3486 - accuracy: 0.8333 - val_loss: 0.6645 - val_accuracy: 0.7500\n",
            "Epoch 457/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3488 - accuracy: 0.8351 - val_loss: 0.6641 - val_accuracy: 0.7500\n",
            "Epoch 458/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3490 - accuracy: 0.8316 - val_loss: 0.6649 - val_accuracy: 0.7500\n",
            "Epoch 459/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3492 - accuracy: 0.8299 - val_loss: 0.6646 - val_accuracy: 0.7500\n",
            "Epoch 460/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3493 - accuracy: 0.8299 - val_loss: 0.6640 - val_accuracy: 0.7500\n",
            "Epoch 461/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3494 - accuracy: 0.8351 - val_loss: 0.6657 - val_accuracy: 0.7500\n",
            "Epoch 462/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3491 - accuracy: 0.8368 - val_loss: 0.6651 - val_accuracy: 0.7500\n",
            "Epoch 463/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3488 - accuracy: 0.8351 - val_loss: 0.6660 - val_accuracy: 0.7500\n",
            "Epoch 464/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3490 - accuracy: 0.8333 - val_loss: 0.6655 - val_accuracy: 0.7500\n",
            "Epoch 465/500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3494 - accuracy: 0.8316 - val_loss: 0.6659 - val_accuracy: 0.7500\n",
            "Epoch 466/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3487 - accuracy: 0.8368 - val_loss: 0.6690 - val_accuracy: 0.7500\n",
            "Epoch 467/500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3487 - accuracy: 0.8316 - val_loss: 0.6644 - val_accuracy: 0.7500\n",
            "Epoch 468/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3486 - accuracy: 0.8368 - val_loss: 0.6645 - val_accuracy: 0.7500\n",
            "Epoch 469/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3487 - accuracy: 0.8333 - val_loss: 0.6679 - val_accuracy: 0.7500\n",
            "Epoch 470/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3488 - accuracy: 0.8351 - val_loss: 0.6660 - val_accuracy: 0.7500\n",
            "Epoch 471/500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3487 - accuracy: 0.8299 - val_loss: 0.6639 - val_accuracy: 0.7448\n",
            "Epoch 472/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3490 - accuracy: 0.8316 - val_loss: 0.6631 - val_accuracy: 0.7552\n",
            "Epoch 473/500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3487 - accuracy: 0.8333 - val_loss: 0.6652 - val_accuracy: 0.7500\n",
            "Epoch 474/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3494 - accuracy: 0.8316 - val_loss: 0.6644 - val_accuracy: 0.7500\n",
            "Epoch 475/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3489 - accuracy: 0.8368 - val_loss: 0.6625 - val_accuracy: 0.7500\n",
            "Epoch 476/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3488 - accuracy: 0.8299 - val_loss: 0.6596 - val_accuracy: 0.7500\n",
            "Epoch 477/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3489 - accuracy: 0.8368 - val_loss: 0.6617 - val_accuracy: 0.7552\n",
            "Epoch 478/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3489 - accuracy: 0.8368 - val_loss: 0.6620 - val_accuracy: 0.7500\n",
            "Epoch 479/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3491 - accuracy: 0.8333 - val_loss: 0.6650 - val_accuracy: 0.7500\n",
            "Epoch 480/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3483 - accuracy: 0.8351 - val_loss: 0.6643 - val_accuracy: 0.7500\n",
            "Epoch 481/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3490 - accuracy: 0.8351 - val_loss: 0.6658 - val_accuracy: 0.7500\n",
            "Epoch 482/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3489 - accuracy: 0.8299 - val_loss: 0.6650 - val_accuracy: 0.7448\n",
            "Epoch 483/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3487 - accuracy: 0.8351 - val_loss: 0.6677 - val_accuracy: 0.7500\n",
            "Epoch 484/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3492 - accuracy: 0.8316 - val_loss: 0.6674 - val_accuracy: 0.7500\n",
            "Epoch 485/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3491 - accuracy: 0.8333 - val_loss: 0.6657 - val_accuracy: 0.7500\n",
            "Epoch 486/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3489 - accuracy: 0.8316 - val_loss: 0.6656 - val_accuracy: 0.7500\n",
            "Epoch 487/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3489 - accuracy: 0.8333 - val_loss: 0.6662 - val_accuracy: 0.7500\n",
            "Epoch 488/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3490 - accuracy: 0.8316 - val_loss: 0.6645 - val_accuracy: 0.7500\n",
            "Epoch 489/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3487 - accuracy: 0.8351 - val_loss: 0.6631 - val_accuracy: 0.7552\n",
            "Epoch 490/500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3489 - accuracy: 0.8333 - val_loss: 0.6657 - val_accuracy: 0.7500\n",
            "Epoch 491/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3487 - accuracy: 0.8368 - val_loss: 0.6670 - val_accuracy: 0.7500\n",
            "Epoch 492/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3485 - accuracy: 0.8333 - val_loss: 0.6623 - val_accuracy: 0.7448\n",
            "Epoch 493/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3484 - accuracy: 0.8403 - val_loss: 0.6662 - val_accuracy: 0.7500\n",
            "Epoch 494/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3489 - accuracy: 0.8333 - val_loss: 0.6652 - val_accuracy: 0.7500\n",
            "Epoch 495/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3490 - accuracy: 0.8299 - val_loss: 0.6647 - val_accuracy: 0.7500\n",
            "Epoch 496/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3491 - accuracy: 0.8351 - val_loss: 0.6647 - val_accuracy: 0.7500\n",
            "Epoch 497/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3491 - accuracy: 0.8351 - val_loss: 0.6638 - val_accuracy: 0.7500\n",
            "Epoch 498/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3484 - accuracy: 0.8385 - val_loss: 0.6668 - val_accuracy: 0.7500\n",
            "Epoch 499/500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3486 - accuracy: 0.8351 - val_loss: 0.6637 - val_accuracy: 0.7552\n",
            "Epoch 500/500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3487 - accuracy: 0.8333 - val_loss: 0.6665 - val_accuracy: 0.7500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PC5OntiACj3r",
        "outputId": "a035cfe1-3af1-4418-b755-e242610ea11d"
      },
      "id": "PC5OntiACj3r",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_32 (Dense)            (None, 6)                 54        \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 4)                 28        \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 1)                 5         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 87 (348.00 Byte)\n",
            "Trainable params: 87 (348.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_class_nn_1 = (model_2.predict(X_test_norm)> 0.5 ).astype('int32')\n",
        "y_pred_prob_nn_1 = model_2.predict(X_test_norm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3f83fA74Ctbq",
        "outputId": "196cd9f4-ec02-4fe6-8177-1ebbc60c3489"
      },
      "id": "3f83fA74Ctbq",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 3ms/step\n",
            "6/6 [==============================] - 0s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_7.history[\"loss\"],'r', label=\"Train Loss\")\n",
        "ax.plot(run_hist_7.history[\"val_loss\"],'b', label=\"Validation Loss\")\n",
        "ax.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "QLeCZPE5C-pK",
        "outputId": "8f64af83-d205-41f2-887b-f4f3ad1af70a"
      },
      "id": "QLeCZPE5C-pK",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7916903b4fa0>"
            ]
          },
          "metadata": {},
          "execution_count": 86
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGdCAYAAAAxCSikAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABP7klEQVR4nO3dd3hUVf4/8Pek9wLpEAOh92gC2YiILtGAitizLEoRcEVQMCrKqqG5sivKYkFRXCk2WF3aVxBLKFIiIBBqCIQWSgoEkkkCScjM+f3x+c1MJpmEDCTkEt6v57kPzK3nnpnMed9zz8zolFIKRERERBrm0NgFICIiIroSBhYiIiLSPAYWIiIi0jwGFiIiItI8BhYiIiLSPAYWIiIi0jwGFiIiItI8BhYiIiLSPKfGLkB9MBqNOHPmDLy9vaHT6Rq7OERERFQHSikUFRUhLCwMDg6196E0icBy5swZhIeHN3YxiIiI6CqcPHkSLVu2rHWdJhFYvL29AcgJ+/j4NHJpiIiIqC70ej3Cw8PN7XhtmkRgMd0G8vHxYWAhIiK6wdRlOAcH3RIREZHmMbAQERGR5jGwEBERkeYxsBAREZHmMbAQERGR5jGwEBERkeYxsBAREZHmMbAQERGR5jGwEBERkeYxsBAREZHmMbAQERGR5jGwEBERkeYxsBAREd0AduwAPv8cUKqxS9I4msSvNRMREd1IlALq8APFVuvHxMj/w8KA4GDAxwdo167u+7h4EXB3t++4WsIeFiIiqhOlgKKixrnCP3RIehhuBKWlNS8zGoG33gL8/YE336z7PjMyLP9fsQK4/XYgLg4oLq7b9itXAp6eQGSk7XrcvBk4fbr6/NJSQK8H8vPrXtaGwsBCRHST2rYNyM2t+/qzZ8tV/a23AidPNlixqvnoI6BTJ6BXL+CPP65uH7m5ErSUktDQEAwGYPx4CQavvCLzPv4YuO02IDERKCsDxo2ToFJYKMHlk0+A7dtr3l9pKfDjj8CSJZb5n30GlJdLiFi06MrlOn8emDNH/n/8OPDss8DatcCXX0p9zJsH3HEHcN99wLvvAkePyrpKAf36AS1aAAEBQPfu9r1e6p1qAgoLCxUAVVhY2NhFISK6JpmZSr3wglL79jXscX7+WZrvvn3rvs0dd5iafKX+8Y9rO/6ZM0oZjVdez2hUKjDQctzHH7f/WP/+t2z74YdKDRumlL+/UseOyb7nzFFq3bq67Sc9XanERKV+/90y79AhpTZtkn198YWlnLamF16Qf3U6KUPlZd98I/u7cEGp8+flGJ6ete8PUKpDB6Xy85V6912lTp2yLu+RI0otXlz79u+/b3v+gQPyGqw8r2XLuj1n9rCn/WZgIaI6uXBBGlMt27JFqT17GrsUVy87W6mwMGkc2rRRqqTkytusX6/Uffcp9cQTSu3YoVRd3wbvvNPSEF24YL2sokL2ec89ShUVyTyDQSkvL8s2d99t16lZmTpV9vHZZ0pdvqyUXm+9/NIlCRnvvithoGpj+vTT8lxPmaLUp58qVVxsvX16ulJr1ii1fLk0srYa5AkTlFq1yvJ4yBClunWT/b33nlJZWUp9/bVS06ZJELhwQYIGoFT79kqNGqVU9+6W7QMCrhwuKpe/okKpwYOt57drJ/86Otrerlkz2/NbtZJ/Q0KUOnpU6uDcueqBp0MHpd5+u+7lrDo9++zVP+c1YWAhonrXp49Szs7SGFxvNV3V/e9/0nDo9UqlpSnl4CBvrO+8U/O+zp6te6NeFz/+qNTu3dXn5+ZK47d6tQSPMWOU+te/JCh8+qnlnIxGpb77TsrcubN1A/HPf8ry+++XxnT+fKVeeUVCzYwZ0uiZGivT5Oys1N//bl2WCxeUSklR6r//lSDSpo31NitWKLV2rVIPPqjUa68p9eKLlmX9+il18qT0JFRtwMLD5XUxe7ZSS5cq9euvSp0+bTmv4cPlWAsWyLxt25Tq0sWyfUSEUgkJEgTuusvSc2GrUb3rLnmubTWkY8dazvXoUaXc3a/c+Do4SPCoS0Pt7Gxfw378uFJ//CHBZ9gweY1UXr5+vaWO1q6tfV8PPKDUhg3yGjMYLAHMy8t2ffz1r7LvL7+0nn/nnfJaNL0esrKUCgqyfUxfX9vzV626lr8U2xhYiG4yRUVyVdpQzpyxvGlNmdJwx7ElL08alvh4SyNfWiq9PaYy/f3v0pCbHvv7S2NucuiQvNnm5irl5yfB4PLlmo9ZUCDd9zNmSN0WFEhvwKJFlu0qKqSRNh3z448t21dUKBUZKfN1OqVGjqz+5j9vnjTkla/SAaU8PJRKSpL/R0cr9cMPNTcqy5ZZHpuOV3l64QUpc79+tTeKCQk190RUnWJilLrlltrXmT5dqa++sp7Xs6dSbm61b+fqqtTevdVDGKBUcrK8xhMTqy8LCFCqrEye38cek3nNmsn8226T3pSnn675uC1aVH8eKr+WrlQnc+dKOGnWzBIYKjMapdyOjlIPBoP18r59ZT/u7kpNnKjU5s3S+7JwYfV9HTwodXvkiIQOV1frsjg6SmB6/HF53LlzzbcXFyywbFc5vJWWyt/dkCFKtW4t9di2rVIXL9b8N3O1GFiIbiJnzyrVvLm8oaxYIfez69O331q/IT71lPXyTZvkDXfDBsu8wsLqtxkqr5+cLG9+mzYplZpafZ3Ll2WMgcGg1F/+Yjm2j49csfr4WJepWTPrcQ6A3BL45BN54w0Pl3nx8Zblw4Yp9dBDSi1ZIsdctEi6vAsKlOrRw7JeXJxSAwdaHj/xhFzZVu2e79LFUv5ffrlyI+fubukRMgWBxx6Tq+/cXMuyyrcHHBysb+WYpokT5bilpbaXV566dpXelv37lVq50npZYKDUi6OjUi4uSn3/ffX9/e1vMuZj0iSl/u//lIqNrVvQMU1/+pPUT8eOlnkjR1Y/joeH9ePKt/oyMmT7pCTbt2IcHKrfGjQYpOeoRQulhg6VgBIYqNSjj1qC8LBhsv3o0XL7xM1NGvt582T+HXco9dJLlnVOnLB+3dcWgk3Pj63ewtxcpX777erGhxw+rNSIEfK3dPfdUjZvb0tdbN5c87ZGo/SoTZum1MyZlm2qKi+XQNgQGFiIbiKffmr9Zv3QQzL/wgUZWFn51oO9Nm+u3hh06GBZfvCg5b6+k5N0fX/4oTTGTk7SuH/9tVwNJiYq9fnnMh+Qrm4HB+luP3xYGpTCQum1MN0aMa1b18nfX6kBA+zbBpDbLab/P/CA/dubGsmSEmnE+vSReW3bVl/P1dW6kfX0tH0FXLkBDwuT5+LIEVlm6kUA5LZK5ZBa+arZ1lS1W/+LL5QKDpZlH30k8zIzrRv8kyfldsK4cdXHMX32mWXfp0/LLSfT4xEjpKFbuVLWM93WUEpeF61bS89YWZn04pluVTk6yqDe116Tx9Om1fwaffbZ6ud4tWMtCgulXGVlcpux8iDWzEzpbSspkSDXUA34tfjkE+t6ePRR657G2ly+LLcsr/cYMAYWajIMBuk1MN0Xry+7dys1frxSOTlXXvf776Wx/eqrK69bXKxU795ydTh8uP3lMhhkHMDSpXV/Q7znnuoN4oULciUNyPiI/HxpPO+8s/bgcvmyXDlPmyZvXjU1erm5Su3aZfs2hK3pSrcQvLwswcfW5OxsPY7A2VnGO3z+ufQWuLjI9qaG0dY+/PysH1ftpak6Pf20jJExdblX7UkID1fqzTflytjU4CckWJbrdEpt324dPEaPlrENX35pCWP//a/t52LXLul5mDhReokqW7NG9t+tW/UGprRUqWeeqX4+8+fLsW2pqJBQcjUuXpTbF++9J48LCiQE2RrXcyVlZdJ7UlAgj8vLpSeoNufPy23Kv/5V6j8urnp93SyysizPd+fOjV2aumFgoRtSSYlc/W3cKG92e/bI2ASg7p9IqKiQwZf79knPQ3m57fVMjUjl3oIVK5TautV6PaNRqdBQy5tAWprM37xZqVmzLFe8SkljcPvt1o3Er79KMPrrX6u/8Z46JbdzKqs81iE0VLqwa+tmPnbMcstgxw7bg+UeeUS68U2P162Tq9pffrHsR6+veZxDs2bynBgMctsCkPpzcZH/t2oldWdqtAHp6YiIqFuYqTp5e8uVduWejqQkGUx58KDcV1+71roeDhyQcKCU1NeECVKev/xFqUGDJFgcPSp12qqVJQxWVCgVFSXH6NvXerzC//4n6+TlyWvx0iXLsvvvtw5+lXsVAAkSlQc4PvWUhKvK9u2TgHW1ioqqj4WozPSx5ZdfvvKtCmo6TH+jNQVhrWFgIU0wGKSBLy6W5F8bo1FuZdTWkF2pN+Ts2erd+SNGSAgpLZXu3vnzJShUXmfDBvk0hqmhNb2579olA+Qqr/vOOzIQzvQ4LEwGuBmNlnESgO2PJbZuLVeDs2cr9ec/yzqtWknZlJJwY+u8hwyRMRSfflq9fp94Qtbp10/m3XvvlQOBKWgAMiBx797qAxlNDfftt1s3ilU/0RATY3luS0os+16wQEKB6R45IOGhrEwa8OJiCRmlpRJCUlPlCj8jw1L/la8Wly69woutjvT66h+BzcyUQHPunDTy3t5y/rbeToYPlx4XU3A1SU627kXRitzcut8SoKbhxAm5NXujYGDRiMuXLZ+J14KyMhkw1qaN9Rcf1cb0fQxt28pAwxEjlPrpJ+kG79ZNqddfl8FeZ8/KVfBzz0mDUFYm908rN27z5tk+xtdf1+3Ke+ZMOZapAf30U+mBGDfOMtistkba9B0SlQf7AUr16lU95OzfX3OPQ+WBkoDU56BB1j0YW7fa3nbSpOrznnvO+gp93Di5ep42rfq68+ZZustNAwQBy8C6Dz+Ux6Gh0gCbBqK6uko4sVWmDh2sA1a7dtKwr1tX/fsxlLL+tEXVhnvHDvkirqpX/vv2Xd0nDJ59Vj7OWpfvI6kveXkynsKW8nLbg4nPnpVerI8/rrlXj4iqY2DRCNO3GtbX1eGVTi87W5J1TW+YkydbGppBg2ReTk71b0es7KOPqjdwgYGWj+HZmjp1sj1y383N9n3t2j426O1t/Z0QV5oqf69Av34y+LHyiPm6TqYv7zJNf/2r9eP4eOmZqLrdAw9Yzst01X3nnVf+BszKU+X77++9V33gaVSUHNs05qPyx2nLyuRYpt6oFSuk0c/IkPBReV+rV1t/0qVrVwkVph6fmly8KD0NU6fWvh4R0ZUwsDSQEyeqf9eF0SgNwiOPWF8F5udbGoKIiCvvOz+/5gFxer1S/ftLY/PNN/JRwq+/lmUFBXL86GhLYxQdXf32SVmZdWPu7Cy3MkJDZTBibm7141ZUWMZv3HabUm+8IR+frdx4RkbW/P0NOp3cPlmyxHrg4aBBlvEcOTnW27zxhvQCPf64DCzcvVt6bO66q+YGPiZGvhXT9IVmpaVyO8dk3TopS/Pm1redYmLkmyEBGSRr69MGgPQoFBQodeutsv6yZZZu9gcftF638m0b05dCnTsnIaRyz4yfn9yeqtrb88Yb1Z+HvDyl/vMf6/VM+7r99tpeVdWZwp+Tkzyu/F0ZkybZty8iomvFwNIAfv5ZGonKV9BKyScUKjdsJm+9Zd1wm24NGY3SA3LxooxnOHBAGjVTo//ii5ZvhTQxfe6/6rRnj/W988pTQoJ0y2dlSRj64AOZHxoqtwCqrm/rm0HXr5dlvr6WQYpjx1q2iY21rLtpkwSM/HwZDxIfb30L6OxZ62Dj4SFfLmX6gihPT2msTV8DXlVpqYzxmDFDvuAoPFzGa5huj1zJzp0SOPPyLGV4+WW5lTJjhoyf2Lu3+u2eyoGgoqJ679Xp03IeX38tz11tX95W+TtAPvnEMr+4WF4Xpo/21mT7dnlOKn8E1/Qx1Lq6eFEGMlf+ps2HH5ZbZnv32rcvIqJr1eCB5aOPPlIRERHK1dVV9erVS22t+tGKKi5cuKCee+45FRISolxcXFS7du3UqkpfBjB58mQFwGrqUPnjG1fQ0IGlokIGTJoaiU2b5Gr+rbfk9kflBu7sWQkhVb990HRVXdfbAqYvs1LK8vsSVadXX7Ue6PnllzJWwPRtkt26Vf+o6KxZMsi06lcyt28vjdeKFdVv5wwdainLgQOybYcO1p8yqYucHOmdqDrexNFRPjp8vRw/LkEvO7v6sl27pLdp/Hgp2/Tp9XfcEyfkVlpAQO234a6kokJ62qZOrZ/vgqiosD1WhYiooTVoYFm8eLFycXFRX3zxhdq/f78aPXq08vPzU7m27ikopcrKylRMTIy677771KZNm9SxY8fU+vXrVVql0XqTJ09WXbp0UdnZ2ebpbNXPe9aiIQPL8OHVx1g8+qh1o+vubhnQuWSJ5ZMlAwZIz0rV3+2oPPn6yq2KqgGieXP54a7hwy1d+FlZ1lfppsnf3/rKvvJHWCtPTz1l+Shmdrb0kFQe31F1TINpsjeYXElpqXzs1MtLbnVd6RNEjcFgkIHJDfHlULX1ohAR3UwaNLD06tVLja30S1MGg0GFhYWpGTNm2Fz/k08+UZGRkaq8lqHzkydPVj169LC3KGYNFVj277duuGsKAv/7n3zSwxReTL0ppqvo0lL50a99++Tq/fz56r/9YjDIoMeafmSrTx/LukVF1sHi5Zety236/gXTdnfeKT0GVb+LwWiUq+vK35ppmp58Um5zXKHz7JrU98+UExHRjcWe9tsBdigvL8eOHTsQHx9vnufg4ID4+Hikpqba3GblypWIi4vD2LFjERwcjK5du+Ltt9+GwWCwWu/w4cMICwtDZGQkhgwZgqysrBrLUVZWBr1ebzU1hPbtgcWLgTvvBEaNAj7+GIiIsF6emws88gjQt6/Mu3QJ8PYGvv4aaNFC5rm6Aj17Al26AEFBgL8/4OUFuLlZ9uXgAGzcCBw9Cnz2mWV+VJRsM2GCZZ6XF5CcbHn8wgvW5b7rLiAsDHB0BObMATZsAGbPBpycrNfT6WSdxx+3nv/DD8CXXwJ//SvQq1fd68teOl3D7ZuIiJoWpyuvYnHu3DkYDAYEBwdbzQ8ODsbBgwdtbnP06FGsXbsWQ4YMwerVq5GZmYnnnnsOly9fxuTJkwEAsbGxWLBgATp06IDs7GxMnToVffr0wb59++Dt7V1tnzNmzMDUqVPtKfpVcXICEhNlMnnkEeDf/5b/P/ywhAkAuPdeoFUrCSkLFwJt2th/PD8/mYYNA/bvBzp3Bp55xva6zz0HnDkDdOgAhIdbL3N2Bn77DSgoALp1u/JxBw2SUPbbb0CnTsCAAfaXnYiIqCHplFKqriufOXMGLVq0wJYtWxAXF2eeP3HiRGzYsAFbt26ttk379u1RWlqKY8eOwdHREQAwa9YszJw5E9nZ2TaPU1BQgIiICMyaNQsjR46strysrAxlZWXmx3q9HuHh4SgsLISPj09dT+eq5OcDH3wAXL4MvPwy0KyZZZlSN26vQUUFsGoVEB0NtGzZ2KUhIqKbgV6vh6+vb53ab7t6WAICAuDo6Ijc3Fyr+bm5uQgJCbG5TWhoKJydnc1hBQA6deqEnJwclJeXw8XFpdo2fn5+aN++PTIzM23u09XVFa6urvYUvd40bw7U1Llzo4YVQHqTBg1q7FIQERHZZtcYFhcXF0RHRyMlJcU8z2g0IiUlxarHpbLevXsjMzMTRqPRPO/QoUMIDQ21GVYAoLi4GEeOHEFoaKg9xSMiIqImyq7AAgBJSUmYN28eFi5ciPT0dIwZMwYlJSUYMWIEAGDo0KGYNGmSef0xY8bg/PnzGD9+PA4dOoRVq1bh7bffxtixY83rvPzyy9iwYQOOHz+OLVu24OGHH4ajoyMGDx5cD6dIRERENzq7bgkBQGJiIs6ePYvk5GTk5OQgKioKa9asMQ/EzcrKgoODJQeFh4fjp59+wosvvoju3bujRYsWGD9+PF599VXzOqdOncLgwYORn5+PwMBA3HHHHfj9998RGBhYD6dIRERENzq7Bt1qlT2DdoiIiEgb7Gm/7b4lRERERHS9MbAQERGR5jGwEBERkeYxsBAREZHmMbAQERGR5jGwEBERkeYxsBAREZHmMbAQERGR5jGwEBERkeYxsBAREZHmMbAQERGR5jGwEBERkeYxsBAREZHmMbAQERGR5jGwEBERkeYxsBAREZHmMbAQERGR5jGwEBERkeYxsBAREZHmMbAQERGR5jGwEBERkeYxsBAREZHmMbAQERGR5jGwEBERkeYxsBAREZHmMbAQERGR5jGwEBERkeYxsBAREZHmMbAQERGR5jGwEBERkeYxsBAREZHmMbAQERGR5jGwEBERkeYxsBAREZHmMbAQERGR5jGwEBERkeYxsBAREZHmMbAQERGR5jGwEBERkeYxsBAREZHmMbAQERGR5jGwEBERkeZdVWCZM2cOWrVqBTc3N8TGxmLbtm21rl9QUICxY8ciNDQUrq6uaN++PVavXn1N+yQiIqKbh92BZcmSJUhKSsLkyZOxc+dO9OjRAwkJCcjLy7O5fnl5Oe655x4cP34c33//PTIyMjBv3jy0aNHiqvdJRERENxedUkrZs0FsbCx69uyJjz76CABgNBoRHh6O559/Hq+99lq19efOnYuZM2fi4MGDcHZ2rpd9VqXX6+Hr64vCwkL4+PjYczpERETUSOxpv+3qYSkvL8eOHTsQHx9v2YGDA+Lj45Gammpzm5UrVyIuLg5jx45FcHAwunbtirfffhsGg+Gq91lWVga9Xm81ERERUdNlV2A5d+4cDAYDgoODreYHBwcjJyfH5jZHjx7F999/D4PBgNWrV+PNN9/Ee++9h7feeuuq9zljxgz4+vqap/DwcHtOg4iIiG4wDf4pIaPRiKCgIHz22WeIjo5GYmIiXn/9dcydO/eq9zlp0iQUFhaap5MnT9ZjiYmIiEhrnOxZOSAgAI6OjsjNzbWan5ubi5CQEJvbhIaGwtnZGY6OjuZ5nTp1Qk5ODsrLy69qn66urnB1dbWn6ERERHQDs6uHxcXFBdHR0UhJSTHPMxqNSElJQVxcnM1tevfujczMTBiNRvO8Q4cOITQ0FC4uLle1TyIiIrq52H1LKCkpCfPmzcPChQuRnp6OMWPGoKSkBCNGjAAADB06FJMmTTKvP2bMGJw/fx7jx4/HoUOHsGrVKrz99tsYO3ZsnfdJRERENze7bgkBQGJiIs6ePYvk5GTk5OQgKioKa9asMQ+azcrKgoODJQeFh4fjp59+wosvvoju3bujRYsWGD9+PF599dU675OIiIhubnZ/D4sW8XtYiIiIbjwN9j0sRERERI2BgYWIiIg0j4GFiIiINI+BhYiIiDSPgYWIiIg0j4GFiIiINI+BhYiIiDSPgYWIiIg0j4GFiIiINI+BhYiIiDSPgYWIiIg0j4GFiIiINI+BhYiIiDSPgYWIiIg0j4GFiIiINI+BhYiIiDSPgYWIiIg0j4GFiIiINI+BhYiIiDSPgYWIiIg0j4GFiIiINI+BhYiIiDSPgYWIiIg0j4GFiIiINI+BhYiIiDSPgYWIiIg0j4GFiIiINI+BhYiIiDSPgYWIiIg0j4GFiIiINI+BhYiIiDSPgYWIiIg0j4GFiIiINI+BhYiIiDSPgYWIiIg0j4GFiIiINI+BhYiIiDSPgYWIiIg0j4GFiIiINI+BhYiIiDSPgYWIiIg076oCy5w5c9CqVSu4ubkhNjYW27Ztq3HdBQsWQKfTWU1ubm5W6wwfPrzaOv3797+aohEREVET5GTvBkuWLEFSUhLmzp2L2NhYzJ49GwkJCcjIyEBQUJDNbXx8fJCRkWF+rNPpqq3Tv39/zJ8/3/zY1dXV3qIRERFRE2V3D8usWbMwevRojBgxAp07d8bcuXPh4eGBL774osZtdDodQkJCzFNwcHC1dVxdXa3W8ff3t7doRERE1ETZFVjKy8uxY8cOxMfHW3bg4ID4+HikpqbWuF1xcTEiIiIQHh6OQYMGYf/+/dXWWb9+PYKCgtChQweMGTMG+fn5Ne6vrKwMer3eaiIiIqKmy67Acu7cORgMhmo9JMHBwcjJybG5TYcOHfDFF19gxYoV+Oqrr2A0GnH77bfj1KlT5nX69++PRYsWISUlBf/617+wYcMGDBgwAAaDweY+Z8yYAV9fX/MUHh5uz2kQERHRDUanlFJ1XfnMmTNo0aIFtmzZgri4OPP8iRMnYsOGDdi6desV93H58mV06tQJgwcPxvTp022uc/ToUbRp0wa//vor+vXrV215WVkZysrKzI/1ej3Cw8NRWFgIHx+fup4OERERNSK9Xg9fX986td929bAEBATA0dERubm5VvNzc3MREhJSp304Ozvj1ltvRWZmZo3rREZGIiAgoMZ1XF1d4ePjYzURERFR02VXYHFxcUF0dDRSUlLM84xGI1JSUqx6XGpjMBiwd+9ehIaG1rjOqVOnkJ+fX+s6REREdPOw+1NCSUlJmDdvHhYuXIj09HSMGTMGJSUlGDFiBABg6NChmDRpknn9adOm4eeff8bRo0exc+dOPPnkkzhx4gRGjRoFQAbkvvLKK/j9999x/PhxpKSkYNCgQWjbti0SEhLq6TSJiIjoRmb397AkJibi7NmzSE5ORk5ODqKiorBmzRrzQNysrCw4OFhy0IULFzB69Gjk5OTA398f0dHR2LJlCzp37gwAcHR0xJ49e7Bw4UIUFBQgLCwM9957L6ZPn87vYiEiIiIAdg661Sp7Bu0QERGRNjTYoFsiIiKixsDAQkRERJrHwEJERESax8BCREREmsfAQkRERJrHwEJERESax8BCREREmsfAQkRERJrHwEJERESax8BCREREmsfAQkRERJrHwEJERESaZ/evNRMRUdNkMBhw+fLlxi4GNTHOzs5wdHS85v0wsBAR3eSUUsjJyUFBQUFjF4WaKD8/P4SEhECn0131PhhYiIhucqawEhQUBA8Pj2tqVIgqU0rh4sWLyMvLAwCEhoZe9b4YWIiIbmIGg8EcVpo3b97YxaEmyN3dHQCQl5eHoKCgq749xEG3REQ3MdOYFQ8Pj0YuCTVlptfXtYyRYmAhIiLeBqIGVR+vLwYWIiIi0jwGFiIiIgCtWrXC7NmzG7sYVAMGFiIiuqHodLpapylTplzVfrdv345nnnnmmsp21113YcKECde0D7KNnxIiIqIbSnZ2tvn/S5YsQXJyMjIyMszzvLy8zP9XSsFgMMDJ6crNXWBgYP0WlOoVe1iIiOiGEhISYp58fX2h0+nMjw8ePAhvb2/8+OOPiI6OhqurKzZt2oQjR45g0KBBCA4OhpeXF3r27Ilff/3Var9VbwnpdDp8/vnnePjhh+Hh4YF27dph5cqV11T2//3vf+jSpQtcXV3RqlUrvPfee1bLP/74Y7Rr1w5ubm4IDg7GY489Zl72/fffo1u3bnB3d0fz5s0RHx+PkpKSayrPjYQ9LEREZE0p4OLF639cDw+gnj6t9Nprr+Hdd99FZGQk/P39cfLkSdx33334xz/+AVdXVyxatAgDBw5ERkYGbrnllhr3M3XqVLzzzjuYOXMmPvzwQwwZMgQnTpxAs2bN7C7Tjh078MQTT2DKlClITEzEli1b8Nxzz6F58+YYPnw4/vjjD7zwwgv48ssvcfvtt+P8+fPYuHEjAOlVGjx4MN555x08/PDDKCoqwsaNG6GUuuo6utEwsBARkbWLF4FKt1Wum+JiwNOzXnY1bdo03HPPPebHzZo1Q48ePcyPp0+fjmXLlmHlypUYN25cjfsZPnw4Bg8eDAB4++238cEHH2Dbtm3o37+/3WWaNWsW+vXrhzfffBMA0L59exw4cAAzZ87E8OHDkZWVBU9PTzzwwAPw9vZGREQEbr31VgASWCoqKvDII48gIiICANCtWze7y3Aj4y0hIiJqcmJiYqweFxcX4+WXX0anTp3g5+cHLy8vpKenIysrq9b9dO/e3fx/T09P+Pj4mL9m3l7p6eno3bu31bzevXvj8OHDMBgMuOeeexAREYHIyEg89dRT+Prrr3Hx//d09ejRA/369UO3bt3w+OOPY968ebhw4cJVleNGxcBCRETWPDykt+N6T/X4bbueVXpqXn75ZSxbtgxvv/02Nm7ciLS0NHTr1g3l5eW17sfZ2dnqsU6ng9ForLdyVubt7Y2dO3fi22+/RWhoKJKTk9GjRw8UFBTA0dERv/zyC3788Ud07twZH374ITp06IBjx441SFm0iLeEiIjImk5Xb7dmtGLz5s0YPnw4Hn74YQDS43L8+PHrWoZOnTph8+bN1crVvn178+/rODk5IT4+HvHx8Zg8eTL8/Pywdu1aPPLII9DpdOjduzd69+6N5ORkREREYNmyZUhKSrqu59FYGFiIiKjJa9euHZYuXYqBAwdCp9PhzTffbLCekrNnzyItLc1qXmhoKF566SX07NkT06dPR2JiIlJTU/HRRx/h448/BgD88MMPOHr0KO688074+/tj9erVMBqN6NChA7Zu3YqUlBTce++9CAoKwtatW3H27Fl06tSpQc5BixhYiIioyZs1axaefvpp3H777QgICMCrr74KvV7fIMf65ptv8M0331jNmz59Ot544w3897//RXJyMqZPn47Q0FBMmzYNw4cPBwD4+flh6dKlmDJlCkpLS9GuXTt8++236NKlC9LT0/Hbb79h9uzZ0Ov1iIiIwHvvvYcBAwY0yDlokU41gc9E6fV6+Pr6orCwED4+Po1dHCKiG0ZpaSmOHTuG1q1bw83NrbGLQ01UTa8ze9pvDrolIiIizWNgISIiIs1jYCEiIiLNY2AhIiIizWNgISIiIs1jYCEiIiLNY2AhIiIizWNgISIiIs1jYCEiIiLNY2AhIqKb0l133YUJEyaYH7dq1QqzZ8+udRudTofly5df87Hraz83k6sKLHPmzEGrVq3g5uaG2NhYbNu2rcZ1FyxYAJ1OZzVV/fpnpRSSk5MRGhoKd3d3xMfH4/Dhw1dTNCIiauIGDhyI/v3721y2ceNG6HQ67Nmzx+79bt++Hc8888y1Fs/KlClTEBUVVW1+dnZ2g/8O0IIFC+Dn59egx7ie7A4sS5YsQVJSEiZPnoydO3eiR48eSEhIQF5eXo3b+Pj4IDs72zydOHHCavk777yDDz74AHPnzsXWrVvh6emJhIQElJaW2n9GRETUpI0cORK//PILTp06VW3Z/PnzERMTg+7du9u938DAQHh4eNRHEa8oJCQErq6u1+VYTYXdgWXWrFkYPXo0RowYgc6dO2Pu3Lnw8PDAF198UeM2Op0OISEh5ik4ONi8TCmF2bNn44033sCgQYPQvXt3LFq0CGfOnGF3GRERVfPAAw8gMDAQCxYssJpfXFyM7777DiNHjkR+fj4GDx6MFi1awMPDA926dcO3335b636r3hI6fPgw7rzzTri5uaFz58745Zdfqm3z6quvon379vDw8EBkZCTefPNNXL58GYD0cEydOhW7d+8232EwlbnqLaG9e/fiz3/+M9zd3dG8eXM888wzKC4uNi8fPnw4HnroIbz77rsIDQ1F8+bNMXbsWPOxrkZWVhYGDRoELy8v+Pj44IknnkBubq55+e7du3H33XfD29sbPj4+iI6Oxh9//AEAOHHiBAYOHAh/f394enqiS5cuWL169VWXpS6c7Fm5vLwcO3bswKRJk8zzHBwcEB8fj9TU1Bq3Ky4uRkREBIxGI2677Ta8/fbb6NKlCwDg2LFjyMnJQXx8vHl9X19fxMbGIjU1FX/5y1/sPSciIroGSgEXL17/43p4ADrdlddzcnLC0KFDsWDBArz++uvQ/f+NvvvuOxgMBgwePBjFxcWIjo7Gq6++Ch8fH6xatQpPPfUU2rRpg169el3xGEajEY888giCg4OxdetWFBYWWo13MfH29saCBQsQFhaGvXv3YvTo0fD29sbEiRORmJiIffv2Yc2aNfj1118BSPtWVUlJCRISEhAXF4ft27cjLy8Po0aNwrhx46xC2bp16xAaGop169YhMzMTiYmJiIqKwujRo69caTbOzxRWNmzYgIqKCowdOxaJiYlYv349AGDIkCG49dZb8cknn8DR0RFpaWlwdnYGAIwdOxbl5eX47bff4OnpiQMHDsDLy8vucthF2eH06dMKgNqyZYvV/FdeeUX16tXL5jZbtmxRCxcuVLt27VLr169XDzzwgPLx8VEnT55USim1efNmBUCdOXPGarvHH39cPfHEEzb3WVpaqgoLC83TyZMnFQBVWFhoz+kQEd30Ll26pA4cOKAuXbpknldcrJTElus7FRfXvdzp6ekKgFq3bp15Xp8+fdSTTz5Z4zb333+/eumll8yP+/btq8aPH29+HBERof79738rpZT66aeflJOTkzp9+rR5+Y8//qgAqGXLltV4jJkzZ6ro6Gjz48mTJ6sePXpUW6/yfj777DPl7++viitVwKpVq5SDg4PKyclRSik1bNgwFRERoSoqKszrPP744yoxMbHGssyfP1/5+vraXPbzzz8rR0dHlZWVZZ63f/9+BUBt27ZNKaWUt7e3WrBggc3tu3XrpqZMmVLjsauy9TpTSqnCwsI6t98N/imhuLg4DB06FFFRUejbty+WLl2KwMBAfPrpp1e9zxkzZsDX19c8hYeH12OJiYhI6zp27Ijbb7/dPBwhMzMTGzduxMiRIwEABoMB06dPR7du3dCsWTN4eXnhp59+QlZWVp32n56ejvDwcISFhZnnxcXFVVtvyZIl6N27N0JCQuDl5YU33nijzseofKwePXrA09PTPK93794wGo3IyMgwz+vSpQscHR3Nj0NDQ2sdP3qlY4aHh1u1n507d4afnx/S09MBAElJSRg1ahTi4+Pxz3/+E0eOHDGv+8ILL+Ctt95C7969MXny5Ksa5GwvuwJLQEAAHB0dre5xAUBubi5CQkLqtA9nZ2fceuutyMzMBADzdvbsc9KkSSgsLDRPJ0+etOc0iIioFh4eQHHx9Z/sHe86cuRI/O9//0NRURHmz5+PNm3aoG/fvgCAmTNn4v3338err76KdevWIS0tDQkJCSgvL6+3ekpNTcWQIUNw33334YcffsCuXbvw+uuv1+sxKjPdjjHR6XQwGo0NcixAPuG0f/9+3H///Vi7di06d+6MZcuWAQBGjRqFo0eP4qmnnsLevXsRExODDz/8sMHKAtgZWFxcXBAdHY2UlBTzPKPRiJSUFJvJ0xaDwYC9e/ciNDQUANC6dWuEhIRY7VOv12Pr1q017tPV1RU+Pj5WExER1Q+dDvD0vP5TXcavVPbEE0/AwcEB33zzDRYtWoSnn37aPJ5l8+bNGDRoEJ588kn06NEDkZGROHToUJ333alTJ5w8eRLZ2dnmeb///rvVOlu2bEFERARef/11xMTEoF27dtU+Bevi4gKDwXDFY+3evRslJSXmeZs3b4aDgwM6dOhQ5zLbw3R+lS/4Dxw4gIKCAnTu3Nk8r3379njxxRfx888/45FHHsH8+fPNy8LDw/Hss89i6dKleOmllzBv3rwGKauJ3beEkpKSMG/ePCxcuBDp6ekYM2YMSkpKMGLECADA0KFDrQblTps2DT///DOOHj2KnTt34sknn8SJEycwatQoAJIQJ0yYgLfeegsrV67E3r17MXToUISFheGhhx6qn7MkIqImx8vLC4mJiZg0aRKys7MxfPhw87J27drhl19+wZYtW5Ceno6//e1v1XryaxMfH4/27dtj2LBh2L17NzZu3IjXX3/dap127dohKysLixcvxpEjR/DBBx+YeyBMWrVqhWPHjiEtLQ3nzp1DWVlZtWMNGTIEbm5uGDZsGPbt24d169bh+eefx1NPPWX1qdqrYTAYkJaWZjWlp6cjPj4e3bp1w5AhQ7Bz505s27YNQ4cORd++fRETE4NLly5h3LhxWL9+PU6cOIHNmzdj+/bt6NSpEwBgwoQJ+Omnn3Ds2DHs3LkT69atMy9rKHYHlsTERLz77rtITk5GVFQU0tLSsGbNGnOlZmVlWSXSCxcuYPTo0ejUqRPuu+8+6PV6bNmyxSrBTZw4Ec8//zyeeeYZ9OzZE8XFxVizZk21L5gjIiKqbOTIkbhw4QISEhKsxpu88cYbuO2225CQkIC77roLISEhdl0EOzg4YNmyZbh06RJ69eqFUaNG4R//+IfVOg8++CBefPFFjBs3DlFRUdiyZQvefPNNq3UeffRR9O/fH3fffTcCAwNtfrTaw8MDP/30E86fP4+ePXviscceQ79+/fDRRx/ZVxk2FBcX49Zbb7WaBg4cCJ1OhxUrVsDf3x933nkn4uPjERkZiSVLlgAAHB0dkZ+fj6FDh6J9+/Z44oknMGDAAEydOhWABKGxY8eiU6dO6N+/P9q3b4+PP/74mstbG51SSjXoEa4DvV4PX19fFBYW8vYQEZEdSktLcezYMbRu3ZoXidRganqd2dN+87eEiIiISPMYWIiIiEjzGFiIiIhI8xhYiIiISPMYWIiIiEjzGFiIiAhN4AOjpGH18fpiYCEiuomZvu79YmP8PDPdNEyvr6o/L2APp/oqDBER3XgcHR3h5+dn/hE9Dw8P89fbE10rpRQuXryIvLw8+Pn5Wf14o70YWIiIbnKmH5q92l/+JboSPz+/Ov9Ick0YWIiIbnI6nQ6hoaEICgrC5cuXG7s41MQ4OztfU8+KCQMLEREBkNtD9dGwEDUEDrolIiIizWNgISIiIs1jYCEiIiLNY2AhIiIizWNgISIiIs1jYCEiIiLNY2AhIiIizWNgISIiIs1jYCEiIiLNY2AhIiIizWNgISIiIs1jYCEiIiLNY2AhIiIizWNgISIiIs1jYCEiIiLNY2AhIiIizWNgISIiIs1jYCEiIiLNY2AhIiIizWNgISIiIs1jYCEiIiLNY2AhIiIizWNgISIiIs1jYCEiIiLNY2AhIiIizWNgISIiIs1jYCEiIiLNY2AhIiIizWNgISIiIs1jYCEiIiLNY2AhIiIizbuqwDJnzhy0atUKbm5uiI2NxbZt2+q03eLFi6HT6fDQQw9ZzR8+fDh0Op3V1L9//6spGhERETVBdgeWJUuWICkpCZMnT8bOnTvRo0cPJCQkIC8vr9btjh8/jpdffhl9+vSxubx///7Izs42T99++629RSMiIqImyu7AMmvWLIwePRojRoxA586dMXfuXHh4eOCLL76ocRuDwYAhQ4Zg6tSpiIyMtLmOq6srQkJCzJO/v7+9RSMiIqImyq7AUl5ejh07diA+Pt6yAwcHxMfHIzU1tcbtpk2bhqCgIIwcObLGddavX4+goCB06NABY8aMQX5+fo3rlpWVQa/XW01ERETUdNkVWM6dOweDwYDg4GCr+cHBwcjJybG5zaZNm/Cf//wH8+bNq3G//fv3x6JFi5CSkoJ//etf2LBhAwYMGACDwWBz/RkzZsDX19c8hYeH23MaREREdINxasidFxUV4amnnsK8efMQEBBQ43p/+ctfzP/v1q0bunfvjjZt2mD9+vXo169ftfUnTZqEpKQk82O9Xs/QQkRE1ITZFVgCAgLg6OiI3Nxcq/m5ubkICQmptv6RI0dw/PhxDBw40DzPaDTKgZ2ckJGRgTZt2lTbLjIyEgEBAcjMzLQZWFxdXeHq6mpP0YmIiOgGZtctIRcXF0RHRyMlJcU8z2g0IiUlBXFxcdXW79ixI/bu3Yu0tDTz9OCDD+Luu+9GWlpajb0ip06dQn5+PkJDQ+08HSIiImqK7L4llJSUhGHDhiEmJga9evXC7NmzUVJSghEjRgAAhg4dihYtWmDGjBlwc3ND165drbb38/MDAPP84uJiTJ06FY8++ihCQkJw5MgRTJw4EW3btkVCQsI1nh4RERE1BXYHlsTERJw9exbJycnIyclBVFQU1qxZYx6Im5WVBQeHunfcODo6Ys+ePVi4cCEKCgoQFhaGe++9F9OnT+dtHyIiIgIA6JRSqrELca30ej18fX1RWFgIHx+fxi4OERER1YE97Td/S4iIiIg0j4GFiIiINI+BhYiIiDSPgYWIiIg0j4GFiIiINI+BhYiIiDSPgYWIiIg0j4GFiIiINI+BhYiIiDSPgYWIiIg0j4GFiIiINI+BhYiIiDSPgYWIiIg0j4GFiIiINI+BhYiIiDSPgYWIiIg0j4GFiIiINI+BhYiIiDSPgYWIiIg0j4GFiIiINI+BhYiIiDSPgYWIiIg0j4GFiIiINI+BhYiIiDSPgYWIiIg0j4GFiIiINI+BhYiIiDSPgYWIiIg0j4GFiIiINI+BhYiIiDSPgYWIiIg0j4GFiIiINI+BhYiIiDSPgYWIiIg0j4GFiIiINI+BhYiIiDSPgYWIiIg0j4GFiIiINI+BhYiIiDSPgYWIiIg0j4GFiIiINO+qAsucOXPQqlUruLm5ITY2Ftu2bavTdosXL4ZOp8NDDz1kNV8pheTkZISGhsLd3R3x8fE4fPjw1RSNiIiImiC7A8uSJUuQlJSEyZMnY+fOnejRowcSEhKQl5dX63bHjx/Hyy+/jD59+lRb9s477+CDDz7A3LlzsXXrVnh6eiIhIQGlpaX2Fo+IiIiaILsDy6xZszB69GiMGDECnTt3xty5c+Hh4YEvvviixm0MBgOGDBmCqVOnIjIy0mqZUgqzZ8/GG2+8gUGDBqF79+5YtGgRzpw5g+XLl9t9QkRERNT02BVYysvLsWPHDsTHx1t24OCA+Ph4pKam1rjdtGnTEBQUhJEjR1ZbduzYMeTk5Fjt09fXF7GxsTXus6ysDHq93moiIiKipsuuwHLu3DkYDAYEBwdbzQ8ODkZOTo7NbTZt2oT//Oc/mDdvns3lpu3s2eeMGTPg6+trnsLDw+05DSIiIrrBNOinhIqKivDUU09h3rx5CAgIqLf9Tpo0CYWFhebp5MmT9bZvIiIi0h4ne1YOCAiAo6MjcnNzrebn5uYiJCSk2vpHjhzB8ePHMXDgQPM8o9EoB3ZyQkZGhnm73NxchIaGWu0zKirKZjlcXV3h6upqT9GJiIjoBmZXD4uLiwuio6ORkpJinmc0GpGSkoK4uLhq63fs2BF79+5FWlqaeXrwwQdx9913Iy0tDeHh4WjdujVCQkKs9qnX67F161ab+yQiIqKbj109LACQlJSEYcOGISYmBr169cLs2bNRUlKCESNGAACGDh2KFi1aYMaMGXBzc0PXrl2ttvfz8wMAq/kTJkzAW2+9hXbt2qF169Z48803ERYWVu37WoiIiOjmZHdgSUxMxNmzZ5GcnIycnBxERUVhzZo15kGzWVlZcHCwb2jMxIkTUVJSgmeeeQYFBQW44447sGbNGri5udlbPCIiImqCdEop1diFuFZ6vR6+vr4oLCyEj49PYxeHiIiI6sCe9pu/JURERESax8BCREREmsfAQkRERJrHwEJERESax8BCREREmsfAQkRERJrHwEJERESax8BCREREmsfAQkRERJrHwEJERESax8BCREREmsfAQkRERJrHwEJERESax8BCREREmsfAQkRERJrHwEJERESax8BCREREmsfAQkRERJrHwEJERESax8BCREREmsfAQkRERJrHwEJERESax8BCREREmsfAQkRERJrHwEJERESax8BCREREmsfAQkRERJrHwEJERESax8BCREREmsfAQkRERJrHwEJERESax8BCREREmsfAQkRERJrHwEJERESax8BCREREmsfAQkRERJrHwEJERESax8BCREREmsfAQkRERJrHwEJERESax8BCREREmsfAQkRERJp3VYFlzpw5aNWqFdzc3BAbG4tt27bVuO7SpUsRExMDPz8/eHp6IioqCl9++aXVOsOHD4dOp7Oa+vfvfzVFq399+gB/+Qvw0UfAb78BX30FPPcc0LYtMGIEMH488PrrwLp1wJYtwNmzQEUFsG8f8OOPwIEDwGefAdOnA1OmAB9+COzfD0ydCmzaJP9//XWgb19Ztyb79sk26emAUnUr++XLQHm5lGPlSuDSJSA/3/a6RiNgMNhdPfVOrwcyMhq7FEREpDE6pera+oklS5Zg6NChmDt3LmJjYzF79mx89913yMjIQFBQULX1169fjwsXLqBjx45wcXHBDz/8gJdeegmrVq1CQkICAAksubm5mD9/vnk7V1dX+Pv716lMer0evr6+KCwshI+Pjz2nU7vTp4GWLe3fztHx6hp/BwcgKgo4dQoIDAR8fCSc/PGHhCCTZs0APz/A1RVwcwO8vYHCQlnn4kVp9CMjJeRculT9OPffD/TrJ+GqoAA4dgzYsAHw9JRjXroE/PnPsk5aGrBnj5THVCfh4UC3bkDXrhIusrOBe+8FdDpg6VIps5sbcOgQEBoKeHjIei1aSDnLymTbDh3keJ6esu5XXwG7dlnKmZgIzJwpZfz2WznfhATg3Dlg0SKph8mTpWzZ2cCOHcDq1XLuzZoBDzwAHDki5c3Lk+39/SV4Xr4MPPqoHD8/HygpAW65BbhwAfjgAznnrl2BUaNk+wsXgJ075Vjdu1sCaWQkcNddsjwgAPD1lee+oAB49lmgVSvg1VflHLOygPbt5VhlZbJ+WRng7CzPfWEhsGaN1F+fPlJfAHDypJxzZKTs3yQ/X5Z17izBVyl5Xpydbb++jEbL66whFBfL83zbbfJauFZGY8OVlYg0wZ722+7AEhsbi549e+Kjjz4CABiNRoSHh+P555/Ha6+9Vqd93Hbbbbj//vsxffp0ABJYCgoKsHz5cnuKYtZggaWsDEhNlZ6QTZukQWzZUhq9y5clKHTsCBw+DBw8KL0ZWVmyrZeXhIrTp4FevYCwMHlDP3IEOHrU+jg6Xd17Ta6GgwPg4gKUljbcMRqTg4OlMbZX167y/JWVAREREmyqhjwvL3nuTEJCgJwc2/tzcZGyVA6Yjo6Ak5McIzRUwk1pqcw3GiUEBQZKcLx40XJOsbFSlrQ0mafTAcHBMvn5yWuzvNz6+E5OElq6dZP1c3Ik5OTny36aNweefhrYuBHYtk3CVseOEua6dJHX+cmTEt58fICYGGD3buD774F77pHyFxUBP/8sZe3bV17Tf/whodFgAO64AxgwQF7TrVtLuDt0SM67ZUsp/5YtQJs28v+WLQF3d+DOOyWUbd4MvP++9Fo+/7wcd+9eqT8vL9lvWRkQFydl3LJFlnfrJvXv5iZ1u2mThLknnpD6XLYMyMyUMjZvLsH+8mUJgz16yN9pZibQv7+UWSk5XrNm8jx5egIpKVLPkZHy9x8cLPtZs0YeOztLnZq20evlYsDDQ+a1by/nevCgBPbMTOlZ9fUFeveWntDu3aWOg4OB776T5/GFF+TcMjLkOKYwWxOlgOPH5XVlqjdX1+rrXbwIfPON1HFEhNRNUZG8vmpz7JiE5AEDpEx+fvIeZy+lpP4DAuQ8T5yQ+rFx8Vury5etg3p6urwG2re3v0xV90UNqsECS3l5OTw8PPD999/joYceMs8fNmwYCgoKsGLFilq3V0ph7dq1ePDBB7F8+XLcc889ACSwLF++HC4uLvD398ef//xnvPXWW2jevLnN/ZSVlaGsrMz8WK/XIzw8vP4Dy9XIyZHGKixM3iQrKqQRqay8XP4gdu6UNy1PT3kzX7VK/h8ZCZw5I41aQYG8UWVlAaNHy5tVerosX7FC3gjDw6Vh8POzXKlnZ0vD4eAgf/zl5cCcOfJGt307cP68NLwuLlKGjh2lUXv/fdlXQADw+++y3cMPS0gD5BhHj0oDkZoqb646nbwBu7vLm6yzs/x7xx1SH2fOSM/RsWPSAPv7y7F++00al9JSWc/HRxqYwEB54zp1St4MnZykB8fbG/jhB+mheOwxWbZ3r5TLyUkaWV9fCYl5eTK/WTNpNNzd5XFRkRyjtttvHToAQ4dKo7xhg2V+s2ZSb6bj9esnYefoUct5VOXiUj1U1KZFCzl/U0gBpH4DAy3nZIufnxzHFHio8Tg5STgoKam+zM1N/j6Kiuzfb+Wg7O0tf6PBwRIYg4Lk9XfunOVvOTPTsq2zMxAfL41xQYG8nk6dsvz9APK+U1wsr7M2bWTav1/ekzp2lL9xX1851vr11ufn6SlB+PRp+XvQ6+Xvo1kzeU26u0tIDgyU94LUVAl0Bw/KNv7+8j62d6/8zYwYAXTqJEEwM1P+/g8elJDdrRswcqS8jx09Kj3Fu3dLj2rbtnJhafq7TUiQ94WzZ6UsgITTigopv4ODvPc6OFj2n5cnx4iMlP2Fhcnz1rmzBKCTJ4G1a+X5MBqlrgMDJfht2SLljoqSMt15p9SLm5uU1d1dQv+KFVIfu3YBDz4o6xuNMvzg6FGpn6NH5T2uSxfgvvvkomD3bhlaEB5uqfvycnm/OHVK2pDERCnnqVMyRUVJEDUY5D129Wp5/YSGSrk8PeUc3d1ludEoPcy5ufI+3LKlBFNAXjt1vPNRVw0WWM6cOYMWLVpgy5YtiIuLM8+fOHEiNmzYgK1bt9rcrrCwEC1atEBZWRkcHR3x8ccf4+mnnzYvX7x4MTw8PNC6dWscOXIEf//73+Hl5YXU1FQ4OjpW29+UKVMwdepUm8dp9MBC9evcOQllHh7y+OJF+UNq3VquznJz5Q8sOFiuqEz27pUr9eHDpQFxcLAOkPv3A19/LYErKEj+KE+flj/idu0s+8rLkwAYGCih4OBBy5tAQICUoaBAlqWnS1C85RbpHejcWULbiRPSQIWFSUj195fbSSUlcsspK0veTBwdpdfA1RVYuFDenPr0kXmhoVKW06flnI8ckXN57DFphCIi5I33ww+lPNnZUkceHjK/TRt5k9q/X95sb71VehRSU6WB+OMPuSJPSACio6VH5Px5aZicnOQ2T2CgNGimQN6pk7yx3XIL0LOnnEPbtsA//iGNTIsWwP/9n5TtuefkvJKTpfyBgTJvwwapBy8vCbAGgxwvKkq2KyiQnpKyMjmXDh3kuSoslEDt6CjlT0iQxxUVlp6OLl3kvI4ckefSFKLLy+X5adlSerH8/YElS6TOTAIDLSE0P9/Sg9eypZTryBGpV9OFU2SkNNL5+dV7SyMj5TkqKpLzqczNTY5f+dhEtXF3l9dnQYG8puqzdz48XP4Gz5yxnt+li7xGTbe265HmAovRaMTRo0dRXFyMlJQUTJ8+HcuXL8ddd91lc/2jR4+iTZs2+PXXX9GvX79qyzXdw0JEFpcuSVAxjUU5dUp6rv76V2msK8vLk6vmXr0sY6YAy0Dxqj2uprcupWoe61JRIVeqAQESDExjay5flmBkelxYKL1uUVES1MLCLMtMofT334G777aUWym5dWTqFQXkzf7gQdn36dMS8B54QMqnlGXMV2ioXBU/+KAEsXPnLMFyxw650t2wAXj8cbkaT00FBg+W3oHCQqnXM2ckgPboISFQr5dbnMePyz779pVjhYVJsFy/XgJXs2ZyDE9PGWPVrBnwn/9IvXfsCGzdKre+TNu++KLUTdu2EsqXL5deg2HDpAzh4cCCBcB//ysh/cEHJRRu3izldHOTYBcZKc9xVpYEZm9vOe/HHwc+/1zmT5wodf3JJxIWTe3M7t0SjBMSpKwHD0qI7tlTyhkZKSHy/Hk5nouLhOaCApl3yy3SI+LhIa8HZ2dLb4KXl/SUnjwpAeDppy1jCXftstzCPXBAeom9vKTn5MIF6fEyNfJ/+pP0Rv/+u5xLQICE8LVr5XitWslr+dw5y/Pg5WW55bxrl9SXp6fsq1MneZ1s3Sr78feX49ti6sl1dJR6vXjRcqt1/355LXt5yfl17Sp1kZ1tuQCs2jPr7CwXbkFBcmxTYHd0lPqsx3ZWs7eETEaNGoWTJ0/ip59+qnGdwMBAvPXWW/jb3/52xf012BgWIiIiE9PtfHsHlStlGatYUWF7jMzFixJ02ratPozAxGCQ3s+iIglfAQESJkJCJFSZeqJNjEbgyy8l0PXuLSGrWTPr8l++LPu9dElC2alTMg4rOFiWp6dLmOrUSaaqFxrXyJ72u4Zasc3FxQXR0dFISUkxBxaj0YiUlBSMGzeuzvsxGo1WPSRVnTp1Cvn5+QgNDbWneERERA3HxeXqtjMFBJ2u5gG9Hh7Sw1UbR0cJDTVtX5WDg/SEmdgaF+rsLJObm4SaqkxBRQPsCiwAkJSUhGHDhiEmJga9evXC7NmzUVJSghEjRgAAhg4dihYtWmDGjBkAgBkzZiAmJgZt2rRBWVkZVq9ejS+//BKffPIJAKC4uBhTp07Fo48+ipCQEBw5cgQTJ05E27ZtzR97JiIiopub3YElMTERZ8+eRXJyMnJychAVFYU1a9Yg+P93H2VlZcGh0v3kkpISPPfcczh16hTc3d3RsWNHfPXVV0hMTAQAODo6Ys+ePVi4cCEKCgoQFhaGe++9F9OnT4errY/hERER0U3H7u9h0SKOYSEiIrrx2NN+82skiYiISPMYWIiIiEjzGFiIiIhI8xhYiIiISPMYWIiIiEjzGFiIiIhI8xhYiIiISPMYWIiIiEjzGFiIiIhI8xhYiIiISPPs/i0hLTL9uoBer2/kkhAREVFdmdrtuvxKUJMILEVFRQCA8PDwRi4JERER2auoqAi+vr61rtMkfvzQaDTizJkz8Pb2hk6nq9d96/V6hIeH4+TJk/xhxQbEer5+WNfXB+v5+mA9Xz8NUddKKRQVFSEsLAwODrWPUmkSPSwODg5o2bJlgx7Dx8eHfwzXAev5+mFdXx+s5+uD9Xz91HddX6lnxYSDbomIiEjzGFiIiIhI8xhYrsDV1RWTJ0+Gq6trYxelSWM9Xz+s6+uD9Xx9sJ6vn8au6yYx6JaIiIiaNvawEBERkeYxsBAREZHmMbAQERGR5jGwEBERkeYxsFzBnDlz0KpVK7i5uSE2Nhbbtm1r7CLdUH777TcMHDgQYWFh0Ol0WL58udVypRSSk5MRGhoKd3d3xMfH4/Dhw1brnD9/HkOGDIGPjw/8/PwwcuRIFBcXX8ez0L4ZM2agZ8+e8Pb2RlBQEB566CFkZGRYrVNaWoqxY8eiefPm8PLywqOPPorc3FyrdbKysnD//ffDw8MDQUFBeOWVV1BRUXE9T0XTPvnkE3Tv3t38xVlxcXH48ccfzctZxw3jn//8J3Q6HSZMmGCex7quH1OmTIFOp7OaOnbsaF6uqXpWVKPFixcrFxcX9cUXX6j9+/er0aNHKz8/P5Wbm9vYRbthrF69Wr3++utq6dKlCoBatmyZ1fJ//vOfytfXVy1fvlzt3r1bPfjgg6p169bq0qVL5nX69++vevTooX7//Xe1ceNG1bZtWzV48ODrfCbalpCQoObPn6/27dun0tLS1H333aduueUWVVxcbF7n2WefVeHh4SolJUX98ccf6k9/+pO6/fbbzcsrKipU165dVXx8vNq1a5davXq1CggIUJMmTWqMU9KklStXqlWrVqlDhw6pjIwM9fe//105Ozurffv2KaVYxw1h27ZtqlWrVqp79+5q/Pjx5vms6/oxefJk1aVLF5WdnW2ezp49a16upXpmYKlFr1691NixY82PDQaDCgsLUzNmzGjEUt24qgYWo9GoQkJC1MyZM83zCgoKlKurq/r222+VUkodOHBAAVDbt283r/Pjjz8qnU6nTp8+fd3KfqPJy8tTANSGDRuUUlKvzs7O6rvvvjOvk56ergCo1NRUpZSESwcHB5WTk2Ne55NPPlE+Pj6qrKzs+p7ADcTf3199/vnnrOMGUFRUpNq1a6d++eUX1bdvX3NgYV3Xn8mTJ6sePXrYXKa1euYtoRqUl5djx44diI+PN89zcHBAfHw8UlNTG7FkTcexY8eQk5NjVce+vr6IjY0113Fqair8/PwQExNjXic+Ph4ODg7YunXrdS/zjaKwsBAA0KxZMwDAjh07cPnyZau67tixI2655Raruu7WrRuCg4PN6yQkJECv12P//v3XsfQ3BoPBgMWLF6OkpARxcXGs4wYwduxY3H///VZ1CvD1XN8OHz6MsLAwREZGYsiQIcjKygKgvXpuEj9+2BDOnTsHg8Fg9SQAQHBwMA4ePNhIpWpacnJyAMBmHZuW5eTkICgoyGq5k5MTmjVrZl6HrBmNRkyYMAG9e/dG165dAUg9uri4wM/Pz2rdqnVt67kwLSOxd+9exMXFobS0FF5eXli2bBk6d+6MtLQ01nE9Wrx4MXbu3Int27dXW8bXc/2JjY3FggUL0KFDB2RnZ2Pq1Kno06cP9u3bp7l6ZmAhamLGjh2Lffv2YdOmTY1dlCapQ4cOSEtLQ2FhIb7//nsMGzYMGzZsaOxiNSknT57E+PHj8csvv8DNza2xi9OkDRgwwPz/7t27IzY2FhEREfjvf/8Ld3f3RixZdbwlVIOAgAA4OjpWGw2dm5uLkJCQRipV02Kqx9rqOCQkBHl5eVbLKyoqcP78eT4PNowbNw4//PAD1q1bh5YtW5rnh4SEoLy8HAUFBVbrV61rW8+FaRkJFxcXtG3bFtHR0ZgxYwZ69OiB999/n3Vcj3bs2IG8vDzcdtttcHJygpOTEzZs2IAPPvgATk5OCA4OZl03ED8/P7Rv3x6ZmZmae00zsNTAxcUF0dHRSElJMc8zGo1ISUlBXFxcI5as6WjdujVCQkKs6liv12Pr1q3mOo6Li0NBQQF27NhhXmft2rUwGo2IjY297mXWKqUUxo0bh2XLlmHt2rVo3bq11fLo6Gg4Oztb1XVGRgaysrKs6nrv3r1WAfGXX36Bj48POnfufH1O5AZkNBpRVlbGOq5H/fr1w969e5GWlmaeYmJiMGTIEPP/WdcNo7i4GEeOHEFoaKj2XtP1OoS3iVm8eLFydXVVCxYsUAcOHFDPPPOM8vPzsxoNTbUrKipSu3btUrt27VIA1KxZs9SuXbvUiRMnlFLysWY/Pz+1YsUKtWfPHjVo0CCbH2u+9dZb1datW9WmTZtUu3bt+LHmKsaMGaN8fX3V+vXrrT6eePHiRfM6zz77rLrlllvU2rVr1R9//KHi4uJUXFycebnp44n33nuvSktLU2vWrFGBgYH8GGglr732mtqwYYM6duyY2rNnj3rttdeUTqdTP//8s1KKddyQKn9KSCnWdX156aWX1Pr169WxY8fU5s2bVXx8vAoICFB5eXlKKW3VMwPLFXz44YfqlltuUS4uLqpXr17q999/b+wi3VDWrVunAFSbhg0bppSSjza/+eabKjg4WLm6uqp+/fqpjIwMq33k5+erwYMHKy8vL+Xj46NGjBihioqKGuFstMtWHQNQ8+fPN69z6dIl9dxzzyl/f3/l4eGhHn74YZWdnW21n+PHj6sBAwYod3d3FRAQoF566SV1+fLl63w22vX000+riIgI5eLiogIDA1W/fv3MYUUp1nFDqhpYWNf1IzExUYWGhioXFxfVokULlZiYqDIzM83LtVTPOqWUqt8+GyIiIqL6xTEsREREpHkMLERERKR5DCxERESkeQwsREREpHkMLERERKR5DCxERESkeQwsREREpHkMLERERKR5DCxERESkeQwsREREpHkMLERERKR5DCxERESkef8PU2XChSQv/CEAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_7.history[\"accuracy\"],'r', label=\"Accuracy\")\n",
        "ax.plot(run_hist_7.history[\"val_accuracy\"],'b', label=\"Validation Accuracy\")\n",
        "ax.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "urub9cklDFBR",
        "outputId": "d777b019-f710-4026-a769-fbb967afd9f2"
      },
      "id": "urub9cklDFBR",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x791674f4e860>"
            ]
          },
          "metadata": {},
          "execution_count": 87
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion and Google Colab Link"
      ],
      "metadata": {
        "id": "V_P2EfZWDXoh"
      },
      "id": "V_P2EfZWDXoh"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "1JQGRrdHDbv5"
      },
      "id": "1JQGRrdHDbv5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Google Colab"
      ],
      "metadata": {
        "id": "_mqmOwEhL3Gw"
      },
      "id": "_mqmOwEhL3Gw"
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://colab.research.google.com/drive/1SFq6drAAp1V8pLIw_szpF1l-EeoKx26D?usp=sharing"
      ],
      "metadata": {
        "id": "uD07n0j_L1VD"
      },
      "id": "uD07n0j_L1VD"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}